{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDF resume file:  Police - Experienced.pdf\n",
      "NER type: Trained NER\n",
      "Scenario C: Become a:  Data Analyst\n",
      "Show displacy skills from PDF:  True\n",
      "Recommender type:  cypher-skills\n",
      "Classification type: Python code\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">performed general patrol and operational police duties and was responsible for law enforcement duties to ensure the safety, welfare, and protection of students, staff, and property in the regions under the agency's authorized jurisdiction. • maintained order, responded to emergencies, and prevented crime to ensure public safety. • demonstrated successful engagement of the community -oriented policing philosophy. • enforced all applicable codes, ordinances, laws, and regulations. • assisted accident victims and others who needed first aid for injuries sustained. • interviewed victims, criminals, and eyewitnesses; wrote investigative reports; and examined evidence to determine whether violations had occurred. • gave evidence in court or acted as an eyewitness in traffic and prosecution cases.</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No skills found in the resume so general courses will be proposed.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                                                Recommended courses                                                </span>\n",
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Title                                      </span>┃<span style=\"font-weight: bold\"> URL                                                                </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\"> Machine Learning with Python               </span>│<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\"> https://www.vaia.be/en/courses/module-12-machine-learning-with-py… </span>│\n",
       "│<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\"> DEEPK 2024, on deep learning and kernel m… </span>│<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\"> https://www.vaia.be/en/courses/deepk-2024                          </span>│\n",
       "│<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\"> Leverage your R Skills: Data Wrangling &amp;a… </span>│<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\"> https://www.vaia.be/en/courses/leverage-your-r-skills-data-wrangl… </span>│\n",
       "│<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\"> Getting started with R software for data … </span>│<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\"> https://www.vaia.be/en/courses/getting-started-with-r-software-fo… </span>│\n",
       "│<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\"> Statistics and Econometrics Seminars       </span>│<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\"> https://www.vaia.be/en/courses/statistics-and-econometrics-semina… </span>│\n",
       "└────────────────────────────────────────────┴────────────────────────────────────────────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                                                Recommended courses                                                \u001b[0m\n",
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mTitle                                     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mURL                                                               \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[37m \u001b[0m\u001b[37mMachine Learning with Python              \u001b[0m\u001b[37m \u001b[0m│\u001b[37m \u001b[0m\u001b[37mhttps://www.vaia.be/en/courses/module-12-machine-learning-with-py…\u001b[0m\u001b[37m \u001b[0m│\n",
       "│\u001b[37m \u001b[0m\u001b[37mDEEPK 2024, on deep learning and kernel m…\u001b[0m\u001b[37m \u001b[0m│\u001b[37m \u001b[0m\u001b[37mhttps://www.vaia.be/en/courses/deepk-2024                         \u001b[0m\u001b[37m \u001b[0m│\n",
       "│\u001b[37m \u001b[0m\u001b[37mLeverage your R Skills: Data Wrangling &a…\u001b[0m\u001b[37m \u001b[0m│\u001b[37m \u001b[0m\u001b[37mhttps://www.vaia.be/en/courses/leverage-your-r-skills-data-wrangl…\u001b[0m\u001b[37m \u001b[0m│\n",
       "│\u001b[37m \u001b[0m\u001b[37mGetting started with R software for data …\u001b[0m\u001b[37m \u001b[0m│\u001b[37m \u001b[0m\u001b[37mhttps://www.vaia.be/en/courses/getting-started-with-r-software-fo…\u001b[0m\u001b[37m \u001b[0m│\n",
       "│\u001b[37m \u001b[0m\u001b[37mStatistics and Econometrics Seminars      \u001b[0m\u001b[37m \u001b[0m│\u001b[37m \u001b[0m\u001b[37mhttps://www.vaia.be/en/courses/statistics-and-econometrics-semina…\u001b[0m\u001b[37m \u001b[0m│\n",
       "└────────────────────────────────────────────┴────────────────────────────────────────────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "05/02/2024 06:51:21 PM Romance Daylight Time | INFO | app.ipynb finished running - no skills found in the resume\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from spacy.util import filter_spans\n",
    "import pickle\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from rich.table import Table\n",
    "from rich.console import Console\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=pd.errors.PerformanceWarning)\n",
    "warnings.filterwarnings('ignore') \n",
    "\n",
    "project_dir = os.getenv(\"PROJECT_PATH\")\n",
    "\n",
    "sys.path.insert(1, project_dir + '/')\n",
    "sys.path.insert(2, project_dir + '/utils/')\n",
    "sys.path.insert(3, project_dir + '/utils/neo4j/')\n",
    "sys.path.insert(4, project_dir + '/models/')\n",
    "\n",
    "from connection import Neo4jConnection\n",
    "import recommender_model\n",
    "import classification_model\n",
    "import pdf_util\n",
    "import kb_util\n",
    "import logger_util\n",
    "import monitor_util\n",
    "import query\n",
    "import graph\n",
    "\n",
    "from spacy import displacy\n",
    "\n",
    "import altair as alt\n",
    "\n",
    "\n",
    "###################################################################################################################################\n",
    "def read_resume(filename: str) -> str:\n",
    "    \n",
    "    file_content = pdf_util.read_PDF('%s/data/cv/%s' % (os.getenv(\"PROJECT_PATH\"),filename))   \n",
    "    \n",
    "    #Remove punctuation from the data\n",
    "    file_content = kb_util.fix(file_content)\n",
    "        \n",
    "    return file_content\n",
    "\n",
    "\n",
    "def extract_skills(data: str, conn: Neo4jConnection, nlp: any, loaded_matcher: any, NER_type: str, show_displacy:bool) -> list[str]:\n",
    "\n",
    "\n",
    "    #Evaluate A - Ruler version\n",
    "    if NER_type == 'A':       \n",
    "        doc = nlp(data)\n",
    "        if show_displacy: \n",
    "            displacy.render(doc, style=\"ent\", jupyter=True)\n",
    "        tags = list(ent.text.lower() for ent in doc.ents if ent.label_ == 'SKILL')\n",
    "           \n",
    "    #Evaluate   - Matcher version before NET Model is trained\n",
    "    if NER_type == 'B':\n",
    "        doc = nlp(data)\n",
    "        matches = loaded_matcher(doc, as_spans=True)\n",
    "        filtered_spans =spacy.util.filter_spans(matches)\n",
    "        doc.ents = filter_spans(filtered_spans)              \n",
    "        if show_displacy:\n",
    "            displacy.render(doc, style=\"ent\", jupyter=True)\n",
    "        tags = list(ent.text.lower() for ent in doc.ents if ent.label_ == 'SKILL')\n",
    "        \n",
    "    #Evaluate C - Trained annoted model   \n",
    "    if NER_type == 'C':\n",
    "        doc = nlp(data)\n",
    "        if show_displacy:\n",
    "            displacy.render(doc, style=\"ent\", jupyter=True)\n",
    "        tags = list(ent.text.lower() for ent in doc.ents if ent.label_ == 'SKILL')    \n",
    "        \n",
    "    #Evaluate D - GPT\n",
    "    #TODO Upgrade account\n",
    "    if NER_type == 'D':\n",
    "        \"\"\"\n",
    "        import openai \n",
    "\n",
    "        # assigning API KEY to initialize openai environment \n",
    "        openai.api_key = '' \n",
    "\n",
    "        MODEL = \"gpt-3.5-turbo\"\n",
    "        \n",
    "        completion = openai.chat.completions.create(\n",
    "            model=MODEL,   \n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "                {\"role\": \"user\", \"content\": \"Perform NER on the following sentence: 'In Brussels I worked with Bill Gates on Big Data, NLP, Functional, Business and Technical Analysis with a LLM for sourcing data flows into a Data Lake. Working within an Investments context. Working with IBM BI and Data Warehousing technologies.' and return it as JSON and indicate the start and end indexes of the entities. Also name the resulting array 'Entities'. Also add the original sentence as the first element in the response. Only include the entities that are  part of the machien learning domain\"}   \n",
    "            ]\n",
    "        )\n",
    "        print(completion.choices[0].message.content)        \n",
    "        \"\"\"\n",
    "        \n",
    "        response = {\n",
    "        \"Original_Sentence\": \"In Brussels I worked with Bill Gates on Big Data, NLP, Functional, Business and Technical Analysis with a LLM for sourcing data flows into a Data Lake. Working within an Investments context. Working with IBM BI and Data Warehousing technologies.\",\n",
    "        \"Entities\": [\n",
    "            {\n",
    "            \"Entity\": \"Big Data\",\n",
    "            \"Start_Index\": 35,\n",
    "            \"End_Index\": 43\n",
    "            },\n",
    "            {\n",
    "            \"Entity\": \"NLP\",\n",
    "            \"Start_Index\": 45,\n",
    "            \"End_Index\": 47\n",
    "            },\n",
    "            {\n",
    "            \"Entity\": \"Data Lake\",\n",
    "            \"Start_Index\": 99,\n",
    "            \"End_Index\": 107\n",
    "            }\n",
    "        ]\n",
    "        }\n",
    "        \n",
    "        tags = [x['Entity'].lower() for x in response['Entities']]\n",
    "        \n",
    "    no_duplicates_list = list(set(tags))  \n",
    "    \n",
    "    return no_duplicates_list\n",
    "\n",
    "\n",
    "def cast_item(item: any) -> str:\n",
    "    if isinstance(item, float):\n",
    "        item = round(item, 4)\n",
    "    return str(item)\n",
    "\n",
    "\n",
    "def print_courses(recommended_courses:pd.DataFrame) -> None:\n",
    "    \n",
    "    table = Table(title=\"Recommended courses\")\n",
    "    table.add_column(\"Title\", style=\"white\", no_wrap=True)    \n",
    "    table.add_column(\"URL\", style=\"white\", no_wrap=True)   \n",
    "    for index, row in recommended_courses.iterrows():\n",
    "        table.add_row(row['title'], row['url'])\n",
    "    console = Console()\n",
    "    console.print(table)\n",
    "    \n",
    "\n",
    "def print_profiles(profiles:pd.DataFrame, classification_type:str) -> None:      \n",
    "    \n",
    "    table = Table(title=\"Profile matching scores\")\n",
    "    table.add_column(\"Profile\", style=\"white\", no_wrap=True)    \n",
    "    \n",
    "    if classification_type != 'B':\n",
    "        table.add_column(\"Count\", style=\"white\")   \n",
    "        table.add_column(\"Max\", style=\"white\")  \n",
    "        table.add_column(\"Coverage\", style=\"white\")  \n",
    "        table.add_column(\"Total score\", style=\"white\")  \n",
    "        \n",
    "        for index, row in profiles.iterrows():\n",
    "            table.add_row(row['profile'], cast_item(row['count']), cast_item(row['max']), cast_item(row['coverage']), cast_item(row['total_score']))\n",
    "        \n",
    "        df = pd.melt(profiles, id_vars=['profile'], value_vars=['count', 'max', 'coverage', 'total_score'], var_name='Genre', value_name='Score')\n",
    "    \n",
    "        chart = alt.Chart(df).mark_bar().encode(\n",
    "            column=alt.Column('Genre'),\n",
    "            x=alt.X('profile'),\n",
    "            y=alt.Y('Score'),\n",
    "            color=alt.Color('profile', scale=alt.Scale(range=['#EA98D2', '#659CCA', '#F6C85F']))\n",
    "                ).configure_view(\n",
    "                    strokeWidth=0.0,\n",
    "                )\n",
    "\n",
    "        chart.show()\n",
    "\n",
    "    else:\n",
    "        table.add_column(\"skills\", style=\"white\")  \n",
    "        for index, row in profiles.iterrows():\n",
    "            table.add_row(row['profile'],row['skills'])\n",
    "\n",
    "    console = Console()\n",
    "    console.print(table)\n",
    "   \n",
    "\n",
    "def print_app_config(PDF_resume: str,NER_type: str,scenario: str,to_be_profile: str,show_displacy: bool,recommender_type: str,classification_type: str) -> None:\n",
    "    \n",
    "    print(f'PDF resume file: ', PDF_resume) \n",
    "        \n",
    "    if NER_type == 'A':\n",
    "        print('NER type: Ruler')\n",
    "    if NER_type == 'B':\n",
    "        print('NER type: Matcher')\n",
    "    if NER_type == 'C':\n",
    "        print('NER type: Trained NER')  \n",
    "    if NER_type == 'D': \n",
    "        print('NER type: Open AI')\n",
    "    \n",
    "    if scenario == 'A':\n",
    "        print('Scenario A: Improve existing profile with current skills')\n",
    "    if scenario == 'B':\n",
    "        print('Scenario B: Improve existing profile with missing skills')\n",
    "    if scenario == 'C':\n",
    "        print(f'Scenario C: Become a: ', to_be_profile)\n",
    "        \n",
    "    print(f'Show displacy skills from PDF: ', show_displacy)\n",
    "   \n",
    "    print(f'Recommender type: ', recommender_type)    \n",
    "   \n",
    "    if classification_type == 'A1':\n",
    "        print(f'Classification type: Python code')\n",
    "    if classification_type == 'A2':\n",
    "        print(f'Classification type: Cypher query')\n",
    "    if classification_type == 'B':\n",
    "        print(f'Classification type: Text classification')\n",
    "   \n",
    "    print(\"====================================================================================================\")\n",
    "    print()\n",
    "\n",
    "\n",
    "def missing_skills(conn: Neo4jConnection, profiles: any, my_skills: list) -> tuple[str, pd.DataFrame]:\n",
    "        \n",
    "    if type(profiles) is not pd.DataFrame:\n",
    "        chosen_profile = profiles[0]\n",
    "    else:\n",
    "        chosen_profile = profiles.iloc[0]['profile']    \n",
    "\n",
    "    to_learn = query.get_remaining_skills_by_profile(conn, chosen_profile, my_skills)\n",
    "         \n",
    "    return chosen_profile, to_learn\n",
    "\n",
    "\n",
    "def config_app(NER_type: str) -> tuple[logger_util.Logger_util, monitor_util.Monitor, Neo4jConnection, any, any]:\n",
    "    # Load the stored environment variables ########################################################################\n",
    "    load_dotenv()\n",
    "\n",
    "    app_logger, monitor, conn, nlp, loaded_matcher = None, None, None, None, None\n",
    "\n",
    "    # Setup #########################################################################################################\n",
    "\n",
    "    app_logger = logger_util.Logger_util(os.getenv(\"LOG_FILE\"))\n",
    "    monitor = monitor_util.Monitor(os.getenv(\"MONITOR_FILE\"))\n",
    "\n",
    "    conn = Neo4jConnection(uri=os.getenv(\"DB_URI\"), \n",
    "                        user=os.getenv(\"DB_USERNAME\"),              \n",
    "                        pwd=os.getenv(\"DB_PASSWORD\"))\n",
    "    \n",
    "    # Load the NER model    \n",
    "    if NER_type == 'A':\n",
    "        NER_model = 'ruler_model'\n",
    "        nlp = spacy.load(\"%s/models/NER/%s\" % (os.getenv(\"PROJECT_PATH\"),NER_model))\n",
    "    \n",
    "    if NER_type == 'B':\n",
    "        nlp = spacy.load(\"en_core_web_sm\")\n",
    "        nlp.vocab.strings.add('SKILL')\n",
    "        filename = \"%s/models/NER/finalized_matcher.pickle\" % (os.getenv(\"PROJECT_PATH\"))\n",
    "        loaded_matcher = pickle.load(open(filename, 'rb'))    \n",
    "    \n",
    "    if NER_type == 'C':\n",
    "        NER_model = 'model-best-C_PT_E_HP_P'\n",
    "        nlp = spacy.load(\"%s/models/NER/%s\" % (os.getenv(\"PROJECT_PATH\"),NER_model))\n",
    "    \n",
    "      \n",
    "    \n",
    "    return app_logger, monitor, conn, nlp, loaded_matcher\n",
    "\n",
    "\n",
    "def main(PDF_resume:str, \n",
    "         NER_type:str = 'C', \n",
    "         scenario:str = 'C', \n",
    "         to_be_profile:str = 'Data Analyst', \n",
    "         show_displacy:bool = 'True', \n",
    "         recommender_type:str = 'cypher-skills', \n",
    "         classification_type:str = 'A1') -> None:  \n",
    "    \"\"\"Read a PDF resume and extract skills. Then, based on the scenario, recommend courses to improve the skills.\n",
    "\n",
    "    Args:\n",
    "      PDF_resume: The PDF resume file from data/cv directory.\n",
    "      NER_type: The NER type to use: A = Ruler / B = Matcher / C = Trained NER / D = Open AI\n",
    "      scenario: The application scenario: A = Improve existing profile with current skills / B = Improve existing profile with missing skills / C = Become a specific profile\n",
    "      to_be_profile: The profile to become for scenario C: Data Analyst / Data Scientist / Data Engineer\n",
    "      show_displacy: Show displacy skills from PDF.\n",
    "      recommender_type: The recommender type to use: tfidf-data / tfidf-skills / cypher-skills\n",
    "      classification_type: The classification type to use: A1 = Python code / A2 = Cypher query / B =  text classification\n",
    "\n",
    "    Returns:\n",
    "      None\n",
    "\n",
    "    Raises:\n",
    "      Exception: If any error occurs.\n",
    "    \"\"\"\n",
    "    #try:\n",
    "\n",
    "    #Configure application\n",
    "    app_logger, monitor, conn, nlp, loaded_matcher  = config_app(NER_type)\n",
    "    print_app_config(PDF_resume,NER_type,scenario,to_be_profile,show_displacy,recommender_type,classification_type)\n",
    "\n",
    "    # Read resume and extract skills\n",
    "    data = read_resume(PDF_resume)\n",
    "\n",
    "    # Extract skills\n",
    "    skills = extract_skills(data, conn, nlp, loaded_matcher, NER_type, show_displacy)\n",
    "\n",
    "    if len(skills) == 0:\n",
    "        print('No skills found in the resume so general courses will be proposed.')\n",
    "\n",
    "        skills = []        \n",
    "        log_profiles= {\"profile\": {\"0\": None}}\n",
    "        recommended_courses = query.get_courses_with_many_skills(conn, 5)\n",
    "        \n",
    "        print_courses(recommended_courses)\n",
    "\n",
    "        monitor.write_to_log(scenario,data,NER_type,skills,log_profiles,recommended_courses.to_dict(),classification_type,recommender_type,to_be_profile)\n",
    "        app_logger.logger.info('app.ipynb finished running - no skills found in the resume')\n",
    "\n",
    "    else:\n",
    "        print(f'Skills found in the PDF resume: ', skills)    \n",
    "        \n",
    "        \n",
    "        if scenario == 'A' or scenario == 'B':\n",
    "            # Define profile\n",
    "            if classification_type == 'A1':\n",
    "                profiles = classification_model.profiles_A1(conn, skills)\n",
    "            if classification_type == 'A2':           \n",
    "                profiles = classification_model.profiles_A2(conn, skills)     \n",
    "            if classification_type == 'B':\n",
    "                profiles = recommender_model.profiles_B(conn, skills)          \n",
    "                \n",
    "        else:\n",
    "            #Scenario C = specific profile\n",
    "            profiles = [to_be_profile]\n",
    "\n",
    "        if profiles is None:\n",
    "            print('No profile found')\n",
    "        else:        \n",
    "            if scenario == 'A' or scenario == 'B':\n",
    "                print_profiles(profiles,classification_type) \n",
    "            \n",
    "            # Search for missing skills for the profile\n",
    "            if scenario == 'B' or scenario == 'C':\n",
    "                chosen_profile, df_skills_to_learn = missing_skills(conn, profiles, skills)\n",
    "                graph.show_skill_score_graph(df_skills_to_learn)\n",
    "                skill_to_learn = ' '.join([x for x in df_skills_to_learn['skill']])\n",
    "            else:\n",
    "                chosen_profile = profiles.iloc[0]['profile']\n",
    "                skill_to_learn = ' '.join([x for x in skills])   \n",
    "            \n",
    "            print()\n",
    "            print(f'Chosen profile: ', chosen_profile)\n",
    "            \n",
    "            print(f'Skills to learn based on scenario: ', skill_to_learn)\n",
    "            print()\n",
    "            \n",
    "            if recommender_type == 'tfidf-data':\n",
    "                # Get all courses from the database to use the full data\n",
    "                courses = query.get_all_courses(conn)\n",
    "                field = 'data'\n",
    "            if recommender_type == 'tfidf-skills':\n",
    "                # Get all courses from the database with a list of skills\n",
    "                courses = query.get_all_courses_with_skills(conn)\n",
    "                field = 'skills'\n",
    "\n",
    "            if recommender_type == 'tfidf-data' or recommender_type == 'tfidf-skills':          \n",
    "                # Get recommended courses           \n",
    "                recommended_courses = recommender_model.courses_tfidf(courses, field, skill_to_learn, 5)\n",
    "            else:\n",
    "                if scenario == 'A':\n",
    "                    recommended_courses = recommender_model.courses_cypher(conn, skills, 5)\n",
    "                else:\n",
    "                    recommended_courses = recommender_model.courses_cypher(conn, df_skills_to_learn['skill'], 5)\n",
    "                                \n",
    "            print_courses(recommended_courses)\n",
    "                    \n",
    "            if scenario == 'C':\n",
    "                log_profiles= {\"profile\": {\"0\": chosen_profile}}\n",
    "            else:\n",
    "                log_profiles = profiles.to_dict()\n",
    "                        \n",
    "            monitor.write_to_log(scenario,data,NER_type,skills,log_profiles,recommended_courses.to_dict(),classification_type,recommender_type,to_be_profile)\n",
    "            app_logger.logger.info('app.ipynb finished running')\n",
    "\n",
    "    #except Exception as e:\n",
    "    #   app_logger.logger.info(getattr(e, 'message', repr(e)))\n",
    "\n",
    "main(PDF_resume = 'Police - Experienced.pdf')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
