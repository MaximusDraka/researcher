{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to create the driver: Cannot resolve address e8ffa4e9.databases.neo4j.io:7687\n",
      "PDF resume file:  Police - Experienced.pdf\n",
      "NER type: Trained NER\n",
      "Scenario C: Become a:  Data Analyst\n",
      "Show displacy skills from PDF:  True\n",
      "Recommender type:  cypher-skills\n",
      "Classification type: Python code\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">performed general patrol and operational police duties and was responsible for law enforcement duties to ensure the safety, welfare, and protection of students, staff, and property in the regions under the agency's authorized jurisdiction. • maintained order, responded to emergencies, and prevented crime to ensure public safety. • demonstrated successful engagement of the community -oriented policing philosophy. • enforced all applicable codes, ordinances, laws, and regulations. • assisted accident victims and others who needed first aid for injuries sustained. • interviewed victims, criminals, and eyewitnesses; wrote investigative reports; and examined evidence to determine whether violations had occurred. • gave evidence in court or acted as an eyewitness in traffic and prosecution cases.</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No skills found in the resume so general courses will be proposed.\n",
      "Query failed: Cannot resolve address e8ffa4e9.databases.neo4j.io:7687\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 380\u001b[0m\n\u001b[0;32m    375\u001b[0m             app_logger\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mapp.ipynb finished running\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    377\u001b[0m     \u001b[38;5;66;03m#except Exception as e:\u001b[39;00m\n\u001b[0;32m    378\u001b[0m     \u001b[38;5;66;03m#   app_logger.logger.info(getattr(e, 'message', repr(e)))\u001b[39;00m\n\u001b[1;32m--> 380\u001b[0m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mPDF_resume\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mPolice - Experienced.pdf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[1], line 304\u001b[0m, in \u001b[0;36mmain\u001b[1;34m(PDF_resume, NER_type, scenario, to_be_profile, show_displacy, recommender_type, classification_type)\u001b[0m\n\u001b[0;32m    302\u001b[0m skills \u001b[38;5;241m=\u001b[39m []        \n\u001b[0;32m    303\u001b[0m log_profiles\u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprofile\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mNone\u001b[39;00m}}\n\u001b[1;32m--> 304\u001b[0m recommended_courses \u001b[38;5;241m=\u001b[39m \u001b[43mquery\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_courses_with_many_skills\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    306\u001b[0m print_courses(recommended_courses)\n\u001b[0;32m    308\u001b[0m monitor\u001b[38;5;241m.\u001b[39mwrite_to_log(scenario,data,NER_type,skills,log_profiles,recommended_courses\u001b[38;5;241m.\u001b[39mto_dict(),classification_type,recommender_type,to_be_profile)\n",
      "File \u001b[1;32mC:\\Users/tom/projects/skill-skeleton/utils/neo4j\\query.py:216\u001b[0m, in \u001b[0;36mget_courses_with_many_skills\u001b[1;34m(conn, num_recommendations)\u001b[0m\n\u001b[0;32m    206\u001b[0m parameters \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum_recommendations\u001b[39m\u001b[38;5;124m'\u001b[39m: num_recommendations}\n\u001b[0;32m    208\u001b[0m query_string \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'''\u001b[39m\n\u001b[0;32m    209\u001b[0m \u001b[38;5;124mMATCH (c:Course)-[o:OFFERS]->(s:Skill)\u001b[39m\n\u001b[0;32m    210\u001b[0m \u001b[38;5;124mWITH c, count(*) as skills\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;124mLIMIT $num_recommendations\u001b[39m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;124m\u001b[39m\u001b[38;5;124m'''\u001b[39m\n\u001b[1;32m--> 216\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pd\u001b[38;5;241m.\u001b[39mDataFrame(\u001b[43m[\u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m_\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquery\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery_string\u001b[49m\u001b[43m,\u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m)\n",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not iterable"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from spacy.util import filter_spans\n",
    "import pickle\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from rich.table import Table\n",
    "from rich.console import Console\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=pd.errors.PerformanceWarning)\n",
    "warnings.filterwarnings('ignore') \n",
    "\n",
    "project_dir = os.getenv(\"PROJECT_PATH\")\n",
    "\n",
    "sys.path.insert(1, project_dir + '/')\n",
    "sys.path.insert(2, project_dir + '/utils/')\n",
    "sys.path.insert(3, project_dir + '/utils/neo4j/')\n",
    "sys.path.insert(4, project_dir + '/models/')\n",
    "\n",
    "from connection import Neo4jConnection\n",
    "import recommender_model\n",
    "import classification_model\n",
    "import pdf_util\n",
    "import kb_util\n",
    "import logger_util\n",
    "import monitor_util\n",
    "import query\n",
    "import graph\n",
    "\n",
    "from spacy import displacy\n",
    "\n",
    "import altair as alt\n",
    "\n",
    "\n",
    "###################################################################################################################################\n",
    "def read_resume(filename: str) -> str:\n",
    "    \n",
    "    file_content = pdf_util.read_PDF('%s/data/cv/%s' % (os.getenv(\"PROJECT_PATH\"),filename))   \n",
    "    \n",
    "    #Remove punctuation from the data\n",
    "    file_content = kb_util.fix(file_content)\n",
    "        \n",
    "    return file_content\n",
    "\n",
    "\n",
    "def extract_skills(data: str, conn: Neo4jConnection, nlp: any, loaded_matcher: any, NER_type: str, show_displacy:bool) -> list[str]:\n",
    "\n",
    "\n",
    "    #Evaluate A - Ruler version\n",
    "    if NER_type == 'A':       \n",
    "        doc = nlp(data)\n",
    "        if show_displacy: \n",
    "            displacy.render(doc, style=\"ent\", jupyter=True)\n",
    "        tags = list(ent.text.lower() for ent in doc.ents if ent.label_ == 'SKILL')\n",
    "           \n",
    "    #Evaluate   - Matcher version before NET Model is trained\n",
    "    if NER_type == 'B':\n",
    "        doc = nlp(data)\n",
    "        matches = loaded_matcher(doc, as_spans=True)\n",
    "        filtered_spans =spacy.util.filter_spans(matches)\n",
    "        doc.ents = filter_spans(filtered_spans)              \n",
    "        if show_displacy:\n",
    "            displacy.render(doc, style=\"ent\", jupyter=True)\n",
    "        tags = list(ent.text.lower() for ent in doc.ents if ent.label_ == 'SKILL')\n",
    "        \n",
    "    #Evaluate C - Trained annoted model   \n",
    "    if NER_type == 'C':\n",
    "        doc = nlp(data)\n",
    "        if show_displacy:\n",
    "            displacy.render(doc, style=\"ent\", jupyter=True)\n",
    "        tags = list(ent.text.lower() for ent in doc.ents if ent.label_ == 'SKILL')    \n",
    "        \n",
    "    #Evaluate D - GPT\n",
    "    #TODO Upgrade account\n",
    "    if NER_type == 'D':\n",
    "        \"\"\"\n",
    "        import openai \n",
    "\n",
    "        # assigning API KEY to initialize openai environment \n",
    "        openai.api_key = '' \n",
    "\n",
    "        MODEL = \"gpt-3.5-turbo\"\n",
    "        \n",
    "        completion = openai.chat.completions.create(\n",
    "            model=MODEL,   \n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "                {\"role\": \"user\", \"content\": \"Perform NER on the following sentence: 'In Brussels I worked with Bill Gates on Big Data, NLP, Functional, Business and Technical Analysis with a LLM for sourcing data flows into a Data Lake. Working within an Investments context. Working with IBM BI and Data Warehousing technologies.' and return it as JSON and indicate the start and end indexes of the entities. Also name the resulting array 'Entities'. Also add the original sentence as the first element in the response. Only include the entities that are  part of the machien learning domain\"}   \n",
    "            ]\n",
    "        )\n",
    "        print(completion.choices[0].message.content)        \n",
    "        \"\"\"\n",
    "        \n",
    "        response = {\n",
    "        \"Original_Sentence\": \"In Brussels I worked with Bill Gates on Big Data, NLP, Functional, Business and Technical Analysis with a LLM for sourcing data flows into a Data Lake. Working within an Investments context. Working with IBM BI and Data Warehousing technologies.\",\n",
    "        \"Entities\": [\n",
    "            {\n",
    "            \"Entity\": \"Big Data\",\n",
    "            \"Start_Index\": 35,\n",
    "            \"End_Index\": 43\n",
    "            },\n",
    "            {\n",
    "            \"Entity\": \"NLP\",\n",
    "            \"Start_Index\": 45,\n",
    "            \"End_Index\": 47\n",
    "            },\n",
    "            {\n",
    "            \"Entity\": \"Data Lake\",\n",
    "            \"Start_Index\": 99,\n",
    "            \"End_Index\": 107\n",
    "            }\n",
    "        ]\n",
    "        }\n",
    "        \n",
    "        tags = [x['Entity'].lower() for x in response['Entities']]\n",
    "        \n",
    "    no_duplicates_list = list(set(tags))  \n",
    "    \n",
    "    return no_duplicates_list\n",
    "\n",
    "\n",
    "def cast_item(item: any) -> str:\n",
    "    if isinstance(item, float):\n",
    "        item = round(item, 4)\n",
    "    return str(item)\n",
    "\n",
    "\n",
    "def print_courses(recommended_courses:pd.DataFrame) -> None:\n",
    "    \n",
    "    table = Table(title=\"Recommended courses\")\n",
    "    table.add_column(\"Title\", style=\"white\", no_wrap=True)    \n",
    "    table.add_column(\"URL\", style=\"white\", no_wrap=True)   \n",
    "    for index, row in recommended_courses.iterrows():\n",
    "        table.add_row(row['title'], row['url'])\n",
    "    console = Console()\n",
    "    console.print(table)\n",
    "    \n",
    "\n",
    "def print_profiles(profiles:pd.DataFrame, classification_type:str) -> None:      \n",
    "    \n",
    "    table = Table(title=\"Profile matching scores\")\n",
    "    table.add_column(\"Profile\", style=\"white\", no_wrap=True)    \n",
    "    \n",
    "    if classification_type != 'B':\n",
    "        table.add_column(\"Count\", style=\"white\")   \n",
    "        table.add_column(\"Max\", style=\"white\")  \n",
    "        table.add_column(\"Coverage\", style=\"white\")  \n",
    "        table.add_column(\"Total score\", style=\"white\")  \n",
    "        \n",
    "        for index, row in profiles.iterrows():\n",
    "            table.add_row(row['profile'], cast_item(row['count']), cast_item(row['max']), cast_item(row['coverage']), cast_item(row['total_score']))\n",
    "        \n",
    "        df = pd.melt(profiles, id_vars=['profile'], value_vars=['count', 'max', 'coverage', 'total_score'], var_name='Genre', value_name='Score')\n",
    "    \n",
    "        chart = alt.Chart(df).mark_bar().encode(\n",
    "            column=alt.Column('Genre'),\n",
    "            x=alt.X('profile'),\n",
    "            y=alt.Y('Score'),\n",
    "            color=alt.Color('profile', scale=alt.Scale(range=['#EA98D2', '#659CCA', '#F6C85F']))\n",
    "                ).configure_view(\n",
    "                    strokeWidth=0.0,\n",
    "                )\n",
    "\n",
    "        chart.show()\n",
    "\n",
    "    else:\n",
    "        table.add_column(\"skills\", style=\"white\")  \n",
    "        for index, row in profiles.iterrows():\n",
    "            table.add_row(row['profile'],row['skills'])\n",
    "\n",
    "    console = Console()\n",
    "    console.print(table)\n",
    "   \n",
    "\n",
    "def print_app_config(PDF_resume: str,NER_type: str,scenario: str,to_be_profile: str,show_displacy: bool,recommender_type: str,classification_type: str) -> None:\n",
    "    \n",
    "    print(f'PDF resume file: ', PDF_resume) \n",
    "        \n",
    "    if NER_type == 'A':\n",
    "        print('NER type: Ruler')\n",
    "    if NER_type == 'B':\n",
    "        print('NER type: Matcher')\n",
    "    if NER_type == 'C':\n",
    "        print('NER type: Trained NER')  \n",
    "    if NER_type == 'D': \n",
    "        print('NER type: Open AI')\n",
    "    \n",
    "    if scenario == 'A':\n",
    "        print('Scenario A: Improve existing profile with current skills')\n",
    "    if scenario == 'B':\n",
    "        print('Scenario B: Improve existing profile with missing skills')\n",
    "    if scenario == 'C':\n",
    "        print(f'Scenario C: Become a: ', to_be_profile)\n",
    "        \n",
    "    print(f'Show displacy skills from PDF: ', show_displacy)\n",
    "   \n",
    "    print(f'Recommender type: ', recommender_type)    \n",
    "   \n",
    "    if classification_type == 'A1':\n",
    "        print(f'Classification type: Python code')\n",
    "    if classification_type == 'A2':\n",
    "        print(f'Classification type: Cypher query')\n",
    "    if classification_type == 'B':\n",
    "        print(f'Classification type: Text classification')\n",
    "   \n",
    "    print(\"====================================================================================================\")\n",
    "    print()\n",
    "\n",
    "\n",
    "def missing_skills(conn: Neo4jConnection, profiles: any, my_skills: list) -> tuple[str, pd.DataFrame]:\n",
    "        \n",
    "    if type(profiles) is not pd.DataFrame:\n",
    "        chosen_profile = profiles[0]\n",
    "    else:\n",
    "        chosen_profile = profiles.iloc[0]['profile']    \n",
    "\n",
    "    to_learn = query.get_remaining_skills_by_profile(conn, chosen_profile, my_skills)\n",
    "         \n",
    "    return chosen_profile, to_learn\n",
    "\n",
    "\n",
    "def config_app(NER_type: str) -> tuple[logger_util.Logger_util, monitor_util.Monitor, Neo4jConnection, any, any]:\n",
    "    # Load the stored environment variables ########################################################################\n",
    "    load_dotenv()\n",
    "\n",
    "    app_logger, monitor, conn, nlp, loaded_matcher = None, None, None, None, None\n",
    "\n",
    "    # Setup #########################################################################################################\n",
    "\n",
    "    app_logger = logger_util.Logger_util(os.getenv(\"LOG_FILE\"))\n",
    "    monitor = monitor_util.Monitor(os.getenv(\"MONITOR_FILE\"))\n",
    "\n",
    "    conn = Neo4jConnection(uri=os.getenv(\"DB_URI\"), \n",
    "                        user=os.getenv(\"DB_USERNAME\"),              \n",
    "                        pwd=os.getenv(\"DB_PASSWORD\"))\n",
    "    \n",
    "    # Load the NER model    \n",
    "    if NER_type == 'A':\n",
    "        NER_model = 'ruler_model'\n",
    "        nlp = spacy.load(\"%s/models/NER/%s\" % (os.getenv(\"PROJECT_PATH\"),NER_model))\n",
    "    \n",
    "    if NER_type == 'B':\n",
    "        nlp = spacy.load(\"en_core_web_sm\")\n",
    "        nlp.vocab.strings.add('SKILL')\n",
    "        filename = \"%s/models/NER/finalized_matcher.pickle\" % (os.getenv(\"PROJECT_PATH\"))\n",
    "        loaded_matcher = pickle.load(open(filename, 'rb'))    \n",
    "    \n",
    "    if NER_type == 'C':\n",
    "        NER_model = 'model-best-C_PT_E_HP_P'\n",
    "        nlp = spacy.load(\"%s/models/NER/%s\" % (os.getenv(\"PROJECT_PATH\"),NER_model))\n",
    "    \n",
    "      \n",
    "    \n",
    "    return app_logger, monitor, conn, nlp, loaded_matcher\n",
    "\n",
    "\n",
    "def main(PDF_resume:str, \n",
    "         NER_type:str = 'C', \n",
    "         scenario:str = 'C', \n",
    "         to_be_profile:str = 'Data Analyst', \n",
    "         show_displacy:bool = 'True', \n",
    "         recommender_type:str = 'cypher-skills', \n",
    "         classification_type:str = 'A1') -> None:  \n",
    "    \"\"\"Read a PDF resume and extract skills. Then, based on the scenario, recommend courses to improve the skills.\n",
    "\n",
    "    Args:\n",
    "      PDF_resume: The PDF resume file from data/cv directory.\n",
    "      NER_type: The NER type to use: A = Ruler / B = Matcher / C = Trained NER / D = Open AI\n",
    "      scenario: The application scenario: A = Improve existing profile with current skills / B = Improve existing profile with missing skills / C = Become a specific profile\n",
    "      to_be_profile: The profile to become for scenario C: Data Analyst / Data Scientist / Data Engineer\n",
    "      show_displacy: Show displacy skills from PDF.\n",
    "      recommender_type: The recommender type to use: tfidf-data / tfidf-skills / cypher-skills\n",
    "      classification_type: The classification type to use: A1 = Python code / A2 = Cypher query / B =  text classification\n",
    "\n",
    "    Returns:\n",
    "      None\n",
    "\n",
    "    Raises:\n",
    "      Exception: If any error occurs.\n",
    "    \"\"\"\n",
    "    #try:\n",
    "\n",
    "    #Configure application\n",
    "    app_logger, monitor, conn, nlp, loaded_matcher  = config_app(NER_type)\n",
    "    print_app_config(PDF_resume,NER_type,scenario,to_be_profile,show_displacy,recommender_type,classification_type)\n",
    "\n",
    "    # Read resume and extract skills\n",
    "    data = read_resume(PDF_resume)\n",
    "\n",
    "    # Extract skills\n",
    "    skills = extract_skills(data, conn, nlp, loaded_matcher, NER_type, show_displacy)\n",
    "\n",
    "    if len(skills) == 0:\n",
    "        print('No skills found in the resume so general courses will be proposed.')\n",
    "\n",
    "        skills = []        \n",
    "        log_profiles= {\"profile\": {\"0\": None}}\n",
    "        recommended_courses = query.get_courses_with_many_skills(conn, 5)\n",
    "        \n",
    "        print_courses(recommended_courses)\n",
    "\n",
    "        monitor.write_to_log(scenario,data,NER_type,skills,log_profiles,recommended_courses.to_dict(),classification_type,recommender_type,to_be_profile)\n",
    "        app_logger.logger.info('app.ipynb finished running - no skills found in the resume')\n",
    "\n",
    "    else:\n",
    "        print(f'Skills found in the PDF resume: ', skills)    \n",
    "        \n",
    "        \n",
    "        if scenario == 'A' or scenario == 'B':\n",
    "            # Define profile\n",
    "            if classification_type == 'A1':\n",
    "                profiles = classification_model.profiles_A1(conn, skills)\n",
    "            if classification_type == 'A2':           \n",
    "                profiles = classification_model.profiles_A2(conn, skills)     \n",
    "            if classification_type == 'B':\n",
    "                profiles = recommender_model.profiles_B(conn, skills)          \n",
    "                \n",
    "        else:\n",
    "            #Scenario C = specific profile\n",
    "            profiles = [to_be_profile]\n",
    "\n",
    "        if profiles is None:\n",
    "            print('No profile found')\n",
    "        else:        \n",
    "            if scenario == 'A' or scenario == 'B':\n",
    "                print_profiles(profiles,classification_type) \n",
    "            \n",
    "            # Search for missing skills for the profile\n",
    "            if scenario == 'B' or scenario == 'C':\n",
    "                chosen_profile, df_skills_to_learn = missing_skills(conn, profiles, skills)\n",
    "                graph.show_skill_score_graph(df_skills_to_learn)\n",
    "                skill_to_learn = ' '.join([x for x in df_skills_to_learn['skill']])\n",
    "            else:\n",
    "                chosen_profile = profiles.iloc[0]['profile']\n",
    "                skill_to_learn = ' '.join([x for x in skills])   \n",
    "            \n",
    "            print()\n",
    "            print(f'Chosen profile: ', chosen_profile)\n",
    "            \n",
    "            print(f'Skills to learn based on scenario: ', skill_to_learn)\n",
    "            print()\n",
    "            \n",
    "            if recommender_type == 'tfidf-data':\n",
    "                # Get all courses from the database to use the full data\n",
    "                courses = query.get_all_courses(conn)\n",
    "                field = 'data'\n",
    "            if recommender_type == 'tfidf-skills':\n",
    "                # Get all courses from the database with a list of skills\n",
    "                courses = query.get_all_courses_with_skills(conn)\n",
    "                field = 'skills'\n",
    "\n",
    "            if recommender_type == 'tfidf-data' or recommender_type == 'tfidf-skills':          \n",
    "                # Get recommended courses           \n",
    "                recommended_courses = recommender_model.courses_tfidf(courses, field, skill_to_learn, 5)\n",
    "            else:\n",
    "                if scenario == 'A':\n",
    "                    recommended_courses = recommender_model.courses_cypher(conn, skills, 5)\n",
    "                else:\n",
    "                    recommended_courses = recommender_model.courses_cypher(conn, df_skills_to_learn['skill'], 5)\n",
    "                                \n",
    "            print_courses(recommended_courses)\n",
    "                    \n",
    "            if scenario == 'C':\n",
    "                log_profiles= {\"profile\": {\"0\": chosen_profile}}\n",
    "            else:\n",
    "                log_profiles = profiles.to_dict()\n",
    "                        \n",
    "            monitor.write_to_log(scenario,data,NER_type,skills,log_profiles,recommended_courses.to_dict(),classification_type,recommender_type,to_be_profile)\n",
    "            app_logger.logger.info('app.ipynb finished running')\n",
    "\n",
    "    #except Exception as e:\n",
    "    #   app_logger.logger.info(getattr(e, 'message', repr(e)))\n",
    "\n",
    "main(PDF_resume = 'Police - Experienced.pdf')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
