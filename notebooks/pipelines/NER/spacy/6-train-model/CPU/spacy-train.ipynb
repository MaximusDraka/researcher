{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model 'C:/Users/tom/projects/skill-skeleton/notebooks/pipelines/NER/spacy/train/model-best'\n",
      "['tok2vec', 'ner']\n",
      "('SKILL',)\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf8\n",
    "\"\"\"Example of training an additional entity type\n",
    "\n",
    "This script shows how to add a new entity type to an existing pre-trained NER\n",
    "model. To keep the example short and simple, only four sentences are provided\n",
    "as examples. In practice, you'll need many more â€” a few hundred would be a\n",
    "good start. You will also likely need to mix in examples of other entity\n",
    "types, which might be obtained by running the entity recognizer over unlabelled\n",
    "sentences, and adding their annotations to the training set.\n",
    "\n",
    "The actual training is performed by looping over the examples, and calling\n",
    "`nlp.entity.update()`. The `update()` method steps through the words of the\n",
    "input. At each word, it makes a prediction. It then consults the annotations\n",
    "provided on the GoldParse instance, to see whether it was right. If it was\n",
    "wrong, it adjusts its weights so that the correct action will score higher\n",
    "next time.\n",
    "\n",
    "After training your model, you can save it to a directory. We recommend\n",
    "wrapping models as Python packages, for ease of deployment.\n",
    "\n",
    "For more details, see the documentation:\n",
    "* Training: https://spacy.io/usage/training\n",
    "* NER: https://spacy.io/usage/linguistic-features#named-entities\n",
    "\n",
    "Compatible with: spaCy v2.1.0+\n",
    "Last tested with: v2.1.0\n",
    "\"\"\"\n",
    "from __future__ import unicode_literals\n",
    "from __future__ import print_function\n",
    "import re\n",
    "import plac\n",
    "import random\n",
    "from pathlib import Path\n",
    "import spacy\n",
    "import json\n",
    "import logging\n",
    "from spacy.tokens import DocBin\n",
    "from spacy.training import Example\n",
    "\n",
    "LABEL = \"SKILL\"\n",
    "TRAIN_DATA_FILE = \"vaia-annotated.json\"\n",
    "model=\"C:/Users/tom/projects/skill-skeleton/notebooks/pipelines/NER/spacy/train/model-best\"\n",
    "new_model_name=\"training\"\n",
    "output_dir='C:/Users/tom/projects/skill-skeleton/models/NER/Model_02'\n",
    "n_iter=30\n",
    "   \n",
    "\n",
    "\"\"\"Set up the pipeline and entity recognizer, and train the new entity.\"\"\"\n",
    "random.seed(0)\n",
    "\n",
    "nlp = spacy.load(model)  # load existing spaCy model\n",
    "print(\"Loaded model '%s'\" % model)\n",
    "\n",
    "print(nlp.pipe_names)\n",
    "print(nlp.get_pipe(\"ner\").labels)\n",
    "\n",
    "ner = nlp.get_pipe(\"ner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(TRAIN_DATA_FILE, 'r') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "TRAIN_DATA = data['annotations'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting iteration 0\n",
      "Losses {'tok2vec': 5.472005670835908, 'ner': 2208.779726286151}\n",
      "Starting iteration 1\n",
      "Losses {'tok2vec': 1.4314704520787103, 'ner': 108.56472799972738}\n",
      "Starting iteration 2\n",
      "Losses {'tok2vec': 2.782760229851, 'ner': 130.06670160788235}\n",
      "Starting iteration 3\n",
      "Losses {'tok2vec': 1.9067399650156909, 'ner': 75.84146406856851}\n",
      "Starting iteration 4\n",
      "Losses {'tok2vec': 3.3555507963583673, 'ner': 62.74332898228721}\n",
      "Starting iteration 5\n",
      "Losses {'tok2vec': 3.9188381312284197, 'ner': 69.78457094639084}\n",
      "Starting iteration 6\n",
      "Losses {'tok2vec': 2.130813261622959, 'ner': 50.28858127320698}\n",
      "Starting iteration 7\n",
      "Losses {'tok2vec': 4.112041435201656, 'ner': 66.17496203707601}\n",
      "Starting iteration 8\n",
      "Losses {'tok2vec': 9.819685707946835, 'ner': 134.07488648359262}\n",
      "Starting iteration 9\n",
      "Losses {'tok2vec': 3.0078020300368715, 'ner': 49.107000549249115}\n",
      "Starting iteration 10\n",
      "Losses {'tok2vec': 4.01104944064901, 'ner': 39.67277101276683}\n",
      "Starting iteration 11\n",
      "Losses {'tok2vec': 0.6995252381864677, 'ner': 8.931053843587652}\n",
      "Starting iteration 12\n",
      "Losses {'tok2vec': 1.782240356534745, 'ner': 13.374804939292147}\n",
      "Starting iteration 13\n",
      "Losses {'tok2vec': 4.084980045500868, 'ner': 4.071735833094664}\n",
      "Starting iteration 14\n",
      "Losses {'tok2vec': 1.6803824075901426, 'ner': 10.262579448917602}\n",
      "Starting iteration 15\n",
      "Losses {'tok2vec': 0.4148161209703155, 'ner': 2.492719252846158}\n",
      "Starting iteration 16\n",
      "Losses {'tok2vec': 0.0009963857566825903, 'ner': 0.00578254427620219}\n",
      "Starting iteration 17\n",
      "Losses {'tok2vec': 1.1026117141472023, 'ner': 1.3884220568578312}\n",
      "Starting iteration 18\n",
      "Losses {'tok2vec': 0.07897069107686774, 'ner': 0.434017925274185}\n",
      "Starting iteration 19\n",
      "Losses {'tok2vec': 2.206074067234116, 'ner': 8.51836486840475}\n",
      "Starting iteration 20\n",
      "Losses {'tok2vec': 3.012377178561387, 'ner': 10.68967363975538}\n",
      "Starting iteration 21\n",
      "Losses {'tok2vec': 3.3817763028511116, 'ner': 9.941751231730201}\n",
      "Starting iteration 22\n",
      "Losses {'tok2vec': 2.031224191603496, 'ner': 7.156427626196122}\n",
      "Starting iteration 23\n",
      "Losses {'tok2vec': 0.5889770108089817, 'ner': 1.822677227496645}\n",
      "Starting iteration 24\n",
      "Losses {'tok2vec': 0.26612253139367925, 'ner': 0.7991584224370637}\n",
      "Starting iteration 25\n",
      "Losses {'tok2vec': 0.23077506251245156, 'ner': 0.6840169779017105}\n",
      "Starting iteration 26\n",
      "Losses {'tok2vec': 1.4865399410023372, 'ner': 4.206744823822683}\n",
      "Starting iteration 27\n",
      "Losses {'tok2vec': 1.3822505843357376, 'ner': 3.67304305901298}\n",
      "Starting iteration 28\n",
      "Losses {'tok2vec': 1.549282211065416, 'ner': 4.000573587558874}\n",
      "Starting iteration 29\n",
      "Losses {'tok2vec': 9.653796700571428e-07, 'ner': 2.495179907847641e-06}\n"
     ]
    }
   ],
   "source": [
    "move_names = list(ner.move_names)\n",
    "optimizer = nlp.begin_training()\n",
    "# batch up the examples using spaCy's minibatch\n",
    "for itn in range(n_iter):\n",
    "    print(\"Starting iteration \" + str(itn))\n",
    "    random.shuffle(TRAIN_DATA)\n",
    "    losses = {}        \n",
    "    for text, annotations in TRAIN_DATA:\n",
    "        example = Example.from_dict(nlp.make_doc(text), annotations)\n",
    "        nlp.update([example],sgd=optimizer, losses=losses, drop=0.3)\n",
    "    print(\"Losses\", losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entities in 'This course is intended as a basic introduction to using NVivo for qualitative data analysis.\n",
      "\t\n",
      "                            <p>NVivo is a widely used computer assisted qualitative data analysis software package which provides a potentially useful tool for the management and analysis of qualitative research data. This course is intended as a basic introduction to using NVivo for qualitative data analysis. Whether you are completely new to NVivo or have some previous experience with it  you will find this course both useful and enjoyable. This course blends lectures with hands-on exercises which allows you to try out the tools you've seen in the class under guidance.<br></p>\n",
      "<p><strong>What you will learn</strong>:</p>\n",
      "<p>At the end of this course you will master the core functionalities to apply the latest version of NVivo (1.0) to your project  including:</p>\n",
      "<ul><li><strong>Import</strong> - Creating a research project and importing different data formats such as Word documents  PDFs  webpages  audio  video and images into NVivo; classifying data files and managing their classifications</li><li><strong>Organize</strong> - Organizing codes  code text and create codes; apply coding stripes and highlights; use cases with classification and attributes; make annotations and memos  create sets and links to files</li><li><strong>Explore</strong> - Exploring lexical queries  word frequency and text search; apply code and matrix queries; illustrate with visualizations such as mind maps  concept maps  and coding matrix charts; coordinate team work by applying coding comparison</li></ul><p><strong>Not included in this course</strong>:</p>\n",
      "<ul><li>Theoretical framework of qualitative data analysis - Although this course will introduce some basic concepts of qualitative data analysis it is not a systematic review of the different theories.</li><li>Advanced qualitative methodologies - This course covers only the most salient features of NVivo and does not teach how to analyse qualitative data according to specific qualitative methods or designs  such as thematic analysis  grounded theory  content analysis  discourse analysis etc.</li></ul><h2>Target audience</h2>\n",
      "<p>Young researchers and data analysts who are new to qualitative research and curious about NVivo.</p>\n",
      "<h2>Fees</h2>\n",
      "<p>The participation fee is 330 EUR for participants from the private sector. Reduced prices apply to students and staff from non-profit  social profit  and government organizations. An exam fee of 35 EUR will be applied.</p>\n",
      "<ul><li>Industry  private sector  profession*: <strong>â‚¬ 330</strong></li><li>Non profit  government  higher education staff: <strong>â‚¬ 250</strong></li><li>(Doctoral) students  unemployed: <strong>â‚¬ 150</strong></li></ul><p>*If two or more employees from the same company enrol simultaneously for this course a reduction of 20% on the course fee is taken into account starting from the second enrolment.</p>\n",
      "<h2>Registration</h2>\n",
      "<p>More information and registration on our <a href=\"https://beta-academy.ugent.be/en/program/short-and-long-running-initiatives/2023-2024-2023m9nv-module-9-getting-started-with-nvivo\" tabindex=\"-1\">Beta-Academy website</a>.</p>\n",
      "                       '\n",
      "SKILL data analysis\n",
      "SKILL computer\n",
      "SKILL data analysis\n",
      "SKILL data analysis\n",
      "SKILL Word\n",
      "SKILL word\n",
      "SKILL data analysis\n",
      "SKILL data analysis\n",
      "SKILL content\n"
     ]
    }
   ],
   "source": [
    "# test the trained model\n",
    "test_text = \"This course is intended as a basic introduction to using NVivo for qualitative data analysis.\\n\\t\\n                            <p>NVivo is a widely used computer assisted qualitative data analysis software package which provides a potentially useful tool for the management and analysis of qualitative research data. This course is intended as a basic introduction to using NVivo for qualitative data analysis. Whether you are completely new to NVivo or have some previous experience with it  you will find this course both useful and enjoyable. This course blends lectures with hands-on exercises which allows you to try out the tools you've seen in the class under guidance.<br></p>\\n<p><strong>What you will learn</strong>:</p>\\n<p>At the end of this course you will master the core functionalities to apply the latest version of NVivo (1.0) to your project  including:</p>\\n<ul><li><strong>Import</strong> - Creating a research project and importing different data formats such as Word documents  PDFs  webpages  audio  video and images into NVivo; classifying data files and managing their classifications</li><li><strong>Organize</strong> - Organizing codes  code text and create codes; apply coding stripes and highlights; use cases with classification and attributes; make annotations and memos  create sets and links to files</li><li><strong>Explore</strong> - Exploring lexical queries  word frequency and text search; apply code and matrix queries; illustrate with visualizations such as mind maps  concept maps  and coding matrix charts; coordinate team work by applying coding comparison</li></ul><p><strong>Not included in this course</strong>:</p>\\n<ul><li>Theoretical framework of qualitative data analysis - Although this course will introduce some basic concepts of qualitative data analysis it is not a systematic review of the different theories.</li><li>Advanced qualitative methodologies - This course covers only the most salient features of NVivo and does not teach how to analyse qualitative data according to specific qualitative methods or designs  such as thematic analysis  grounded theory  content analysis  discourse analysis etc.</li></ul><h2>Target audience</h2>\\n<p>Young researchers and data analysts who are new to qualitative research and curious about NVivo.</p>\\n<h2>Fees</h2>\\n<p>The participation fee is 330 EUR for participants from the private sector. Reduced prices apply to students and staff from non-profit  social profit  and government organizations. An exam fee of 35 EUR will be applied.</p>\\n<ul><li>Industry  private sector  profession*: <strong>\\u20ac 330</strong></li><li>Non profit  government  higher education staff: <strong>\\u20ac 250</strong></li><li>(Doctoral) students  unemployed: <strong>\\u20ac 150</strong></li></ul><p>*If two or more employees from the same company enrol simultaneously for this course a reduction of 20% on the course fee is taken into account starting from the second enrolment.</p>\\n<h2>Registration</h2>\\n<p>More information and registration on our <a href=\\\"https://beta-academy.ugent.be/en/program/short-and-long-running-initiatives/2023-2024-2023m9nv-module-9-getting-started-with-nvivo\\\" tabindex=\\\"-1\\\">Beta-Academy website</a>.</p>\\n                       \"\n",
    "doc = nlp(test_text)\n",
    "print(\"Entities in '%s'\" % test_text)\n",
    "for ent in doc.ents:\n",
    "    print(ent.label_, ent.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to C:\\Users\\tom\\projects\\skill-skeleton\\models\\NER\\Model_02\n",
      "Loading from C:\\Users\\tom\\projects\\skill-skeleton\\models\\NER\\Model_02\n",
      "SKILL data analysis\n",
      "SKILL computer\n",
      "SKILL data analysis\n",
      "SKILL data analysis\n",
      "SKILL Word\n",
      "SKILL word\n",
      "SKILL data analysis\n",
      "SKILL data analysis\n",
      "SKILL content\n"
     ]
    }
   ],
   "source": [
    "# save model to output directory\n",
    "if output_dir is not None:\n",
    "    output_dir = Path(output_dir)\n",
    "    if not output_dir.exists():\n",
    "        output_dir.mkdir()\n",
    "    nlp.meta[\"name\"] = new_model_name  # rename model\n",
    "    nlp.to_disk(output_dir)\n",
    "    print(\"Saved model to\", output_dir)\n",
    "\n",
    "    # test the saved model\n",
    "    print(\"Loading from\", output_dir)\n",
    "    nlp2 = spacy.load(output_dir)\n",
    "    # Check the classes have loaded back consistently\n",
    "    assert nlp2.get_pipe(\"ner\").move_names == move_names\n",
    "    doc2 = nlp2(test_text)\n",
    "    for ent in doc2.ents:\n",
    "        print(ent.label_, ent.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.youtube.com/watch?v=IqOJU1-_Fi0&list=PLBmcuObd5An559HbDr_alBnwVsGq-7uTF&index=4"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
