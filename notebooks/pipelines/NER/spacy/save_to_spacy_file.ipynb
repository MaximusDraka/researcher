{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokyo Tower\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#https://spacy.io/usage/training\n",
    "\n",
    "import spacy\n",
    "from spacy.tokens import DocBin\n",
    "from spacy import displacy\n",
    "\n",
    "nlp = spacy.blank(\"en\")\n",
    "training_data = [\n",
    "  (\"Tokyo Tower is 333m tall.\", [(0, 11, \"BUILDING\")]),\n",
    "]\n",
    "# the DocBin will store the example documents\n",
    "db = DocBin()\n",
    "for text, annotations in training_data:\n",
    "    doc = nlp(text)\n",
    "    ents = []\n",
    "    for start, end, label in annotations:\n",
    "        span = doc.char_span(start, end, label=label)\n",
    "        print(span) \n",
    "        ents.append(span)    \n",
    "   \n",
    "    doc.ents = ents\n",
    "    db.add(doc)\n",
    "db.to_disk(\"./train.spacy\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "174\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Efficient use of a network protocol analyzer in cyber threats  Many companies rely on a Security Information and Event Management system SIEM to consolidate data from various applications and equipment  allowing them to maintain an overview of their security landscape To investigate alerts generated by their SIEM system more thoroughly  they turn to a Network Protocol Analyzer NPA An NPA captures  analyzes  and visualizes network traffic and can have a broad range of applicationsHowever  the procedures and configurations of NPAs vary according to the specific issue at hand cybersecurity  troubleshooting  etc  which often leads to incorrect or inefficient usage in practice During this workshop  we will build the knowledge and skills necessary to use Network Protocol Analyzers correctly and efficiently  particularly in the context of cybersecurity threats We will work with reallife scenarios and gain practical insights into the underlying workings of NPAs The NPA that we will delve deeper into during the workshop is the opensource NPA  Wireshark This session is part of the series Cybersecurity excellence Session 1 Tackling cybersecurity challenges a complex security puzzle  28 February 2024  Vincent Naessens KU LeuvenSession 2 ‘Privacy by design a technical approach to privacy risk  26 March 2024  Kim Wuyts PwCSession 3 Efficient use of a network protocol analyzer in cyber threats workshop  24 April 2024  Tom Cordemans KU LeuvenSession 4 Hacking and protecting embedded devices workshop  29 May 2024  Jorn Lapon KU LeuvenSession 5 EU cybersecurity standards and regulation for IoT ecosystems and Industrial Control Systems  28 August 2024  Vincent Naessens KU LeuvenSession 6 Cyberattack response  25 September 2024  Tom Bauwens Eubelius  Kalman Tiboldi TVHSession 7 Postquantum cryptography  23 October 2024  Eric Michiels IBM  In an increasingly technologydriven world cybersecurity stands as the cornerstone of digital resilience In this programme we will explore the full spectrum of cybersecurity from prevention to response while gaining both immediate handson skills and a foresight for the future of cybersecurity This programme brings together academic researchers and industrial experts and thus provides a blend of lectures and use cases and practical testimonials httpspuckuleuvenbenlopleidingefficientuseofanetworkprotocolanalyzerincyberthreatsworkshopxdojwgde0jla3bpz Session 3  Cybersecurity excellence series 2024 workshopGhentKU Leuven Postuniversitair Centrum,\n",
       " Digital Ethics  As our reliance on technology continues to grow  the importance of  digital ethics cannot be overstated In todays world  organisations in  every sector must be aware of the ethical implications of their actions  in the digital realm From the handling of personal data to the  development of new technologies  the decisions we make have the  potential to impact individuals  society  and the environment in  profound ways By participating in this course  you will gain the  knowledge and skills necessary to navigate the complex ethical landscape  of the digital world and make informed decisions that align with your  organisations values Our course will cover a range of important topics  including ethics  frameworks and tools  regulation and legal issues  developing ethical  technology  technology assessment  ethical dilemmas  and ethics in data  and visualisation This course is designed for professionals working in a wide range of organisations and industries Whether you are employed in government  industry  academia  or the nonprofit sector  you will benefit from the comprehensive coverage of key topics in Digital Ethics The course is particularly relevant for those working in fields such as technology  interaction design  data analysis  policymaking  law  and research However  anyone with an interest in Digital Ethics and the impact of technology on society will find value in this course Session 1 Ethics frameworks – Thursday 18 April 2024  During this session  we will explore the various frameworks that can be  used to justify ethical decisions  including virtue ethics  consequence  ethics  and duty ethics The participants will learn how to think  ethically  and how these basic ethics frameworks can be applied to  various scenarios in which digital technologies play a central role We  will also explore the concept of responsibility  including the different  types of responsibility moral  legal  causal or role responsibility  that can arise in the digital realm and discuss the responsibility gap  This session will provide attendees with a solid foundation in the basic  principles of ethics and their relation to digital technology Session 2 Building Ethical Foundations  Thursday 25 April 2024  This session aims to create a communal learning environment among the  participants  both online and onsite During this session  participants  will introduce themselves  share their professional backgrounds and  discuss their expectations for the course  providing invaluable insight  for the instructors to tailor the subsequent sessions Additionally   participants will reflect on the ethical aspects of their jobs   exploring potential ethical dilemmas within their specific work contexts  such as government  industry  academia  or nonprofit sectors This  early engagement is designed to foster a deeper understanding and  awareness of the ethical issues to be explored throughout the course   setting the stage for a more insightful reflection during the closing  session Session 3 Tools and methods for ethical decision making  Thursday 2 May 2024  In this session we will introduce tools and methods that can be used to  make ethical decisions in different contexts  such as in industry   government  academia and research Participants will learn about  practical frameworks and tools such as the guidance ethics approach  the  AI Blindspots and the Data Ethics Decision Aid This session will  provide attendees with the basic tools and methods in the practice of  ethical decisionmaking in the digital realm Session 4 Technology assessment in practice – Thursday 16 May 2024  This session will provide insight into the impact and effects of  technology  and will introduce tools and methods for assessing the risks  of innovation and averting undesirable consequences of new  technologies The session will look into the challenges of achieving  positive or negative impacts with technology due to the interplay of  technology  society  organisations and individuals A dedicated focus  will be on the impact of AI technologies in a government context as well  as on evaluating the results of social corporate responsibility actions  in the context of a company This session will provide attendees with  practical examples of how to effectively assess the risks and potential  consequences of technology Session 5 Designing ethical technology – Thursday 23 May 2024  In this session  we will explore different approaches to designing  technology that takes into account the needs and values of human beings  We will explore humanitycentered design including design thinking   inclusive design  valuecentered design  and participatory design or  cocreation We will then discuss how technologies are often designed  in a way that threatens our digital wellbeing  and which strategies can  be used to improve digital wellbeing This session will provide  attendees with the tools and knowledge they need to create ethical  technology that is designed with people at its core Session 6 Ethical topics and dilemmas – Thursday 30 May 2024 This session will explore the application of behaviorist principles in  digital technologies  particularly in the realm of surveillance It will  highlight how these technologies not only observe but actively  influence and modify user behavior  raising important ethical questions  about privacy  autonomy  and the power dynamics between users and  technology providers The session will emphasize the need for ethical  guidelines to address the challenges posed by digital surveillance This  session further examines the various functions fairness and equality  hold in the AI governance debate Drawing from political philosophical  theories of justice and practical usecases  a relational perspective on  AI is developed to understand better the social and technical dynamics  that give rise to digital injustice This session will provide attendees  with an understanding of the ethical challenges that can arise in the  digital world  and the tools and frameworks that can be used to address  them Session 7 Legal and policy issues – Thursday 6 June 2024  This session will explore a number of legal issues that arise in the  digital realm This session will first provide attendees with an  understanding of appropriate legal frameworks related to the free flow  of information  personal data protection  and the principles  rights  and obligations of the EUs General Data Protection Regulation GDPR  This session will also provide a comprehensive review of the impact AI  may have on individual and collective human rights across various  sectors The participants will learn about the technical legal  instruments at their disposal to combat AI discrimination  including  legal tools related to direct and indirect discrimination  as well as  discrimination by association Moreover  participants will be invited to  critically reflect on the resilience of ethics in the context of AI  This approach to AI will consider highlevel legal instruments within  the European Union  such as the EU Charter on Fundamental Rights  the  proposed AI Act  and the set of equality directives A comparative law  approach will also be mobilized to provide a better understanding of  addressing AI challenges with traditional legal instruments Session 8 Ethics in data and visualisation – Thursday 13 June 2024  In this session  we will discuss the ethical aspects of handling and  visualising of data We will start by examining how data are  constructed and therefore are inherently biased  rather than  representing an objective truth We cross over to understand the value  of visualising data  acknowledging its potential risk to yet further  objectify this constructed  situated nature of data We then dive into  how some data visualisations can be unintentionally perceived as  unethical  whether through potentially misleading design choices  the  use of dubious data  the omission of uncertainties  or the disregard of  cognitive biases This session aims to provide practical skills and  reflective insights for handling and visualising data in ways that are  more transparent  equitable and responsible Session 9 Closing and reflection – Thursday 20 June 2024 The seventh and final session will be a closing session focused on  reflection In this session  participants will have the opportunity to  reflect on how the topics covered in the previous sessions apply to  their own professional situations This session will provide a space for  attendees to share their thoughts  insights  and experiences  and to  discuss how they plan to incorporate the knowledge and skills they have  gained into their work This will be a valuable opportunity for  participants to consolidate their learning and to develop a personal  plan for applying the principles of Digital Ethics in their professional  lives  More info  Share this course   httpswwwkuleuvenbedigisoceducationandtraininghybridcourseondigitalethics 18 Apr 2024  20 Jun 2024 coursehybridKU Leuven,\n",
       " Big Data for Health amp Care The Arisal of Data Spaces  In recent years  a series of health data spaces have arised However   at the moment  the strategic oversight is lost and many questions  remain For example Which data space initiatives are out thereHow do they relate to each otherHow will they work togetherin synergy to maximize the impactHow will this affect the local data management at the level of the individual data partners With this symposium  we aspire to facilitate an indepth exploration of data spaces and research infrastructures  elucidate challenges and best practices for largescale projects  and engage in a panel debate on the feasibility of implementing and integrating various data spaces at different levels  all underpinning the advancement of healthcare data sharing and research The  event plans to highlight different Belgian data spaces and to delve  into profound discussions during panel debates  exploring complex topics  like challenges and future perspectives in health data sharing and analysis As iHD will comoderate the event  the bridge towards Europe is guaranteed Target Audience The symposium is tailored for health data enthusiasts  from Belgium and neighboring countries While expecting diverse  attendees  both beginners and experts  we are aiming for accessibility  without compromising depth In our sessions  we explore a wide array of dimensions  ranging from  geographical nuances to various data types and the complexities of  transmural care We delve into the intricacies of firstline care   hospital settings  and innovative mobile healthcare mHealth  Furthermore  our exploration extends to discovering the transformative  potential inherent in different data types  encompassing everything from  imaging to omics and harmonized clinical data JoinTheJourney  All speakers are asked to touch upon the following questions in preparation of their talk What are their “why” and expected clinical impactWhich sociotechnical challenges are they trying to addressWhat are their main achievements so farWhat excites them for the future10001010  Meeting Start Welcome Liesbet M Peeters UHasselt  Dipak Kalra iHD10101120  Session 1 Borderless Insights  Unveiling Opportunities  Challenges in Scaling RWD across Limburg  Flanders  Belgium and Europe Moderator Liesbet M Peeters UHasselt andor Dipak Kalra iHDKeynote 1 Setting the scene  introducing the European Health Data Space and explaining the overall challenges of scalingup health data and how they are currently handled at the European levelDipak Kalra iHDHealth Campus province of LimburgPiet Stinissen UHasseltDepartment of CareKoenraad Jacob Department of CareBelgian Health Data Agency HDA and Data Governance at SciensanoSofie De Broe HDA  SciensanoPanel Debate session 111201140  Coffee Break11401250  Session 2 Breaking Barries  Navigating RWD Challenges from First Line to Hybrid Digital Care in Transmural Integrated Settings Moderator Liesbet M Peeters UHasselt andor Dipak Kalra iHDKeynote 2 Enhancing Hybrid Digital Healthcare  Principles of Quality Assurance in Digital InnovationsChristophe Maes iHDFirst line General practioners  Intego and Population Health ManagementBert Vaes IntegoUnlocking Belgiums health data reuse potential the RWD4BE iniativeIngrid Maes InovigateRemote monitoring mHealthHans De Clercq BytesfliesPanel Debate Session 212501350  Lunch Break13501500  Session 3 Data Diversity Unveiled  Exploring Omics  Clinical  and Brainrelated Data in RealWorld Scenarios Moderator Liesbet M Peeters UHasselt andor Dipak Kalra iHDKeynote 3 Assuring Research Excellence Strategies for Assessing Data Quality in European ProjectsJens Declerck iHDOHDSI BelgiumAnnelies Verbiest UZAEBRAINS BelgiumWim Vanduffel KU LeuvenELIXIR BelgiumFrederik Coppens VIBPanel Debate Session 315001520  Coffee Break15201630  Session 4 Synergizing Tomorrow  Unveiling Strategies to Maximise Collaboration and ProgressArisal of Data Spaces Why I am excited and worriedPanel DebateModerator Liesbet M Peeters UHasselt andor Dipak Kalra iHDPiet Stinissen Health Campus Limburg  Sofie De Broe Health Data Agency  Bert Vaes Intego  Hans De Clercq Byteflies  BeMedTech  Annelies Verbiest OHDSI  Frederik Coppens ELIXIRExample of questions that will be addressedHow can we ensure strategic oversightHow can we maximise synergyHow to cocreate a joint strategyWhats next  aspirations for the futureClosing remarksLiesbet M Peeters UHasselt  Dipak Kalra iHD16301730  Networking Reception    The Research Group in Biomedical Data Sciences of UHasselt and The European Institute for Innovation through Health Data iHD are delighted to invite you to the “Big Data in Health and Care The Arisal of Data Spaces” Symposium The term data space has gained a lot of traction lately specifically with the upcoming European Health Data Space legislation The definition of data space is still under discussion However we and others eg NCP Flanders describe it as a  decentralized infrastructure for trustworthy data sharing and exchange  in data ecosystems based on commonly agreed principles httpswwwuhasseltbeeninstitutenenbiomedenimmunologybiomedicaldatasciencesbigdataforhealthcarethearisalofdataspaces Symposium symposiumHasseltHasselt University,\n",
       " AI Face Morphing  Why not use some really serious  cool  advanced AI technologies to make something very fun and silly Well  that is exactly what we aim to do on our socalled Brainjar days During a Brainjar day  everyone on the team receives the opportunity to experiment with something of their choice So  I thought what if I could use AI image generation to merge two faces Oh  and Im not just talking about a face swap Im talking about actually generating a completely new face made of features of two original faces And even better what if I could find a way to visualize the morphing process from one face to the other Lets see how far I got with my Frankensteinish experiment  More info  Share this course   httpsbrainjaraiblogsaifacemorphing Frankenstein would be proud AI Face Morphing in action BlogpostOnlineBrainjar,\n",
       " Large Language Models  1400  Keynote talk The I in LLMs stands for Intelligence Large  Language Models and their use in Natural Language Processing MarieCatherine de Marneffe FNRSUCLouvain In this seminar  we will review what Large Language Models LLMs are  and see how they are currently used in Natural Language Processing  NLP I will first briefly go over the developments in the NLP field  that led to LLMs After describing what LLMs are and highlighting their  advantages and disadvantages  we will delve into their current uses in  NLP Finally  I will go over some of my own research  investigating what  LLMs capture of pragmatics 1615  Short presentations Charlotte Nachtegael ULB DUVEL an activelearning annotated biomedical corpus for the recognition of oligogenic combinationsJan Held ULiège Explainability model for football referee decisionBenoît Ronval UCLouvain LLMs and tabular data zeroshot generation and synthetic data for fairnessMartin Balfroid UNamur Towards LLMgenerated code tours for onboardingVincent Stragier UMons LLMbased interactive agents for visually impaired and blind individualsChristophe Crochet UCLouvain How LLM and prompt engineering can close the gap between formal verification and network protocol testingLize Pirenne ULiège Context referencing citations for factuality improvement  More info  Share this course   httpwwwciluliegebetraildoctoralseminarsindexhtml 28 Mar 2024 1400  1800 seminaronline amp LouvainlaNeuveTRAIL,\n",
       " 2024 Digital Finance Conference  Come along and dive into the topics that will define tomorrow’s CFO  including  The digital CFO revolution Winning the war for talent Navigating climate change Mastering the art and science of negotiation with investors And more  Join us to take part in expert session with leading CFOs  technology experts and worldfamous academics The event rounds up with an inspirational keynote talk from Hod Lipson  – the groundbreaking Columbia University Professor in Robotics and AI  His accolades include being named as Esquire magazine’s Best and Brightest – and his lab has been listed as one of the 25 Most Awesome Labs in the US by Popular Science Forbes has listed him as one of the Top 7 Data Scientists in the World – and his TED talk is the most viewed on AI His talk will be on The Next AI – a deep dive into what’s driving AI  how to use it and how to anticipate its future Afterwards  there will be networking over dinner with CFOs  finance  leaders and company representatives It promises to be an intimate   relaxed and thoughtprovoking finale to the day  Join the fourth edition of our Digital Finance Conference – and join the revolution in financial leadership To succeed today’s finance leaders need so much more than financial  knowhow They need to be able to see the big picture to anticipate and  respond to trends and phenomena like GenAI climate change investor  negotiations and the war for talent Join us to delve into these subjects – and look towards a future where success isn’t simply achieved it’s sustained httpswwwvlerickcomenevents2024digitalfinanceconference The CFO of the future eventGhentVlerick Business School,\n",
       " Spring Fest GenAI for Business  Welcome to Spring Fest GenAI for Business  a celebration of the dynamic growth and achievements of our Postgraduate Studies in Big Data and Analytics in Business and Management  which was initiated in the academic year 20172018 Since then  our program has fostered a vibrant alumni network  and now its time to reunite and expand our connections within the thriving Big Data and Analytics community At this Spring Fest  we invite you to join us for an insightful afternoon program Our distinguished keynotes will provide a broader perspective on the application of GenAI in the world of business Theyll delve into the innovative possibilities and emerging trends that GenAI offers  equipping you with valuable insights to navigate this transformative landscape Following the keynotes  well transition into a captivating networking event  where youll have the opportunity to reunite with former participants  forge new connections  and exchange knowledge and experiences with professionals from a diverse range of companies and organizations This event is a unique opportunity to engage  learn  and grow within the realm of Big Data and Analytics Afternoon Program GenAI for Business 1400 Welcome Reception 1430 Opening 1440 GenAI Introduction and Academic Perspective Prof dr Jochen De Weerdt  prof dr Seppe vanden Broucke  KU Leuven 1530 Sustainable Value Creation with LLMs beyond Early Adoption Tim Leers  RD and machine Learning Engineer Dataroots 1630 Coffee Break 1700 Trends in GenAI and the Hugging Face Ecosystem Niels Rogge  Hugging Face  ML6 1800 Practical Use Cases in Business TBD Evening Program 1900 Welcome with aperitif 1945 Start dinner Opening by Prof dr Jochen De Weerdt  KU Leuven Coffee  dessert buffet 2330 Closing  At this Spring Fest we invite you to join us for an insightful afternoon program Our distinguished keynotes will provide a broader perspective on the application of GenAI in the world of business Theyll delve into the innovative possibilities and emerging trends that GenAI offers equipping you with valuable insights to navigate this transformative landscape  Following the keynotes well transition into a captivating networking event where youll have the opportunity to reunite with forme httpspuckuleuvenbenlopleidingykzo8gyer6lr3j5v GenAI BigData DataAnalytics seminarLeuvenKU Leuven Postuniversitair Centrum,\n",
       " The Society for Imprecise Probabilities Theories and Applications Summer School  Our summer school has the aim of introducing doctoral students – and other interested researchers – to the basics of imprecise probabilities  from its foundations in applied mathematics and logic to its applications in quantum physics  economy and AI Emphasis will be put on why and how imprecision is adopted in  relevant to  or even necessary in each of these fields On the last day  we’ll provide the participants with a number of research projects on the subjects of the lectures  which they will work on in smaller groups supervised by the lecturers This will allow the participants to work together with and learn from fellow students and researchers  who presumably have expertise in different research fields  More info  Share this course   httpsschool24siptaorgregistration 12 Aug 2024  16 Aug 2024 Summer SchoolGentUGent amp VAIA,\n",
       " The Smart Factory amp Digital Supply Chain  The threeday Smart Factory and Digital Supply Chain programme consists of three modules Together they cover the most important strategic building blocks of your operations and supply chain  Module 1 The smart supply chain   Discover smart operations and understand why they’re so important  Explore the impact digital technologies will have on your supply chain  Know how digital technologies will transform your organisation – and impact competition  Learn how to measure the return on investment of digitally  transforming your operations and supply chain – and how to build a case  for Industry 40   Module 2 The Smart Factory From Operational Excellence to Industrial Manufacturing Platforms  See the smart manufacturing big picture Have we reached Industry 40 – or are we heading to 50 Discover how digital twin technology and new standards for connectivity lead to a new level of operational excellence Explore how AI and ML can augment operational decisionmaking  Find out how digitisation supports localisation and operational resilience  Discover how platformbased business models can power new  manufacturing models – and the threats and opportunities for established  companies  Module 3 Leadership in digital transformation   Explore roles in digital transformation – including your own  Learn about necessary experiments and making the right choices Discover how to manage the change of a digital transformation  If  you want to transform your operations with digital technologies  this  programme is a great place to start It gives you the knowledge  skills  and insight to benchmark your digital strategy – and lead and manage  your transformation Your immediate return on your investment in the programme will include  Understanding current and emerging trends Knowing the changing impact that digitisation may have on your supply chain and production Learning how to move beyond operational excellence – and how  digitisation should shape future business models  differentiation  and  sustainability Discovering how to use and deploy technologies correctly  Highlighting the digital initiatives you need to take now – and how to measure their impact to grow your business Developing the essential knowledge and skills required to measure  analyse and successfully implement digital initiatives Embracing digital leadership to take your business to the next level   Operations and supply chain managers who want to draw up a plan to further digitalise their supply chain and factory Plant managers and production managers who want to motivate their team towards digitalisation Managers working in a manufacturing organisation who want to steer digital choices and set priorities Supply chain consultants who want to grow further to include more people in digital initiatives Logistic service providers  who want to develop a plan to digitalise their distribution centres and supply chain   One  of Europe’s leading institutes of technology and one of its leading  business schools have come together to create this unique threeday  programme With Vlerick Business School you learn the latest in smart  supply chains and digital leadership And with the RWTH Aachen  Engineering Campus you get an actionfocused learning experience  You gain the skills experience and confidence to implement a smart  factory and digital supply chain – and develop a plan to make the  transition  httpswwwvlerickcomenprogrammesprogrammesinoperationssupplychainmanagementthesmartfactoryanddigitalsupplychain Industry 40 Smart operations amp supply chain management for sustainable competitive advantage courseGhentVlerick Business School,\n",
       " Creating business value with AI and big data  Machine learning  natural language processing  robotics  cloud and modern data platforms… They all have immense potential for your organisation But how do you make them work for you  More info  Share this course   httpswwwvlerickcomenprogrammesprogrammesindigitaltransformationcreatingbusinessvaluewithaiandbigdata 14 Oct 2024  11 Mar 2025 CourseBrusselsVlerick Business School,\n",
       " Keeping things private Exploring opensource large language models for sensitive text data  Target audience The main target audience are researchers from both academia and  industry  working with sensitive text data eg  patient records  HR  files who want to explore opensource large language models In  addition  anyone wanting to learn about opensource large language  models is welcome Prerequisites For the lecture in the morning  there are no prerequisites in terms of background or skills  and no equipment is needed For the handson workshop in the afternoon  a basic understanding of  Python and the command line is required Google Colab notebooks are  provided so no programming from scratch  but participants need to at  least understand the given Python code and be able to tweak it Advanced  programming skills  however  are not required In case of doubt   contact the workshop teacher Pieter Fivez Pieterfivezuantwerpenbe For the workshop  make sure to bring a fully charged laptop with  Python installed on it version 39 or higher Access to Google Colab  free or paying is required  too This course is the very first edition of the TEXTUA Invites series  in which TEXTUA University of Antwerp invites national and international experts to tackle diverse challenges within the field of text mining This course is coorganized by the Flanders AI Academy VAIA The lecture is given by international NLP expert dr Enrique Manjavacas  and the workshop is given by text mining expert and TEXTUA coordinator dr Pieter Fivez The opening and introduction is given by TEXTUA director prof dr Walter Daelemans TEXTUA is a core facility of the University of Antwerp  directed by prof dr Walter Daelemans and coordinated by dr Pieter Fivez  which provides scalable text mining solutions to researchers from any scientific discipline It offers a diverse collection of services for a broad range of textual data  including automatically transcribed speech and written text in images TEXTUA bundles the unique existing expertise in digital text analysis at the University of Antwerp with special emphasis on explainable Artificial Intelligence   More info  Share this course   httpswwwuantwerpenbeenresearchfacilitiestextuaeducationalactivitiestextuainvitesenrique 15 Apr 2024 1000  1600 lecture amp workshopAntwerpTEXTUA UAntwerp VAIA,\n",
       " AI Excellence Lecture Series  Due to the proliferation of wholeslideimaging WSI digital scanners it is now possible to leverage computer vision  image analysis  and machine learning techniques  such as deep learning to process the digital pathology images in hopes to derive  diagnosis and prognosis markers The convergence of digital imaging  data science and pathology gave rise to a new research area known as digital pathology Digital pathology greatly enhances diagnostic accuracy and allows a variety of pathology tasks to be completed with greater efficiency This presentation will offer a general introduction to the topic  it will outline and discuss imaging tasks needed for the successful implementation of a digital pathology pipeline  and it will offer overview and insights on how datadriven solutions such as deep neural networks can be used to derive markers from digital pathology slides It will also be shown that a diagnostic system that combines deep learning and prior histological knowledge can provide useful diagnosticprognostic markers Lastly  open research issues and implementation challenges will be briefly discussed  More info  Share this course   httpswwwiaidaorgeventcatailecturestypefuture pHighquality scientific lectures on several current hot AI topicsp Weekly lecturesOnlineArtificial Intelligence Doctoral Academy AIDA,\n",
       " AI in Business and Industry  The Postgraduate Certificate Artificial Intelligence in Business and Industry aims  to give engineers  computer scientists and other professionals the  opportunity to specialise in the field of artificial intelligence  The  programme has been designed with a specific need in the job market in  mind many current employees in for example RD divisions of leading  companies are highly skilled but did not receive specific training on  AI in their formal education Perhaps you  too  experience the need to  bring your AI skills up to date and are looking for a qualitative AI  course to do that This postgraduate training allows professionals to  acquire in one year a solid academic knowledge of artificial  intelligence  as well as insight into the domains of image and language  computer visionNLP and business aspects of AI  The postgraduate programme Artificial Intelligence in Business and Industry stands  firmly on its own but also opens the door to more Participants can  choose to follow a followup track into the Advanced Master AI in Business and Industry to  be launched in September 2023  where they gain access to the wider  range of indepth  broadening and  in particular  more applied modules  The courses offered in the postgraduate programme form an integral part  of the Advanced Master Artificial Intelligence in Business and Industry   and participants who pass the courses in the postgraduate programme  will be granted exemptions when following the rest of the master’s  programme The programme aims at different  kinds of engineers eg in Engineering Science  Engineering Technology   or Business Engineers who majored in data science or applied computer  science In addition  the programme is open to masters in mathematics  and physics In general  any participant with a master’s degree that  offers sufficient background in mathematics  programming and technology  will be admitted If you do not have one of the aforementioned master  diplomas  you can submit a file with your motivation and CV to the  programme committee  who will assess your application Note that Python  proficiency basic is required An optional 6month subscription to  Datacamp can be provided upon registration  While recently  graduated students are welcome  the programme also offers added value to  professionals with field experience  wishing to re or upskill  themselves in the field of Artificial Intelligence in order to make the  most of their career opportunities The programme specifically caters to  participants looking for a theoretical  academically grounded approach  to AI Given the advanced content of the courses  the profiles most  suitable for this postgraduate are  for example  IT developers and  functional analysts or RD staff  engineers  project leaders and  managers The programme starts with the theoretical AI foundations that are indispensable for professionals Participants therefore get 3 academic courses that teach them the scientific basics of artificial intelligence In addition  the door is opened to industrial applications and general business applications with the courses in the second semester Fundamentals of AI In this course  you will acquire a deep knowledge and insight into foundational techniques from Artificial Intelligence  including search methods and their applications to games  the version spaces algorithm for machine learning  constraint processing techniques  strips planning and theorem proving for firstorder predicate logic You will be able to simulate each of the above techniques with pen and paper on small new examples and have insight into the relevance of these techniques for applications in domains such as manufacturing  health  education  logistics  manufacturing  and robotics  Machine Learning and Inductive Inference This  course will familiarize you with the domain of machine learning  which  concerns techniques to build software that can learn how to perform a  certain task or improve its performance on it by studying examples of  how it has been accomplished previously  and in a broader sense the  discovery of knowledge from observations inductive inferenceAfter following this course  you will have a basic understanding of the general principles of learninghave an overview of the existing techniques for machine learning and data miningunderstand how these techniques work  and why they workbe able to implement programs that learn or exhibit adaptive behavior  using these techniquesbe uptodate with the current state of the art in machine learning researchbe able to contribute to contemporary machine learning research  Artificial Neural Networks and Deep Learning The  course aims to introduce the basic techniques  methods and properties  of ANN and to study their application to selected problems The basic  concepts will be introduced in the lectures Advanced topics and recent  research results will be touched upon occasionally You will study and  develop explicit neural network models for selected applications Computer Vision and Natural Language Processing The  course introduces natural language processing technologies and their  applications in a variety of tasks  which include text mining  machine  translation  question answering and dialogue modelling It also  introduces computer vision algorithms and their applications such as  image classification  object detection  and image segmentation Special  attention goes to applications that require the joint processing of  language and visual data  as this is a natural way to interact with  machines  The students will gain insights into suitable machine  learning algorithms that ideally are trained with limited annotated  examples or human feedback They will learn how to build and critically  assess an application making use of the most recent techniques and  resources  Business Analytics In this course  you will  learn to understand how business problems can be formulated with  advanced analytics techniques as a potential solution You will be able  to reason on the organizational and managerial aspects of applying big  data and analytics techniques and understand how prescriptive analytics  and causal ML can help to use analytics for business decisionmaking  The course teaches you how analytical modelling techniques can be  optimized and evaluated from a profitdriven perspective and how  analytics techniques can exploit networkbased information  After  following “Business Analytics”  you will know how to deal with  unstructured data in the form of textual inputs  and how to use such  data for practical business applications such as sentiment analysis or  social media analytics The course deals with how stateoftheart  explainability techniques can give insights into blackbox machine  learning models and how process mining techniques can be applied to data  sets originating from processaware information systems  including  automated process discovery  conformance checking and extension Upon  completion of the course  you know which data science tools and  environments are important for realizing applications of machine  learning in business  including platforms such as Hadoop  Spark  etc   which business applications might benefit from deep learning techniques   and how to apply them and evaluate their appropriateness  The postgraduate programme on Artificial Intelligence in Business and  Industry aims to give engineers computer scientists and other  professionals the opportunity to specialise in the field of artificial  intelligence This programme allows professionals to acquire a solid  academic knowledge of AI within one year along with insight into the  domains of image and language computer visionNLP and business aspects  of AI  httpspuckuleuvenbenlopleidingxdojwgdemjla3bpz Postgraduate Certificate postgraduateKortrijkKU Leuven Postuniversitair Centrum,\n",
       " Digital Finance  This programme combines an online introduction and three days on campus to prepare you and your team for digital transformation You’ll start by measuring your finance team’s digital maturity – then develop a roadmap for the future And you’ll gain the tools  knowledge and inspiration you need to get your finance team on board with new technology Module 1 Digital maturity and strategy  Digital maturity scan results Assess your finance function’s digital maturity and analytics capability Digital strategy roadmap Develop a digital strategy to prepare your team to adopt new technology  Module 2 The finance team and the technological landscape  Data management and governance Find out how wellgoverned data can generate business insights and empower decision making Cybersecurity and the role of the CFO Explore the robust systems and processes you need to protect your company and its money Robotization Understand and learn how to implement RPA solutions AI for finance Discover the potentials of algorithms  generative AI and machine learning and how finance teams can adopt this Ethics in the digital age Define the organisational norms you need to maintain accountability through digital transformation  Module 3 Bring your finance team into the digital age  Digital leadership Get the right structure in place to make digital transformation successful Investing in innovative technologies Explore the upside of uncertainty and the value of managerial flexibility Digital strategy roadmap Prepare to transform your finance function   Develop a digital transformation strategy for your finance team Explore cloud technology  softbots  AI and other technology that will change the way finance teams work Better understand risks and ethical concerns in the digital age Learn how to lead and manage highperforming finance teams Use data and technology to become a more proactive business partner Gain the skills and confidence to lead your finance team and organisation through digital transformation   Executives with strategic and financial responsibilities Current CFOs or future CFOs – such as finance managers  finance directors and controllers Professionals with an interest in finance and technology – from a  variety of industries and sectors and from organisations of all sizes Professionals with 10 years’ management experience and strong financial acumen   Today’s  CFOs and finance managers need more than just technical knowledge To  help their organisations succeed they need financial expertise  strategic thinking technology insights and digital leadership skills This innovative digital finance course is designed to turn you into a  digital CFO It encourages you to think beyond finance You’ll learn to  embrace the technology that can help you become a more effective  leader guide your team through growth – and create longterm  sustainable value for your organisation httpswwwvlerickcomenprogrammesprogrammesinaccountingfinancedigitalfinance Get the skills and technologies to lead your team into the future courseBrusselsVlerick Business School,\n",
       " How to setup a Health Data Sharing Initiative  Part I before lunch Navigating the Roadmap of SettingUp a Health Data Sharing InitiativeDuring  this session  the participants will be introduced into the highlevel  roadmap of settingup a data sharing initiative We will delve into the  initial stages of ideation  missionvision definition  stakeholder  identification  and engagement strategies necessary to establish a solid  foundation required to successfully kickstart the initiativesAfterwards   we will introduce them into the process of finetuning the idea   governance principles  data collection  harmonization  quality  assessment  and finally  transforming data into insightful  visualizations  ensuring a holistic approach towards initiative setup Part II afternoon Practical Examples and HandsOn ExercisesSome  basic concepts of data handling and analyses will be explained through  simple handson exercises For example  participants will engage in  practical exercises involving transforming data from patientlevel to  aggregated  while also addressing concerns such as handling missing data  and ensuring data quality Next to this  we will explore how insights  can be visualized through a dashboard interface Important note  these exercises will be simple and will not require coding experience or expertise in data science  On Monday 22 April the Research Group in Biomedical Data Sciencesof UHasselt is organising a handson workshop called How to set up a health data sharing initiative in which participants will be through the various stages of successfully setting up and implementing this type of initiative We aim for peertopeer knowledge leveraging via a number of pioneers in the field as well as demonstrating a number of crucial concepts via simple exercises eg data missingness data aggregation and the visualisation of data via a dashboard inspired by the COVID19 in MS Global Data Sharing Initiative GDSI httpswwwuhasseltbeeninstitutenenbiomedenimmunologybiomedicaldatasciencesworkshophowtosetupahealthdatasharinginitiative Workshop workshopDiepenbeekHasselt University,\n",
       " Applied Artificial Intelligence  You already have a degree andor you are an innovative entrepreneur or ambitious business developer Youre passionate about technology and want to be a part of a quickly evolving world of AI Youre creative and a problem solver You enjoy analysing problems and finding systematic solutions You know the basics of programming No experience with programming We recommend finishing a oneyear programming course first Afterwards you can enrol for this postgraduate degree  You are expected to master the basics of programming  so what does this entail The postgraduate course is a very handson course During the  different workshops  you will usually use a computer and get to work  with Python You can find a lot of tutorials online about Python and  programming Main concepts you need to master are variables  basic  arithmic functions  string manipulations  looping and conditionals An extensive knowledge of Python is required as we use extended standard libraries during the classes Is attendance required for each class There is no obligation But the strength of the program is the  personal interaction with teachers and students All classes are also  professionally streamed and recorded if you cannot attend every class  live There are also group works  so your attendance is recommended for  those projects When do the classes take place Classes always take place on Tuesdays between 9 am and 6 pm at the latest  which allows for combination with work  What language is the course taught in All courses are taught entirely in English However  most teachers can also answer your questions in Dutch We provide you with the necessary tools  techniques and insights to become an allround player in the field of artificial intelligence The first semester will be all about the foundations of artificial intelligence with deep insights into data science  machine learning and big data The second semester will have a focus on practicality  where intelligent interfaces  NLP platforms  speech platforms  computer vision and robotics will be at the centre of our programme Finally  you also get the opportunity to gain experience in the field during an internship at an AI company AI fundamentals  During the introductory week you will be immersed in various aspects  of AI how does AI learn  which techniques and applications are there   and what are the pitfalls and limits that you have to take into account  Data Science  You become acquainted with the entire work chain of the data  scientist  from collecting and processing the data over modelling the  problem to deliver the result to the customer We always emphasize the  pitfalls and the boundaries of AI and we ensure that our results are  ethically responsible and safe  Machine Learning  We dig deeper into the core of AI machine learning We deal with  regression and classification  investigate the functioning of neural  networks  deep learning  genetic algorithms  clustering  etc We learn  to train models using existing libraries  considering the limitations of  the data set that we are starting from IoT  Big Data IoT is getting more and more important in our daily lives Smart  cities  industry 40  ehealth  the applications are countless Through  this evolution  loads of data are being created that all have to find  their way to the Cloud where they are processed into information that is  of interest to the user In this course we learn techniques to process  and visualize large amounts of data in an efficient way We are also  introduced to the newest trend of edge computing that places less  pressure on the Cloud  AI Project  In this course  you will be immersed in stateoftheart AI  technologies to prepare you to develop your own project independently or  as part of a team  under the guidance of our own AI experts Previous  student projects include  Smart Home with an AI model to manage your electricity use  AI Platform that teaches you signlanguage  Drones that follow you based on facial recognition  And many more  Machine Learning Operations MLOps In the professional and academical world a lot of models are created  but only a few make it to deployment andor production environment The  reason for this is that most AIexperts still manually organise their  worksflows Machine Learning Operation MLOps should bring an end to  this In this course we talk about the challenges within MLOps  the  workflows and we will use industry standard MLOps tools Internship Optional  The internship offers students a unique opportunity to gain several weeks of handson experience at leading companies such as ML6  Imec and Humanai Students work on real AI projects  learn from experts and expand their professional network This handson experience allows students to apply their acquired knowledge  gain insight into the daytoday practice of AI and prepare for a successful career while making valuable connections with potential employers in the industry After completing our postgraduate degree in Artificial Intelligence  students will have the crucial knowledge and skills to be successful in the AI domain They will be able to apply machine learning and deep learning techniques  develop effective solutions to complex problems and integrate ethical considerations into AI applications In addition  our programme offers extensive networking opportunities and access to top industry companies  such as ML6 Check out the blog where one of our students shares his inspiring internship experience at ML6  where he gained valuable handson experience and contributed to pioneering projects Invest in your future and open the door to a rewarding career in the fastgrowing world of artificial intelligence with our postgraduate degree  More info  Share this course   httpswwwerasmushogeschoolbeenprogrammespostgraduateappliedartificialintelligence 1 Oct 2024  31 Aug 2025 postgraduateBrusselsErasmushogeschool Brussel,\n",
       " Supervised machine learning with tensor network kernel machines  In this talk Kim Batselier will introduce tensor network kernel machines These models are able to learn nonlinear patterns from data for both regression and classification tasks and are described by an exponential amount of model parameters Livedemos will show that such models can be learned efficiently and at the same time achieve stateofthe art performance on validation data  In this talk Kim Batselier will introduce tensor network kernel machines These models are able to learn nonlinear patterns from data for both regression and classification tasks and are described by an exponential amount of model parameters Livedemos will show that such models can be learned efficiently and at the same time achieve stateofthe art performance on validation data httpshomesesatkuleuvenbesistawwwbdmbacktotherootsindexphpseminars Seminar by Kim Batselier Delft University of Technology seminarHeverlee LeuvenKU Leuven ESAT STADIUS,\n",
       " Generative AI for Everyone  Instructed by AI pioneer Andrew Ng  Generative AI for Everyone offers  his unique perspective on empowering you and your work with generative  AI Andrew will guide you through how generative AI works and what it  can and can’t do It includes handson exercises where you’ll learn to  use generative AI to help in daytoday work and receive tips on  effective prompt engineering  as well as learning how to go beyond  prompting for more advanced uses of AI You’ll delve into realworld applications and learn common use cases   and get handson time with generative AI tools to put your knowledge  into action  and gain insight into AI’s impact on both business and  society This course was created to ensure everyone can be a participant in our AIpowered future Generative AI ToolsAI Strategy for Work and BusinessAI StrategyHow Generative AI WorksAI ProductivityAI Beyond Prompting Generative AI for Everyone is for anyone who’s interested in learning about the uses  impacts  and underlying technologies of generative AI  today and in the future It doesn’t require any coding skills or prior knowledge of AIFor business leadersLearn how generative AI can impact your business  and how to develop generative AI strategy to increase productivityFor professionalsReady to use AI at the workplace This course offers you an overview of AI tools and techniques that you can apply in your workFor everyoneAI is a transformative technology that will impact everyone Understanding how it works and how to use it puts you in the drivers seat  More info  Share this course   httpswwwdeeplearningaicoursesgenerativeaiforeveryone Learn how generative AI works and how to use it in your life and at work courseonlineDeepLearningAI,\n",
       " Machine Learning with Python    Tackle the analytical part of data mining projects                               Description Many modern digital applications increasingly rely on machine learning as a means to derive predictive strength from highdimensional data sets Compared to traditional statistics  the absence of a focus on scientific hypotheses  and the need for easily leveraging detailed signals in the data require a different set of models  tools  and analytical reflexes This course aims to bring participants to the level where they can independently tackle the analytical part of data mining projects This means that the most common types of projects will be addressed  regressiontype with continuous outcomes  classification with categorical outcomes  and clustering For each of these  the practical use of a set of standard methods will be shown  like Random Forests  Gradient Boosting Machines  Support Vector Machines  kNearestNeighbors  Kmeans  Furthermore  throughout the course  concepts will be highlighted that are of concern in every statistical learning applications  like the curse of dimensionality  model capacity  overfitting and regularization  and practical strategies will be offered to deal with them  introducing techniques such as the Lasso and ridge regression  crossvalidation  bagging and boosting Instructions will also be given on a selection of specific techniques that are often of interest  such as modern visualization of highdimensional data  model calibration  outlier detection using isolation forests  explanation of blackbox models  Finally  the last lecture will introduce the idea of deep learning as a powerful tool for data analysis  discussing when and how to practically use it  and when to shy away from it Target audience This course targets professionals and investigators from all areas that are involved in predictive modeling based on large andor highdimensional databases Fees The participation fee is 1470 EUR for participants from the private sector Reduced prices apply to students and staff from nonprofit  social profit  and government organizations An exam fee of 35 EUR will be applied Industry  private sector  profession € 1470Non profit  government  higher education staff € 1105Doctoral students  unemployed € 600If two or more employees from the same company enrol simultaneously for this course a reduction of 20 on the course fee is taken into account starting from the second enrolment Registration More information and registration on our BetaAcademy website  Tackle the analytical part of data mining projects httpsbetaacademyugentbeenprogramshortandlongrunninginitiatives202320242024m12pymodule12machinelearningwith Tackle the analytical part of data mining projects courseGhentUGent,\n",
       " Digital Marketing  In a careful blend of two online and three oncampus modules  you’ll develop the knowledge and skills to make informed decisions and create strategies that are resilient and adaptable in a constantly changing digital environment Module 1 Introduction to digital marketing online  Be inspired by new trends and technologies – and understand their impact on customer behaviour Discover how to create a digital marketing strategy which tells a consistent story across all channels  Module 2 Acquiring customers via digital channels  Explore the benefits of outbound digital marketing and the value of digital ad platforms Understand the power of content marketing – and the role that generative AI can play Discover how to improve website user experience through AB testing  Module 3 Customer conversion and retention  Dive into CRMs and customer data platforms – and how they can power segmentation and personalisation Discover how to automate personalised communications Use big data and AI to boost customer loyalty Explore how to enhance brand advocacy through word of mouth and influencer marketing  Module 4 Online simulation online  Gain handson experience of handling common digital marketing challenges Develop your decisionmaking skills  Module 5 Reviewing your digital marketing strategy  Discover how to measure effectiveness Develop a clear view of the competitive advantage of omnichannel marketing   Embrace marketing technologies and discover how they can power  lead generation  increase conversion  and enhance loyalty and advocacy Develop an integrated  competitive  differentiating digital marketing strategy that’s aligned to your context Leverage AI and generative AI to drive efficiency Learn how to develop greater customer insight and articulate a  single customer view to improve personalisation of marketing  communications Discover how to balance marketing budget across multiple channels Apply everything you’ve learned in a handson  riskfree learning experience   Marketers from B2B and B2C organisations who want to develop a  strategic understanding of digital marketing – and support their teams  to implement it Advertising managers  brand managers  CRM specialists  channel  marketers and ecommerce specialists who need to create a digital  marketing strategy Agency owners  content marketers  marcomms specialists Owners of startups and scaleups who want to increase their customer reach through digital channels   If  your digital marketing efforts are focused on channels it may be time  to reboot your strategy This programme sets out a holistic powerful  and integrated approach to digital marketing that can transform your  results You’ll learn how to develop a robust strategy allocate budgets  improve your customer experience keep up with latest trends and grow  your business All of this is underpinned with a clear understanding of  AI big data and other technologies httpswwwvlerickcomenprogrammesprogrammesinmarketingsalesdigitalmarketing Learn to create futureproof technologyenabled digital marketing strategies courseonline amp GhentVlerick Business School,\n",
       " Current Trends in AI  Advanced GenAI 17 April 2024  12301530h Dr Thomas Winters These  days  we are surrounded by creative text and image generators like GPT  and diffusion models that seem to be able to generate anything we want  But how do we ensure that these types of AI truly aid us in overcoming  our unique challenges This talk sheds light on several techniques for  controlling such generative models We look at several powerful prompt  engineering techniques – the art of enhancing our communication with AI –  and useful ways of connecting these generators to other systems We  dive into the world of autoregressive text generators  learn their inner  mechanisms and which training phases they went through to get to the  current stateoftheart text generators These insights help us  understand why certain prompt engineering techniques such as fewshot  prompting  roleprompting and chainofthought prompting are able to  outperform simpler prompting methods We also briefly look at several  other techniques to overcome the limitations of such models  such as  retrievalaugmented generation and function calling Similarly  we  uncover the workings of diffusion models and show several techniques to  gain more control over the generated images We show how even some of  AIs classic hard problems  such as humour generation  become even more  within reach thanks to these large language models and their prompt  engineering techniques Knowledge Graphs 17 April 2024  16001900h Prof Pieter Bonte and prof Anastasia Dimou Knowledge  graphs have become the ultimate technology for unlocking the full  potential of your data  illuminating the connections between entities   attributes  and relationships with unparalleled clarity Sharing   exchanging data  harvesting insights  driving innovation  fostering  integration  and revolutionizing data exploration  knowledge graphs pave  the way for transformative discoveries and understanding In this seminar  the following topic will be tackled Introduction to knowledge graphsSemantic Web basics RDFFrom raw data to knowledge graphs with R2RMLUnlocking insights with querying through SPARQL MLOps 25 April 2024  12301530h Prof Mathias Verbeke and drs Lara Luys One  of the main challenges for industry today is to get machine learning  models out of the proofofconcept phase and into production This is  not an easy task since data in production is not static  due to which  the model performance can degrade over time Machine learning operations  or MLOps is a paradigm that aims to address this problem Being a  contraction of Machine Learning and DevOps  MLOps focuses on developing  and maintaining machine learning models in production This includes  training  evaluating as well as monitoring the model In this seminar   the MLOps pipeline and the underlying principles will be explained   illustrated by means of a number of tools that can be used in the MLOps  process AIEdge 25 April 2024  16001900h Prof Hans Hallez and drs Gregory De Ruyter Edge  Computing has been proven to be an optimised way to delegate  computation from the cloud towards the devices where the sensing takes  place Edge computing on embedded devices mostly limits itself towards  compression  filtering or other basic analysis Recent trends also show  that devices near the edge of the sensor network are capable of machine  learning algorithms In this session  we will explore different  techniques to bring machine learning towards the edge network and deploy  these algorithms First  we will give an overview of what embedded  devices are  and how we can perform machine learning at these devices  both in inference and in training Second  we will give a handson  demonstration as an inspiration of how machine learning at the edge can  be implemented  The world of artificial intelligence evolves at an astonishing speed For those working with AI on a daily basis staying up to date with the newest techniques within various domains is a challenge In this seminar series academic experts will bring you up to speed with the hottest topics Advanced GenAI Knowledge Graphs MLOps and AIEdge All seminars include a handson component httpspuckuleuvenbenlopleidingcurrenttrendsinaikwdjog3exxqm4807 Bring AIprofessionals up to speed with the latest developments in the field lezingenreeksBruggeKU Leuven Postuniversitair Centrum VAIA,\n",
       " Interior AI  Take a picture of your room with or without furniture  choose your  favorite style and voilà  the system draws a new interior for you  More info  Share this course   httpsinterioraicom Generate interior ideas for your home ToolOnlineby Levelsio,\n",
       " An Introduction to ChatGPT  ChatGPT  by OpenAI  is a conversational language model that has gripped headlines worldwide  placing the power of AI at your fingertips In this course  you’ll learn everything you need to know to begin using ChatGPT effectively and responsibly No prior knowledge is required Start learning about the capabilities and limitations of ChatGPT today  so you can start effectively leveraging the power of AI Get ready to take your workflows and business processes to the next level with the groundbreaking conversational language model  ChatGPT In this course  youll dive headfirst into the exciting world of generative AI and discover how to wield ChatGPT like a pro From text summarization  explaining complex concepts  drafting engaging marketing content  and generating and explaining code  youll learn about the most common applications of ChatGPT Plus  you’ll be equipped with a framework to evaluate new use cases and determine if ChatGPT is the right solution for your needs Finally  youll explore the legal and ethical considerations that come with implementing ChatGPT in various situations Dont miss out on this opportunity to unlock the full potential of ChatGPT and revolutionize the way you work  More info  Share this course   httpswwwdatacampcomcoursesintroductiontochatgptutmsourcecustomerioutmmediumemailutmcampaign2303211newsletterreg2b2c3all4na5na6dcinsights7na8emalci9na10bau11emailutmcontentblastutmtermspotlight pChatGPT by OpenAI is a conversational language model that has gripped headlines worldwide placing the power of AI at your fingertips In this course you’ll learn everything you need to know to begin using ChatGPT effectively and responsibly No prior knowledge is required Start learning about the capabilities and limitations of ChatGPT today so you can start effectively leveraging the power of AIp  course 1 hourOnlineDatacamp,\n",
       " Data for policy 2024  Decoding the Future Trustworthy Governance with AI  We invite researchers  practitioners  and policymakers to join us in charting a path towards more trustworthy decisionmaking and governance with the transformative potential of AI We are seeking conference submissions that transcend boundaries  from cuttingedge generative AI technologies reshaping governmentcitizen interactions to enhanced surveillance capabilities that influence centralised power dynamics In a world where AIpowered technologies are becoming integral to critical decisionmaking processes  it is time to chart a new course We welcome submissions covering a wide range of topics  including but not limited to AI applications for policy formulation and implementationImpact of Generative AI on public service delivery and citizen engagementMachine agency in governance and decisionmakingHumanAI collaboration and decisionmaking in governanceAIdriven decision support systems for public administrationLegal and regulatory frameworks for AI in governanceSafety  transparency  fairness  accountability  and trust in AIdriven decisionmakingData  and infrastructure technologies working in tandem with AI to transform  decisionmaking in governance chatbots  platforms  distributed ledger  systems  digital twins  augmented reality  etcGovernance  models and frameworks for effective utilisation of AI options in  decisionmaking processes to enhance good governance practices The Data for Policy conference series is the premier global forum for  multiple disciplinary and crosssector discussions around the theories   applications and implications of data science innovation in governance  and the public sector The general chairs Dr Zeynep Engin Founder  Data  for Policy  Jon Crowcroft University of Cambridge and Stefaan  Verhulst NYU are delighted to be working with local chairs from our  host Imperial College  Professor Mark Kennedy and Dr Rosella Arcucci for  the 2024 edition in this conference series Data for Policy is an  independent nonprofit initiative  registered as a community interest  company in the UK For any enquiries or further information  please contact teamdataforpolicyorg or check httpsdataforpolicyorgdata We welcome submissions covering a wide range of topics  including but not limited to AI applications for policy formulation and implementationImpact of Generative AI on public service delivery and citizen engagementMachine agency in governance and decisionmakingHumanAI collaboration and decisionmaking in governanceAIdriven decision support systems for public administrationLegal and regulatory frameworks for AI in governanceSafety  transparency  fairness  accountability  and trust in AIdriven decisionmakingData and infrastructure technologies working in tandem with AI to transform decisionmaking in governance chatbots  platforms  distributed ledger systems  digital twins  augmented reality  etcGovernance models and frameworks for effective utilisation of AI options in decisionmaking processes to enhance good governance practicesThe Data for Policy conference series is the premier global forum for multiple disciplinary and crosssector discussions around the theories  applications and implications of data science innovation in governance and the public sector The general chairs Dr Zeynep Engin Founder  Data for Policy  Jon Crowcroft University of Cambridge and Stefaan Verhulst NYU are delighted to be working with local chairs from our host Imperial College  Professor Mark Kennedy and Dr Rosella Arcucci for the 2024 edition in this conference series Data for Policy is an independent nonprofit initiative  registered as a community interest company in the UK For any enquiries or further information  please contact teamdataforpolicyorg or check httpsdataforpolicyorgdata Standard tracks Data for Policy has six nondomain specific and overarching areas of interest for the conference and journal The areas are interrelated and do not indicate siloed activity They are rather an articulation of the breadth and depth of the vision and mission for improved datadriven decisions and policymaking  which is the ethos of the Data for Policy community The six areas are the bases for the conference’s standard tracks  as follows AREA 1 DIGITAL  DATADRIVEN TRANSFORMATIONS IN GOVERNANCE From data to decisions knowledge generation and evidence formationProcess  psychology and behaviour of decisionmaking in digital eraGovernment operations and servicesGovernmentcitizen interactions and open governmentDemocracy  public deliberation  public infrastructure  justice  mediaPublic  private and voluntary sector governance and policymakingAREA 2 TECHNOLOGIES  ANALYTICS Data Science and Artificial IntelligenceBehavioural and predictive analyticsLarge language models – foundation modelsDigital Twins  Ledger Systems  Platforms  Cloud Technologies etcEdge analytics and federated learningUser interaction and experienceGovTech  RegTech  LegalTech  CivicTech etcAREA 3 POLICY  LITERACY FOR DATA Governance  law and management of data and associated technologiesDesign principles and impact assessmentLiteracy  translation  communicationIntermediaries  trusts  collaborativesRegulation of databased services and processesOpen science  open research infrastructure  and FAIR Findable  Accessible  Interoperable and Reusable practiceAREA 4 ETHICS  EQUITY  TRUSTWORTHINESS Privacy  data sharing and consentUncertainties  error and\n",
       " bias in datadriven processesHuman rights  values and selfdeterminationInformation and power asymmetryResponsibility  benevolence  and maliciousnessFairness  transparency  explainability  accountability  interpretability and reliabilityValidation  assurance and certification of datadriven servicesAREA 5 ALGORITHMIC GOVERNANCE Automation of governmentgovernance processes and servicesGood governance throughwithbyof algorithmsAlgorithm agency in decisionmaking potentials and perilsAlgorithmic behaviour in socioeconomic contextsHuman agency in algorithmic governanceHumanmachine collaboration models in critical decisionmakingAREA 6 GLOBAL CHALLENGES  DYNAMIC THREATS Human existence and the planetInequalities and discriminationSustainability and environmentGlobal shocks and resiliencePopulation health and pandemicsSecurity  organised crime and hostile environmentsInternational collaboration  The Data for Policy conference series is the premier global forum for multiple disciplinary and crosssector discussions around the theories applications and implications of data science innovation in governance and the public sector The general chairs Dr Zeynep Engin Founder Data for Policy Jon Crowcroft University of Cambridge and Stefaan Verhulst NYU are delighted to be working with local chairs from our host Imperial College Professor Mark Kennedy and Dr Rosella Arcucci for the 2024 edition in this conference series Data for Policy is an independent nonprofit initiative registered as a community interest company in the UK We invite researchers practitioners and policymakers to join us in charting a path towards more trustworthy decisionmaking and governance with the transformative potential of AI We are seeking conference submissions that transcend boundaries from cuttingedge generative AI technologies reshaping governmentcitizen interactions to enhanced surveillance capabilities that influence centralised power dynamics In a world where AIpowered technologies are becoming integral to critical decisionmaking processes it is time to chart a new course httpsdataforpolicyorg2024registration We are delighted to launch Data for Policy 2024 in collaboration with Imperial College London and Cambridge University Press ConferenceLondonData for Policy,\n",
       " AI in Healthcare Hype or Help  Christos Chatzichristos of kuleuven and VAIAcad explains how the use of Artificial Intelligence AI in healthcare is revolutionizing the way medical professionals provide care to patients From diagnosis to treatment  AI can help doctors and other healthcare professionals make more informed decisions  ultimately leading to better patient outcomes  More info  Share this course   httpswwwyoutubecomwatchvA28i8BnibPo Discover how AI is making healthcare more personalised more objective and more preventive webinarSkillstown amp VAIA,\n",
       " HumanRobot Collaboration  Robots are becoming an integral part of our economy  society and planet  assisting us in various tasks However  the rapid growth in robotics usage has also given rise to relevant concerns regarding sustainability At present  urgent issues such as rareearth material usage  ewaste  energy efficiency and ethical concerns hinders the sustainable development of robotics As we increasingly rely on robotics  it becomes increasingly critical and urgent to ensure that these technological advancements are sustainable and ecofriendly Since robotics is the integration of many technologies  we will discuss in this Forum sustainable robotics technologies ranging from material science  material processing and metal  electronics with sensors and processing  actuators  energy  power and batteries and control and artificial intelligence Programme will be announced soon Organised by General Chair  Prof An Jacobs VUB   Program Chair Dr Shirley Elprama VUB Program Committee members Prof Bernardo Innocenti ULB  Prof Tamas Heidegger Obuda University  Hungary  More info  Share this course   httpswwwbriasbeenbriasforumonhumanrobotcollaboration 26 Apr 2024 0900  1700 seminaronline amp BrusselsBrussels Institute of Advanced Studies BrIAS FARI,\n",
       " Law Ethics and Policy of Artificial Intelligence  In 2021  KU Leuven organised the first edition of the Summer School  on the Law  Ethics and Policy of Artificial Intelligence AI Given the  programmes overwhelming success  three editions have taken place thus  far The fourth edition will take place from 1 to 10 July 2024 The Summer School aims to provide a comprehensive overview of the  various legal  ethical and policyrelated issues around AI and  algorithmdriven processes more broadly As these technologies have a  growing impact on all domains of our lives  it becomes increasingly  important to map  understand and assess the challenges and opportunities  they raise This requires an interdisciplinary approach  which is why  we are collaborating across faculties and departments to organise this  Summer School The programmes goal is to offer participants the latest  insights on AI from various perspectives  and in particular the fields  of law  ethics and policy  The lectures are provided by renowned academics  policymakers from  EU and international institutions as well as practitioners  allowing  participants to grasp not only the theoretical but also the practical  implications of the use of AI in these fields  The Summer Schools intended audience concerns postgraduate students  who already obtained a masters degree and juniorsenior researchers  from various disciplines  as well as policy analysts  lawyers and legal  experts  civil servants  members of civil society organisations  AI  practitioners  and other professionals with an interest in broadening  their understanding of AI and its impact on society  Participants receive a certificate of attendance with the equivalence  of 3 ECTS credits Those interested also have an opportunity to share  their research with fellow participants through a research presentation  session  Thus far  the Summer School has taken place as a hybrid event  enabling participants to join both on campus and online  Whether physically or virtually  we look forward to welcoming you to Leuven Course overview The Summer School covers a range of topics that will enable  participants to better grasp the various legal  ethical and policy  implications of the development and use of AI in society All lectures  are taught in English The schedule of the Summer Schools 2023 edition can be found here Most lectures focus on horizontal domains of interest  covering topics such as  Philosophy of AI Ethics of AI AI and Data Protection Law AI and Competition Law AI and Intellectual Property Law AI and Consumer Protection AI and Liability Law AI and Labour Law AI and Fairnes The European Commissions proposals for an AI Regulation  the Digital Services Act  the Digital Markets Act AI governance and the role of European  International institutions  Though Artificial Intelligence is a general purpose technology  many  of its legal  ethical and policyrelated implications are context or  sectorspecific Therefore  the programme also explores several vertical  domains These cover inter alia  AI and Law Enforcement AI and Public Services AI and Warfare AI and Healthcare AI and Education AI and Legal Tech  At the end of the course  participants who attended 90 of the  classes and passed the exam receive a certificate of attendance with an  equivalence of 3 ECTS credits Those interested will also have the  possibility to present their own research during a research presentation  session  Intended Audience The Summer School’s intended audience concerns postgraduate students  who already obtained a masters degree and PhD researchers from various  disciplines  as well as more senior researchers  policy analysts   lawyers and legal experts  civil servants  members of civil society  organisations  AI practitioners  and other professionals with an  interest in broadening their understanding of AI and its impact on  society Programme Format  Location In the past  the Summer School was organised as a hybrid event  enabling participants to join either on campus or online  The lectures take place at the KU Leuven Faculty of Law College De Valk  DV3 Faculty of Law  KU Leuven Tiensestraat 41 3000 Leuven Belgium The application process for the Summer Schools 2024 edition will run from 19 February to 27 March 2024 If you would like us to keep you posted  you can register your interest here Application process In their application form  applicants are asked to provide  A cover letter of max 500 words explaining their background and motivation for enrolling to the Summer School A CV in PDF format and At  least one letter of recommendation in PDF format including the  signatorys name  title and signature Depending on your profile  the  recommendations can be academic or professional in nature  The results of the selection process will be communicated to applicants by midApril Places  in the programme are limited to ensure the quality and depth of the  interactions and discussions English proficiency is required though no  certificate of language proficiency will be asked In addition to the quality of applications  the selection committee also aims to ensure a diverse cohort of participants Tuition fees In  2024  the Summer School will once again be offered in a hybrid format   In the application form  applicants will be able to indicate their  preferred participation format or indicate that they would be happy to  participate in either format Here below we list the tuition fees in each case 1 Tuition fees for the on campus programme  For postgraduate  PhD students €825 For senior researchers  civil servants and employees of civil society organisations €995 For other professionals €1250  This  fee includes all the classes and course materials  lunches  coffee  breaks  social activities and a closing dinner It also includes the  certificate of attendance with the equivalence of 3 ECTS credits Note  that this fee does not include accommodation For information about  accommodation in Leuven  please consult the KU Leuven housing website 2 Tuition fees for the online programme  For postgraduate  PhD students €595 For senior researchers  civil servants and employees of civil society organisations €750 For other professionals €995  This  fee includes all the classes and course materials  access to the online  learning platform  and a certificate of attendance with the equivalence  of 3 ECTS credits  We reserve the right to only offer the programme on campus  depending on the amount of online applications received  The general terms and conditions for enrolling in certified continuing education programmes at KU Leuven can be found here Please note the following cancellation policy  Until 24 May 2024 50 reimbursement of the tuition fee From 25 May 2024 no reimbursement of the tuition fee  Scholarships This  year  we expect to be able to offer three scholarships in the form of a  tuition fee waiver  aimed at ensuring that meritorious applicants who  would otherwise not be able to afford the course  can  nevertheless participate In their application form  those applying for a  scholarship will be able to upload an additional letter in which they  set out the reasons why they believe to be eligible for a tuition fee  waiver In addition  successful applicants from LDC countries will receive a tuition fee discount of €150  Get a comprehensive overview of the various legal ethical and policyrelated issues around AI and algorithmdriven processes more broadly As these technologies have a growing impact on all domains of our lives it becomes increasingly important to map understand and assess the challenges and opportunities they raise The programmes goal is to offer participants the latest insights on AI from various perspectives and in particular the fields of law ethics and policy httpswwwlawkuleuvenbeaisummerschooldescriptionai Summer School Law ethics and policy of AI summer schoolLeuvenKU Leuven,\n",
       " A NoCode Approach to Decision Support and Knowledge Capturing  In their daytoday operations  companies typically make many small but important decisions  such as  which employee should handle an incoming requestwhich service should be recommended to a specific customerhow should a specific product be configured to meet a customers requirement whether a specific customer is entitled to a discount  etc  Decision  support systems can help employees make these decisions faster  more  reliably and more consistently  reducing costs and increasing confidence  in the process To develop such systems  blackbox AI methods such as  deep learning are not wellsuited  because they lack the required  transparency and explainability A more promising approach are  knowledgebased AI systems  which derive their intelligence not from  data  but from logical models of rules  regulations and expert  knowledge In this workshop  you will get to know the  stateoftheart IDP knowledgebase system  developed at KU Leuven It  is currently being used by companies in the manufacturing httpswwwyoutubecomwatchvkpPe0GRjifE  financial httpsyoutubeZzsy4MtdWBE  and legal sectors to provide various decision support  both to their  customers and inhouse This system is based on methods and techniques  that were developed for declarative programming systems such as Prolog   but it offers a number of important innovations 1 instead of focusing  only on querying  the IDP system provides a wide range of different  functionalities that can be used to implement rich interactive  interfaces that support users in different workflows  2 instead of  relying on programmers  the system allows its end users to maintain the  underlying knowledge base  which means that we can cut out the middle  man of IT staff and allow the business experts themselves to update the  system  thereby not only reducing cost and turnaround time but also  putting the ownership of the decision knowledge in the right hands The  workshop starts with a brief introduction to Knowledgebased AI and  presents existing applications in the financial and manufacturing  sectors We then proceed with a handson tutorial  using a freely  available web interface that participants access from their own laptops  In this workshop you will get to know the stateoftheart IDP  knowledgebase system that has been developed at KU Leuven and is  currently used by companies in various sectors You will be able to build basic applications using IDP and you will be able to identify potential use cases for this technology httpspuckuleuvenbenlopleiding6kjpeqerb3gbx7zo Workshop workshopBruggeKU Leuven Postuniversitair Centrum VAIA,\n",
       " Privacy by design a technical approach to privacy risk  Since the implementation of the GDPR in 2018  GDPR  sets the legal framework for protecting personal data It requires  appropriate technical measures and privacy bydefault and bydesign  approaches to be implemented In this session  well dive deeper in the  world of privacy by design We tackle concrete guidelines on how to  incorporate privacy by design in your development process This will  include Privacy engineering 101 why  what  howPrivacy threat modeling as guidePrivacy Enhancing Technologies deidentification techniques  privacypreserving solutionsIntegrating privacy in your secure development lifecycle This session is part of the series Cybersecurity excellence Session 1 Tackling cybersecurity challenges a complex security puzzle  28 February 2024  Vincent Naessens KU LeuvenSession 2 ‘Privacy by design a technical approach to privacy risk  26 March 2024  Kim Wuyts PwCSession 3 Efficient use of a network protocol analyzer in cyber threats workshop  24 April 2024  Tom Cordemans KU LeuvenSession 4 Hacking and protecting embedded devices workshop  29 May 2024  Jorn Lapon KU LeuvenSession 5 EU cybersecurity standards and regulation for IoT ecosystems and Industrial Control Systems  28 August 2024  Vincent Naessens KU LeuvenSession 6 Cyberattack response  25 September 2024  Tom Bauwens Eubelius  Kalman Tiboldi TVHSession 7 Postquantum cryptography  23 October 2024  Eric Michiels IBM  More info  Share this course   httpspuckuleuvenbenlopleidingprivacybydesignatechnicalapproachtoprivacyrisk5zexkgzr5kloyb68 26 Mar 2024 1400  1700 trainingGhentKU Leuven Postuniversitair Centrum,\n",
       " Hacking and protecting embedded devices  The Internet of Things IoT presents significant opportunities for businesses  but it also introduces unique and new security challenges ‘Smart’ devices connected to the internet serve as potential entry points for cybercriminals and can render your company exceptionally vulnerable Enhanced cybersecurity for embedded devices and systems is therefore essential In this workshop  you will gain practical insights into security issues related to embedded systems We will delve into seven typical IoT hacks  providing you with handson knowledge of common vulnerabilities in embedded devices  contemporary attacks  and security technologies Additionally  you will become familiar with security guidelines OWASP for designing  developing  and maintaining new embedded systems By the end of the workshop  you will have the expertise to detect common vulnerabilities and enhance the security of embedded devices This session is part of the series Cybersecurity excellence Session 1 Tackling cybersecurity challenges a complex security puzzle  28 February 2024  Vincent Naessens KU LeuvenSession 2 ‘Privacy by design a technical approach to privacy risk  26 March 2024  Kim Wuyts PwCSession 3 Efficient use of a network protocol analyzer in cyber threats workshop  24 April 2024  Tom Cordemans KU LeuvenSession 4 Hacking and protecting embedded devices workshop  29 May 2024  Jorn Lapon KU LeuvenSession 5 EU cybersecurity standards and regulation for IoT ecosystems and Industrial Control Systems  28 August 2024  Vincent Naessens KU LeuvenSession 6 Cyberattack response  25 September 2024  Tom Bauwens Eubelius  Kalman Tiboldi TVHSession 7 Postquantum cryptography  23 October 2024  Eric Michiels IBM  In an increasingly technologydriven world cybersecurity stands as the cornerstone of digital resilience In this programme we will explore the full spectrum of cybersecurity from prevention to response while gaining both immediate handson skills and a foresight for the future of cybersecurity This programme brings together academic researchers and industrial experts and thus provides a blend of lectures and use cases and practical testimonials httpspuckuleuvenbenlopleidinghackingandprotectingembeddeddevicesworkshopj5no0lj0prgwmp9b Session 4  Cybersecurity excellence series 2024 workshopGhentKU Leuven Postuniversitair Centrum,\n",
       " Defining Responsible AI strategies  This course will be given by Johan Loeckx at the FARI Test  Experience Center Cantersteen 16  1000  Brussels on Wednesday 24 April 2024 from 900 to 1600 – lunch not included The training will provide CEOs with toolkits that allow them to  design a highlevel strategy for AI The toolkits are designed to  understand their current position  explore opportunities  the impact on  their organisation  and most importantly  draw a roadmap of innovation  actions Purpose Introduce toolkits to define AI strategies that boost your business Target audience This executive masterclass is intended for CEOsGeneral directors of medium to large SMEs  who wish to transform their business with AI This training is for you if… – Your competitors investing in AI – You need to scale – You are confronted with a lack of talent – You wish to create new revenue streams from your data – You encounter too much variability in your processes – You need to develop new capabilities to stay competitive – You lack highquality insights to improve your bottom line  quality  or efficiency – You need better customer experience As FARI is supported by the European Resilience  Recovery Fund RRF  we can continue to offer free access to participants from public administrations public institutions and research institutions We can also provide a 50 discount to participants from the following target groups Educational institutionsNGOs and nonprofit organisationsBrussels based companiesBrussels citizens  More info  Share this course   httpswwwfaribrusselseducationdefiningresponsibleaistrategies 24 Apr 2024 0900  1600 executive masterclassBrusselsFARI,\n",
       " Thats AI  That’s AI is your introduction to the world’s most important technological development Find out how AI is transforming everything around us and learn how to become an active participant in this exciting new world  More info  Share this course   httpswwwthatsaiorg Explore the fascinating world of Artificial Intelligence IntroductiecursusOnlineEPFL Extension School,\n",
       " Digital Strategy amp AI  Over six modules  this programme equips you with insights and tools to drive your organisations digital and AI strategy Module 1 Introduction to Digital Strategy and AI Dive into what digital and AI strategy is and why its importantExplore digitalisation and how it can transform your organisation Module 2 The Context of Digital and AI Strategy Understand the building blocks of an effective digital and AI strategyExplore how digitalisation can impact an organisation’s strategy  performance and boost its sustainability Module 3 Digitalisation of Work Discover how AI and digitalisation impact how work gets doneLearn how to digitalise work Module 4 Digitalisation of Products  Processes and Business Models Identify digital and AI innovation initiatives that enhance performance and support strategic prioritiesLearn how to leverage digital technology to transform processes  products and services  and business models Module 5 Organising for Digital  AI Strategy  and Initiatives Discover how to strategise and organise for implementing digital strategy and AI strategy effectively Module 6 Evaluating Digital Strategy  AI and Initiatives Discover how to sustain a competitive advantage through the use of digital technologies and artificial intelligenceExplore ways to measure and evaluate the success of digital and AI initiatives Gain a thorough understanding of how digital and generative AI are different and drive performanceIdentify digital and AI initiatives to transform work  products  processes  and business modelsDevelop a thorough knowledge of how to prioritise digital and AI strategy initiatives and evaluate success   Executives  general managers or managing directors who want to build or stress test a digital and AI strategy Strategy  Innovation  Marketing  IT or other directors or managers involved in driving digital and AI strategy Professionals and entrepreneurs who are fascinated by the impact  of digital and AI technology on business and want to capitalise on  digital disruption Professionals who are keen to stay ahead in today’s digital global marketplace   Digital strategy and AI is changing how we do business – and no industry is immune to its power This programme for business professionals gives you a comprehensive understanding of how digital technology and artificial intelligence can support your strategic priorities You’ll live and learn the key principles of digital strategy and AI – and gain the knowledge skills and insights to take the leap into giving your organisation a sustainable competitive edge httpswwwvlerickcomenprogrammesprogrammesindigitaltransformationdigitalstrategyandai Discover how to outperform your competition courseGhentVlerick Business School,\n",
       " Cyberattack response  In this session  we provide a comprehensive guide on  effectively responding to cyberattacks within the bounds of the law  The presentation explores the intricate web of legal considerations that  accompany cyber incidents  delving into the realms of criminal law   data protection  privacy laws  and regulatory compliance together with  all other possible side effects  We begin by dissecting the  anatomy of a cyberattack through an incident response plan A  significant portion of the lecture is dedicated to the legal framework  surrounding cyberattacks This includes an examination of data breach  notification requirements  both domestically and internationally  as  well as an exploration of the evolving landscape of cyberrelated  legislation The discussion extends to the legal obligations imposed on  organisations  shedding light on potential liabilities and consequences  for noncompliance  Furthermore  the lecture addresses  upon  experiences learned  the critical role of digital forensics in incident  response and legal proceedings We gain an understanding of best  practices for preserving electronic evidence  ensuring its admissibility  in court  and collaborating with law enforcement agencies The lecture  also focuses on the postincident phase  elucidating the legal aspects  of breach disclosure  communication strategies  and managing  reputational fallout Practical guidance on engaging with regulatory  bodies  law enforcement  and legal counsel is provided  offering a  roadmap for a coordinated and lawful response to cyber incidents  To  conclude  we get a firsthand account from a company TVH that has  experienced a cyberattack and that has been through the challenges of  postattack damage control  This session is part of the series Cybersecurity excellence Session 1 Tackling cybersecurity challenges a complex security puzzle  28 February 2024  Vincent Naessens KU LeuvenSession 2 ‘Privacy by design a technical approach to privacy risk  26 March 2024  Kim Wuyts PwCSession 3 Efficient use of a network protocol analyzer in cyber threats workshop  24 April 2024  Tom Cordemans KU LeuvenSession 4 Hacking and protecting embedded devices workshop  29 May 2024  Jorn Lapon KU LeuvenSession 5 EU cybersecurity standards and regulation for IoT ecosystems and Industrial Control Systems  28 August 2024  Vincent Naessens KU LeuvenSession 6 Cyberattack response  25 September 2024  Tom Bauwens Eubelius  Kalman Tiboldi TVHSession 7 Postquantum cryptography  23 October 2024  Eric Michiels IBM  In an increasingly technologydriven world cybersecurity stands as the cornerstone of digital resilience In this programme we will explore the full spectrum of cybersecurity from prevention to response while gaining both immediate handson skills and a foresight for the future of cybersecurity This programme brings together academic researchers and industrial experts and thus provides a blend of lectures and use cases and practical testimonials httpspuckuleuvenbenlopleidingcyberattackresponseyb6enq6mnngmdv98 Session 6  Cybersecurity excellence series 2024 trainingGhentKU Leuven Postuniversitair Centrum,\n",
       " AI in Healthcare Hype or Help  Work and research in healthcare  are evolving rapidly  partly because of innovative technology that is  introduced due to a farreaching digitization of the health sector AI  is one of these technologies that already influences healthcare today  for the benefit of patients  professionals  and scholars  and it will  continue to do so in the future Therefore  current and future  professionals and scholars  like yourself  will be challenged with the  correct adoption of AI in healthcare This course is intended to empower you as a healthcare professional  or scholar with insights and critical knowledge on the AI era  general  principles and concepts of AI  the added value of AI in healthcare and  associated data  ethics and regulatory boundaries The course considers  AI in healthcare  both from the perspective of the healthcare  professional who wants to be able to evaluate the benefits  limitations  and pitfalls of working with AI as well as from the developer’s  perspective  who needs to be aware of the technical background in  establishing and validating algorithms for AI applications  as well as  of the healthcare context  Define key enabling factors and limitations of AI tools Explain the main concepts of AI techniques Identify added value and risks of AI in healthcare applications Define healthcare data requirements  and identify related societal  ethical  and legal regulations Explain the role and implications of AI in healthcare Examine reallife use cases in which AI is already applied in clinical practice   More info  Share this course   httpswwwedxorglearnartificialintelligencekuleuvenaiinhealthcarehypeorhelpindexproductqueryID5b11f2ca493da42ece5f33c3cc2968b7position3linkedfromautocompletecautocomplete Online course online courseKU Leuven amp VAIA,\n",
       " Profile insightsFind out how your skills align with the job descriptionSkillsDo you have experience in VisioYesNoEducationDo you have a Bachelors degreeYesNo Job detailsHere’s how the job details align with your profilePay114000  176090 a yearJob typeFulltimeShift and scheduleDay shift LocationSterling VA BenefitsPulled from the full job description401kDental insuranceDisability insuranceEmployee stock purchase planHealth insuranceLife insurancePaid parental leaveShow morechevron down Full job description Sr Business Analyst  Cognizant’s Digital Engineering practice is seeking a highly qualified Sr Business Analyst with 10 years’ experience developing and building highperforming scalable enterprise applications You will be part of a digital software team that works on highdemand applications Our engineers have a passion for highquality reliable and maintainable code You will work side by side with product managers designers and clients making decisions together to quickly deliver valuable working software to clients and their users Our engineers are agile and retrospective and not afraid to identify what we’re doing wrong so we can fix it and what we’re doing right so we can improve on it Above all we judge success by the success of our team and the happiness of our customers  Cognizant Digital Engineering If you’re like us you’ve got big ideas At Cognizant we’re exploring new ideas every day We help industry leading companies reinvent their business models and innovate products that create new value—by connecting people with things insights and experiences Cognizant digital engineering designs engineers and delivers digital products and experiences that drive digitalfirst business models We offer the most comprehensive digital engineering expertise and clientcentric methodology for sustainable innovation  Location Sterling  VA or Remote  You must be legally authorized to work in the USA      Business Analyst Job Responsibilities      the development testing and product managers operations personnel CPOs Project managers etc to ensure accurate development and implementation based on Core customer requirements and needs Warranty on certain models from requirements analysis to detailed characterization     Efficiently lead the conversation and gather requirements from Business understand the concerns identify the risk and communicate it in timely fashion    Ensure document the application system by following multiple cross functional requirements eg Security Quality crossfunctional Business Legal    Perform evaluate and communicate thorough quality assurance at every stage of systems development    Determine and develop user requirements for systems in production to ensure maximum usability    Partner with stakeholders across business units ex sales finance security compliance to develop analyses and documentation in a collaborative way communicating effectively and efficiently with production managerial and executive teams    Evaluate analyze and communicate systems requirements on a continuing basis and maintain systems processes including the delivery of monthly status reports to all appropriate parties    Ability to make quick informed decision and understand the clear priority and escalate as needed    Must be creative to deliver innovative solutions to address critical business needs Highly agile and ability to quickly pivot the plan and execute      Required skills and qualifications    At least 3 years of domain knowledge in Communication and Media processes    Five or more years of experience in analytics and systems development    High proficiency with SQL and database management    Proven analytical abilities    Experience in generating process documentation and reports    Excellent communication skills with an ability to translate data into actionable insights    Preferred skills and qualifications    Bachelor’s degree or equivalent in information technology or computer science    Strong working knowledge of relevant Microsoft applications including Visio    Proven ability to manage projects and user testing    Extensive experience with data visualization    High proficiency in technical writing     Salary and Other Compensation  The annual salary for this position is between 114000 176090 USD depending on experience and other qualifications of the successful candidate  This position is also eligible for Cognizant’s discretionary annual incentive program based on performance and subject to the terms of Cognizant’s applicable plans  Application for this role will be received until 4302024  Benefits Cognizant offers the following benefits for this position subject to applicable eligibility requirements  MedicalDentalVisionLife Insurance Paid holidays plus Paid Time Off 401k plan and contributions LongtermShortterm Disability Paid Parental Leave Employee Stock Purchase Plan  Disclaimer The salary other compensation and benefits information is accurate as of the date of this posting Cognizant reserves the right to modify this information at any time subject to applicable law  Why Choose Cognizant  It takes a lot to succeed in today’s fastpaced market and Cognizant Technology Solutions has become a leader in the industry We love big ideas and even bigger dreams We stand out because we put human experiences at the core Our associates enjoy robust benefits and training opportunities from our industryrecognized awardwinning Academy team You will have access to hundreds of technical trainings to keep your skillsets fresh and have opportunities to acquire certifications on the newest technologies  Everything we do at Cognizant we do with passion—for our clients fortune 100 companies our communities and our organization It’s the defining attribute that we look for in our people  If you love ambiguity excited by change and excel through autonomy we’d love to hear from you  About Cognizant Digital Engineering  Welldesigned software transcends digital technology going beyond the fulfillment of basic requirements to focus instead on human needs Within Cognizant Digital Engineering we help clients develop software products that transform human insights into tangible productionready digital solutions We also work with our clients to scale their native cloud applications Using insights from the lived experiences of our consumers we seamlessly replace traditional service strategies with engaging precise and direct digital applications Designing phenomenal software is vital to success in the digital economy—and we understand that a humancentric approach is key to this design  LIJO1  IND123   Employee Status  Full Time Employee  Shift  Day Job  Travel  No  Job Posting  Apr 01 2024    About Cognizant  Cognizant Nasdaq100 CTSH is one of the worlds leading professional services companies transforming clients business operating and technology models for the digital era Our unique industrybased consultative approach helps clients envision build and run more innovative and efficient businesses Headquartered in the US Cognizant is ranked 185 on the Fortune 500 and is consistently listed among the most admired companies in the world Learn how Cognizant helps clients lead with digital at wwwcognizantcom or follow us USJobsCognizant    Applicants may be required to attend interviews in person or by video conference In addition candidates may be required to present their current state or government issued ID during each interview   Cognizant is an equal opportunity employer All qualified applicants will receive consideration for employment without regard to sex gender identity sexual orientation race color religion national origin disability protected Veteran status age or any other characteristic protected by law  If you have a disability that requires a reasonable accommodation to search for a job opening or submit an application please email CareersNA2cognizantcom with your request and contact information   ,\n",
       " Profile insightsFind out how your skills align with the job descriptionSkillsDo you have experience in SalesYesNoEducationDo you have a Masters degreeYesNo Job detailsHere’s how the job details align with your profilePay113700  160600 a year LocationFoster City CA BenefitsPulled from the full job description401kDental insuranceFlexible spending accountHealth insuranceHealth savings accountLife insurancePaid time offShow morechevron down Full job description Company Description  Visa is a world leader in payments and technology with over 259 billion payments transactions flowing safely between consumers merchants financial institutions and government entities in more than 200 countries and territories each year Our mission is to connect the world through the most innovative convenient reliable and secure payments network enabling individuals businesses and economies to thrive while driven by a common purpose – to uplift everyone everywhere by being the best way to pay and be paid  Make an impact with a purposedriven industry leader Join us today and experience Life at Visa Job Description  Visa Digital Products team is on the forefront of Visa’s innovation responsible for building digital platforms such as Visa Token Services and Visa Click to Pay aka Secure Remote CommerceSRC This team is also responsible for setting standards in the payment industry level EMVCo and W3C for digital commerce Platform product team is responsible for defining product requirements for Visa Click to Pay and Token products collaborate with cross functional teams including but not limited to Product Technology Commercialization UX DesignResearch Legal Marketing Branding and different Visa Regional teams to build great products at scale and drive adoption  This position will be responsible for shaping and developing the product strategy requirements and delivery of digital and physical token provisioning solutions leveraging Visa Token Service  Job Description  Want to build the future payment experience for Visa cardholders around the world  Imagine being part of an agile team where your ideas transform the payment experience for millions of Visa cardholders globally Visa Digital Platform team is looking for Product Managers to join our diverse team to build new product capabilities and enhancing existing ones Our platform capabilities will be used by merchants PSPs and wallets to enable payment experience in their online and physical checkouts  Essential Functions   Defining product and market requirements by understanding the needs of issuers and merchantstoken requestors during token provisioning process  Establish detailed business requirements and specifications for existing and new services and products  Collaborate deeply within product and other crossfunctional teams such as development architecture testing integration design etc  Analyze data to provide actionable insights and iterate product capabilities  Proactively identify gaps in the current product offering and lead the effort to develop solutions that drive business value  Track payment industry trends standards and competitive offerings in the ecommerce and mobile payments arena Identify opportunities for new valueadded and differentiated features  Coordinate with the regional product teams and internal teams to ensure countrymarket and regulatory requirements are met delivered and tested for a successful launch  Participate in client facing discussions provide feedback learn evaluate and apply in defining product  Maintain indepth knowledge of services APIs offered by Digital Solutions Product team  Managing grooming planning and execution of a steady product backlog in a very fast paced agile environment  Perform triage on critical issues escalating as necessary and communicating consistently and clearly with all concerned parties   This is a hybrid position Hybrid employees can alternate time between both remote and office Employees in hybrid roles are expected to work from the office 23 set days a week determined by leadershipsite with a general guidepost of being in the office 50 or more of the time based on business needs Qualifications  Basic Qualifications   2 or more years of work experience with a Bachelor’s Degree or an Advanced Degree eg Masters MBA JD MD or PhD  Ecommerce and payment industry knowledge  Experience in driving product strategy and go to market  Product experience that enables excellent user experiences especially with services for ecommerce or payment systems or financial systems  Experience demonstrating strong leadership selfmotivation accountability and team player   Preferred Qualifications   3 or more years of work experience with a Bachelor’s Degree or more than 2 years of work experience with an Advanced Degree eg Masters MBA JD MD  Strong collaboration and communication skills with the ability to effectively work crossorganizationally  Demonstrate strong customer centric mindset  Successful demonstration of product delivery in either or both Agile eg scrum and waterfall software development methodologies  Ability to lead drive consensus and deliver in a matrix organization with multiple stakeholders  Creativity and resourcefulness to overcome unexpected roadblocks  Proven track record of taking ownership and driving meaningful results  Ability to deliver initiatives from conception through completion  Superior analytical and problemsolving skills to synthesize and communicate complex information effectively    Additional Information  Work Hours Varies upon the needs of the department  Travel Requirements This position requires travel 510 of the time  MentalPhysical Requirements This position will be performed in an office setting The position will require the incumbent to sit and stand at a desk communicate in person and by telephone frequently operate standard office equipment such as telephones and computers  Visa is an EEO Employer Qualified applicants will receive consideration for employment without regard to race color religion sex national origin sexual orientation gender identity disability or protected veteran status Visa will also consider for employment qualified applicants with criminal histories in a manner consistent with EEOC guidelines and applicable local law  Visa will consider for employment qualified applicants with criminal histories in a manner consistent with applicable local law including the requirements of Article 49 of the San Francisco Police Code  US APPLICANTS ONLY The estimated salary range for a new hire into this position is 11370000 to 16060000 USD per year which may include potential sales incentive payments if applicable Salary may vary depending on jobrelated factors which may include knowledge skills experience and location In addition this position may be eligible for bonus and equity Visa has a comprehensive benefits package for which this position may be eligible that includes Medical Dental Vision 401 k FSAHSA Life Insurance Paid Time Off and Wellness Program  ,\n",
       " Profile insightsFind out how your skills align with the job descriptionSkillsDo you have experience in VisioYesNoEducationDo you have a Bachelors degreeYesNo Job detailsHere’s how the job details align with your profilePay67400  121300 a yearJob typeFulltime LocationDelaware BenefitsPulled from the full job description401kHealth insurancePaid time offTuition reimbursement Full job description You could be the one who changes everything for our 28 million members Centene is transforming the health of our communities one person at a time As a diversified national organization you’ll have access to competitive benefits including a fresh perspective on workplace flexibility  Position Purpose  Perform various analysis and interpretation to link business needs and objectives for assigned function This role will be heavily focused around reporting process analysis and reconciliation between different systems including analyzing enrollment 834 files and identifying data load issues This role will also work with enrollment shared services to determine root cause and follow up on fixes as applicable   Support business initiatives through data analysis identification of implementation barriers and user acceptance testing of various systems  Identify and analyze user requirements procedures and problems to improve existing processes  Perform detailed analysis on multiple projects recommend potential business solutions and ensure successful implementations  Identify ways to enhance performance management and operational reports related to new business implementation processes  Coordinate with various business units and departments in the development and delivery of training programs  Develop share and incorporate organizational best practices into business applications  Diagnose problems and identify opportunities for process redesign and improvement  Formulate and update departmental policies and procedures  Serve as the subject matter expert on the assigned function product to ensure operational performance  Ability to travel   EducationExperience  Bachelor’s degree in related field or equivalent experience 46 years of business process or data analysis experience preferably in healthcare Advanced knowledge of Microsoft Applications including Excel and Access preferred Project management experience preferred  Benefits and Payment Configuration  Bachelor’s degree in related field or equivalent experience 4 years of business process analysis preferably in healthcare ie documenting business process gathering requirements or claims paymentanalysis experience Advanced knowledge of Microsoft Applications including Excel and Access preferred Experience in benefits pricing contracting or claims and knowledge of provider reimbursement methodologies Knowledge of managed care information or claims payment systems preferred Previous structured testing experience preferred  Compliance CodingPrepay Compliance Payment Integrity  Bachelor’s degree in related field or equivalent experience 4 years of business process analysis ie ie documenting business process gathering requirements Experience in healthcare industry preferably with managed care techniques and administrative philosophy Experience in claims coding analysis or medical claim reviewresearch preferred Knowledge of Amisys claims payment system and Business Objects preferred  Encounters  Bachelor’s degree in related field or equivalent experience 4 years of business process analysis ie documenting business process gathering requirements experience in healthcare industry or 3 years of managed care encounters experience Advanced knowledge of Microsoft Applications including Excel and Access preferred Experience with encounters or claims business analysis experience in healthcare preferably managed care or Medicaid Knowledge of Amisys or other claims system and HIPAA transactions ie 837 999 824 277 preferred Experience witSQL Scripting or basic query writing is required  Medicare  Bachelor’s degree in related field or equivalent experience 4 years of business process analysis ie documenting business process gathering requirements Experience in healthcare industry preferably with managed care techniques and administrative philosophy Experience in managed health care experience preferably with Medicare Experience working with and leading diverse teams in matrix managed environments Advanced knowledge of Microsoft applications including Excel and Access preferred Project management experience preferred  Provider Data  Bachelor’s degree in related field or equivalent experience 4 years of business process analysis documenting business process gathering requirements experience in healthcare industry andor working in a data driven environment Advanced knowledge of Microsoft Applications including Excel Project and Visio preferred Knowledge of data migration software enhancementplanning and Agile preferred Experience managing projects with a high reliance on technology  Member  Provider Solutions  Bachelor’s degree in related field or equivalent experience 4 years of business process analysis ie documenting business process gathering requirements experience in healthcare industry andor customer service or enrollment functions Advanced knowledge of Microsoft Applications including Excel and Visio preferred Experience managing projects with a high reliance on technology Knowledge of data integration software enhancementsplanning and Agile preferred Pay Range 6740000  12130000 per year   Centene offers a comprehensive benefits package including competitive pay health insurance 401K and stock purchase plans tuition reimbursement paid time off plus holidays and a flexible approach to work with remote hybrid field or office work schedules Actual pay will be adjusted based on an individuals skills experience education and other jobrelated factors permitted by law Total compensation may also include additional forms of incentives  Centene is an equal opportunity employer that is committed to diversity and values the ways in which we are different All qualified applicants will receive consideration for employment without regard to race color religion sex sexual orientation gender identity national origin disability veteran status or other characteristic protected by applicable law  ,\n",
       " Profile insightsFind out how your skills align with the job descriptionSkillsDo you have experience in TableauYesNoEducationDo you have a Bachelors degreeYesNo Job detailsHere’s how the job details align with your profileJob typeFulltime LocationBrentwood TN Full job description    Welcome to Ovation Healthcare        At Ovation Healthcare formerly QHR Health we’ve been making local healthcare better for more than 40 years Our mission is to strengthen independent community healthcare We provide independent hospitals and health systems with the support guidance and techenabled shared services needed to remain strong and viable With a strong sense of purpose and commitment to operating excellence we help rural healthcare providers fulfill their missions        The Ovation Healthcare difference is the extraordinary combination of operations experience and consulting guidance that fulfills our mission of creating a sustainable future for healthcare organizations Ovation Healthcare’s vision is to be a dynamic integrated professional services company delivering innovative and executable solutions through experience and thought leadership while valuing trust respect and customer focused behavior        We’re looking for talented motivated professionals with a desire to help independent hospitals thrive Working with Ovation Healthcare you will have the opportunity to collaborate with highly skilled subject matter specialists and operations executives in a collegial atmosphere of professionalism and teamwork        Ovation Healthcare’s corporate headquarters is located in Brentwood TN For more information visit        wwwovationhccom           We are seeking a dynamic and experienced professional to join our team as a Sr Analyst – Contracts and Pricing As a key member in our organization you will be responsible analyzing financial impacts of new and existing agreements as well as completing market baskets for new member hospitals The ideal candidate will possess strong analytical skills a deep understanding of data visualization GPO business practices healthcare and hospital operation knowledge and a proven track record of delivering accurate and timely analysis of large data sets        Duties and Responsibilities           Data Collection and Preparation            Collect and consolidate data from multiple sources including databases and spreadsheets            Cleanse preprocess and validate data to ensure accuracy completeness and consistency            Develop and maintain data pipelines and workflows for efficient data extraction and transformation            Data Analysis and Interpretation            Perform exploratory data analysis to identify trends correlations and outliers            Apply statistical methods and data mining techniques to uncover insights and patterns in the data            Conduct hypothesis testing and regression analysis to validate findings and make datadriven recommendations            Data Visualization and Reporting            Create visualizations dashboards and reports to present data insights in a clear and compelling manner            Use data visualization tools such as Tableau Power BI or matplotlib to communicate complex data concepts effectively            Customize visualizations to meet the needs of different stakeholders and facilitate decisionmaking            Performance Monitoring and Optimization            Monitor key performance indicators KPIs and metrics to track business performance and identify areas for improvement            Collaborate with business units to define performance benchmarks and goals            Analyze data to identify opportunities for process optimization cost reduction and revenue enhancement            Crossfunctional Collaboration            Collaborate with crossfunctional teams to support datadriven decisionmaking            Provide data expertise and insights to support strategic initiatives and business projects            Communicate findings and recommendations to stakeholders through presentations reports and interactive sessions           Knowledge Skills and Abilities           GPO Operations            Healthcare Supply Chain Operations            Detail Oriented            Collaborative            Strategic thinker            Customer Service oriented            Innovative           Work Experience Education and Certifications           Bachelors degree in Computer Science Statistics Mathematics Economics or related field advanced degree is a plus            Proven experience typically 25 years in data analysis business intelligence or related field            Proficiency in SQL for data querying and manipulation            Familiarity with data visualization tools such as Tableau Power BI or matplotlib            Expert user of Microsoft Suite            Strong analytical skills with the ability to interpret complex datasets and derive actionable insights            Excellent communication and presentation skills with the ability to convey technical concepts to nontechnical stakeholders            Detailoriented mindset with a focus on data accuracy quality and integrity            Ability to work independently and collaboratively in a fastpaced environment        ,\n",
       " Profile insightsFind out how your skills align with the job descriptionSkillsDo you have experience in SharePointYesNo Job detailsHere’s how the job details align with your profileJob typeContract LocationCamden NJ Full job description  Title Business System AnalystTechnical Writer    Contract Details      Location Camden NJ       Hybrid  Onsite 3 days a week       Duration One year       Start April 22 2024       Candidates Considered US Citizens GC and H1b     Automotive client experience is a very big plus    Business Systems Analyst  Technical Writer  Responsibilities  The Senior Business Analyst is responsible for working with IT team members and business partners to understand and document business systems processes as well as to coordinate IT projects for telematics systems This role will have strong skills in workplan development and progress tracking who will prepare and present updates regularly to relevant management channels ensuring that our goals of transparency and communication are achieved The role includes producing documentation around current and future business and system processes as well as presentations of information presentations and documentation for various levels of the organization from executive leadership to scrum teams   Analyze Current Business Processes Evaluate existing organizational workflows and identify areas for improvement based on industry trends and professional business knowledge  Gather Requirements from Stakeholders Collaborate with various stakeholders including management users and project teams to understand their needs and translate them into functional requirements  Research and Gather Information Collaborate with subject matter experts across various teams to collect relevant information  Write and Edit Content Develop procedure manuals technical specifications and process documentation around current and future processes Ensure accuracy clarity and consistency Manage collection and review of portfolio executive stakeholder updates  Create User Guides and Training Materials Produce materials that help endusers understand software applications systems and processes  Proofread and Edit Review and refine internal and external communication including print and web content to enhance clarity and accuracy  Identify Areas for Improvement Continuously assess business processes and systems Propose enhancements to increase efficiency and productivity  Provide Training and Support Train team on using software effectively in their daily tasks Offer ongoing support as needed  Stay Updated Keep abreast of advancements in technology and industry standards to produce relevant and effective documentation   Business Systems Analyst  Technical Writer  Required Skills  MUST HAVES   6 – 8 years of experience  Analytical Skills Business Systems Analysts must analyze data identify patterns and propose solutions to improve business processes  Business Acumen and Process Understanding Deep understanding of business operations process modeling and translating business requirements into technical specifications  Software Development Familiarity with concepts of databases programming system architectures data modeling and software development life cycles  ProblemSolving Analyzing situations and finding creative solutions Ability to identify issues propose solutions and optimize systems  Tools      Competency in Microsoft applications including Word Excel Outlook PowerPoint and SharePoint  Experience in SharePoint JIRA and Confluence   Research Skills Gathering information from subject matter experts  Writing Skills Creating clear accurate and engaging documentation Experience in communicating to senior leadership Experience in building professional senior  executive leadership presentations  Editing and Proofreading Ensuring quality and consistency  Attention to Detail Ensuring accuracy in technical documentation  Knowledge Acquisition Able to gather and document current and future processes systems and needs  Research Abilities Staying informed about industry advancements and emerging technologies   ,\n",
       " Profile insightsFind out how your skills align with the job descriptionSkillsDo you have experience in Internet of thingsYesNo Job detailsHere’s how the job details align with your profilePay49458  63073 a yearJob typeTemporaryFulltime Location301 W High St Jefferson City MO 65101 BenefitsPulled from the full job descriptionHealth insurance Full job description Job Location  The office for this position is located in the Truman Bldg 301 W High Street Jefferson City MO 65101 Candidates who complete a successful onboarding and training period may be eligible to work at an alternate location in compliance with OAITSDs Distributed Workforce Plan  Why you’ll love this position  As a Business Analyst the core responsibilities of this position include the overall direction coordination implementation execution control and completion of project reviews Projects will cover a diverse range of technologies and objectives Determining technical requirements of agency projects and translating them into functional specifications Determines systems scope objectives and functionality based on user input and understanding of business processes Provides the basis for the design or modification of information systems through technical analysis and document requirements  This is a temporary fulltime benefiteligible position based upon federal ARPA funding Position funding will end no later than December 31 2026  This position is with the Office of Administration Information Technology Services Division OAITSD  ITSD Core Values  We Innovate and Partner with Passion Respect and Integrity United as OneTeam   Build a relationship with the customer Process mapping Defines objectives Defining systems scope Embrace ITSD Core Values Documents requirements Estimating cost Provides the basis for the design or modification of information systems Facilitate meetings Defines roles and responsibilities Defines functionality based on user input and understanding   Project Review Team consists of review and analysis of agency projects software software versions databases web interfaces applications connectivity requirements security requirements access requirements hardware and roles and responsibilities coordinate reviews with Engineering and Communications Client Engagement Services and Office of Cyber Security as required Skill in outlining project scope objectives and functionality Skill in translating business processes into information technology requirements Ability to assess situations including risks and benefits and receive feedback from stakeholders Coordinating midlevel work with customers related to technical work Research technologies Providing recommendations to ITSD partners Advanced Knowledge of IOT Internet Of Things Devices Knowledge of IT Business areas create and interpret process diagramsflow charts Ability to translate technical terminology into common terms Assess situations risks  benefits and receiveorganize feedback from stakeholders Successful background check results are required for employment in this position This may include background checks involving a candidate’s name andor fingerprints and other screenings as needed for the specific position  Lack of postsecondary education will not be used as the sole basis denying consideration to any applicant  The classification for this position is Business Analyst click for more information  The State of Missouri offers an excellent benefits package that includes a defined pension plan generous amounts of leave and holiday time and eligibility for health insurance coverage Your total compensation is more than the dollars you receive in your paycheck To help demonstrate the value of working for the State of Missouri we have created an interactive Total Compensation Calculator This tool provides a comprehensive view of benefits and more that are offered to prospective employees The Total Compensation Calculator and other applicant resources can be found here  If you have questions please contact ITSDRecruitingoamogov   ,\n",
       " Profile insightsFind out how your skills align with the job descriptionSkillsDo you have experience in User acceptance testingYesNoEducationDo you have a Masters degreeYesNo Job detailsHere’s how the job details align with your profilePay116974  187158 a yearJob typeFulltime LocationIrvine CA BenefitsPulled from the full job descriptionRetirement plan Full job description     “I can succeed as the Senior Digital Analytics Analyst at Capital Group”        As the Senior Digital Analytics Analyst you demonstrate strong working knowledge in the assigned area and work under direction only as needed You develop and deliver complex digital analytics insights and guidance to support business decision making and continuously improve digital experiences        Primary ResponsibilitiesEssential Functions      Independently produce deep analysis for various digital assets in the assigned business area Develop and deliver reports to support the implementation and performance of digital assets     Track measure and analyze website and application trends  Gather organize and analyze data to inform strategy formulate insights and make actionable recommendations  Design and build reports using tools like Adobe Analytics Tableau etc  Automate and deliver reoccurring reports  Provide real time reporting and monitoring of anomalies in web performance  Design and execute analysis of ad hoc requests     Serve as a subject matter expert on analytics tagging perform user acceptance testing implements AB tests supports implementation and execution     Independently write requirements for measurement framework for new digital assets landing pages mobile applications etc  Identify defects in tagging and implementation and work with IT to solution on the problem  Validate all tagging implementations  Maintain an understanding of industry best practices for tagging implementation and execution  Partner with IT to implement and execute all tagging     Support optimization of business processes     Manage and Support marketing technology tools  Collaborate with cross functional teams including IT Marketing Pods and Digital Channel Stakeholders to bring enhancement to current processes  Assist in stakeholder and team trainings on the technologies       “I am the person Capital Group is looking for”        SkillsQualifications      You have a minimum of 3 years’ relevant experience not necessarily within Finance with the ability to motivate inspire and achieve goals  You have demonstrated experience delivering actionable insight for a consumer business  You have excellent problemsolving skills along with the ability to find creative solutions for challenges regarding campaigns and communication of results  You are able to manage multiple projects at the same time in a fastpaced environment You can independently identify and set priorities in rapidly changing and ambiguous environment  You have knowledge of SEO and SEM best practices digital marketing tools Adobe Analytics Adobe Audience Manager other DMPs etc and channels  You have advanced ETL and SQL writing skills  You have knowledge of in at least one statistical analysis tool such as R or Python  You are an expert in dash boarding tools eg Tableau and have advanced experience in Excel  You have a BABSc degree in Business  Mathematics  Statistics  Computer Science  Analytics  Econometrics Master’s degree is preferred      ‎   Southern California Base Salary Range 116974187158      ‎       ‎       ‎       ‎       ‎       ‎   ‎      ‎       ‎       ‎       ‎       ‎       ‎       ‎     In addition to a highly competitive base salary per plan guidelines restrictions and vesting requirements you also will be eligible for an individual annual performance bonus plus Capital’s annual profitability bonus plus a retirement plan where Capital contributes 15 of your eligible earnings     You can learn more about our compensation and benefits   here     Temporary positions in Canada and the United States are excluded from the above mentioned compensation and benefit plans    We are an equal opportunity employer which means we comply with all federal state and local laws that prohibit discrimination when making all decisions about employment As equal opportunity employers our policies prohibit unlawful discrimination on the basis of race religion color national origin ancestry sex including gender and gender identity pregnancy childbirth and related medical conditions age physical or mental disability medical condition genetic information marital status sexual orientation citizenship status AIDSHIV status political activities or affiliations military or veteran status status as a victim of domestic violence assault or stalking or any other characteristic protected by federal state or local law   ,\n",
       " Profile insightsFind out how your skills align with the job descriptionSkillsDo you have experience in Statistical analysisYesNoEducationDo you have a Masters degreeYesNo Job detailsHere’s how the job details align with your profileJob typeFulltimeShift and schedule8 hour shiftDay shiftMonday to Friday Location500 Parnassus Ave San Francisco CA 94143 Full job description         Uses skills as a seasoned experienced research professional with a full understanding of indepth statistical analyses and  or research software programming techniques Demonstrates good judgment in selecting methods and techniques for obtaining solutions       The Research Data Analyst will work as part of a Research Program team to conduct geographic information system GIS and epidemiologic analyses in support of research projects manuscripts and grant proposals The Research Data Analyst’s primary role will be to work alongside the Principal Investigators and study teams to clean organize and analyze large multilevel datasets including surveillancecancer registry data and longitudinal data The Research Data Analyst will develop and maintain research gathering retrieval and reporting systems prepare reports and documents research methods work independently and with a variety of integrated epidemiologic and geographic datasets and explore and make recommendations for geospatial data resources and analytic approaches The Research Data Analyst will participate in the design of analyses and the tabulation and presentation of research data as well as coauthor and may leadauthor scientific manuscripts Additional tasks may include contributing to the development of grant proposals for the Research Program The Research Data Analyst will be expected to use skills as an experienced research professional with a full understanding of statistical analyses and application of epidemiologic principles communicate and disseminate research findings with a broad set of collaborators provide highlevel support to internal and external investigatorsfaculty in geospatialGIS and epidemiologic research projects and publications       THIS POSITION IS A 1YEAR CONTRACT APPOINTMENT  The final salary and offer components are subject to additional approvals based on UC policy  To see the salary range for this position we recommend that you make a note of the job code and use that to look up TCS NonAcademic Titles Search httpstcsucopedunonacademictitles  Please note An offer will take into consideration the experience of the final candidate AND the current salary level of individuals working at UCSF in a similar role  For roles covered by a bargaining unit agreement there will be specific rules about where a new hire would be placed on the range  To learn more about the benefits of working at UCSF including total compensation please visit httpsucnetuniversityofcaliforniaeducompensationandbenefitsindexhtml    Department Description      The Department of Epidemiology and Biostatistics DEB housed within the UCSF School of Medicine has a vision to advance discoveries and insights into the distribution determinants and outcomes of disease that will drive improvements in population health worldwide The DEB has three missions 1 education 2 science and 3 research Its educational mission is to train students in epidemiologic and biostatistical methods for studying disease etiology and prevention evaluating tests and treatments and using evidencebased approaches in clinical practice and population health The scientific mission of the DEB is to perform outstanding basic clinical and population health research along a spectrum from molecules to society and to develop tools for the translation of knowledge that will improve clinical practice and population health and ensure optimal use of resources The clinical mission of the Department is to support the practice of public health and preventive medicine in local state national and international health agencies       Required Qualifications   Bachelors degree in related area and 5 years of related experience and  or equivalent experience  training  Experience with preparing reports manuscript writing and support grant proposals  Excellent oral and writing communication skills including the ability to analyze and draw conclusions from large datasets  Thorough knowledge of research function  Thorough skills associated with statistical analysis and systems programming database design and data security measures  Thorough skills in analysis and consultation  Skills to communicate complex information in a clear and concise manner both verbally and in writing  Research skills at a level to evaluate alternate solutions and develop recommendations  Outstanding skills in manipulating and analyzing largescale GIS data and programming experiences in ArcGIS R STATA andor SAS  Excellent attention to detail and organizational skills and ability to track multiple projects and responsibilities simultaneously  Selfmanagement skills Ability to work in fast paced environment under changing conditions handle multiple complex tasks and demands and meet deadlines and deliverables with minimal supervision  Ability to work collaboratively and meet deadlines and deliverables with minimal supervision     Preferred Qualifications   Master’s degree in related area and 3 years of relevant experience and  or related field  Academic background and recognized expertise in geography or epidemiology and ability to apply advanced geographyepidemiologic principles and methods in the analysis of health data  Skills in project management     About UCSF      The University of California San Francisco UCSF is a leading university dedicated to promoting health worldwide through advanced biomedical research graduatelevel education in the life sciences and health professions and excellence in patient care It is the only campus in the 10campus UC system dedicated exclusively to the health sciences We bring together the world’s leading experts in nearly every area of health We are home to five Nobel laureates who have advanced the understanding of cancer neurodegenerative diseases aging and stem cells       Pride Values      UCSF is a diverse community made of people with many skills and talents We seek candidates whose work experience or community service has prepared them to contribute to our commitment to professionalism respect integrity diversity and excellence – also known as our PRIDE values        In addition to our PRIDE values UCSF is committed to equity – both in how we deliver care as well as our workforce We are committed to building a broadly diverse community nurturing a culture that is welcoming and supportive and engaging diverse ideas for the provision of culturally competent education discovery and patient care Additional information about UCSF is available at diversityucsfedu        Join us to find a rewarding career contributing to improving healthcare worldwide       Equal Employment Opportunity      The University of California San Francisco is an Equal OpportunityAffirmative Action Employer All qualified applicants will receive consideration for employment without regard to race color religion sex sexual orientation gender identity national origin age protected veteran or disabled status or genetic information       Organization      Campus       Job Code and Payroll Title      006257 RSCH DATA ANL 3        Job Category      Professional NonClinical Research and Scientific       Bargaining Unit      99  PolicyCovered No Bargaining Unit        Employee Class      Contract       Percentage      100       Location      Flexible combination of onsite and remote work San Francisco CA       Shift      Days       Shift Length      8 Hours        Additional Shift Details      MondayFriday 40 hours 830am to 530 pm flexible         ,\n",
       " Profile insightsFind out how your skills align with the job descriptionSkillsDo you have experience in RYesNoEducationDo you have a Masters degreeYesNo Job detailsHere’s how the job details align with your profilePay98613  126000 a yearJob typeFulltime LocationChampaign IL 61820 BenefitsPulled from the full job descriptionHealth insurancePaid time offParental leaveRetirement planTuition reimbursement Full job description Description  Corteva Agriscience LLC seeks a fulltime Data Analyst based in Champaign IL Position includes a telecommute benefit within commuting distance to a Champaign IL Corteva office as directed This position will be responsible for the deployment of operational methods for the integration and organic technical improvement of the Pasture  Land Management PLM Digital Tools decision support platform   Qualifications  Requirements Masters degree or equiv in Geographic Information Science Data Science or a related field  3 years related exp Must also have 12 months of exp with 1 perform Quality Assurance checks on incoming data feature sets using ArcGIS and connect data sets into enterprise geodata systems 2 work with complex and multifaceted data sets in conjunction with commercial biology and GIS specialists to support timeseries analysis of crops and grasses and related management decisions 3 expertise to create new tools and technology in Data Engineering including skills in R Python and development for cloud Linux and Windows platforms 4 Crop and Land Use classification involving the separation of areas covered by different plant species and types of land and 5 utilize the follow toolstechnologies RShiny fullstack development solution ArcPy Time series predictive modeling ObjectBased Image Analysis using ECognition software Please apply online at httpscareerscortevacomenus Salary 98613 to 126000year  Benefits – How We’ll Support You    Numerous development opportunities offered to build your skills  Be part of a company with a higher purpose and contribute to making the world a better place  Health benefits for you and your family on your first day of employment  Four weeks of paid time off and two weeks of wellbeing pay per year plus paid holidays  Excellent parental leave which includes a minimum of 16 weeks for mother and father  Future planning with our competitive retirement savings plan and tuition reimbursement program  Learn more about our total rewards package here – Corteva Benefits  Check out life at Corteva wwwlinkedincomcompanycortevalife    Are you a good match Apply today We seek applicants from all backgrounds to ensure we get the best most creative talent on our team  ,\n",
       " Profile insightsFind out how your skills align with the job descriptionSkillsDo you have experience in Systems engineeringYesNoEducationDo you have a Masters degreeYesNo Job detailsHere’s how the job details align with your profilePay200000  215000 a yearJob typeFulltime LocationColorado Springs CO BenefitsPulled from the full job description401kDental insuranceDisability insuranceFlexible spending accountHealth insuranceLife insurancePaid time offShow morechevron down Full job description Job Title Space Training Analyst 4441  Job Location Colorado Springs CO 80919  Job Salary 200000215000  Job Summary  Galapagos Federal Systems LLC is looking for an enthusiastic and highly qualified candidate to assume the role of Space Training Analyst Support and to join our team of qualified diverse individuals  The core responsibility of this position revolves around delivering robust Space Training Analyst Support As part of this role the selected individual will be tasked with executing a spectrum of training operations analyst functions encompassing meticulous planning seamless coordination comprehensive analysis proficient execution and insightful reporting pertaining to space systems training Moreover the incumbent will be expected to provide integrated analysis support across various domains including design reviews the development of training strategies participation in training planning working groups and engagement in analogous trainingcentric forums  Ideal candidates will possess demonstrable analytical prowess across a range of specialized areas including Statics and Experimental Design Database Management and advanced analytical techniques such as Big Data Analytics Additionally candidates should have handson experience in either crafting proprietaryinternal tools or leveraging commercial test and space Model Based System Engineering MBSE Modeling and Simulation MS digital engineering and analysis tools such as Satellite Tool Kit STK or equivalent platforms to dissect space architectures sensors and communication systems  Technical proficiency is paramount with candidates expected to have familiarity in critical domains such as Space System Architectures Satellite and Ground Segment Design EOIRRF Sensors Astrodynamics Propulsion GNC spacerelated data communications and Space Battle Management and Control  Job Requirements   Skills  Experience Required  10 years relevant DoD Department of Defense work experience Perform analysis on pretest predictions models and simulations to design test events and profiles define data collection requirements and establish gonogo criteria to meet test objectives Develop a data management and analysis plan DMAP to ensure proper data collection for Modeling and Simulation MS realtime test execution and postmission data processing evaluation and analysis Create and review test planning documentation including Test Plans Test Information Sheets Safety Packages Data Analysis Management Plans Technical and Safety Review Board Briefs Test Readiness Briefs Test Cards TestAnalysis Reports and Test Results Briefs Monitor the gathering of MS data and realtime test and range parameters evaluating test results to determine if system configurations performance and architecture meet system requirements effectiveness and suitability Set up data requests order and process data conduct quality control reviews resolve data anomalies and analyze data according to the data analysis plan Develop enhance and utilize data analysis tools as needed to support the analysis and reporting of advanced highly complex test simulations and scenarios facilitating the evaluation of system performance effectiveness and suitability Provide operational suitability test support to space system test programs serving as the expert on issues related to reliability availability compatibility transportability interoperability maintainability safety human factors manpower supportability logistics supportability environmental effects system documentation and training requirements Contribute to all aspects of test design and planning using comprehensive knowledge of the system under test test policies and test range capabilities Assist the Test Director in preparing highquality suitability analysis across various test venues during all test phases to inform system development and operational evaluation Develop specific data collection processing evaluation and reporting procedures for space system suitability while proactively identifying suitability gaps risks or other issues across multiple test programs Extensive experience within System Program Offices SPOs andor Program Management Offices PMOs demonstrating a record of accomplishments Exhibits comprehensive knowledge and expertise in Research Development Test and Evaluation RDTE proficiently utilizing test and training materiel systems Possesses a deep understanding of the fielding and sustainment processes associated with space test and training materiel systems Proficient in the application of Model Based Systems Engineering techniques ensuring efficient and effective system development and analysis Wellversed in a diverse array of domains including Space System Architectures Satellite and Ground Segment design electrooptical EO Infrared IR and Radio Frequency RF Sensors Astrodynamics Propulsion Guidance Navigation and Control GNC Spacerelated data communications and Space Battle Management and Control Demonstrates exceptional written and oral communication abilities coupled with strong leadership qualities fostering productive team collaboration and engagement Recognized as an industry leader renowned for exceptional analytical skills and substantial contributions to the field Education  Certifications BSBA required STEM or equivalent experience preferred MSMA preferred STEM or equivalent experience preferred Key SkillsExperience Required for Interview Selection ONLY Research Development Test and Evaluation RDTE of test and training materiel systems Fielding and Sustainment of test and training materiel systems Model Based Systems Engineering Space System Architectures Satellite and Ground Segment design electrooptical EO Infrared IR and Radio Frequency RF Sensors Astrodynamics Propulsion Guidance Navigation and Control GNC Spacerelated data communications or Space Battle Management and Control Recent experience working in a classified environment with classified programs  Benefits  Medical dental vision disability and life insurance Flexible Spending Accounts 401k PTO Tuition reimbursement Paid federal holidays  Security Clearance  Must be a US Citizen A highlevel Department of Defense active security clearance may be required Applicants selected will be subject to a security investigation and may need to meet eligibility requirements for access to government information  Physical Requirements  Work may involve sitting or standing for extended periods of time and typing and reading from a computer screen The candidate must have enough mobility including bending reaching and kneeling to complete daily duties in a prompt and efficient manner and that may include lifting to thirty pounds as necessary  Company Summary  Headquartered in Hawaii Galapagos Federal Systems LLC is an SBA Certified Native Hawaiian Organization 8a Small Business specializing in global information technology and offering professional solutions in IT Design  Installation Cybersecurity Engineering  Support Application Integration  Development Software  Hardware Engineering Network  Systems Management Information Systems Security and Business Management Services  Leveraging over 30 years of providing IT services to the federal  commercial market with projects found around the world our team has innovative expertise in the development of a wide range of technological solutions Galapagos Federal Systems LLC is an equal opportunity employer  Our service commitment is simple  Quality IT Solutions On Time  On Budget  Company Employment Statement  Galapagos Federal Systems LLC reserves the right to change or modify job duties and assignments at any time The above job description is not all encompassing as positions functions and qualifications may vary depending on business needs Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions  Galapagos Federal Systems LLC is an equal opportunity employer and does not discriminate against applicants based on race color creed religion medical condition legally protected genetic information national origin sex including pregnancy childbirth or related medical condition sexual orientation gender identity and expression age disability or Vietnam era or other eligible veteran status or legally protected characteristics        Get job alerts by email Sign up now Join Our Talent Network      Job Snapshot  Employee Type FullTime      Location Colorado Springs CO Onsite      Job Type Government Strategy  Planning Training      Experience Not Specified      Date Posted 03212024      ,\n",
       " Profile insightsFind out how your skills align with the job descriptionSkillsDo you have experience in VisioYesNoEducationDo you have a Bachelors degreeYesNo Job detailsHere’s how the job details align with your profileJob typeFulltimeShift and scheduleWeekends as neededEvenings as needed Location7501 West Memorial Road Oklahoma City OK 73142 Full job description This individual uses techniques and tasks to work as a liaison among stakeholders to understand the operations structure and policies of the organization and also recommend IT solutions that enable the organization to successfully complete new business initiatives In addition this individual is highly organized works well in a team environment and partners closely with the IT Systems Analysts role while leading projects   RESPONSIBILITIES   Protects organizations value by keeping information confidential  Works with stakeholders and functional areas to develop business requirements  Identifies and resolves gaps in technology processes and resources  Ensures timely delivery of requirements and design documents in line with project milestones  Regularly provides guidance and direction to junior Business Analysts   Documentation   Statement of Work  Project Plan  Business Process Diagrams  User Training Guides  Meeting Minutes  Project Status Updates   Miscellaneous   Attends meetings and serves on committees as requested  Performs additional duties and assignments as requested   EducationCertification   Bachelor’s degree in Information Science Business Administration or related discipline   Experience   2 years of IT related Business Analysis experience  1 years of relevant technical IT experience  Long term multiphase systems implementation projects  Advanced knowledge and experience with diagraming  Principles and best practices from PMIBOK  User Acceptance Testing  The Systems Development Life Cycle  Project Proposals  Software Testing  Regression Testing  Change Management  Emerging technology trends    PREFERRED QUALIFICATIONS  EducationCertification   Has PMI or vendor specific certifications   SkillsAbilities   Demonstrates interpersonal skills required to successfully work in a team environment and communicates effectively across a variety of stakeholder groups Has excellent written and verbal communication skills  Must adhere to PMI code of ethics and professional conduct  Experience in defining detailed business requirements to support strategic andor tactical projects  Proven ability to document business requirements business processes and project plans  Can evaluate critical systems prioritize workflow and determine solutions  Is confident to have face to face interactions with the business  stakeholders including upper management and chief officers  Can easily adapt and learn new software systems and technology  Must demonstrate a commitment to continuous learning and mentoring  Can Interpret and apply laws regulations policies and procedures  Must possess proficiency in MS Office applications Word Excel PowerPoint Outlook Visio  Can work flexible hours including weekends and evenings    Paycom is an equal opportunity employer and prohibits discrimination and harassment of any kind Paycom makes employment decisions on the basis of business needs job requirements individual qualifications and merit Paycom wants to have the best available people in every job Therefore Paycom does not permit its employees to harass discriminate or retaliate against other employees or applicants because of race color religion sex sexual orientation gender identity pregnancy national origin military and veteran status age physical or mental disability genetic characteristic reproductive health decisions family or parental status or any other consideration made unlawful by applicable laws Equal employment opportunity will be extended to all persons in all aspects of the employeremployee relationship This policy applies to all terms and conditions of employment including but not limited to hiring training promotion discipline compensation benefits and separation of employment The Human Resources Department has overall responsibility for this policy and maintains reporting and monitoring procedures Any questions or concerns should be referred to the Human Resources Department To learn more about Paycoms affirmative action policy equal employment opportunity or to request an accommodation  Click on the link to find more information paycomcomcareerseeoc  ,\n",
       " Profile insightsFind out how your skills align with the job descriptionSkillsDo you have experience in TableauYesNoEducationDo you have a Bachelors degreeYesNo LocationNew York NY BenefitsPulled from the full job description401k401k matchingGym membershipHealth insurancePaid time offParental leave Full job description  A market leader in credit intelligence Reorg brings together journalists financial analysts legal analysts technologists and data scientists to collect and synthesize highly complex information into actionable intelligence Since 2013 tens of thousands of professionals across hedge funds investment banks management consulting and law firm verticals have come to rely on Reorg to make better faster and more confident decisions in pace with the fastmoving credit markets For more information visit wwwreorgcom    Working at Reorg       Consistent with our growth Reorg hires innovators and trailblazers across the globe to drive our business and our incredible corporate culture alike Our core values – Action Oriented Customer First Mindset Effective Team Players and Driven to Excel – define an organizational ethos that’s as highperforming as it is human Among other perks Reorg employees enjoy competitive health benefits matched 401k and pension plans Paid time off generous parental leave gym subsidies educational reimbursements for career development recognition programs petfriendly offices and much more      The Role   Reorg’s Digital Marketing team is seeking a Marketing Data Analyst to unlock the power of datadriven decisionmaking within our marketing and commercial teams You will play a pivotal role in extracting valuable insights from complex data sets to shape our marketing strategies enhance customer experience and drive our business forward  Responsibilities  Developing a deep understanding of our products internal tools strategic priorities stakeholder needs as well as key customers segments Data Mining and Analysis Implement advanced data mining techniques to extract valuable insights from large structured and unstructured data sets Insights Generation Analyze data to identify trends patterns and insights that inform marketing strategies and decisionmaking processes Reporting and Visualization Develop and present clear comprehensive reports and visualizations that translate complex data into actionable insights for the marketing team Crossfunctional Collaboration Work closely with marketing sales product and IT teams to ensure alignment of insights and strategies across the organization Customer Segmentation and Targeting Utilize data mining to refine customer segmentation and targeting strategies enhancing personalization and engagement Campaign Analysis Measure and analyze the effectiveness of marketing campaigns providing recommendations for optimization and future strategies  Requirements  Bachelor’s degree or higher 3 years of data science statistics or a related field Proven experience in data mining analysis and reporting within a marketing context Strong analytical skills with the ability to collect organize analyze and disseminate significant amounts of information with attention to detail and accuracy Proficiency in data mining and analytics tools eg SQL R Python and data visualization tools eg Tableau Power BI Knowledge of digital marketing channels and metrics Excellent communication and presentation skills with the ability to translate data insights into actionable marketing strategies Strong problemsolving skills and the ability to work under pressure in a fastpaced environment Team player with the ability to collaborate effectively with crossfunctional teams Ability to work from the New York City office 3 days per week US remote candidates will also be considered   At Reorg we consider a range of factors in connection with compensation decisions including experience skills location and our business needs and limitations As a result compensation may vary within and across similar roles and positions Please note that the salary range information below is a good faith estimate for this position and actual compensation for any individual may fall outside this range if warranted by the circumstances applicable to that individual If we identify a role that would be suitable for a broader range of skills and experience such that we would consider hiring at multiple levels then the range listed below may reflect that breadth  The salary range estimate for this position is 75000  90000  The actual compensation will be at Reorg’s sole discretion and will be determined by the aforementioned and other relevant factors This position is eligible for additional commissionbased compensation  Reorg provides equal employment opportunities EEO to all employees and applicants for employment without regard to race color religion sex national origin age disability or genetics In addition to federal law requirements Reorg complies with applicable state and local laws governing nondiscrimination in employment in every location in which the company has facilities This policy applies to all terms and conditions of employment including recruiting hiring placement promotion termination layoff recall transfer leaves of absence compensation and training   ,\n",
       " Profile insightsFind out how your skills align with the job descriptionSkillsDo you have experience in Supervising experienceYesNoEducationDo you have a Bachelors degreeYesNo Job detailsHere’s how the job details align with your profilePay90000  100000 a yearJob typeFulltime LocationArlington VA 22209 BenefitsPulled from the full job description401k401k matchingADD insuranceCell phone reimbursementDental insuranceFlexible spending accountHealth insuranceShow morechevron down Full job description      Trilogy Federal provides financial management information technology IT consulting program management services and strategic consulting to federal agencies Trilogy has an extensive history helping federal clients achieve their most ambitious business modernization and optimization goals with the ability to deliver targeted subject matter expertise and full life cycle support       Trilogy Federal is looking for a strategic and thoughtful Sr Data Analyst to consult and develop datacentered projects In keeping with this overarching aim the Sr Data Analyst will be required to outline work requirements quickly develop an understanding of our customer’s datarelated challenges provide solutions that consider the customer’s specific requirements and constraints and work with a crossfunctional team to deliver timely and tangible results You should also harness your mastery of data analysis to consult and directly participate in various aspects of these and other projects To be successful as a Sr Data Analyst you should use data to ultimately inform sound decisionmaking in support of automation efforts and efficiency The ideal candidate will also assist in the development of junior staff       Primary Responsibilities    Formulating suggesting and managing datadriven projects which are geared at furthering the businesss interests  Collating and cleaning data from various entities for later use by junior data scientists  Delegating tasks to Junior Data Scientists to realize the successful completion of projects  Monitoring the performance of Junior Data Scientists and providing them with practical guidance as needed  Selecting and employing advanced statistical procedures to obtain actionable insights  Crossvalidating models to ensure their generalizability  Producing and disseminating nontechnical reports that detail the successes and limitations of each project  Suggesting ways in which insights obtained might be used to inform business strategies  Staying informed about developments in Data Science and adjacent fields to ensure that outputs are always relevant  Assist clients on functional and data requirements to enhance reporting effectiveness  Develop Microsoft Forms to assist clients with gathering information Use analytics to evaluate and summarize responses  Provide subject matter experience for clients seeking to improve content management and versioning  Adhere to established methodologies while analyzing processes for improved performance and adaptability       Minimum Requirements    Able to obtain a Public Trust Clearance  Bachelor’s degree data science statistics computer science or similar preferred  10 years’ experience  Consultative mindset and demonstrated work experience providing solutions for clients and proactively collaborating with Stakeholders  Deep knowledge of statistics and linear algebra concepts ANOVA distributions PCA  Proficiency in R or Python  Proficiency in SQL  Familiar with machine learning principles and techniques  Demonstrable history of devising and overseeing datacentered projects  Ability to relay insights in laymans terms such that these can be used to inform business decisions  Capacity to work independently or collaboratively with a crossfunctional team       Preferred Qualifications    VA experience preferred  Advanced degree in data science statistics computer science or similar  Detailoriented with the ability to manage multiple tasksrequests  Strong written and verbal communications skills  Supervision and mentorship skills       Benefits including but not limited to    Health dental and vision plans  Optional FSA  Paid parental leave  Safe Harbor 401k with employer contributions 100 vested from day 1  Paid time off and 11 paid holidays  No cost group term lifeADD plan and optional supplemental coverage  Pet insurance  Monthly phone and internet stipend  Tuition and training reimbursement          90000  100000 a year         This range is not a guarantee of compensation or salary as Trilogy Federal conducts an individual equity review for every candidate based on experience location education industry experience and comparisons to internal pay bands In addition to salary Trilogy offers robust benefits including medicaldentalvision insurance coverage 401k match paid holidays paid time off tuition reimbursement and a very supportive worklife balance       Regarding remote positions Trilogy Federal is only able to offer virtual employment in the following states Colorado Connecticut Delaware DC Florida Illinois Indiana Maine Maryland Massachusetts New York South Carolina Texas and Virginia     Trilogy Federal is an Equal Employment Opportunity employer We do not discriminate based upon race religion color national origin gender including pregnancy childbirth or related medical conditions sexual orientation gender identity gender expression age status as a protected veteran status as an individual with a disability or other applicable legally protected characteristics    ,\n",
       " Profile insightsFind out how your skills align with the job descriptionSkillsDo you have experience in Project managementYesNoEducationDo you have a Bachelors degreeYesNo LocationHouston TX 77043 BenefitsPulled from the full job descriptionDental insuranceEmployee assistance programHealth insurancePaid time offRetirement planVision insurance Full job description    Company Overview    Founded in 1906 over the last 110 years CEMEX has grown into a global building materials company that provides high quality products and reliable service to customers and communities throughout the Americas Europe Africa the Middle East and Asia Here at CEMEX we offer our employees competitive wages career growth excellent benefits including health dental  vision plans vacation or paid time off employee assistance program and retirement plan options along with over a century of stability to build your next career on      Job Summary    The Sales Administration Analyst provides support to the sales team provides metrics analysis and support to the customer base with focus on the MRT and Admixtures business lines for all the US operations and all customer segments      Job Responsibilities    Support on invoicing InternalExternal customers creditdebit memos create update and maintain sales contracts and sales pricing Support during audit inquiries Forecasting Process and control of purchase orders for the department ie confirm no duplications payments are released etc Support during month end  month end reports Support with pricing and volume analysis on all business lines Coordinate as needed creation and setup of additional invoicing of products services and fees Support system customer hierarchy changes  updates Assist with customer reconciliations Provide the sales force with information requests ie volume reports customer pricing PO numbers etc Assist in new customer set ups Process vendor POs for various associations membership dues customer events etc Manage weekly billing process for MRT and Admixtures business lines Request corrections on identified errors prior to invoicing assist sales force troubleshoot pricing errors issues with new contracts etc Coordinate  communicate with terminal managers and regional logistic teams       Qualifications    Bachelor’s degree in business or related field 14 years of experience Proven knowledge and experience with Accounting Invoicing Pricing Customer Care Administration       Knowledge Skills and Abilities    Advanced skills in Microsoft Office Excel including Macro  Pivot Table PowerPoint Word etc SAP skills strongly preferred InvoicingAccounting software experience preferred Excellent analytical and problemsolving skills Ability to track measure and analyze dataresults and key metrics Strong project management organizational skills planning skills Strong interpersonal skills and attention to detail Team player able take a leadership role in dealing effectively with various internal and external teamsdepartments Proven ability to work independently meet multiple deadlines and manage a heavy workload in a fastpaced environment Ability to work independently and with minimal supervision       Working Conditions    Capable of working in an open concept office environment      Physical Requirements    Requires walking sitting lifting pushing pulling and climbing to a significant degree Exerting up to 20 pounds of force occasionally andor a negligible amount of force frequently Job involves sitting most of the time but also involves walking or standing for brief periods of time While performing the duties of this job the employee is regularly required to talk and hear in order to communicate to employeesvisitors      Legal Notices    CEMEX is an EEOAA equal opportunityaffirmative action institution and does not discriminate on the basis of race color religion religious creed sex sexual orientation gender identity or expression national origin ancestry age physical or mental disability medical condition genetic information marital or familial status military or veteran status or any other characteristic protected by under federal state or local law in the programs or activities which it operates CEMEX will consider for employment qualified applicants with criminal histories in a manner consistent with all local state and federal laws CEMEX is an EVerify participating employer Arizona SmokeFree Act CEMEX complies with the State of Arizona’s SmokeFree Act Arizona Revised Statutes § 3660101 Smoking andor the use of tobacco or related products is prohibited in and on CEMEX property as well as any building andor vehicle owned or leased by CEMEX      EEO Statement  En Español    CEMEX es una institución EEOAA igualdad de oportunidadacción afirmativa y no discrimina en base al sexo edad raza color religión discapacidad física o mental credo origen nacional estatus veterano orientación sexual infomación genética identidad de género o expresión de género en los programas o actividades los cuales opera     ,\n",
       " Profile insightsFind out how your skills align with the job descriptionSkillsDo you have experience in StatisticsYesNoEducationDo you have a Masters degreeYesNo Job detailsHere’s how the job details align with your profileJob typeFulltime Location107 Gilbreth Parkway Mullica Hill NJ 08062 Full job description MAJOR FUNCTION The Managing Data Analyst will be a key member of the Advanced Analytics team for developing business intelligence solutions and visualizations of strategic data insights They will organize and manage large scale data projects including business requirement gathering collaborating with business partners and developing data visualizations for operational and strategic improvement projects QUALIFICATIONS  Education  Experience  Bachelor’s or Master’s degree in a quantitative field such as Mathematics Statistics Physics Economics Computer Science Minimum 2 years of relevant experience in data analysis or related field   CertificationLicensure  NA  Knowledge  Skills  Strong analytical and problemsolving skills Advanced proficiency in Excel SQL and basic data visualization tools  Proven working experience in Analytics and Business Intelligence for the purpose of deriving business insights Ability to collect organize analyze and disseminate significant amounts of information with attention to detail and accuracy  Proven experience in data analysis with a focus on project management Mastery of data quality and business intelligence concepts familiar with data science concepts Experience with data models database design development data mining and segmentation techniques Knowledge of statistics and experience using statistical packages for analyzing data sets Excel SPSS SAS etc Excellent leadership and communication skills    Physical Requirements N Never O Occasionally 20 F Frequently 2080 C Constantly 80  Lifting 20lbs O Standing F Sitting C  Lifting 2050lbs N Climbing N Kneeling F  Lifting50lbs N Crouching O Reaching F  Carrying O Hearing C Walking F  Pushing O Talking C Vision C  Environmental Conditions  Noise N Varied Temperatures N Cleaning Agents N  Noxious odors N Patient Exposure N Operative Equipment N       At Inspira Health you’ll join with the area’s most dedicated and distinguished team to bring quality and compassionate care to our communities We focus on clinical excellence providing evidencebased care to help each patient achieve the best possible outcome The scope and depth of our network can open many doors for your learning and career growth Our charitable nonprofit health care organization serves communities across southern New Jersey The network which traces its roots to 1899 comprises three hospitals a comprehensive cancer center sleep medicine cardiac testing digestive health and wound care urgent care imaging and rehabilitation and primary and specialty physician practices in Gloucester Cumberland Salem and Camden counties Inspira is an Equal Opportunity Employer All qualified applicants will receive consideration for employment without regard to race religion creed color national origin ancestry age marital status affectional or sexual orientation familial status disability liability for service in the Armed Forces of the United States nationality sex gender identity or expression  ,\n",
       " Profile insightsFind out how your skills align with the job descriptionCertificationsDo you have a valid Professional In Human Resources certificationYesNoSkillsDo you have experience in SQLYesNoEducationDo you have a Bachelors degreeYesNo Job detailsHere’s how the job details align with your profileJob typeFulltime Location7501 West Memorial Road Oklahoma City OK 73142 Full job description This position works with HR and the business to develop reports and provide analysis to inform and support decisionmaking This role will utilize data analysis methodologies reporting and data visualization tools requires an understanding of data miningmashing and data visualization with an analytical mindset an understanding of data quality auditing and proactively improve the quality of reporting and data and the ability to frequently interface with executive and senior leaders  RESPONSIBILITIES   Conducts analysis of HR andor business data to identify actionable insights Merges data from multiple sourcessystems and provides adhoc reporting when needed  Leverages internal HR andor business data using internal tools systems and data sources  Collaborates with crossfunctional teams HR IT Product Management and Development to develop progressive analytics use cases for Product Management  Proactively partners with key stakeholders to address business gaps or opportunities identified through analytics  Develops reports dashboards and models to explore data and explain opportunities  Merges structured semistructured and unstructured data from several systems to highlight company trends related to recruiting and other business areas  Performs moderately complex data analysis and generates insights to support the HR workforce analytics needs of the business to drive informed business decisions  Delivers high quality analysis reports presentations using simple and effective visualizations that can be scaled for consumption by a larger audience  Creates and maintains monthly and quarterly workforce metrics and analysis  Builds strong relationships and collaborates with teammates business leaders and other internal clients  Automates data and analytics solutions builds and prototypes dashboards to provide insights  Continuously monitors data quality and integrity  Performs statistical tests on large datasets to determine data quality and integrity  Evaluate system performance and design as well as its effect on data quality  Collaborate with database developers to improve data collection and storage processes  Run data queries to identify coding issues and data exceptions as well as cleaning data  Documents processes and maintains data records  Adhere to best practices in data analysis and collection  Keep abreast of developments and trends in data quality analysis  Manipulates and analyzes large data sets to gain insights and provide recommendations  Documents and maintains procedures for reports and records of information management and storage protocols  Develops and delivers weekly monthly and quarterly client group metrics  Leverages advanced technical knowledge of excel and other data visualization tools  Utilize project management tools to manage data development projects   EducationCertification   Bachelors degree   Experience   2 years of experience in Data Analytics  Experience with data visualization and advanced analytics tools  Human Resources experience   PREFERRED QUALIFICATIONS  EducationCertification   Bachelors degree in Business Finance Human Resources or Quantitative Analytics  PMI and PHR certification   Experience   2 years of experience in HR Data Analytics  Human ResourcesWorkforce Analytics experience  Experience with Power BI  Experience in coding languages including DAX SQL and Python   SkillsAbilities   Critical analytical thinker with strong communication skills  Strong analytical skills and the ability to collect organize analyze and disseminate significant amounts of information with attention to detail and accuracy  Information chain analysis and management  Root cause analysis  Technical expertise regarding data models database design development data mining and segmentation techniques  Adept at queries report writing and presenting findings  Selfstarter who thrives in a fastpaced environment  Strong understanding of HR processes and procedures  Collaborative partner builds and maintains professional relationships  Project management skills    Paycom is an equal opportunity employer and prohibits discrimination and harassment of any kind Paycom makes employment decisions on the basis of business needs job requirements individual qualifications and merit Paycom wants to have the best available people in every job Therefore Paycom does not permit its employees to harass discriminate or retaliate against other employees or applicants because of race color religion sex sexual orientation gender identity pregnancy national origin military and veteran status age physical or mental disability genetic characteristic reproductive health decisions family or parental status or any other consideration made unlawful by applicable laws Equal employment opportunity will be extended to all persons in all aspects of the employeremployee relationship This policy applies to all terms and conditions of employment including but not limited to hiring training promotion discipline compensation benefits and separation of employment The Human Resources Department has overall responsibility for this policy and maintains reporting and monitoring procedures Any questions or concerns should be referred to the Human Resources Department To learn more about Paycoms affirmative action policy equal employment opportunity or to request an accommodation  Click on the link to find more information paycomcomcareerseeoc  ,\n",
       " Profile insightsFind out how your skills align with the job descriptionSkillsDo you have experience in TableauYesNoEducationDo you have a Masters degreeYesNo Job detailsHere’s how the job details align with your profileJob typeFulltime LocationRemote Full job description POSITION SUMMARY   Under the direction of the Senior Director of Finance Pharmacy the Senior Revenue Cycle Business Analyst position is responsible for developing standard reports and overseeing financial activities of BMC Pharmacy They will play a key role in projects across the BMC Pharmacy function with a focus on analysis of data to inform management drive accountability and guide financial decisions This position is very dynamic and given the entrepreneurial and fastpaced atmosphere of the BMC Pharmacy business development office the candidate must be able to work independently and solve problems that have a significant impact to BMC financials and its strategic plan HeShe shares responsibility for the operational effectiveness within the Pharmacy department to ensure that highquality financial services are delivered in accordance with applicable policies procedures and professional standards HeShe analyzes the financialeconomic benefits and cost impact of new and existing business initiatives Prepares recommendations and business models to assist the organization in improving resource allocationutilization Provides analytical support to resolve operating and finance issues Creates a positive constructive and supportive relationship between Finance and Pharmacy   Position Senior Revenue Cycle Business Analyst  Department Pharmacy Finance  Schedule Full Time   ESSENTIAL RESPONSIBILITIES  DUTIES   The Senior Revenue Cycle Business Analyst will play a key role in various aspects of financial planning and evaluation which may include the development of the annual operating budget and multiyear financial plan capital expenditure planning month end close monitoring and new program evaluations   Financial ReportingBudget Tasks   Develops tests and deploys standard reports and dashboards based on business requirement document specifications Complete special projects and other duties as assigned Assists in the development of business plans and sophisticated financial models to adapt to changes in services or long term planning Coleads the annual forecast process including modeling advanced assumptions at a very detailed level    Project ManagementFinancial Planning   Works collaboratively with Business Systems Analysts andor directly with key business users to ensure business requirements and report specifications are documented accurately and completely Conducts market analysis by attending conferences to stay up to date on changes in billingregulatory compliances 340b Incorporates data from multiple sources in evaluations Examples include hospital and physician billing system budget system cost accounting system and general ledger Work on andor lead special projects that require research and analysis May involve partnering with other business areas to identify and resolve issues Conform to hospital standards of performance and conduct including those pertaining to patient rights so that the best possible customer service and patient care may be provided Utilizes hospital’s behavioral standards as the basis for decision making and to support the hospital’s mission and goals Complete special projects and other duties as assigned Develops tests and deploys standard reports and dashboards based on business requirement document specifications Works collaboratively with Business Systems Analysts andor directly with key business users to ensure business requirements and report specifications are documented accurately and completely Incorporates data from multiple sources in evaluations Examples include hospital and physician billing system budget system cost accounting system and general ledger Work on andor lead special projects that require research and analysis May involve partnering with other business areas to identify and resolve issues Conform to hospital standards of performance and conduct including those pertaining to patient rights so that the best possible customer service and patient care may be provided Utilizes hospital’s behavioral standards as the basis for decision making and to support the hospital’s mission and goals Complete special projects and other duties as assigned    JOB REQUIREMENTS   EDUCATION   Bachelors degree required preferably in a finance field or related field of study Masters Degree in Business Public Health or related field preferred    CERTIFICATES LICENSES REGISTRATIONS REQUIRED   Epic Revenue Data Model Clarity Certification    EXPERIENCE   5 years of related managed healthcare or insurance operations experience Expertise with relational database concepts data modeling and OLAP technologies Demonstrated proficiency in Business Objects Crystal Reporting including Universe Designer Web Intelligence Dashboards and Explorer    KNOWLEDGE AND SKILLS   Project management skills including familiarity with project management phases techniques and tools  Ability to overcome obstacles and lead projects to a successful conclusion Ability to translate data into useful information and to communicate key findings and assumptions in concise fashion to senior management for decision making purposes Highly analytical thinking with talent for identifying scrutinizing improving and streamlining work processes Advanced MS Excel Access Word and PowerPoint skills Experience with hospital claims data Tableau andor MS Access or SQL a plus EPIC experience required with EPIC Certifications preferred Strong commitment to excellence and person and professional growth Excellent written and verbal communication skills Strong interpersonal skills to effectively work and communicate with all levels in the organization Knowledge of health care finance and delivery systems preferred but not required    Equal Opportunity EmployerDisabledVeterans  ,\n",
       " Profile insightsFind out how your skills align with the job descriptionSkillsDo you have experience in S3YesNoEducationDo you have a Bachelors degreeYesNo Job detailsHere’s how the job details align with your profilePay55  75 an hourJob typeContractShift and schedule8 hour shift LocationChicago IL BenefitsPulled from the full job description401kDental insuranceHealth insurance Full job descriptionJob Title Data Analyst Location Chicago IL Duration Long Term Role is also available in McLean VA – Richmond VA – Plano TX – New York NY Responsibilities · Utilize AWS cloud infrastructure to design develop and maintain data analytics solutions · Collaborate with crossfunctional teams to gather requirements and translate them into scalable AWSbased solutions · Perform data modeling data transformation and data visualization tasks using AWS services such as EC2 S3 EKS OpenShift Lambda API Gateway RDS CFT etc · Implement best practices for data security data governance and data quality assurance within the AWS environment · Optimize and finetune AWS resources to ensure high performance and cost efficiency · Troubleshoot and resolve issues related to AWS infrastructure and data pipelines · Stay updated on the latest AWS services and features to continuously enhance our data analytics capabilities Requirements · Bachelors degree in Computer Science Information Technology or related field · Minimum of 3 years of handson experience working with AWS cloud services · Strong understanding of AWS architecture principles and best practices · Proficiency in using AWS services such as EC2 S3 EKS OpenShift Lambda API Gateway RDS CFT etc · Experience with data analytics tools and technologies including data modeling ETL processes and data visualization · Familiarity with data security and compliance standards in the AWS cloud environment · Excellent problemsolving skills and ability to troubleshoot complex issues · Strong communication and collaboration skills with the ability to work effectively in a team environment Job Type Contract Salary 5500  7500 per hour Benefits  401k Dental insurance Health insurance  Schedule  8 hour shift  Experience  AWS 2 years Required Data pipelines 2 years Required Data Governance 2 years Required  Work Location On the road ,\n",
       " Profile insightsFind out how your skills align with the job descriptionSkillsDo you have experience in TableauYesNoEducationDo you have a Bachelors degreeYesNo LocationPortland ME 04101 Full job description JOIN OUR TEAM  Onpoint Health Data is a dynamic fastgrowing nonprofit company located in Portland Maine committed to delivering independent reliable and insightful data solutions to clients nationwide If you are a motivated selfstarter looking for an opportunity to work with emerging technologies and a collaborative energetic team Onpoint would be a perfect fit We offer a competitive benefits package and a great office space conveniently located in Portlands East End We work a hybrid schedule with two inoffice days each week Tuesdays and Thursdays  DEPARTMENT  Data Analytics and Operations  DESCRIPTIVE SUMMARY  The Health Data Analyst HDA works closely with the Analytics team to review analyze and provide graphical and verbal presentation of health care data The HDA learns to run queries and interprets outcomes to provide a key quality assurance role for our clients data The HDA will also run reports that inform our clients on health care quality access and cost Under direction of senior staff the HDA also investigates unusual findings in the data and helps build new reports and products The HDA must be detail oriented capable of learning independently and able to work on multiple projects at a time in a fastpaced teamoriented environment  RESPONSIBILITIES  Analysis and Reporting  Learn to use software tools such as SQL SAS R to query medical claims data and provide clients reports for multiple projects eg use existing code to conduct linkages run quality measure rates refresh of person level files for analytic use After becoming familiar with coding tools begin to modify code to develop new reports Prepare graphical reports using Tableau Excel and other statistical programs and PowerPoint Work with senior members of the Analytics Team to present health data in an accurate efficient and thoughtful manner May take a lead analyst role on clientproject after becoming familiar with Onpoint processes and databases  Quality Assurance  Support analytic staff by running Onpoints data quality processes for extracts and other Onpoint products and reports This may include running queries using SAS and SQL to identify unusual findings in analyses and reports and reviewing them with the project lead and senior analysts Assist with evaluation and testing of new software applications Help complete review and quality assurance of multiple Onpoint reports and deliverables  General  Work with Health Analytics Manager and project leads regularly to balance multiple projects and priorities Begin to develop expertise in All Payer Claims Data Onpoints data systems and other healthcare topics Begin to develop strong understanding of relational databases Actively seek opportunities to learn and contribute more to the team As a member of a broader team take on and perform duties beyond specific role as assigned  Other  Understand the value that Onpoint places on maintaining the confidentiality and integrity of our corporate and client data and meet applicable privacy and security compliance requirements Ensure that Onpoint and client data is accessed handled processed transmitted disclosed and stored according to operational and IT policies and procedures Immediately report any suspected or actual violation of privacy and security policies or unauthorized access or disclosure of Onpoint or client data Understand that compliance with all privacy and security policies laws and regulations is part of each employees annual performance evaluation Adhere to all policies and procedures as outlined in the Onpoint Health Data Employee Handbook Perform all other duites as assigned  QUALIFICATIONS  Bachelors degree in sciences mathematics or another major with an emphasis on analytical or quantitative skills development or equivalent experience Strong problem solving and critical thinking skills Proficiency utilizing Excel andor other data visualization tools to work with and analyze data sets Excellent verbal and written communication skills An interest in working with clients in a professional environment Detailoriented Experience handling multiple projects while successfully meeting deliverable due dates Experience working collaboratively as well as independently within multidisciplinary teams Experience in health care data and analysis health information technology statistics relational databases andor knowledge of querying and analytical tools eg SAS SQL Tableau R Python Excel preferred  Onpoint Health Data is an equal opportunity employer and prohibits discrimination and harassment of any kind We recruit employ train compensate and promote without regard to race religion creed color national origin age gender identity andor expression sexual orientation marital status disability veteran status or any other basis protected by applicable federal state or local law   ,\n",
       " Profile insightsFind out how your skills align with the job descriptionSkillsDo you have experience in SQLYesNoEducationDo you have a Bachelors degreeYesNo Job detailsHere’s how the job details align with your profileJob typeFulltime LocationWashington DC Full job description Employment Type Full Time  Location Washington DC 23 days onsiteweek and remote the rest of the time  Supervises No   Must be US Citizen and be able to pass a DHS Full Scope Background Investigation   Description of Work  4SSilversword Software  Services is seeking a SAP BusinessobjectsQlik Sense Developer to fill a Data Reporting Engineer position at Customs and Border Protection The candidate is expected to demonstrate expertise drafting reports using SAP Business Objects Qlik Sense and provide information reporting to the functional team supporting the OCMO The Data Reporting Engineer will support the reporting team by authoring scheduled and adhoc reports according to policy and procedural guidance   Duties  Responsibilities   Design and develop complex reports using SAP Business Object and tools like Web Intelligence Plan and implement automated bursting of reports via publication services and scheduling Perform report requirements analysis provide effort estimation create dashboards and draft scheduled as well as adhoc reports Comprehensive knowledge of Data Reporting methodologies and deliverables  Job Requirements   Requirements  Required Education Skills and Experience   Bachelor’s Degree or higher in a business or technical discipline 5 years of development experience with SAP Business Objects including Web Intelligence and relevant experience as a Data and Report Engineer Excellent communication and consulting skills with ability to work independently Strong Knowledge in Qlik Sense Experience with trouble shooting production issues SAP Business Objects Reporting and Data Visualization experience using Web Intelligence and Dashboards Expertise in dimensional data modeling and knowledgeable in writing SQL Good understanding of User Security in Business Objects Experience with migrating reports and enhancing report performance    Physical Requirements  Work may involve sitting or standing for extended periods of time Position may require typing and reading from a computer screen Must have sufficient mobility including but not limited to bending reaching and kneeling to complete daily duties in a timely and efficient manner There is a possibility that due to parking availability and location of work walking moderate to long distance may be required Possible lifting up to 25 lbs Please note 4SSilversword Software and Services LLC reserves the right to change or modify job duties and assignments at any time The above job description is not all encompassing Positions functions and qualifications may vary depending on business needs 4SSilversword Software and Services LLC is an equal opportunity employer and does not discriminate against applicants based on race color creed religion medical condition legally protected genetic information national origin sex including pregnancy childbirth or related medical condition sexual orientation gender identity and expression age disability or Vietnam era or other eligible veteran status or legally protected characteristics        Get job alerts by email Sign up now Join Our Talent Network      Job Snapshot  Employee Type FullTime      Location Washington DC Onsite      Job Type Admin  Clerical Information Technology      Experience Not Specified      Date Posted 03212024      ,\n",
       " Profile insightsFind out how your skills align with the job descriptionSkillsDo you have experience in SmartsheetYesNoEducationDo you have a Masters degreeYesNo Job detailsHere’s how the job details align with your profilePay102340  132440 a yearJob typeFulltime LocationKnoxville TN 37902 BenefitsPulled from the full job description401k401k matchingAdoption assistanceDental insuranceDisability insuranceFlexible scheduleHealth insuranceShow morechevron down Full job description At US Bank we’re on a journey to do our best Helping the customers and businesses we serve to make better and smarter financial decisions and enabling the communities we support to grow and succeed We believe it takes all of us to bring our shared ambition to life and each person is unique in their potential A career with US Bank gives you a wide evergrowing range of opportunities to discover what makes you thrive at every stage of your career Try new things learn new skills and discover what you excel at—all from Day One   Job Description     The Project Analyst position within our organization holds a crucial role within our Design Program through implementation of continuous improvement initiatives program advancements and comprehensive documentation strategies specifically tailored for PAO Market Activation This role is specifically focused on driving enhancements in Site Selection processes CapEx documentation Smartsheet reporting monthly document generation and overall process refinement within the PAO Market Activation framework Additionally it involves spearheading the advancement and documentation of InStore lease programs alongside rigorous reporting obligations To excel in this capacity we seek an individual with exceptional organizational and analytical abilities underpinned by a robust grasp of project management principles The ideal candidate will possess a talent for conceptualizing and developing the programmatic solutions that yield tangible improvements They will be adept at conducting indepth research analyzing data and crafting recommendations that not only reduce costs but also amplify benefits Effective communication and collaboration skills are imperative as this role requires seamless coordination and partnership across various departments     Moreover this role will entail assisting the Market Activation Director with reporting calendar management scheduling program management and presentation generation This aspect of the role involves providing crucial support to ensure smooth operations and effective communication within the Market Activation team The successful candidate will demonstrate proficiency in managing calendars coordinating schedules and generating insightful reports to aid decisionmaking processes Additionally they will possess strong program management skills enabling them to oversee multiple initiatives simultaneously Presentation generation will be a key responsibility requiring the ability to translate complex data and insights into compelling visual narratives These tasks are integral to the success of the Market Activation Director and the overall efficiency of the Market Activation function        Basic Qualifications     Bachelors or Masters degree or equivalent work experience 10 or more years of experience in project management activities   Preferred SkillsExperience     Expert knowledge of assigned business line or functional area Strong organizational and analytical skills Thorough knowledge of project management Ability to identify and resolve exceptions and to analyze data Demonstrated leadership skills Microsoft Office Suite experience    Data management experience       The role offers a hybridflexible schedule which means theres an inoffice expectation of 3 or more days per week and the flexibility to work outside the office location for the other days     If there’s anything we can do to accommodate a disability during any portion of the application or hiring process please refer to our disability accommodations for applicants   Benefits  Our approach to benefits and total rewards considers our team members’ whole selves and what may be needed to thrive in and outside work Thats why our benefits are designed to help you and your family boost your health protect your financial security and give you peace of mind Our benefits include the following some may vary based on role location or hours   Healthcare medical dental vision  Basic term and optional term life insurance  Shortterm and longterm disability  Pregnancy disability and parental leave  401k and employerfunded retirement plan  Paid vacation from two to five weeks depending on salary grade and tenure  Up to 11 paid holiday opportunities  Adoption assistance  Sick and Safe Leave accruals of one hour for every 30 worked up to 80 hours per calendar year unless otherwise provided by law    EEO is the Law  US Bank is an equal opportunity employer committed to creating a diverse workforce We consider all qualified applicants without regard to race religion color sex national origin age sexual orientation gender identity disability or veteran status among other factors   EVerify  US Bank participates in the US Department of Homeland Security EVerify program in all facilities located in the United States and certain US territories The EVerify program is an Internetbased employment eligibility verification system operated by the US Citizenship and Immigration Services  The salary range reflects figures based on the primary location which is listed first The actual range for the role may differ based on the location of the role In addition to salary US Bank offers a comprehensive benefits package including incentive and recognition programs equity stock purchase 401k contribution and pension all benefits are subject to eligibility requirements Pay Range 10234000  12040000  13244000   Job postings typically remain open for approximately 20 days of the posting date listed above however the job posting may be closed earlier should it be determined the position is no longer required due to business need Job postings in areas with a high volume of applicants such as customer service contact center and Financial Crimes investigations remain open for approximately 5 days of the posting listed date  ,\n",
       " Profile insightsFind out how your skills align with the job descriptionSkillsDo you have experience in Systems engineeringYesNoEducationDo you have a Bachelors degreeYesNo Job detailsHere’s how the job details align with your profileJob typeFulltime LocationRedstone Arsenal AL Full job description  Tactica Solutions LLC is seeking an experienced and qualified Business Analyst for a Systems Engineering  Technical Assistance SETA contract supporting the US Army Space and Missile Defense Command USASMDC Office of the Deputy Chief of Staff Engineer DCSENG for facilities engineering  sustainment and environmental planning  compliance on Redstone Arsenal Alabama  Duties and Responsibilities   Create manage and maintain organizational files folders databases and office correspondence Provide recommendations to optimize daily operations increase efficiency and coordinate corrective action activities to resolve issues Maintain track and report the status of contract actions deliverables training credentials data calls and Rolling Action Item List RAIL items Perform office administrative functions calendar synchronization and deconfliction plan andor participate in inperson and virtual meetings and conference calls prepare and disseminate minutes organize and order supplies and coordinate travel Prepare review and track financial and budgetary reports Military Interdepartmental Purchase Requests DD Form 4484482 MIPRAcceptance Financial Requisition Summary FRS forms Purchase Requisitions PR spend plans and forecasts Interface with USASMDC and other agencies’ financial offices in matters related to funding cost reconciliation obligationsdeobligations and discrepancy resolution Establish collaborate and maintain professional relationships with team members customers vendors suppliers and partners Other duties as assigned  Job Requirements   Requirements – Knowledge Skills and Abilities   Bachelor’s degree Minimum of three 3 years of relevant experience supporting internal and external stakeholders Demonstrated ability to determine differences between contract types Costreimbursable Time and Materials TM Firm Fixed Price FFP etc and experience working within typical CLINSLINACRN structure breakdown ie Labor Travel and ODCs Lead preventative and corrective action efforts conduct root cause and statistical analyses and report findings Proficient working in a flexible environment and demonstrated ability to effectively organize prioritize delegate and multitask Possess excellent time management good judgment conflict resolution and excellent written oral and interpersonal communication skills Must be highly proficient using MS Office software applications Word Excel PowerPoint SharePoint Project Teams Outlook Ability and willingness to occasionally travel in support of customer requirements US citizenship required to obtain and maintain a US government issued security clearance at the appropriate level for the duration of the contract Period of Performance   Preferred Qualifications   Knowledge of US Army rank and grade structure and government civilian pay scale equivalencies Knowledge Management Support Tools KMST Information System familiarity Defense Travel System DTS and Joint Travel Regulations JTR familiarity General Fund Enterprise Business System GFEBS data management tool familiarity UnliquidatedNegative Unliquidated Obligations ULONULO resolution experience Active security clearance with current investigation   Job Location  Redstone Arsenal AL  Physical Requirements Work may involve sitting or standing for extended periods of time Position may require typing and reading from a computer screen Must have sufficient mobility including but not limited to bending reaching and kneeling to complete daily duties in a timely and efficient manner May include lifting weight up to thirty 30 pounds as necessary  Tactica Solutions LLC reserves the right to change or modify job duties and assignments at any time The above job description is not allencompassing Position functions and qualifications may vary depending on business needs  Tactica Solutions LLC is an equal opportunity employer and does not discriminate against applicants based on race color creed religion medical condition legally protected genetic information national origin sex including pregnancy childbirth or related medical condition sexual orientation gender identity and expression age disability or Vietnam era or other eligible veteran status or legally protected characteristics        Get job alerts by email Sign up now Join Our Talent Network      Job Snapshot  Employee Type FullTime      Location Redstone Arsenal AL Onsite      Job Type Finance General Business Accounting      Experience Not Specified      Date Posted 03202024      ,\n",
       " Profile insightsFind out how your skills align with the job descriptionSkillsDo you have experience in Systems analysisYesNoEducationDo you have a Masters degreeYesNo Job detailsHere’s how the job details align with your profilePay4339  6949 a monthJob typePermanentParttimeFulltime LocationEnterprise AL Full job description   Description   This posting is being used to fill various Data Processing Systems Analyst positions at the specified location The authorized level of the position is Data Processing Systems Analyst V Applications are being accepted down to the Data Processing Systems Analyst II in the event of recruiting difficulties  Salary Range All new external applicants will be placed on the initial step of the salary range However placement above the initial step of the salary range will be based on special characteristics and critical needs of the position an applicants exceptional qualifications the availability of funds and other relevant factors Such appointments require prior approval Hawaii State Department of Education employees will be placed on the salary range in accordance with Department regulations   Data Processing Systems Analyst II SR18 433900  528200 per month           Data Processing Systems Analyst III SR20 469000  571300 per month           Data Processing Systems Analyst IV SR22 507600  617700 per month           Data Processing Systems Analyst V SR24 571300  694900 per month        Examples of Duties   1 Plans and carries out various factfinding tasks to secure pertinent information on the electronic data processing needs and problems of departments 2 Conducts studies related to work flow work measurement time distribution organizational and functional relationships forms design etc 3 Meets with and interviews personnel from various levels of management and operations 4 Analyzes and coordinates subsystems 5 Determines the feasibility of conversion of operations and procedures to electronic data processing 6 Analyzes procedures from the standpoint of feasibility of using different machines their capacities cost etc 7 Prepares comprehensive reports of findings and recommendations 8 Prepares overall plans and develops detailed procedures and processes for conversion to machine processing utilizing current technologies such as teleprocessing data base management systems etc and including the preparation of flow charts and functional block diagrams 9 Integrates the various systems and procedures with the needs and requirements of the various agencies wherever possible 10 In a line department works in close cooperation with representatives of staff agencies 11 In the central agency works in close cooperation with representatives of operating departments 12 Prepares and maintains procedural manuals 13 May conduct management studies associated with other program or management objectives and needs 14 Prepares reports of work activities and correspondence 15 Reviews work results and follows through to see that management and staff officials have a clear understanding of problem areas 16 Provides guidance and assistance in implementing recommendations accepted by administrator of units serviced 17 Supervises a group of analysts andor programmers and support personnel in specific program areas as a unit supervisor or team leader 18 Coordinates work performed with supervisors of other functional areas and 19 Trains lower level analysts as required   Minimum Qualifications   Basic Education Requirement Graduation from an accredited fouryear college or university with a Bachelor’s degree Excess work experience as described under the Specialized or Supervisory Experience below or any other progressively responsible administrative professional or analytical work experience which provided knowledge skills and abilities comparable to those acquired in four years of successful study while completing a college or university curriculum leading to a baccalaureate degree may be substituted on a yearforyear basis To be acceptable the experience must have been of such scope level and quality as to assure the possession of comparable knowledge skills and abilities  The education or experience background must also demonstrate the ability to write clear and comprehensive reports and other documents read and interpret complex written material and solve complex problems logically and systematically  Experience Requirements Except for the substitutions provided below applicants must have had the types of experience described in the statements immediately following and in the amounts shown in the table below or any equivalent combination of training and experience     Class Title               Specialized Experience yrs               Supervisory Experience yrs               Total Experience yrs                  Data Prossg Systs Anal II               05               0               05                  Data Prossg Systs Anal III               15               0               15                  Data Prossg Systs Anal IV               25               0               25                  Data Prossg Systs Anal V               35                              35           For the Data Processing Systems Analysts V level at least one year of the required Specialized Experience must have been at the fully competent level comparable to the class Data Processing Systems Analyst IV in the State service  For the Data Processing Systems Analyst V level supervisory aptitude rather than actual supervisory experience may be accepted           Specialized Experience Progressively responsible work experience in computer systems analysis which involved the analysis and design of systems for electronic processing of data or stored computer programming experience which included participation in systems analysis       Supervisory Experience Experience in computer systems analysis andor computer programming which included 1 planning and directing the work of others 2 assigning and reviewing their work 3 advising them on difficult and complex problem areas and 4 timing and scheduling their work       For the Data Processing Systems Analyst V level supervisory aptitude rather than actual supervisory experience may be accepted Supervisory aptitude is the demonstration of aptitude or potential for the performance of supervisory duties through successful completion of regular or special assignments which involve some supervisory responsibilities or aspects by serving as a group or team leader or in similar work in which opportunities for demonstrating supervisory capabilities exist by completion of training courses in supervision accompanied by application of supervisory skills in work assignments or by favorable appraisals by a supervisor indicating the possession of supervisory potential       Substitutions Allowed          1 A Bachelor’s degree from an accredited college or university in computer science or in another major including completion of course work comparable to a major in computer science may be substituted for six 6 months of Specialized Experience           2 A Master’s degree in information and computer science from an accredited college or university may be substituted for one and onehalf 112 years of Specialized Experience           3 A Doctorate’s degree in information and computer science from an accredited college or university may be substituted for two 2 years of Specialized Experience           4 Excess Supervisory Experience of the type and quality described above may be substituted for Specialized Experience on a yearforyear basis       Quality of Experience Possession of the required number of years of experience will not in itself be accepted as proof of qualification for a position The applicants overall experience must have been of such scope and level of responsibility as to conclusively demonstrate that applicant has the ability to perform the duties of the position for which applicant is being considered      Supplemental Information   Salary The advertised salary is based on fulltime employment and includes shortage and school year differentials if applicable  Requirements Applicants must meet all the requirements for the position they are seeking as of the date of the application unless otherwise specified Unless specifically indicated the required education and experience may not be gained concurrently Calculation of experience is based on fulltime 40hour workweeks Parttime experience is prorated Example Twelve months of experience at 20 hoursweek is equivalent to six months of experience not one year Also hours worked in excess of 40 hoursweek will not be credited Example Twelve months of experience at 60 hoursweek is equivalent to one year of experience not one and a half years  Temporary Assignment Claims of Temporary Assignment TA experience to meet the minimum qualification requirements must be verified and attached to the application using one of the options below           A copy of the applicant’s TA History Report or equivalent systemgenerated report                A signed letter from the applicant’s supervisor that includes the applicant’s name hisher TA job title the TA start and end dates from mmyy to mmyy hisher specific TA duties performed and either the TA hours worked per week or total TA hours worked or                Copies of the applicant’s signed SF10 Forms         Documents Attach all relevant supporting documents to your application Documents that were attached to applications submitted before November 16 2023 do not automatically attach or transfer to applications submitted on and after December 16 2023 All submitted documents become the property of the Hawaii State Department of Education      Information about Temporary Positions Temporary positions may be extended year to year dependent upon funding and departmental needs Making yourself available for temporary positions increases your employment possibilities and may lead to permanent opportunities A person hired for a temporary position may also become a temporary employee upon satisfactory completion of the initial probation period of at least six months Once a temporary employee you would be eligible to apply for promotion and transfer opportunities to permanent as well as other temporary positions You may also enjoy other rights and benefits as afforded to an employee in a permanent position with the exception of return rights and placement rights associated with a reductioninforce        Equal Opportunity The Hawaii State Department of Education does not discriminate in its educational policies programs and activities on the basis of sex race color religion national origin age and disability in accordance with Title IX of the Education Amendments of 1972 Title VI of the Civil Rights Act of 1964 Section 504 of the Rehabilitation Act of 1973 Age Discrimination Act of 1975 and Americans with Disabilities Act of 1991 The Department does not discriminate in its employment policies programs and activities on the basis of sexual orientation arrest and court record and National Guard participation as well as on the basis of sex race color religion national origin age and disability in accordance with Title VII of the Civil Rights Act of 1964 Age Discrimination in Employment Act of 1967 Americans with Disabilities Act of 1991 Equal Pay Act of 1963 and Chapter 378 Part I Hawaii Revised Statutes    ,\n",
       " Profile insightsFind out how your skills align with the job descriptionSkillsDo you have experience in VisioYesNoEducationDo you have a Bachelors degreeYesNo LocationIndiana BenefitsPulled from the full job description401k401k matchingCommuter assistanceFlexible spending accountHealth insuranceHealth savings accountLife insuranceShow morechevron down Full job description Intrepid sets the standard for delivering excellence in the federal marketplace and is known for treating employees like family We provide our employees with a challenging and supportive work environment paired with a competitive salary and an industryleading 401k contribution We are looking for an Army Mass Transit Benefit Program Analyst to join our team in supporting the United States Army Financial Management Command USAFMCOM  Your daytoday work will include  Provide oversight and support for USAFMCOM’s Mass Transit Benefit Program MTBP Responsibilities include assisting with data entry sorting filing and analysis working to resolve issues directly with participants providing detailed status reports to stakeholders and other adhoc reports on the program and providing monthly training to participants Tasks will include  Provide document processing support including but not limited to data gathering compilation analysis filing and report submission Collect review and analyze data received including but not limited to participant applications location submission forms and recertification checklists for validation  Maintain all Installation Manager and Reviewing Official data within the Transportation Incentive Program System TIPS and access database Assist with the resolution of benefit returns and repayments for participants officials and other stakeholders Provide application site technical assistance for Transportation Incentive Program TIP participants officials and other stakeholders Host system training monthly to TIP participants  At a minimum you should have   Ability to obtain and maintain a federal SECRET security clearance Bachelor’s degree 310 years of experience in quality assurance data entry customer service GFEBS 1 years and the Army military structure We are seeking individuals with varying degrees of experience in these categories  Proficiency in Microsoft Word PowerPoint Visio and Excel  Experience with creating or generating detailed status reports and excellent attention to detail  Experience supporting DoD stakeholders and DoDArmy Financial Management   You will be highly desirable if you have   An active and current SECRET federal security clearance from the DoD  Experience working with federal benefit programs   This job description is subject to change at any time Work Type OnSite Indianapolis IN Estimated Salary Range 11000000 13000000 The provided salary range serves as a broad reference However Intrepid takes various factors into account when establishing base salary offers including the positions scope and responsibilities as well as the candidates experience education skills and prevailing market conditions  WorkLife at Intrepid Wondering what its like to work here Let us give you a glimpse of our exceptional workplace culture Our employees have consistently nominated us for the Best Places to Work award and we take pride in our familylike environment remarkable benefits and gotheextramile attitude The Hours We sincerely value worklife balance Our flexiblehours policy allows you to balance extra time during significant projects with days that are lighter Moreover we offer generous accrual of paid personal leave that doesn’t lose its value no use it or lose it here as well as 11 paid holidays per year The Benefits Our benefits are renowned starting with our outstanding 401k program No match required We contribute 14 of your biweekly pay to your account regardless of your contribution With our lowfee index funds from Fidelity your retirement savings will grow substantially Plus your professional financial advisors are already covered Our topnotch health insurance plan through Blue Cross Blue Shield includes low deductibles 200year and is mostly covered by Intrepid or you can choose a highdeductible plan with an eligible HSA the choice is yours We also provide complimentary life insurance affordable dental vision disability critical illness and pet insurance Additionally you can set aside pretax dollars for medical and dependent care expenses through an FSA We even offer a 1000 scholarship for newborn or adopted children as well as those enrolled in higher education The Perks Enjoy typical perks like corporate discounts as well as unique experiences as an Intrepid employee Youll be a VIP at our annual events including the Chili CookOff Thanksgiving Lunch  Lawn Games IceCream Social Intrepig BBQ and the grand endofyear Christmas bash with amazing prizes Remote workers have special virtual engagement opportunities and exclusive events so no one is left out of the fun Give Back Giving back is ingrained in our values Through our employeemanaged charitable fund the Intrepid Ideal Community Fund ICF we contribute tens of thousands of dollars each year to organizations that help people in need Join us in various volunteer opportunities and help us make a difference in our communities Our vision is to one day create ideal communities where every citizens needs are met Join Us Theres something for everyone at Intrepid If our benefits perks values and mission resonate with you were thrilled to meet you Start your journey as an Intrepid employee by applying today We cant wait to hear from you  About Intrepid Intrepid is a VEVRAA Federal Contractor and an Equal Opportunity Employer committed to making employment decisions based on merit and value All qualified applicants will receive consideration for employment without regard to race color religion sex sexual orientation gender identity national origin disability or status as a protected veteran CJ  ,\n",
       " Profile insightsFind out how your skills align with the job descriptionSkillsDo you have experience in VisioYesNoEducationDo you have a Bachelors degreeYesNo Job detailsHere’s how the job details align with your profilePay92986  158076 a yearJob typeParttimeShift and scheduleOn call LocationReston VA Full job description    ICF is looking for a Senior Business Analyst to support an Enterprise Performance Management EPM project on the Strategy and Business Solutions Support Contract If you are looking for an opportunity to help inform and direct IT investment decisions and develop architectural targets and standards for a client then this is the job for you This position will work remotely for a Federal client in Arlington VA      What you’ll be doing           Leading efforts for the Enterprise Performance Management EPM project            Formulating and defining strategies and business processes for the EPM project through research and factfinding activities            Recommending and applying strategic thinking process improvement and reengineering methodologies and principles to the EPM project by proposing completing and analyzing business data and hybrid enterprise models            Identifying best practices documenting and assessing performance measurements and identifying business and technology solutions to streamline processes            Leading group facilitation sessions interviews and other activities to gather information from stakeholders            Eliciting and managing business and systems level requirements for the EPM project            Employing industry standard tools to manage requirements            Developing medium to complex business process models            Applying portfolio management concepts including businessIT alignment prioritization and market research techniques for the EPM project            Conducting knowledge transfer of strategic plans scope requirements and other analyses to program and project teams to ensure successful implementation of solutions to client areas            Ensuring recommendeddelivered solutions meet business needs for the EPM project         What you will need           7 years of work experience as a business analyst            US Citizenship required by Federal Government            The ability to successfully obtain a Public Trust which involves a thorough background and financial investigation         Preferred SkillsExperience           Bachelors degree in Accounting Finance Business Administration Marketing Information Systems Management Computer Science or an equivalent combination of education andor experience            Excellent written and verbal communication and personal skills with ability to present to groups including Clevel executives            Solid understanding of the commercial IT market for hardware and software            Exhibit strong communication facilitation interview document writing and presentation skills            Mastery in independently applying business analysis on moderately to highly complex projects            Demonstrated ability to elicit requirements document user stories develop business process models and perform feasibility and cost benefit analyses            Advanced knowledge and experience with applying Agile Methodologies concepts and practices            Knowledge and experience using and applying human centric design principles            Advanced proficiency in analytical project planning negotiating and interpersonal skills            Ability to perform costbenefit analysis trending forecasting and financial analysis            Knowledge and understanding of onprem and offprem Cloud based environments            Knowledge and understanding of Enterprisewide platform deployment software            Proficiency in using Microsoft applications Word Excel PowerPoint Project SharePoint Teams and Visio            Experience using Tableau Power Apps Azure DevOps Salesforce Appian and ServiceNow         Additional Qualifications           Ability to express information to individuals or groups effectively taking into account the audience and nature of the information            Ability to work in a fastpaced environment            Ability to effectively manage a team            Ability to understand people processes and technologies to address business needs for process improvements            Ability to lead a highly complex project            Ability to identify problems and use sound judgement to generate and evaluate alternatives to make recommendations            Ability to thoroughly pay attention to details when performing and reviewing work            Ability to work with clients and customers to assess their needs provide information or assistance resolve their problems and satisfy their expectations           Working at ICF    ICF is a global advisory and technology services provider but we’re not your typical consultants We combine unmatched expertise with cuttingedge technology to help clients solve their most complex challenges navigate change and shape the future       We can only solve the worlds toughest challenges by building an inclusive workplace that allows everyone to thrive We are an equal opportunity employer committed to hiring regardless of any protected characteristic such as race ethnicity national origin color sex gender identityexpression sexual orientation religion age disability status or militaryveteran status Together our employees are empowered to share their expertise and collaborate with others to achieve personal and professional goals For more information please read our        EEO  AA policy           Reasonable Accommodations are available including but not limited to for disabled veterans individuals with disabilities and individuals with sincerely held religious beliefs in all phases of the application and employment process To request an accommodation please email        icfcareercentericfcom    and we will be happy to assist All information you provide will be kept confidential and will be used only to the extent required to provide needed reasonable accommodations        Read more about        workplace discrimination rights    the        Pay Transparency Statement    or our benefit offerings which are included in the        Transparency in Benefits Coverage Act        Pay Range  There are multiple factors that are considered in determining final pay for a position including but not limited to relevant work experience skills certifications and competencies that align to the specified role geographic location education and certifications as well as contract provisions regarding labor categories that are specific to the position The pay range for this position is   9298600  15807600   Nationwide Remote Office US99  ,\n",
       " Profile insightsFind out how your skills align with the job descriptionSkillsDo you have experience in XMLYesNoEducationDo you have a Bachelors degreeYesNo Job detailsHere’s how the job details align with your profilePay7441800  12757440 a yearJob typeFulltime LocationOne Sw Columbia Street Suite 150 Portland OR 97258 BenefitsPulled from the full job description401k401k matchingDental insuranceDisability insuranceEmployee assistance programEmployee discountHealth insuranceShow morechevron down Full job description    About Us    Umpqua Bank is headquartered in the Pacific Northwest with 5000 employees and offers banking services to customers throughout the nation It’s an especially exciting time to join our team as following the recent merger with Columbia Bank we have grown to become a leading westernbased regional bank with more than 50B in assets under management and an unwavering commitment to our associates our customers and our communities  We create a great place to work by offering a special brand of relationship banking and by providing a culture where associates thrive Associates who embody our core values fit in well here and we are eager to meet candidates who demonstrate behaviors that align with Trust Ownership Growth Empathy Teamwork Heart Enjoyment and Relationships  About the Role      Serves as subject matter expert for descriptivepredictive data analysis and reporting within a division business unit andor department Acquires analyzes interprets and disseminates data sets to optimize or create process program andor fiscal solutions for complex organizational challenges May lead projects to improve data quality andor improve workflow process and procedure Defines or helps define program scope and objectives involving all relevant stakeholders and ensuring technical feasibility May fully oversee lifecycles of programs of varying scope including ideation execution monitoring and continuous improvement      Acquires primary and secondary data from varied sources and analyze data extracts and reports to identify trends and data points  Utilizes databases and information systems to research and identify areas for improvement andor new products Interprets data and makes recommendations  Responsible for utilizing data bases and information systems to research and identify areas for improvement andor new products Interprets data and makes recommendations  Maintains detailed knowledge of department functions and in areas of workflow and system data management  Prepares and may lead timely and accurate progress reports utilizing multiple databases and software applications ensuring consistency standardization and compliance  Maintain detailed knowledge of department functions and in areas of workflow and system data management  May consult with managers and possibly executives in the use of analytical and reporting tools to develop effective cost quality operational and customer satisfaction outcomes May act as a liaison to collaborate with other operating groups to resolve problems or make recommendations for programprocess changes  May partner with Technology Advancement Group TAG external vendors and business partners in the development of advancedcomplex reporting capabilities and resolution of issues relating to reporting applications tools and data  Demonstrates compliance with all bank regulations for assigned job function and applies to designated job responsibilities – knowledge may be gained through coursework and onthejob training Keeps up to date on regulation changes  Follows all Bank policies and procedures compliance regulations and completes all required annual or jobspecific training  Maintain a working knowledge of Banks written policies and procedures regarding Bank Secrecy Act Regulation CC Regulation E Bank Security and other regulations as applicable to this job description  May be asked to coach mentor or train others and teach coursework as subject matter expert  Actively learns demonstrates and fosters the Umpqua corporate culture in all actions and words  Takes personal initiative and is a positive example for others to emulate  May perform other duties as assigned     About You      710 years of of related business experience with emphasis in banking information systems controls andor data analysismanagement required  Bachelor’s Degree in Business economics or finance or the equivalent in eduacatin and experience preferred  Advanced knowledge of business analysis business management data systems IT risk management project management and technical problem resolution  Advanced data mining performance metrics and reporting vendor management change management and report writing Statistical analysis descriptive statistics and exploratory data analysis  Advanced knowledge of statistics and experience using statistical packages for analyzing datasets Excel SPSS SAS etc  Experience with reporting packages Business Objects etc databases SQL etc and programming XML Javascript or ETL frameworks preferred  Superior attention to detail  Ability to translate large and complex data sets into understandable conclusions and where applicable actionable solutions  Demonstrated knowledge of banking products systems procedures regulations business acumen and ability to interpret data to make recommendations for improvements as necessary  Ability to work with individuals and teams at all levels across the organization and with external company representatives and vendors Strong communication interpersonal and influencing skills  Technical expertise with automatic data collection and reporting systems including capacity for program troubleshooting and system controls    Work Style  Umpqua Bank offers a Flexible Workplace Program and this opportunity comes with the Flex Office work style which is working in office from a designated company location three days weekly with flexibility to work remotely up to two days weekly  Our Benefits  We offer a competitive total rewards package including base wages and comprehensive benefits The pay range for this role is 7441800 to 12757440 and the pay rate for the selected candidate is dependent upon a variety of nondiscriminatory factors including but not limited to jobrelated knowledge skills and experience education and geographic location The role may be eligible for performancebased incentive compensation and those details will be provided during the recruitment process  We offer eligible associates comprehensive healthcare coverage medical dental and vision plans a 401kretirement savings plan with employer match for qualifying associate contributions an employee assistance program life insurance disability insurance tuition assistance mental health resources identity theft protection legal support auto and home insurance pet insurance access to an online discount marketplace and paid vacation sick days volunteer days and holidays Benefit eligibility begins the first day of the month following the date of hire for associates who are regularly scheduled to work at least thirty hours weekly  Our Commitment to Diversity  Umpqua Bank is an equal opportunity and affirmative action employer committed to employing engaging and developing a diverse workforce All qualified applicants will receive consideration for employment without regard to race color national origin religion sex age sexual orientation gender identity gender expression protected veteran status disability or any other applicable protected status or characteristics If you require an accommodation to complete the application or interviews please let us know by email careersumpquabankcom  To Staffing and Recruiting Agencies  Our posted job opportunities are only intended for individuals seeking employment at Umpqua Bank Umpqua Bank does not accept unsolicited resumes or applications from agencies and Umpqua Bank will not be responsible for any fees related to unsolicited resume submissions Staffing and recruiting agencies are not authorized to submit profiles applications or resumes to this site or to any Umpqua Bank employee and any such submissions will be considered unsolicited unless requested directly by a member of the Talent Acquisition team    ,\n",
       " Profile insightsFind out how your skills align with the job descriptionSkillsDo you have experience in WindowsYesNo Job detailsHere’s how the job details align with your profilePay45000  50000 a yearJob typeFulltime LocationLouisville KY Full job descriptionThe Quality Assurance QA Analyst holds a pivotal position in Alines continuous delivery of innovative and varied products This role entails conducting QA testing on our desktop and web offerings utilizing an array of manual automation and application lifecycle management tools    Responsibilities    Carry out daily Quality Assurance tasks as assigned by the Senior QA Analyst Test Lead and Product Manager ensuring alignment with project objectives Draft manual test cases and integrate them into the master test library utilizing TFS or other relevant technologies contributing to comprehensive test coverage Collaborate with Business Analysts Senior QA Analysts and Product Champions to assist in or create requirements such as use cases user stories and bug reports Regularly communicate testing progress trends and quality insights to the product team fostering transparency and informed decisionmaking Document and report on test executions defects and bugs maintaining accurate records to support quality assurance processes Contribute to the deployment pipeline by aiding in deployment procedures and compiling release notes ensuring smooth and efficient product releases Assist in planning scheduling and measuring results of User Acceptance Testing facilitating effective validation of product functionalities Execute integration and functional testing tasks as assigned verifying the seamless operation of product features Perform automated acceptance tests in accordance with project requirements leveraging automation tools where applicable Evaluate and troubleshoot complex requirements and issues by utilizing diverse information sources ensuring robust problemsolving Analyze data and present findings to the team when necessary enabling informed decisionmaking and continuous improvement May perform other duties as needed andor assigned  Requirements    Possess a degree in a computingrelated discipline or demonstrate an equivalent combination of education and practical experience Hold a minimum of one 1 year of experience in Application Development Quality Assurance exhibiting proficiency in testing methodologies and practices Prior exposure to healthcare or longterm care environments is advantageous though not mandatory Demonstrate proficiency in testing various platforms including Windows ASPNET NET SQL GUI applications web services and web applications encompassing both backend and frontend functionalities Display a solid understanding of software design techniques enabling effective evaluation of application architectures Exhibit experience working within Agile development methodologies illustrating familiarity with iterative development processes and principles Showcase a track record of delivering highquality results within fastpaced and dynamic business environments demonstrating adaptability and efficiency Possess strong communication skills with the ability to clearly document and articulate issues and processes facilitating effective collaboration and problem resolution  ,\n",
       " Profile insightsFind out how your skills align with the job descriptionSkillsDo you have experience in TableauYesNoEducationDo you have a Bachelors degreeYesNo LocationUnited States BenefitsPulled from the full job descriptionGym membershipHealth insurance Full job description    ICON plc is a worldleading healthcare intelligence and clinical research organisation From molecule to medicine we advance clinical research providing outsourced services to pharmaceutical biotechnology medical device and government and public health organisations      With our patients at the centre of all that we do we help to accelerate the development of drugs and devices that save lives and improve quality of life      Our people are our greatest strength are at the core of our culture and the driving force behind our success ICON people have a mission to succeed and a passion that ensures what we do we do well      Hybrid This role will require 3 days a week onsite at our West Point PA 19486 location 2 days remote based     Looking for an individual with ERP system experience SAPAriba preferred    Current or previous Invoicing or Purchase order experience highly preferred    Demonstrable Excel skills needed    Suplpy Chain Logistics Inventory experience preferred but not required    What will you be doing        As a critical requirement in this role the candidate must demonstrate an intermediate to advanced level of proficiency with MS Excel  Experience with data analytics software such as PowerBI Spotfire or Tableau would be nice to have  On a routine basis must be able to create pivot tables and utilize functions vlookup concatenation ifthen within the application  Responsible for building and maintaining MS Excel models using pivot tables to project costs for distribution and warehousing 3rd party packaging 3rd party labeling and drug costs to develop budget forecast  Must be able to fully utilize SAP for financial analysis of RD programs investigational drug and trial costs to accurately maintain and update rolling forecast and profit plan  Must be able to Prepare plan for submission of annual Profit Plan  Develop metrics via Excel models to analyze resource allocations and forecasts for use by managers within the department  Perform KPI analysis and present metric results to global clinical supplies management team  Ability to follow Standard Operating Procedures SOPs  Looking for somoene who can use technology to move the data comparison forward via electronic datasets vs paper comparisons          Education and Work Experience    Bachelor degree Highly Preferred  Looking for about 23 years experience  SAP experience preferred  Intermediate to advanced Excel skills required  Purchase Order experience in SAP a plus  Experience with budgets and forecasting of budgets preferred but not required  Excel SAP Ariba and some type of data analytics software experience would be ideal  Prior supply chain logistics or operations knowledge nice to have     Knowledge Skills and Abilities    Detailoriented  Excellent computer skills including Microsoft applications ERP  CTMS are highly desirable  Proven organization skills  Strong ability to multitask  Understanding of cGMPs      What ICON can offer you   Our success depends on the quality of our people That’s why we’ve made it a priority to build a diverse culture that rewards high performance and nurtures talent      In addition to your competitive salary ICON offers a range of additional benefits Our benefits are designed to be competitive within each country and are focused on wellbeing and work life balance opportunities for you and your family     Our benefits examples include     Various annual leave entitlements  A range of health insurance offerings to suit you and your family’s needs  Competitive retirement planning offerings to maximise savings and plan with confidence for the years ahead  Global Employee Assistance Programme TELUS Health offering 24hour access to a global network of over 80000 independent specialised professionals who are there to support you and your family’s wellbeing  Life assurance  Flexible countryspecific optional benefits including childcare vouchers bike purchase schemes discounted gym memberships subsidised travel passes health assessments among others    Visit our careers website to read more about the benefits of working at ICON httpscareersiconplccombenefits     At ICON diversity inclusion  belonging are fundamental to our culture and values Our rich diversity makes us more innovative which helps us better serve our people patients customers and our communities Were proud of our diverse workforce and the work we’ve done to become a more inclusive organisation We’re dedicated to providing an inclusive and accessible environment for all candidates ICON is committed to providing a workplace free of discrimination and harassment All qualified applicants will receive equal consideration for employment without regard to race color religion sex sexual orientation gender identity national origin disability or protected veteran status If because of a medical condition or disability you need a reasonable accommodation for any part of the application process or in order to perform the essential functions of a position please let us know through the form below      httpscareersiconplccomreasonableaccommodations     Interested in the role but unsure if you meet all of the requirements We would encourage you to apply regardless – there’s every chance you’re exactly what we’re looking for here at ICON whether it is for this or other roles    ,\n",
       " Profile insightsFind out how your skills align with the job descriptionSkillsDo you have experience in NetSuiteYesNo Job detailsHere’s how the job details align with your profilePay50  64 an hourJob typeContractShift and schedule8 hour shiftDay shiftMonday to Friday LocationJacksonville FL BenefitsPulled from the full job description401k401k matchingHealth insuranceLife insuranceRetirement plan Full job descriptionSkillset  Experience  FinanceAccounting MS Excel Advanced Accounting skills Cost Accounting Financial Modeling NetSuiteGeneral Ledger  Our benefits package includes  Comprehensive medical benefits Competitive pay 401k Retirement plan and much more  About INSPYR SolutionsTechnology is our focus and quality is our commitment As a national expert in delivering flexible technology and talent solutions we strategically align industry and technical expertise with our clients business objectives and cultural needs Our solutions are tailored to each client and include a wide variety of professional services project and talent solutions By always striving for excellence and focusing on the human aspect of our business we work seamlessly with our talent and clients to match the right solutions to the right opportunities Learn more about us at inspyrsolutionscom INSPYR Solutions provides Equal Employment Opportunities EEO to all employees and applicants for employment without regard to race color religion sex national origin age disability or genetics In addition to federal law requirements INSPYR Solutions complies with applicable state and local laws governing nondiscrimination in employment in every location in which the company has facilities Job Type Contract Salary 5000  6400 per hour Benefits  401k matching Health insurance Life insurance Retirement plan  Experience level  6 years  Schedule  8 hour shift Day shift Monday to Friday  Application Questions  How long youve been working as a FinancialAccounting Data Analyst How many years of experience do you have with General Ledger Are you proficient in MS Excel How far is your location in Jacksonville FL Are you willing to work on a Hybrid Schedule in Jacksonville FL How much is your target pay per hour on W2  Work Location Remote ,\n",
       " Profile insightsFind out how your skills align with the job descriptionSkillsDo you have experience in Power BIYesNoEducationDo you have a Bachelors degreeYesNo LocationChesterfield MO 63017 BenefitsPulled from the full job descriptionDental insuranceHealth insurancePaid time offTuition reimbursementVision insurance Full job description Were a Little Different   Our mission is clear We bring to life a healing ministry through our compassionate care and exceptional service     At Mercy we believe in careers that match the unique gifts of unique individuals  careers that not only make the most of your skills and talents but also your heart Join us and discover why Modern Healthcare Magazine named us in its Top 100 Places to Work    Overview Profisee Azure  Master Data Management Engineer MDM   Hybrid Position can be partially remote work from home Onsite 2 days a week in St Louis    Please note that as of the posting date of this job announcement Mercy is unable to offer immigration sponsorship or visa assistance for this position We encourage all eligible candidates including US citizens permanent residents and those with existing work authorization to apply   A Master Data Management Engineer is responsible for the technical implementation and maintenance of an enterprises master data management systems This role typically involves working closely with data architects data governance teams and IT teams to develop test and deploy master data management solutions that meet the needs of the ministry    Implement and maintain master data management system Profisee MDM Ensure that master data is accurate consistent and accessible to all stakeholders Analyze business requirements for survivorship rules and deploy into Profisee MDM Integrate master data with other enterprise systems and data sources Incorporate new system models into an Enterprise Data Model for MDM Utilize Azure tools including ADF Databricks PowerApps PowerBI and other Microsoft cloud tools to build MDM solutions Write complex system queries into operational systems to extract datasets that meet master data source ingestion requirements Build Profisee Fastapp visualizations to display source system values and golden record contributors Collaborate with active development teams to assist them in utilizing MDM resources for inflight projects Develop and maintain data quality reference data management and data validation processes    Qualifications    Experience Several years of experience in data engineering data integration and master data management Preferably with Profisee MDM  Required Education Bachelors degree or higher in Computer Science Information Systems or a related field  Other Strong technical skills including proficiency in data management technologies and tools Excellent problemsolving and collaboration skills  Preferred Profissee and Azure experience    We Offer Great Benefits   Dayone comprehensive health vision and dental coverage PTO tuition reimbursement and employermatched retirement funds are just a few of the great benefits offered to eligible coworkers including those working 32 hours or more per pay period    Were bringing to life a healing ministry through compassionate care   At Mercy our supportive community will be behind you every step of your day especially the tough ones You will have opportunities to pioneer new models of care and transform the health care experience through advanced technology and innovative procedures Were expanding to help our communities grow Join us and be a part of it all    What Makes You a Good Match for Mercy    Compassion and professionalism go handinhand with us Having a positive outlook and a strong sense of advocacy is in perfect step with our mission and vision Were also collaborative and unafraid to do a little extra to deliver excellent care  thats just part of our commitment If that sounds like a good fit for you we encourage you to apply  ,\n",
       " Profile insightsFind out how your skills align with the job descriptionSkillsDo you have experience in Vulnerability assessmentYesNo Job detailsHere’s how the job details align with your profilePayFrom 115000 a yearJob typeFulltime LocationNew York NY BenefitsPulled from the full job descriptionHealth insurance Full job description 1 years of test automation frameworks and tools building experience 2 years of noninternship professional software development testing experience Experience programming with at least one modern language such as Java C or C including objectoriented design Experience in penetration testing and exploitabilityfocused vulnerability assessment  We are looking for a Software Dev Engineer in Test for Measurement Ad Tech and Data Science System to join our diverse team at Amazon in USA NY  Growing your career as a Full Time Software Dev Engineer in Test is an incredible opportunity to develop key skills  If you are strong in attention to detail emotional intelligence and have the right drive for the job then apply for the position of Software Dev Engineer in Test Measurement Ad Tech and Data Science at Amazon today    The ideal candidate will be detail oriented have strong organizational skills able to work independently juggle multiple tasks at once and maintain professionalism under pressure all while achieving high quality results You should have deep knowledge of software engineering practices and can drive design and implementation of test strategies in highly complex systems    Key job responsibilities  Convert manual regression tests to automated tests and maintain a high bar on the test quality    Own and improve the automated test coverage metrics    Use defined standards and best practices for testing of applications    A day in the life  Although each day may bring new challenges the majority of your time we will be creating test strategies new automation test tools and infrastructure We collaborate closely with software development teams to achieve a high quality releases that meet tight timelines without introducing new regressions or lowering product quality    We are open to hiring candidates to work out of one of the following locations    New York NY USA     Experience in working with AWS SDK and CDK strong understanding of AWS essentials  Amazon is committed to a diverse and inclusive workplace Amazon is an equal opportunity employer and does not discriminate on the basis of race national origin gender gender identity sexual orientation protected veteran status disability age or other legally protected status For individuals with disabilities who would like to request an accommodation please visit httpswwwamazonjobsendisabilityus    Our compensation reflects the cost of labor across several US geographic markets The base pay for this position ranges from 115000year in our lowest geographic market up to 223600year in our highest geographic market Pay is based on a number of factors including market location and may vary depending on jobrelated knowledge skills and experience Amazon is a total compensation company Dependent on the position offered equity signon payments and other forms of compensation may be provided as part of a total compensation package in addition to a full range of medical financial andor other benefits For more information please visit httpswwwaboutamazoncomworkplaceemployeebenefits This position will remain posted until filled Applicants should apply via our internal or external career site ,\n",
       " Profile insightsFind out how your skills align with the job descriptionSkillsDo you have experience in TableauYesNoEducationDo you have a Masters degreeYesNo Job detailsHere’s how the job details align with your profileJob typeFulltime LocationPittsburgh PA 15238 Full job description  SUMMARY  As a Data Engineer for our Digital Services division you will drive the evolution of our next generation data infrastructure which powers a wide range of analytics and software products You will be responsible for designing developing and maintaining advanced data pipelines using the latest technologies in cloud computing and data processing In this pivotal role you will collaborate with crossfunctional teams including data scientists software engineers and business analysts You will also use your excellent soft skills to interface with nontechnical stakeholders and ensure that their needs are met in the form of functional and nonfunctional requirements  RESPONSIBILITIES  Design build and maintain our data infrastructure to support analytics and integration into software products and services Partner with data scientists to build processing pipelines that enable them to rapidly create highquality machine learning models Work with software engineers to develop and maintain pipelines to feed data to our growing software portfolio Manage ETLELT processes as code and foster a codebase that is extensible and maintainable by all team members Manage the transition from quick prototype to full scalable solution that supports production products Identify recommend and implement innovative approaches and technologies that will evolve our existing processes  Qualifications  Education and experience requirement  BSMS Degree in Computer Science Engineering Data Analytics or related field 3 years’ experience in data engineering ETL development or similar role Strong problemsolving skills to discover address and resolve issues Demonstrated ability to translate technical concepts into actionable insights for different stakeholders    Language and technical skills requirement  Proficient in programming languages such as Python and SQL and development tools such as Git Experience with cloud platforms such as Azure AWS or GCP for deploying and managing data infrastructure Skilled with rational database schema design Handson experience with data processing tools and platforms such as Snowflake Azure Synapse Azure Data Factory Data Bricks etc Solid understanding of machine learning models tools libraries and approaches Experience with business intelligence tools such as Power BI Spotfire Cognos Tableau Qlik     Physical demands and work environment  The physical demands described here are representative of those that must be met by an employee to successfully perform the essential functions of this job Reasonable accommodation may be made to enable individuals with disabilities to perform the essential functions  Work is usually performed in an office environment with normal noise levels Involves prolonged sitting and computer usage Work may involve limited travel    Disclaimer  This job description is not intended and should not be construed to be an exhaustive list of all responsibilities skills efforts or working conditions associated with the job It is intended however to be an accurate reflection of those principal job elements essential for making decisions related to job performance employee development and compensation As such the incumbent may perform other duties and responsibilities as required Its contents imply no contractual obligation and may be changed by the company at any time   ,\n",
       " Profile insightsFind out how your skills align with the job descriptionCertificationsDo you have a valid Certified Information Systems Auditor certificationYesNoSkillsDo you have experience in YAMLYesNo Job detailsHere’s how the job details align with your profileJob typeFulltime LocationRemote BenefitsPulled from the full job descriptionOpportunities for advancement Full job description Secure our Nation Ignite your Future   Become an integral part of a diverse team while working at an industry leading organization where our employees come first At ManTech International Corporation you’ll help protect our national security while working on innovative projects that offer opportunities for advancement   We are seeking a motivated career and teamoriented cybersecurity Integration Layer Data Engineer in support of the US Department of Homeland Security DHS Cybersecurity and Infrastructure Security Agency CISA Continuous Diagnostic  Mitigation CDM Data Services Program The CDM Data Services Program is a critical component of CISA’s national effort to ensure the defense and resilience of cyberspace This is a remote position where the candidate can work from any location within the United States provided they are able to work on an eastern time zone schedule   The CDM Data Services Program mission is to provide a standardized platform to collect transform and integrate cybersecurity data from relevant authoritative data sources into a coherent data delivering actionable information into Agency and Federal Dashboards to identify risk areas in support of mitigation as well as to facilitate coordinated agency and national response to cyberthreats   Our Integration Layer Data Engineering and Quality team guides and verifies data transformations so that our automated solution delivers endtoend results with confidence The solution is managed in cloud environments and the team works closely with developers to create an automated continuous integration CI and continuous delivery CD solutions using Agile delivery methodologies   Responsibilities    Work with internal and external stakeholders to examine contractual data requirements in order to drive data modeling pipelines transformation normalization and quality for each solution release through a SAFe Agile Release Train ART to achieve business goals  Act as subject matter expert regarding data requirements formats types lineage and quality to brief internal and external stakeholders  Analyze raw data from different sources and define consistent and machinereadable formats for the data store  Work with stakeholders to track and obtain nonautomated data sources to maintain freshness  Develop document and communicate processes for seamless data ETL extraction transformation and loading through Cloud based data services  In charge of directing developers on how to join and convert raw data from multiple sources into usable information for analytics and reporting  Work collaboratively with crossfunctional teams to design implement and maintain a scalable and secure data repositorylake that can support analyzing trends and patterns  Prepare options levels of effort and estimates when data requirements change  Develop database objects and schemas that support extracting transforming loading and storage of data based on a logical data model LDM  Participate in Agile ceremonies and track and document work in Jira and Confluence  Ensure data integrity quality and accessibility within the repositorylake  Conduct complex data analysis using SQL based searches and instruct developers on how to handle data quality issues  Explore and implement ways to enhance data quality and reliability and use tools to develop analytical dashboards  Work with Data Scientists to improve the quality and accuracy of the information enabling stakeholders to make more responsible cyber risk decisions  Prepare and maintain datasets for testing and modeling  Develop and maintain the solution’s data dictionary and data lineage  Define data retentions and governance for the solution    Position Requirements    Degree in Computer Science IT or similar field  A minimum of 5 years of proven experience as a Data Engineer or similar role  Solid understanding of relational databases and ETL processes  Proficiency in data transformation normalization and configuration  Technical expertise in data ingestion and manipulation  Knowledge of big data platforms and data source formats from APIs JSON csv yaml  Familiarity with API integration and data pipelines  Experience in creating dashboards eg Tableau PowerBI or similar for data visualization  Experience with data abstraction various data conditions including blank and NULL data and detecting and handling data collisions and filtering logic syntax  Experience with SQLTSQL NoSQL and data visualization tools design  Familiarity with data segmentation cleansing enrichment and indexing  Familiarity with application administration configuration and integration  Experience with data security and segregation physically or logically Know the use of rolebased access and attributebased access when limiting data  Ability to independently perform research on industry standards regulatory requirements and cuttingedge technological trends Have passion for new technologies software and processes  Familiarity with agile development methodologies expertise in the Microsoft Office  Google suite of software    Desired Qualifications    Data engineering or data analyst certification  Scaled Agile Framework SAFe certification  Experience with Data Lakes Data Warehouses or Data Lakehouse  Experience with data governance tools  Experience with cloud services such as Azure AWS or GCP  Understanding of cybersecurity tools such as vulnerability CVE scanners software scanners mobile and network host discovery scanners and other tools in order to understand source data  Familiarity with federal cybersecurity concepts such as Vulnerabilities DISA STIGs NIST FISMA Risk Management Framework and MITRE ATTCK Framework  Experience working in government contracting  Knowledge of programming languages eg Python PowerShell  Experience with data compression data deduplication  Experience with Elasticsearch with Kibana Dashboards404    SecurityClearance Requirements    Must be a US citizen and pass a background investigation  Able to obtain and maintain a DHS SuitabilityEntry on Duty EOD    Physical Requirements    Must be able to remain in a stationary position 50  Constantly operates a computer and other office productivity machinery such as a calculator copy machine and computer printer  The person in this position frequently communicates with coworkers management and customers which may involve delivering presentations Must be able to exchange accurate information in these situations    For all positions requiring access to technologysoftware source code that is subject to export control laws employment with the company is contingent on either verifying USperson status or obtaining any necessary license The applicant will be required to answer certain questions for export control purposes and that information will be reviewed by compliance personnel to ensure compliance with federal law ManTech may choose not to apply for a license for such individuals whose access to exportcontrolled technology or software source code may require authorization and may decline to proceed with an applicant on that basis alone                         ManTech International Corporation as well as its subsidiaries proactively fulfills its role as an equal opportunity employer We do not discriminate against any employee or applicant for employment because of race color sex religion age sexual orientation gender identity and expression national origin marital status physical or mental disability status as a Disabled Veteran Recently Separated Veteran Active Duty Wartime or Campaign Badge Veteran Armed Forces Services Medal or any other characteristic protected by law   If you require a reasonable accommodation to apply for a position with ManTech through its online applicant system please contact ManTechs Corporate EEO Department at 703 2186000 ManTech is an affirmative actionequal opportunity employer  minorities females disabled and protected veterans are urged to apply ManTechs utilization of any external recruitment or job placement agency is predicated upon its full compliance with our equal opportunityaffirmative action policies ManTech does not accept resumes from unsolicited recruiting firms We pay no fees for unsolicited services   If you are a qualified individual with a disability or a disabled veteran you have the right to request an accommodation if you are unable or limited in your ability to use or access httpwwwmantechcomcareersPagescareersaspx as a result of your disability To request an accommodation please click careersmantechcom and provide your name and contact information                        ,\n",
       " Profile insightsFind out how your skills align with the job descriptionSkillsDo you have experience in SpringYesNoEducationDo you have a Bachelors degreeYesNo LocationAsheville NC Full job description Role Data Engineer Software Developer   Asheville NC Hybrid   Long term role until 2026 end    Description Join the forefront of scientific innovation at Clients National Centers for Environmental Information NCEI as a Scientific Research and Data Analyst within the Climate Science and Services Division CSSD Climate Information Services Branch In this role you will play a key part in assembling maintaining and developing highquality instrumental datasets for targeted stakeholder communities and commercial sectors This task involves developing new products and services that are grounded in documented user requirements These products can have a regional national or global focus and they can employ a variety of NCEI NOAA and other data Development activities will employ an approach known as the coproduction of knowledge” wherein developers continuously communicate with practitioners to ensure that products and services are useful and used    Responsibilities   Design develop test and deploy operational software that generates new datasets products services and reports Tasks include but are not limited to code development database development web development integration testing readiness review and operational release Incorporate NOAA and NCEI IT requirements eg security protocols ad hoc changes into operational software and new releases Manage software using NCEI source code tools and maintain requisite documentation eg business rules operational procedures   Required Skills   Experience with the full software development lifecycle SDLC in an Agile environment Experience in the development and maintenance of scientific operational software Proficiency in a diverse range of programming languages including ArcGIS Fortran and Python Experience producing data visualizations from a variety of datasets and file formats Ability to communicate effectively with a geographically dispersed team Familiarity with using a code repository such as GIT Excellent documentation skills to maintain business rules and operational procedures   Preferred Skills   Familiarity with additional programming languages and development environments including OracleAPEX Groovy JavaJavascript React and Spring Familiarity with NOAA and NCEI IT requirements including security protocols Familiarity with climate science and the development of datasets products services and reports derived from climatological data Knowledge of data access and retrieval processes Familiarity with developing deploying and maintaining software in an AWS environment Proven experience in leading migration projects to cloudbased platforms   Minimum QualificationRequirements   Bachelors degree in computer science or a relevant field 5 years of relevant work experience   ,\n",
       " Profile insightsFind out how your skills align with the job descriptionSkillsDo you have experience in TableauYesNo Job detailsHere’s how the job details align with your profilePayFrom 79600 a yearJob typeFulltime LocationSeattle WA BenefitsPulled from the full job descriptionHealth insurance Full job description 3 years of analyzing and interpreting data with Redshift Oracle NoSQL etc experience Experience with data visualization using Tableau Quicksight or similar tools Experience with data modeling warehousing and building ETL pipelines Experience in Statistical Analysis packages such as R SAS and Matlab Experience using SQL to pull data from a database or data warehouse and scripting experience Python to process data for modeling Experience developing and presenting recommendations of new metrics allowing better understanding of the performance of the business  At AWS were working to be the most customer centric company on earth To get there we need exceptionally talented smart and driven individual The Data Center Availability team works with the hundreds of AWS data centers around the globe to deliver the highest quality and lowest cost physical security availability capacity and scaling results for our customers Our aim is to standardize operations globally by delivering tools policy processes and procedures to our internal teams The Availability team is seeking a Systems Development Engineer to design develop and implement software solutions for our Global Asset Management systems Our mission is to provide critical data to operators and engineers that enables them to make informed decisions for maintenance of data center facilities Our team of Systems Development Engineers builds webbased tools to provide data collection interfaces as well as data aggregation processes that vend the data to partner teams for further analytics    AWS Infrastructure Services owns the design planning delivery and operation of all AWS global infrastructure In other words we’re the people who keep the cloud running We support all AWS data centers and all of the servers storage networking power and cooling equipment that ensure our customers have continual access to the innovation they rely on We work on the most challenging problems with thousands of variables impacting the supply chain — and we’re looking for talented people who want to help    You’ll join a diverse team of software hardware and network engineers supply chain specialists security experts operations managers and other vital roles You’ll collaborate with people across AWS to help us deliver the highest standards for safety and security while providing seemingly infinite capacity at the lowest possible cost for our customers And you’ll experience an inclusive culture that welcomes bold ideas and empowers you to own them to completion    Key job responsibilities    Lead the design implementation and delivery of BI solutions in complex ambiguous or poorly defined problem spaces Proactively work to improve the consistency and integration between the team’s BI solutions and any related systems or artifacts owned by other teams Influence the team’s technical and business strategy by making insightful contributions to team priorities and lead in identifying and solving BI architecture deficiencies that limit the innovation Able to communicate your ideas effectively to achieve the right outcome for the team and customer and seek diverse perspectives listen to feedback and are willing to change direction if it creates a better outcome Lead design reviews for BI solutions or analyses for the team and actively participate in reviews for partner teams Actively participate in the hiring process as well as mentor others  improving their skills their knowledge of your BI solutions and their ability to get things done Influence technical decisions made by partner teams via collaborative software effort or by driving BI engineering best practices eg analytical rigor code quality data quality data modelling operational excellence automation visualization  We are open to hiring candidates to work out of one of the following locations    Herndon VA USA  Seattle WA USA     Experience with AWS solutions such as EC2 DynamoDB S3 and Redshift Experience in data mining ETL etc and using databases in a business environment with largescale complex datasets Excellent communication verbal and written and interpersonal skills to translate ambiguous business requirements into complex analyses and actionable insights  Amazon is committed to a diverse and inclusive workplace Amazon is an equal opportunity employer and does not discriminate on the basis of race national origin gender gender identity sexual orientation protected veteran status disability age or other legally protected status For individuals with disabilities who would like to request an accommodation please visit httpswwwamazonjobsendisabilityus    Our compensation reflects the cost of labor across several US geographic markets The base pay for this position ranges from 79600year in our lowest geographic market up to 185000year in our highest geographic market Pay is based on a number of factors including market location and may vary depending on jobrelated knowledge skills and experience Amazon is a total compensation company Dependent on the position offered equity signon payments and other forms of compensation may be provided as part of a total compensation package in addition to a full range of medical financial andor other benefits For more information please visit httpswwwaboutamazoncomworkplaceemployeebenefits This position will remain posted until filled Applicants should apply via our internal or external career site ,\n",
       " Profile insightsFind out how your skills align with the job descriptionSkillsDo you have experience in SparkYesNoEducationDo you have a Bachelors degreeYesNo Job detailsHere’s how the job details align with your profilePayUp to 60 an hourJob typeFulltimeShift and schedule8 hour shift Location103 Pennsylvania Ave Charleroi PA 15022 BenefitsPulled from the full job description401kDental insuranceHealth insurance Full job descriptionRole ML Data Engineer with Vector DB and GenAI Skills – Band 4B  Location Pennsylvania  PA Duration Fulltime Summary We are seeking a passionate and skilled ML Data Engineer Band 4B to join our team in USA You will play a pivotal role in building and maintaining the data infrastructure and pipelines for our cuttingedge Generative AI applications You will collaborate closely with the Generative AI Full Stack Architect and MLOps Engineer to ensure the quality security and accessibility of data for our Generative AI models Responsibilities  Design develop and implement data pipelines for ingesting preprocessing and transforming unstructured data Image pdf Audio video for Generative AI model training and inference Need to have some level of understanding or working experience with Vector DB’s  Like Pinecone  Redis  Chroma Understanding on Large Language Model’s Llama GPT4  Claude 20  to do text summarization  entity extraction and classification Build and maintain efficient data storage solutions including data lakes warehouses and databases appropriate for largescale generative AI datasets Implement data security and governance policies to ensure the privacy and integrity of sensitive data used in Generative AI projects Collaborate with data scientists and engineers to understand data requirements for Generative AI models and translate them into efficient data pipelines Monitor and optimize data pipelines for performance scalability and costeffectiveness Stay uptodate on the latest advancements in data engineering tools and technologies eg Apache Spark Airflow Snowflake Data Bricks  and apply them to our Generative AI platform Document data pipelines and processes for clarity and transparency Communicate effectively with technical and nontechnical stakeholders about data quality and availability for Generative AI projects  Qualifications  Bachelor’s degree in computer science Data Science Statistics or a related field or equivalent experience 6 years of experience in data engineering or related roles such as data pipeline development data storage or ETLELT processes Proven experience building and maintaining data pipelines for machine learning projects Strong understanding of data modeling principles data quality measures and data security best practices Proficient in programming languages like Python SQL and scripting languages eg Bash Shell Familiarity with cloud platforms eg AWS GCP Azure for data storage and processing along with GenAI services like AWS BedRock Excellent communication collaboration and problemsolving skills Ability to work independently and as part of a team Passion for Generative AI and its potential to solve realworld challenges  Band 4B  Senior individual contributor with substantial data engineering expertise and leadership experience Manages complex data projects and initiatives with independent decisionmaking authority Provides technical guidance and mentorship to junior team members Has a demonstrated track record of success in delivering impactful data solutions  Job Type Fulltime Salary Up to 6000 per hour Expected hours No more than 4000 per week Benefits  401k Dental insurance Health insurance  Compensation package  Yearly pay  Experience level  10 years  Schedule  8 hour shift  Experience  Informatica 1 year Preferred SQL 8 years Preferred  Ability to Commute  Charleroi PA 15022 Required  Ability to Relocate  Charleroi PA 15022 Relocate before starting work Required  Work Location In person ,\n",
       " Profile insightsFind out how your skills align with the job descriptionSkillsDo you have experience in SoCYesNoEducationDo you have a Masters degreeYesNo Job detailsHere’s how the job details align with your profilePay101000  190000 a yearJob typeFulltime LocationHillsboro OR BenefitsPulled from the full job descriptionContinuing education credits Full job description     Your tasks   As part of this team you will have an opportunity to architect and work on many different modules within our devices and to work with leaders in the design of world class data converters These devices integrate large high frequency  30 GHz analog blocks along with complex digital blocks to create our custom System on Chip SoC solutions Your tasks will cover the entire spectrum of mixed signal development starting from conceptual work through the design layout and characterization of the devices Responsible to develop cutting edge SoCs for communication systems according to customer specifications finding optimum tradeoffs between system performance power dissipation and cost Drive block specifications for design team Develop run and maintain data converter system MATLAB and Verilog models for an SoC across various usage modes Work with analog and digital implementation teams to ensure proper development of system designs Ability to simulate entire signal path in a mixed‒signal flow Create and own chip level simulations that verify data converter operating modes are implemented correctly We work with other ASIC design groups based in Germany You will work with a highly qualified team of ASIC engineers located both locally and abroad          Application tips  Watch the video and learn all about our application process  Application Interview Contact persons           Your qualifications   MS degree with 5 years of experience or a PhD degree with 3 years of experience Significant experience modeling data converters or radio systems in MATLAB Good knowledge of communication systemsstandards and their application to different wireless and wire‒line applications Deep understanding of design simulation and measurements of high‒speed ICs using CMOS and CML circuits in at least 3 of these areas Digital‒Analog Converters Serializers and de‒serializers Wideband Output Drivers High Performance Phase Locked Loops Low Noise clock designs Operational Amplifiers and Variable Gain Amplifiers and DSP Equalization and compensation techniques Self‒driven ability to work independently while coordinating with IC designers You will need to be able to travel occasionally to European and US locations Candidates must be current US residents with valid work authorization Work effectively in a group setting share expertise provide and receive feedback communicate technical issues work in a team environment to resolve technical issues Additional desirable but not required qualifications include Experience performing mixed signal circuit design across analog and digital domains BiCMOS IC design experience Experience with an Analog Design Flow eg Cadence Virtuoso Xcelium AMS‒Designer Verilog‒AMS and Spectre SERDES transmitter and receiver design eg CDR DFE CTLE jitter modelling        Interested We are looking forward to receiving your application        This is a fulltime position with a total compensation target salary range of 101k190K plus benefits The range is determined by the position geographic location and level Individual pay within the range is determined by several factors including location education or training relevant work history and jobrelated skills       We are committed to hiring and retaining a diverse workforce We are proud to be an Equal Opportunity Employer making decisions without regard to race color religion creed sexual orientation gender identity marital status national origin age veteran status disability or any other protected class                 The Rohde  Schwarz technology group is among the trailblazers when it comes to paving the way for a safer and connected world with its leading solutions in test  measurement technology systems and networks  cybersecurity Founded more than 85 years ago the group is a reliable partner for industry and government customers around the world         Our offer        Flexible working hour models       Training  continuing education       Privately owned company       Promoting innovation       Longterm  attractive work environment         Show more             Cityregion        Hillsboro Oregon USA        Entry level        Professionals        Employment Type        Fulltime unlimited        Ref Number        3160      ,\n",
       " Profile insightsFind out how your skills align with the job descriptionSkillsDo you have experience in MarketingYesNoEducationDo you have a Masters degreeYesNo Job detailsHere’s how the job details align with your profilePay45  50 an hourJob typeFulltime LocationGrand Blanc MI 48439 BenefitsPulled from the full job description401k matchingADD insuranceDental insuranceDisability insuranceEmployee assistance programFlexible spending accountHealth insuranceShow morechevron down Full job description      Hybrid position based in Grand Blanc MI  Dort Financial Credit Union is looking for team members who will execute our mission Enrich peoples lives members employees communities to help achieve our vision To be the leader in our industry by providing quality financial services developing an empowered and diverse team and making our communities a better place to live Dort Financial Credit Union upholds a culture of excellence with opportunities of engagement and advancement for our team members We abide by our core values of Empowerment Accountability Transparency Collaboration and Volunteerism each day and have a strong focus in community involvement  We offer a competitive benefits package immediately upon hire including medical dental and vision insurance LifeADD and Disability Insurance Supplemental Life insurance for employeespousedependent HSA and FSA plans and tuition reimbursement for fulltime team members LegalShield Pet Benefits Employee Assistance Program Telemedicine We also offer a matching 401 k including a safe harbor a referral bonus program and paid time off including holidays  Come join our team Apply today  Minimum Formal Education Bachelor’s Degree in Computer Science Software Engineering or an equivalent field required Master’s Degree in Computer Science Software Engineering or an equivalent field preferred  Experience Three years of handson data management experience including data warehousing data integration modeling optimization and data quality andor other areas directly relevant to data engineering responsibilities and tasks Experience required specifically focusing on data warehouse engineering and data processes Engineering and data management experience in a financial institution preferred Requires proficient frequent and ongoing use of database software platforms Strong fundamental knowledge of financial institution operation and marketing is required  Other Requirements Position requires bondability of employee Position also requires ability to work independently with minimal supervision ability to communicate in a tactful manner excellent organizational skills diplomacy selfmotivation and discipline flexible hours ability to maintain professional conduct in or out of the office with staff members vendors and volunteers a team player attitude toward Dort Financial Credit Union and the exhibiting of that team spirit to staff       ,\n",
       " Profile insightsFind out how your skills align with the job descriptionSkillsDo you have experience in Unit testingYesNoEducationDo you have a Bachelors degreeYesNo Job detailsHere’s how the job details align with your profilePay139800  207325 a yearShift and scheduleOn call Location999 3rd Avenue Seattle WA 98104 BenefitsPulled from the full job descriptionHealth insurancePaid parental leavePaid time offParental leave Full job description Company Overview   DocuSign helps organizations connect and automate how they agree Our flagship product eSignature is the world’s 1 way to sign electronically on practically any device from virtually anywhere at any time Today more than a million customers and a billion users in over 180 countries use DocuSign to accelerate the process of doing business and simplify people’s lives      What youll do   The Common Data platform team is chartered to build the high availability data backend for AI analytics and reporting needs for DocuSign customers We create maintain and operate scalable technology and data solutions that deliver an exceptional experience for our customers We embrace Agile principles and values favor DevOps practices and view infrastructure as code all while we create an infrastructure that scales and supports our growth and an ambitious vision This requires a hardworking highly collaborative team who can identify investigate and implement new technologies to continue securely scaling our global business     The team is looking for Software Engineers with proven track records to join our development team in Seattle or San Francisco This position will be part of a team working on an architectural shift that will allow us to scale to meet the next 10x of growth We need engineers who are ready to grapple with unique requirements of partner teams and build a cloud development and execution environment We need expertise to configure deploy and execute Azure cloud solutions to deliver bigdata processing as well as distributed REST API services for customer facing products This position will demand critical thinking skills ability to learn and understand complex cloud platforms and the ability to work in agile environments     This position is an individual contributor role reporting to the Director of Engineering      Responsibility    Drive design implementation testing and release of products  Build big data pipelines and analytics infrastructure on Azure with Data Factory Databricks Event Hub Data Explorer Cosmos DB and Azure RDBMS platforms  Build secure networking and reliable infrastructure for High Availability and Disaster Recovery  Build big data streaming solutions with 100s of concurrent publishers and subscribers  Collaborate closely with Product Design and Engineering teams to build new features  Participate in an Agile environment using Scrum software development practices code review automated unit testing endtoend testing continuous integration and deployment  Think about how to solve problems at scale and build faulttolerant systems that leverage telemetry and metrics  Investigate fix and maintain code as needed for production issues  Operate high reliability high availability service and participate in oncall rotation     Job Designation   Hybrid Employee divides their time between inoffice and remote work Access to an office location is required Frequency Minimum 2 days per week may vary by team but will be weekly inoffice expectation     Positions at DocuSign are assigned a job designation of either In Office Hybrid or Remote and are specific to the rolejob Preferred job designations are not guaranteed when changing positions within DocuSign DocuSign reserves the right to change a positions job designation depending on business needs and as permitted by local law     What you bring   Basic    BS degree in Computer Science Engineering or equivalent  8 years of experience within a software engineering related field  Experience with data modeling with NoSQL andor SQL  Experience in cloud platforms  Experience in modern server side development using modern programming languages like C or others  Experience using Git or other version control systems and CICD systems  Experience in writing high quality code that is easy to be maintained by others  Experience in agile methodologies     Preferred    Experience with building cloud solutions on Azure  Strong interest or documented experience in large scale microservice architectures on Kubernetes  Experience building large data lakes and data warehouses  Proficiency in big data processing in Apache Spark with Python or Scala  Proficiency in data streaming applications with Event HubKafka  Spark streaming  Proficiency in data pipeline orchestration with Data Factory or similar  A track record of being a selfstarter  Individualteam responsibility is our main driver in the development work      Wage Transparency   Based on applicable legislation the below details pay ranges in the following locations      California 146800  235025 base salary      Washington and New York including NYC metro area 139800  207325 base salary      This role is also eligible for bonus equity and    benefits     Global benefits provide options for the following       Paid Time Off earned time off as well as paid company holidays based on region  Paid Parental Leave take up to six months off with your child after birth adoption or foster care placement  Full Health Benefits Plans options for 100 employer paid and minimum employee contribution health plans from day one of employment  Retirement Plans select retirement and pension programs with potential for employer contributions  Learning and Development options for coaching online courses and education reimbursements  Compassionate Care Leave paid time off following the loss of a loved one and other lifechanging events     Life at DocuSign   Working here      DocuSign is committed to building trust and making the world more agreeable for our employees customers and the communities in which we live and work You can count on us to listen be honest and try our best to do what’s right every day At DocuSign everything is equal      We each have a responsibility to ensure every team member has an equal opportunity to succeed to be heard to exchange ideas openly to build lasting relationships and to do the work of their life Best of all you will be able to feel deep pride in the work you do because your contribution helps us make the world better than we found it And for that you’ll be loved by us our customers and the world in which we live      Accommodation      DocuSign provides reasonable accommodations for qualified individuals with disabilities in job application procedures If you need such an accommodation including an accommodation to properly use our online system you may contact us at accommodationsdocusigncom      If you experience any technical difficulties or issues during the application process or with our interview tools please get in touch with us at taopsdocusigncom for assistance       Our global benefits     Paid time off       Take time to unwind with earned days off plus paid company holidays based on your region           Paid parental leave       Take up to six months off with your child after birth adoption or foster care placement           Full health benefits       Options for 100 employerpaid health plans from day one of employment           Retirement plans       Select retirement and pension programs with potential for employer contributions           Learning  development       Grow your career with coaching online courses and education reimbursements           Compassionate care leave       Paid time off following the loss of a loved one and other lifechanging events          ,\n",
       " Profile insightsFind out how your skills align with the job descriptionCertificationsDo you have a valid AWS Certified Solutions Architect certificationYesNoSkillsDo you have experience in SnowflakeYesNoEducationDo you have a Bachelors degreeYesNo Job detailsHere’s how the job details align with your profilePay130000  170000 a yearJob typeFulltime Location25 Lafayette St Newark NJ 07102 BenefitsPulled from the full job description401k401k matchingDental insuranceHealth insuranceLife insurancePaid time offVision insurance Full job description    Job Classification   Technology  Engineering  Cloud       A GLOBAL FIRM WITH A DIVERSE  INCLUSIVE CULTURE        As the Global Asset Management business of Prudential we’re always looking for ways to improve financial services We’re passionate about making a meaningful impact  touching the lives of millions and solving financial challenges in an everchanging world       We also believe talent is key to achieving our vision and are intentional about building a culture on respect and collaboration When you join PGIM you’ll unlock a motivating and impactful career – all while growing your skills and advancing your profession at one of the world’s leading global asset managers       If you’re not afraid to think differently and challenge the status quo come and be a part of a dedicated team that’s investing in your future by shaping tomorrow today       At PGIM You Can        What you will do       In PGIM Fixed Income our technology group is a dynamic fastpaced environment with exciting changes on the horizon under new senior leadership We are in middle of a technology transformation to build a new platform on CloudAWS from ground up We are seeking a highly skilled and experienced handson Information Architect to join our team As Information Architect Data Modeler you will be responsible for designing and developing logical and physical data models that represent an organizations data requirements and business processes You will work closely with stakeholders database administrators developers and data analysts to ensure accurate and efficient data management        This will be a key role in our new technical initiative and will report into Enterprise Architecture If this sounds interesting then PGIM could be the place for you        What you can expect           Requirements Analysis Collaborating with business stakeholders and data users to understand their data needs business processes and reporting requirements This involves gathering requirements conducting interviews and analyzing existing systems               Data Modeling Creating logical and physical data models that represent the structure relationships and constraints of the organizations data This includes designing entityrelationship diagrams data flow diagrams and data dictionaries using industrystandard modeling techniques               Database Design Translating the logical data model into a physical database design that is optimized for performance scalability and data integrity This includes defining table structures indexes and data types while adhering to database management system DBMS constraints               Data Integration Collaborating with data integration teams to ensure seamless integration of data from various sources into the organizations databases This involves mapping data elements and transforming data to conform to the data model               Collaboration and Communication Working closely with crossfunctional teams such as database administrators developers and data analysts to align data model designs with system requirements Effective communication and collaboration are essential to ensure data model implementation aligns with business objectives               Documentation and Standards Documenting data models data definitions and data standards to provide clear guidelines for data management This documentation serves as a reference for developers data analysts and other stakeholders               Data Governance Collaborating with data governance teams to establish and enforce data management policies standards and best practices This involves ensuring compliance with data privacy regulations and promoting data stewardship          What you will bring           7 years of experience of in Data Modeling and Database Designing in Relational and NonRelational Database at least 5 years in Financial Industries focused on Fixed Income Products            Bachelors degree in Computer Science Information Systems or a related field            Proficiency in SQL data querying and performance optimization techniques            Proficiency in using Data Modeling tools like Erwin ER Studio and DBT            Expert experience in building Dimensional as well as highly normalized data models for OLTP            Familiarity with cloud infrastructure technologies like containers Kubernetes and serverless computing            Experience working with Data Governance tools like Collibra Informatica            Experience building catalogues business terms technical metadata and data lineage            Excellent problemsolving and analytical skills with the ability to translate business requirements into technical solutions            Strong experience with data structures data modeling data lineage and data catalogues          What will set you apart           Experience with Snowflake highly desirable            Certifications in cloud platforms or data management eg AWS Certified Solutions Architect etc are highly desirable       PGIM welcomes all applicants even if you dont meet every requirement If your skills align with the role we encourage you to apply      What we offer you           Medical dental vision life insurance and PTO Paid Time Off            Retirement plans            401k plan with generous company match up to 4            Companyfunded pension plan            Wellness Programs to help you achieve your wellbeing goals including up to 1600 a year for reimbursement of items purchased to support personal wellbeing needs            WorkLife Resources to help support topics such as parenting housing senior care finances pets legal matters education emotional health and career development            Tuition Assistance to help finance traditional college enrollment approved degrees many accredited certificate programs and industry designations          To find out more about our Total Reward package visit Work Life Balance  Prudential Careers       Note Prudential is required by state specific laws to include the salary range for this role when hiring a resident in applicable locations The salary range for this role is from 130000 to 170000 Specific pricing for the role may vary within the above range based on many factors including geographic location candidate experience and skills Roles may also be eligible for additional compensation andor benefits Eligibility to participate in a discretionary annual incentive program is subject to the rules governing the program whereby an award if any depends on various factors including without limitation individual and organizational performance       About PGIM Fixed Income Group       PGIM Fixed Income is a global asset manager offering active solutions across all fixed income markets With approximately 1000 employees and 793bn assets under management the company has offices in Newark London Letterkenny Amsterdam Munich Zurich Tokyo Hong Kong and Singapore Our business climate is a safe inclusive environment centered around mutual respect intellectual honesty transparency and teamwork Our leaders are focused on talent  culture dedicated to fostering growth  development at all levels to develop the industry leaders of tomorrow       About PGIM – Global Asset Management       PGIM is the global asset management business of Prudential Financial Inc NYSE PRU a leading global investment manager with nearly US127 trillion in assets under management as of June 30th 2023 With offices in 18 countries PGIM’s businesses offer a range of investment solutions for retail and institutional investors around the world across a broad range of asset classes including public fixed income private fixed income fundamental equity quantitative equity real estate and alternatives       With a history dating back 145 years and experience through more than 30 market cycles PGIM takes a longterm view not only in our investment philosophy but also in how we develop our talent We want to see our employees excel from their first day with the firm and throughout their tenure with PGIM We will inspire you support you and help you reach your greatest personal and professional aspirations If PGIM sounds like the place for you join us For more information about PGIM visit PGIMcom       Prudential Financial Inc of the United States is not affiliated with Prudential plc which is headquartered in the United Kingdom       Our Commitment to Diversity Equity and Inclusion       Prudential Financial Inc is focused on creating a fully inclusive culture where all employees feel comfortable bringing their authentic selves to work We don’t just accept difference—we celebrate it support it and thrive on it At Prudential employees have a unique opportunity to build their career path by owning their development their career and their future We encourage employees to hone their skills and explore continued opportunities within Prudential       LIMM1                                                                       Prudential Financial Inc of the United States is not affiliated with Prudential plc which is headquartered in the United Kingdom                                                                 Prudential is a multinational financial services leader with operations in the United States Asia Europe and Latin America Leveraging its heritage of life insurance and asset management expertise Prudential is focused on helping individual and institutional customers grow and protect their wealth The companys wellknown Rock symbol is an icon of strength stability expertise and innovation that has stood the test of time Prudentials businesses offer a variety of products and services including life insurance annuities retirementrelated services mutual funds asset management and real estate services                                                                 We recognize that our strength and success are directly linked to the quality and skills of our diverse associates We are proud to be a place where talented people who want to make a difference can grow as professionals leaders and as individuals Visit                                                               wwwprudentialcom                                to learn more about our values our history and our brand                                                                 Prudential is an equal opportunity employer All qualified applicants will receive consideration for employment without regard to race color religion national origin ancestry sex sexual orientation gender identity national origin genetics disability marital status age veteran status domestic partner status  medical condition or any other characteristic protected by law                                                                 The Prudential Insurance Company of America Newark NJ and its affiliates                                                                 Note that this posting is intended for individual applicants Search firms or agencies should email Staffing at                                                               staffingagenciesprudentialcom                                for more information about doing business with Prudential                                                                 PEOPLE WITH DISABILITIES                                If you need an accommodation to complete the application process which may include an assessment please email                                                               accommodationshwprudentialcom                                                                                                Please note that the above email is solely for individuals with disabilities requesting an accommodation If you are experiencing a technical issue with your application or an assessment please email                                                               careerstechnicalsupportprudentialcom                                to request assistance                                                                    ,\n",
       " Profile insightsFind out how your skills align with the job descriptionCertificationsDo you have a valid PMP certificationYesNoSkillsDo you have experience in Data center experienceYesNoEducationDo you have a Masters degreeYesNo Job detailsHere’s how the job details align with your profileJob typeFulltimeShift and scheduleOn call LocationHerndon VA Full job description Bachelor’s degree in Mechanical Engineering Electrical Engineering or an equivalent engineering science plus 3 years of relevant controls experience OR 8 years of relevant controls experience in lieu of a degree 3 years of experience with industrial controls in critical environment data center pharmaceutical manufacturing oil  gas petrochemical laboratory power water etc 2 years of general project or vendor management experience request for proposals bidding change orders quality control and RFI and submittal tracking associated with construction and project execution  As part of the global controls team you will work with highly motivated experts and innovators in the data center industry You will be responsible for troubleshooting project management and maintaining the building management system BMS and electrical power monitoring system EPMS Using Amazon leadership principles you will develop new processes and standards while innovating in the controls space    AWS Data centers have multiple components such as generators uninterruptable power sources diesel generators electrical switchgear power distribution units variable frequency drives automaticstatic transfer switches chillers aircooled and watercooled pumps cooling towers heat exchangers CRAHs air economizers etc All these components have local control systems that interact with each other via open andor proprietary communications protocols The BMS is the primary method of control of all mechanical systems within a data center The EPMS is the primary method of monitoring all electrical systems within a data center    Key job responsibilities    As a Data Center Controls Engineer you will   Troubleshoot and perform Root Cause Analysis or Corrective Action for BMS and EPMS related issues in AWS data centers Train and assist internal customers and stakeholders with the creation design configuration validation installation commissioning and operation of BMS and EPMS systems Provide technical assistance and support to operations during life cycle of the data center Review results and action items from the quarterly maintenances for BMS and EPMS and take actions to get them resolved Develop BMS  EPMS projects scope of work schedule budget and level of efforts LOE to projects requested by customers and stakeholders Manage scope schedule finance and execution of BMS and EPMS improvement projects in AWS data centers Assist in procurement related activities including request for quotationproposals responding to request for information review of vendors proposal and issuance of purchase orders Participate in AWS global oncall schedule to provide immediate BMS and EPMS technical support to inservice data centers Attend project related meetings coordinate with project leaders and regularly report status to Controls and stakeholders management Support Controls projects related commissioning activities in the data centers Review implement troubleshoot and iterate on the controls sequence of operation SOO and provide necessary feedback to the design team Develop and modify controls logic programming and graphical user interfaces Manage multiple stakeholder deliverables requirements and navigate challenging situations Financially manage BMS and EPMS service contracts Frequently visit locally assigned inoperation data centers to troubleshoot meet customers supervise vendor’s work to ensure compliance with the scope design SOO and applicable local codes  We are open to hiring candidates to work out of one of the following locations    Herndon VA USA     MS in Engineering Mechanical Electrical Chemical ControlsAutomation Experience designing configuring programming installing troubleshooting or servicing HVAC Controls or Electrical SCADA systems application specific controllers software and networks Experiencing using common industrial communication protocols MQTT BACnet andor MODBUS Demonstrated understanding of engineering documentation electrical and mechanical diagrams and standard operating procedures Ability to manage multiple stakeholder deliverables requirements and navigate difficult situations Experience designing data centers or critical MEP infrastructure Registered as a Professional Engineer PE or certified Project Management Professional PMP Prior AWSAmazon experience 4 Yr Military Service  Amazon is committed to a diverse and inclusive workplace Amazon is an equal opportunity employer and does not discriminate on the basis of race national origin gender gender identity sexual orientation protected veteran status disability age or other legally protected status For individuals with disabilities who would like to request an accommodation please visit httpswwwamazonjobsendisabilityus ,\n",
       " Profile insightsFind out how your skills align with the job descriptionEducationDo you have a Bachelors degreeYesNo Job detailsHere’s how the job details align with your profilePay117000 a yearJob typeFulltime LocationDenver CO BenefitsPulled from the full job description401k 6 Match401k matchingDental insuranceFlexible spending accountHealth insuranceLife insuranceVision insurance Full job description      The Data Solutions Engineer at Redaptive is responsible for leading programmatic meter design based on customer needs and expectations for energy efficiency projects Reporting to the Senior Manager of Delivery Engineering the Data Solutions Engineer will bring advanced technical expertise in electrical engineering and energy efficiency to deliver highimpact solutions This role is crucial in driving the successful implementation of energy efficiency projects within the organization       Redaptive is an EnergyasaService provider that funds and installs energysaving and energygenerating equipment Redaptive’s programs help many of the world’s most sophisticated organizations reduce energy waste save money lower their carbon emissions and meet their sustainability goals across their entire real estate portfolios With Redaptive customers can overcome capital and contractual barriers to achieve energysaving benefits quickly all with realtime data powered by Redaptive’s proprietary Data Solutions metering platform Redaptive was founded in 2015 and is headquartered in Denver CO Redaptive is backed by CarVal ENGIE New Ventures Linse Capital CBRE Evergy Ventures Rabobank CPP Investments and Honeywell       Our company culture is exciting collaborative and fastpaced We are passionate about changing the world and helping our customers become more environmentally sustainable and profitable We are looking for team members who are driven passionate and want to take on a diverse set of challenges to help grow a great company Redaptive Inc is an equal employment opportunity employer and all qualified applicants will receive consideration for employment For more information visit wwwredaptivecom       LITD1       Responsibilities and Duties    Direct the development of programmatic meter designs tailored to meet customer needs and expectations  Design and review the scope of work for electric gas and water meter customer proposals  Oversee the creation of intricate plans and specifications for programmatic panel audits and designs ensuring precision efficiency and compliance with industry standards and codes  Collaborate closely with multidisciplinary teams to integrate sophisticated audit methodologies seamlessly into overall project designs  Provide advanced technical leadership in electrical engineering specializing in programmatic meter designs to guide and support project teams in achieving successful implementations of energy efficiency solutions across direct indirect and distributor models  Lead team of electrical engineers both in the US and in India  Stay at the forefront of industry advancements trends and emerging technologies related to programmatic meter designs  Lead engagements with external vendors and contractors to ensure the seamless execution of advanced programmatic meter design methodologies  Conduct rigorous quality assurance reviews of complex programmatic meter designs ensuring the highest standards of accuracy reliability and adherence to project specifications  Oversee the activity and implement strategic corrective actions to address discrepancies or challenges identified during the review process  Oversee the generation of detailed documentation including intricate drawings schematics and technical specifications to effectively communicate advanced programmatic meter designs to internal teams and external stakeholders  Produce indepth reports to provide comprehensive updates on the progress and status of advanced programmatic meter designs  Other duties as assigned       Required Abilities Skills and Education    Bachelors degree in Electrical Engineering or a related field  Demonstrated experience in designing and implementing programmatic electrical meter solutions       The Perks    Equity plan participation  Companysubsidized benefits medical dental vision life insurance  Flexible Spending Accounts healthcare and dependent care  6 401k match with immediate vesting  Flexible Time Off  Expected annual salary 117K subject to adjustment for relevant experience skills geo location  Annual bonus subject to company and individual performance    The company is an Equal Opportunity Employer drugfree workplace and complies with ADA regulations as applicable All duties and responsibilities are essential functions and requirements and are subject to possible modification to reasonably accommodate individuals with disabilities The requirements listed in this document are the minimum levels of knowledge skills or abilities             About Redaptive Inc       Redaptive is an EnergyasaService and technology provider that funds and installs energysaving and energygenerating equipment Redaptive’s programs help organizations accelerate and scale efforts to reduce energy waste optimize costs increase resiliency and meet sustainability goals across their entire real estate portfolio With Redaptive customers can quickly overcome capital and resource barriers to achieve energyoriented benefits Our proprietary bestinclass meters and data solutions validate and report on critical building information Redaptive is backed by CarVal ENGIE New Ventures Linse Capital CBRE Evergy Ventures Rabobank CPP Investments and Honeywell       Our company culture is fun collaborative and fast paced We are passionate about changing the world and helping our customers to become more environmentally sustainable and profitable We are looking for team members who are driven passionate and want to take on a diverse set of challenges to help grow a great company Redaptive Inc is an equal employment opportunity employer and all qualified applicants will receive consideration for employment For more information visit redaptivecom       This employer participates in EVerify       CCPA Notice for California Job Applicants     Please no thirdparty recruiters     ,\n",
       " Profile insightsFind out how your skills align with the job descriptionLicensesDo you have a valid Secret Clearance licenseYesNoSkillsDo you have experience in WeblogicYesNoEducationDo you have a Bachelors degreeYesNo Job detailsHere’s how the job details align with your profileJob typeFulltime Location500 12th Street NE Washington DC 20002 Full job description  Overview       CommIT is seeking a Junior Data Engineer with demonstrated expertise supporting projects for the Department of Defense DoD in Washington DC this position can also be hybrid      Established in 2001 CommIT is a Certified VeteranOwned Small Business CVOSB providing innovative technical engineering and data science services Our enterprise systems support includes the Department of Defense’s DoD GCSSMC CAC2S TBMCSMC and the Department of Veteran’s Affairs’ VA telehealth communications We offer acquisition management systems engineering Agile software development cloud management IT modernization data analytics cybersecurity and training including leadingedge DevSecOps automated testing and mobile application development   Responsibilities     Your essential job functions will include but may not be limited to     Provides valuable support to the design team while continually improving their coding and design skills  Assists senior programmers and analysts with all aspects of software design and coding  Builds interactive and complex data visualization and analysis tools such as dashboards  Attends and contributes to project development meetings  Applies codes and improves coding skills  Writes and maintains programming codes for the development of automation or interactive data analytics tools  Works on minor bug fixes of automation or interactive data analytics tools  Monitors the technical performance of data systems  Gathers information from consumers about program functionality  Writes data analytics reports  Archives IHSC datainformation to existing repository platform andor data warehouse or other specified data storage areas  Maintains a repository or database system and SharePoint pages of unstructured and opensource data  Extracts data from various data sources into one for analytic and reporting purposes  Conducts analytic toolsdata systems development tests  Learns the codebase gathers user data and responds to request from senior programmers  Qualifications     Required Experience and Education     Education Required Bachelor of Arts or Bachelor of Science BABS degree required in Computer Science Statistics Data Analytics Data Science Information Management Engineering or a closely related field  Experience Recommended At least three 3 years of data analytics and programmingrelated experience or relevantsimilar experience which includes experienceknowledgeskillsabilities with all of the following      Practical experience in at least two programming applications software packages eg Java CC NET WebLogic HTML ServiceNow SharePoint Power Apps etc preferably including knowledge of relational database design the ability to read and understand data dictionaries data coding and the ability to infer the relationship of the tables to the application and the process  Has an initial level of understanding about maintaining and complying with requirements for the following task areas collecting compiling processing normalizing analyzing and interpreting data using systems support tools such as SQL Python Oracle Tableau Power BI on Microsoft Azure Quicksight on Amazon Web Services Access and Excel  Has experience with documenting and reviewing data sharing agreements outstanding customer service and communication skills relaying technical concepts  Has experience with managing data quality cleansing tagging and metadata management  Has experience with testing and implementing application software with regards to collecting process and storing data  Has experience with project management tools such as MS Project     Security Requirements    Secret Clearance  US Citizenship    Equal Opportunity Employer      CommIT Enterprises Inc is an Equal Opportunity Employer Employment decisions are made without regard to race color religion national origin gender sexual orientation gender identity age physical or mental disability genetic factors militaryveteran status or other characteristics protected by law    ,\n",
       " Profile insightsFind out how your skills align with the job descriptionSkillsDo you have experience in TableauYesNo Job detailsHere’s how the job details align with your profilePay500000 a yearJob typeFulltime LocationDublin CA 94568 Full job description  Job Information   Industry       IT Services         Work Experience       5 years         Salary       500000         City       Dublin         StateProvince       California         Country       United States         ZipPostal Code       94568            Solution Architect  Data Engineering and Analytics  Technical Expertise   Data Architecture  Design    Proven experience designing scalable secure and performant data architectures for big data and analytics workloads   Expertise in data modeling techniques dimensional entityrelationship etc   Knowledge of data governance frameworks and data quality best practices    Cloud Platform Proficiency GCP Focus    Extensive experience with GCP services for data engineering and analytics BigQuery Dataflow Dataproc PubSub etc   Ability to design and implement cloud architecture for data processing and analytics at scale   Understanding of cloud security best practices and compliance requirements    Data Engineering  Integration    Strong understanding of data pipelines ETLELT processes and data transformation techniques   Proficiency in programming languages like Python Java or Scala   Experience with data orchestration tools Airflow Luigi and containerization technologies Docker Kubernetes    Programming and Scripting    Strong skills in programming languages like Python Java or Scala   Ability to write analyze and debug SQL queries    Data Analytics and Visualization    Working knowledge of data analysis tools and platforms   Proficiency in data visualization tools and techniques to present data insights effectively    Machine Learning and AI Optional    Knowledge of machine learning algorithms and their application in data analytics   Familiarity with AI and ML services on GCP AI Platform AutoML etc    Analytical Skills   Data Strategy and Business Intelligence    Ability to develop strategies for data collection analysis and dissemination   Experience in delivering business intelligence and datadriven insights to stakeholders    ProblemSolving and Performance Optimization    Strong analytical and problemsolving skills to address complex datarelated issues   Experience in optimizing data workflows queries and algorithms for performance and costefficiency    Managerial and Soft Skills   Project Management    Experience in leading and managing largescale data projects   Familiarity with project management tools and methodologies eg Agile Scrum    Communication and Leadership    Excellent communication skills to articulate technical concepts to nontechnical stakeholders   Leadership skills to guide and mentor teams    Collaboration and Teamwork    Ability to work collaboratively with crossfunctional teams   Experience in working in a global multicultural environment    Continuous Learning and Adaptation    Commitment to continuous learning and staying updated with the latest trends in technology data engineering and analytics   Ability to adapt to evolving business and technology landscapes     Requirements   Additional Considerations Optional    Experience with data visualization tools Tableau Power BI   Familiarity with data security and privacy regulations GDPR HIPAA   Experience in a specific industry vertical relevant to your organization      ,\n",
       " Profile insightsFind out how your skills align with the job descriptionSkillsDo you have experience in TeachingYesNoEducationDo you have a Bachelors degreeYesNo LocationHoboken NJ BenefitsPulled from the full job description401k matchingDental insuranceGym membershipHealth insurancePaid parental leaveParental leaveUnlimited paid time offShow morechevron down Full job description Company Description  Founded in Europe in 2004 Tipico is now a licensed US Sportsbook operating in New Jersey Iowa Ohio and Colorado Renowned in Germany and globally Tipico offers online betting across 30 sports Guided by values such as innovation and inclusion Tipico focuses on creating topnotch mobile sports betting and casino products Recently recognized as the No 1 rated casino app in the US Tipico is dedicated to enhancing gaming excitement for millions daily Join us in redefining excellence in online entertainment  Please note this role is located in our Hoboken NJ office we work off a hybrid model and come into the office 2 days per week Job Description  The Senior Data Engineer is responsible for developing constructing testing and maintaining Tipico’s data platform and pipelines This is achieved by ensuring the infrastructure is reliable and a high level of data quality is maintained  The Senior Data Engineer will report directly to the VP of data or team lead and work together with rest of the data engineers BI analysts and product teams This person will   Create and maintain both batch ETL and realtime data pipelines and architecture  Ensure all data provided by Data Platform is of the highest quality and is delivered in a timely manner and in line with agreed SLAs  Assemble large and complex data sets that meet functional and nonfunctional business requirements  Identify design and implement internal process improvements automating manual processes optimizing data delivery redesigning infrastructure for greater scalability etc  Build the infrastructure required for optimal extraction transformation and loading of data from a wide variety of data sources using SQL and AWS ‘big data’ technologies  Collaborate with stakeholders including data architects Executive Product Data and IT team members from the beginning to the delivery of a project  Build a scalable modern and trusted data eco system making sure it is responsive available and in line with business requirements  Design build and scale data pipelines across a variety of source systems and streams internal thirdparty as well as cloudbased distributedelastic environments and downstream applications andor selfservice solutions  Think of new ways to help make our data platform more scalable resilient and reliable and then work across our team to put your ideas into action  Take part in sprints workloads and deliverables through agile methodologies  Manage quality assurance verification of accuracy and consistency of data – specifically KPI measures sent to the business  Provide expert level advice to data engineers to deliver high quality data pipelines and ETL flows Review design and code produced by other engineers    Qualifications  Education   Bachelors degree in Computer Science Computer Engineering relevant technical field or equivalent practical experience   Experience   Experience working in an online gaming or fastmoving industry required  7 years of work experience in data engineers and data platforms  Must have experience in successfully implementing datacentric applications such as data warehouses operational data stores and data integration projects  Experience with SQL ETL data modeling and Python  Experience working with terabyte to petabyte scale data  Designing technical solutions and teaching team members   Skills   Excellent Verbal and written Communication skills  Strong analytical and problemsolving skills that balance with creative approaches  Ability to take ownership of projects with diligence and consistency in carrying out tasks with a high level of attention to detail and priority  Collaborative able to engage in interactive discussions with the rest of the team and able to communicate technical concepts clearly and concisely   Language   Fluent in English Oral and written – essential   FunctionalTechnical Competence   Strong experience with largescale production databases and SQL  Solid understanding of cloud data services AWS services such as S3 Athena EC2 RedShift EMR EKS RDS and Lambda  Proficient with one or more big data  new data technologies such as DBT NIFI Airflow Kafka  Knowledge in working with timeseriesanalytics databases such as Elasticsearch  Understanding of containerization and orchestration technologies like DockerKubernetes  Familiarity with Marketing tooling andor CRM systems is preferred  Familiarity with using business intelligence tools such as Domo Superset or other similar tooling   Personal Characteristics   Exemplifies our values – Trust Passion and Progress  Proactive agile innovative and solution orientated work approach with strong sense of ownership and accountability for his’sher’s work and impact on business  Thrives working in a fastpaced and challenging environment  Ability to think outside of the box be innovative adaptable identify continuous improvement areas and come up with creative solutions to challenges  Detailoriented and organized  Strong work ethic and ability to work in a collaborative environment  Ability to multitask and prioritize  Adaptability and flexibility  Constructively challenges with positive arguments  Comfortable with being challenged  seeking challenge    Additional Information  Whats in it for you   Work in a new and thriving industry with high growth potential  Competitive salary and performance bonus  Medical Dental and Vision Insurance  401k employer matching  Unlimited PTO with 15 paid holidays  100 paid parental leave  Professional training and development opportunities  Gym reimbursement  Free workout classes at Prime Cycle in Hoboken NJ  1year free Apple Fitness subscription  Work in an environment with a startup feeling backedup by a leading European sports betting house We are a highvolume business and are taking off in the US   ,\n",
       " Profile insightsFind out how your skills align with the job descriptionSkillsDo you have experience in UnityYesNo Job detailsHere’s how the job details align with your profilePay83000  138200 a yearJob typeFulltimeShift and scheduleOn call LocationRemote Full job description At DICK’S Sporting Goods we believe in how positively sports can change lives On our team everyone plays a critical role in creating confidence and excitement by personally equipping all athletes to achieve their dreams We are committed to creating an inclusive and diverse workforce reflecting the communities we serve  If you are ready to make a difference as part of the world’s greatest sports team apply to join our team today   OVERVIEW   At DICK’S Sporting Goods we believe in how positively sports can change lives On our team everyone plays a critical role in creating confidence and excitement by personally equipping all athletes to achieve their dreams We are committed to creating an inclusive and diverse workforce reflecting the communities we serve   We are creating the future of sports driven by powerful data products and platforms that serve our Athletes and Teammates   We are looking for a Senior Data Engineer to join our passionate team adding your background and experience to make us even stronger In this role you will build dataset and make it accessible to our partner teams by writing great code to simplify the complexity and ensure quality Your work will enable product teams data scientists and decisionmakers across the company to bring together insights and inform our business   We believe that trusted easy to consume data is critical and as a Senior Data Engineer your work will help to build that foundation   You will also be responsible for the daily operations inclusive of troubleshooting and job monitoring You will be a part of the growing Data team reporting to the Sr Director Data Analytics   The impact you will have   DesignStrategy You will design and support the business’s database and table schemas for new and existing data sources for the data warehouse Creates and supports the ETL to facilitate data accommodation into the warehouse In this capacity the Data Engineer designs and develops systems for the maintenance of the business’s data warehouse ETL processes and business intelligence   Collaboration You will be collaborative  working closely with analysts data scientists and other data consumers within the business to gather and deliver high quality data for business cases The Data Engineer also works closely with other disciplinesdepartments and teams across the business in coming up with simple functional and elegant solutions that balance data needs across the business   Analytics You will play an analytical role in quickly and thoroughly analyzing business requirements and subsequently translating the emanating results into good technical data designs In this capacity the Data Engineer establishes the documentation of the data solutions develops and maintains technical specification documentation for all reports and processes   What You Will Do    You’ll be working with a variety of internal teams  Engineering Business  to help them solve their data needs  Your work will provide teams with visibility into how DICKs products are being used and how we can better serve our customers  Identify data needs for business and product teams understand their specific requirements for metrics and analysis and build efficient and scalable data pipelines to enable datadriven decisions across DICKs  Experience in one or more of the following Python Preferred Scala C or Java  Design develop reliable data models and extremely efficient pipelines to build quality data and provide intuitive analytics to our partner teams  Help the Data Analytics  Data Science team apply and generalize statistical and econometric models on large datasets  Drive the collection of new data and the refinement of existing data sources develop relationships with production engineering teams to manage our data structures as the DICKs product evolves  Develop strong subject matter expertise and manage the SLAs for those data pipelines  Participate in design sessions and code reviews to elevate the quality of data engineering across the organization  Participate in an oncall rotation for support during and after business hours  Lead design sessions and code reviews to elevate the quality of data engineering across the organization    Technical Skills    Expert in SQL andor SQL based languages and performance tuning of SQL queries  Strong understanding of NormalizedDimensional model disciplines and similar data warehousing techniques  Experience in one or more of the programming languages are required Python Preferred Scala C or Java Go Kotlin  Strong Experience with cloudbased data warehouses – eg Snowflake Big Query Synapse RedShift etc  Experienced with ETLELT in Databricks with Medallion architecture and with Delta Lake Unity Catalog Delta Sharing Delta Live Tables DLT  Experience with CICD on Databricks using tools such as GitHub Actions and Databricks CLI  Strong Grasp of data management principles Data Lake Data Mesh Data Catalog Data Quality etc    QUALIFICATIONS      5 years of experience in Data Warehousing and development using data technologies such as Relational  NoSQL databases open data formats building data pipelines ETL and ELT with batch or streaming ingestion loading and transforming data  Expert in SQL andor SQL based languages and performance tuning of SQL queries  Strong understanding of NormalizedDimensional model disciplines and similar data warehousing techniques  Experience in one or more of the programming languages are required Python Preferred Scala C or Java Go Kotlin  Strong experience working with ETLELT concepts of data integration consolidation enrichment and aggregation in petabyte scale data sets  Experience with at least one of the following cloud platforms Microsoft Azure Preferred Amazon Web Services AWS or Google Cloud Platform GCP  Strong Experience with cloudbased data warehouses – eg Snowflake Big Query Synapse RedShift etc  Experience with message queuing stream processing Kafka Flink Spark Streams  Strong Grasp of data management principles Data Lake Data Mesh Data Catalog Master Data Data Quality etc  Experience in BI tooling such as Qlik MicroStrategy Tableau PowerBI or Looker  Experience with orchestration tools ControlM Airflow etc  Strong communication skills across different mediums to craft compelling messages to drive action and alignment  Comfort with agile delivery methodologies in a fastpaced complex environment – Scrum SAFe utilizing tools such as Jira Confluence and GitHub  Ideal candidates will have experience working with one of the following industries Retail Supply Chain Logistics Manufacturing or Marketing  Proficient in LinuxUnix environments      LIJN1  Targeted Pay Range 83000  138200 This is part of a competitive total rewards package that could include other components such as incentive equity and benefits Individual pay is determined by a number of factors including experience location internal pay equity and other relevant business considerations We review all teammate pay regularly to ensure competitive and equitable pay We also offer a generous suite of benefits To learn more visit wwwbenefityourliferesourcescom  ,\n",
       " Profile insightsFind out how your skills align with the job descriptionSkillsDo you have experience in PythonYesNoEducationDo you have a Masters degreeYesNo Job detailsHere’s how the job details align with your profileJob typeFulltime LocationLas Vegas NV BenefitsPulled from the full job description401k 6 Match401k matchingDisability insuranceEmployee stock ownership planFlexible scheduleHealth insurancePaid time offShow morechevron down Full job description    Own Your Future         Modern Technology Solutions Inc MTSI is seeking a Electronic Warfare Data Analyst  Engineer to join our growing team in Las Vegas NV This position will require working at a remote work location      Why is MTSI known as a Great Place to Work    Interesting Work Our coworkers support some of the most important and critical programs to our national defense and security  Values Our first core value is that employees come first We challenge our coworkers to provide the highest level of support and service and reward them with some of the best benefits in the industry  100 Employee Ownership we have a stake in each others success and the success of our customers Its also nice to know whats going on across the company we have company wide townhall meetings three times a year  Great Benefits  Most FullTime Staff Are Eligible for   Starting PTO accrual of 20 days PTOyear  10 holidaysyear  Flexible schedules  6 401k match with immediate vesting  Semiannual bonus eligibility July and December  Company funded Employee Stock Ownership Plan ESOP  a separate qualified retirement account  Up to 10000 in annual tuition reimbursement  Other company funded benefits like life and disability insurance  Optional zero deductible Blue CrossBlue Shield health insurance plan   Track Record of Success We have grown every year since our founding in 1993      Modern Technology Solutions Inc MTSI is a 100 employeeowned engineering services and solutions company that provides highdemand technical expertise in Digital Transformation Modeling and Simulation Rapid Capability Development Test and Evaluation Artificial Intelligence Autonomy Cybersecurity and Mission Assurance         MTSI delivers capabilities to solve problems of global importance Founded in 1993 MTSI today has employees at over 20 offices and field sites worldwide      For more information about MTSI please visit wwwmtsivacom    Responsibilities     This individual will possess operational and test experience with Electronic Warfare systems They will be tasked to support analysis of electronic warfare systems This individual will participate and monitor the execution of DTOT missions and processes and analyze and evaluate mission data and report results providing feedback to the customer      ROLE AND RESPONSIBILITIES     Electronic Warfare Systems Analysis Develop test scenarios write test plans execute tests and analyze the data then write the report of your findings Air Operation Analysis Provide expert guidance and oversight on Air Defense Systems ADS analysis both in a model and simulation environment and in an open air test environment Flight Test  o Perform mechanicalelectrical review of EW systems subsystems and components to ensure proper development of test documentation and data collection requirements    o Participate in development of test documentation such as the Test Verification plans test information sheets test matrices test cards data analysis plans etc    o Provide EW support for design reviews test planning working groups test card prep execution and post flight reports    Qualifications     EXPERIENCE     Minimum of 2 years of related experience    Experience with Python MatLab or similar analytical tools experience is desired Knowledge of and an understanding of concepts principles and practices of electronic warfare and survivability testing and analysis Experience with ground radar systems and testing with a clear understanding of flight test principles and discipline Excellent communication and analytical skills Working knowledge of computer systems software and current modeling tools Experience using data analysis tools Previous experience as aircrew member Pilot EWO NAV etc as plus     EDUCATION     Bachelor’s degree or Masters degree in engineering or other mathscience      CLEARANCE     Current TopSecret security clearance required      Travel    Approximately 10 travel may be required      US Citizenship is required      LIRR1       MTSIjobs       mtsi    ,\n",
       " Profile insightsFind out how your skills align with the job descriptionSkillsDo you have experience in Statistical analysisYesNoEducationDo you have a Doctoral degreeYesNo Job detailsHere’s how the job details align with your profilePay9712  14567 an hourJob typeParttime LocationMoffett Field CA 94035 BenefitsPulled from the full job description401kADD insuranceFlexible scheduleHealth insuranceMilitary leavePaid time offParental leaveShow morechevron down Full job description Title RD Data ScientistEngineer    This position is a part time remote opportunity   BELONG CONNECT GROW with KBR   Around here we define the future We are a company of innovators thinkers creators explorers volunteers and dreamers But we all share one goal to improve the world responsibly and safely   KBR is rapidly developing capabilities across a range of engineering RD areas We are looking for candidates who have interest in the emerging field of edge computing and its applications that span UAVs to healthcare applications This position is for an RD data scientistengineer working on collecting analyzing and documenting 5G communication data for edge computing for SLAM and other applications suitable for solution in an edge network Assist in developing data collection process Analyze collected data and recommend modifications to the collection process Write technical documentation regarding SLEDGE edge computing   Required skills and traits   Candidates should have solid understanding of edge computing and previous experience in optimization and statistical analysis  FilteringSignal processingTraining and Validation data set preprocessing  Model Development including noise modeling  Experience performing statistical parameter estimation including familiarity with Maximum Likelihood Estimation MLE and Maximum APosterior Estimation MAP  Experience computing statistical validation metrics on large data sets including chisquare coefficient of determinism R2 and parameter confidence intervals  Experience in developing technical documentation  Track record of successful technical publications  15 years of experience    Other desired skills   Familiarity with models for wireless communication systems  Excellent verbal and written communication    Education Candidate must have a PhD under the discipline of Data ScienceEngineering   Basic Compensation  9712 per hour  14567 per hour  This range is for the California area only   The offered rate will be based on the selected candidate’s knowledge skills abilities andor experience and in consideration of internal parity   Additional Compensation  KBR may offer bonuses commissions or other forms of compensation to certain job titles or levels per internal policy or contractual designation Additional compensation may be in the form of sign on bonus relocation benefits short term incentives long term incentives or discretionary payments for exceptional performance   KBR BENEFITS  KBR offers a wide range of benefits for their employees we offer medical prescription dental vision ADD disability benefits retirement 401k travel benefits PTO holidays flexible work schedules parental leave military leave education assistance and the list goes on and on We also support career advancement through professional training and development   INCLUSION AND DIVERSITY AT KBR  At KBR we are passionate about our people sustainability and our Zero Harm culture These inform all that we do and are at the heart of our commitment to and ongoing journey toward being a more inclusive and diverse company That commitment is central to our team of teams philosophy and fosters an environment of real collaboration across cultures and locations Our individual differences and perspectives bring enhanced value to our teams and help us develop solutions for the most challenging problems We understand that by embracing those differences and working together we are more innovative more resilient and safer   KBR is an equal opportunity employer All qualified applicants will receive consideration for employment without regard to race color religion disability sex sexual orientation gender identity or expression age national origin veteran status genetic information union status andor beliefs or any other characteristic protected by federal state or local law   ,\n",
       " Profile insightsFind out how your skills align with the job descriptionSkillsDo you have experience in Spring BootYesNoEducationDo you have a Bachelors degreeYesNo LocationRemote Full job description             Remote United States                      Data Platform                     At Netflix we want to entertain the world and are constantly innovating on how entertainment is imagined created and delivered to a global audience We currently stream content in more than 30 languages in 190 countries topping over 220 million paid subscribers and are expanding into new forms of entertainment such as gaming        The data infrastructure teams at Netflix enable us to leverage data to bring joy to our members in many different ways We provide centralized data platforms and tools for various business functions at Netflix so they can utilize our data to make critical datadriven decisions We do all the heavy lifting to make it easy for our business partners to work with data efficiently securely and responsibly We aspire to lead the industry standard in building a worldclass data infrastructure as Netflix leads the way to be the most popular and pervasive destination for global internet entertainment        We are looking for distributed systems engineers to help evolve and innovate our infrastructure We are committed to building a diverse and inclusive team to bring new perspectives as we solve the next set of challenges In addition we are open to remote candidates We value what you can do from anywhere in the US        Spotlight on Data Infrastructure Teams        Database Access Platform Learn More           Our team champions advancements in data abstractions building streamlined abstractions atop distributed data stores like Apache Cassandra Elasticsearch Memcached and S3 We cater to diverse Netflix use cases including counters flexible keyvalues and time series Beyond this were the custodians of Hollow Netflixs robust memory colocated dataset library for efficient publishing and consumption With Hollow we’re setting new standards in reducing the footprint of inmemory datasets while allowing rapid access to data benefiting hundreds of Netflix applications across all business verticals Our mandate is clear empower Netflixs microservices to meet their increasing and dynamic data requirements        Your Role           Join us as a Senior Software Engineer on the Data Access Platform team Your main task will be developing and advancing the opensource Hollow library and its use at Netflix via abstractions Hollow is used broadly at Netflix in its mission to entertain the world Youll collaborate closely with various teams lead crossfunctional projects and share our experiences with the opensource community        Check out the Netflix OSS Hollow and hear more about our team on the CDE Channel        Data Platform Infrastructure Learn More           The Data Platform Infrastructure team acts as a platform for our own data platforms Our shared infrastructure and tooling enable Netflix to quickly innovate on providing stateoftheart data and analytics systems to the rest of the company without building bespoke scaffolding for each new system To do this we create highleverage infrastructure control and deployment systems that are finetuned for the needs of running our data systems at scale uniquely many of our tools and systems are written in Python and Go so this is a great team to consider if you enjoy working in a variety of languages        Your Role           As a Senior Software Engineer on the Data Infrastructure team you will play an essential role in designing developing and maintaining our data infrastructure Your work will help Netflix to innovate quickly by providing the company with stateoftheart analytics platforms and data stores You will help to provide the fundamental infrastructure that highscale and highcritical datastore teams at Netflix hosting 1000s of clusters of Cassandra EVCache Elasticsearch and RDS build their control planes on top of You will work closely with various teams and lead crossfunctional initiatives to ensure our infrastructure is efficient scalable and reliable        This would be your dream job if you enjoy   Solving real business needs at large scale by applying your software engineering and analytical problem solving skills  Architecting and building a robust scalable and highly available distributed infrastructure  Leading crossfunctional initiatives and collaborating with engineers product managers and TPM across teams  Sharing our experiences with the open source communities and contributing to Netflix OSS     About you   7 years experience in crafting complex scalable distributed data infrastructure  Proficiency in Java C Golang or Python with a solid understanding of multithreading and memory management  Proven track record of developing and maintaining highimpact systems  Experience building and operating scalable faulttolerant distributed systems  You have a BS in Computer Science or a related field  Familiarity with library development DI frameworks preferably SpringBoot and container technologies  Previous exposure to inmemory dataset systems and Hollow experience is a plus for the Database Access team         A few more things about us        As a team we come from many different countries and our fields of education range from the humanities to engineering to computer science Our team includes product managers program managers designers fullstack developers distributed systems engineers and data scientists Folks have the opportunity to wear different hats should they choose to We strongly believe this diversity has helped us build an inclusive and empathetic environment and look forward to adding your perspective to the mix        At Netflix we carefully consider a wide range of compensation factors to determine your personal top of market We rely on market indicators to determine compensation and consider your specific job family background skills and experience to get it right These considerations can cause your compensation to vary and will also be dependent on your location        The overall market range for roles in this area of Netflix is typically 100000  700000        This market range is based on total compensation vs only base salary which is in line with our compensation philosophy Our culture is unique and we tend to live by our values so it’s worth learning more about Netflix here         ,\n",
       " Profile insightsFind out how your skills align with the job descriptionSkillsDo you have experience in SnowflakeYesNoEducationDo you have a Masters degreeYesNo Job detailsHere’s how the job details align with your profilePay65000  83000 a yearJob typeFulltime LocationEdgewater Park NJ 08010 BenefitsPulled from the full job description401kDental insuranceDisability insuranceFlexible scheduleHealth insurancePaid time offVision insurance Full job description LOCATION 4287 Route 130 S Edgewater Park NJ US 08010  Overview Come join our growing team of data practitioners and be on the leading edge of Burlington’s digital transformation Burlington is seeking a selfdriven and highly motivated individual to join a dynamic team with a passion for data software and engineering At Burlington you will have the opportunity to work with the latest technologies in a goaloriented environment As a Data Engineer I you will be a member of the Enterprise Data and Analytics team supporting business areas including Merchandising Allocations Marketing IT and Supply Chain Analytics teams with insights gained from analyzing Burlington and external data To be successful in this position you will have strong experience pulling data from various internal and external data sources and preparing it for advanced analytics segmentation and modeling Additionally you shoudl have strong interpersonal and relationship building skills as well as written and verbal communication skills Experience  35 years of experience in designing and implementing large scale data loading manipulation processing analysis and exploration solutions Experience developing SQL based data processing 3 years of experience with Data Architecture Data Warehouse Data Lake Data Marts and Data Stores with focus on AIML techniques Experience with Snowflake Oracle Databases AzureAWS and ADLS  Skills and Abilities  Technical expertise with pulling and massaging data Great understanding of firstthird party data Agile Development methodology Database Normalization Advanced SQL skills Understanding of data management principles and processes Passion for data analytics and pushing business innovation  Education  Bachelor’s or master’s degree in Computer Science  Engineering Informatics or related areas  Come join our team You’re going to like it here You will enjoy a competitive wage flexible hours and an associate discount Burlington’s benefits package includes medical dental and vision coverage including life and disability insurance Full time associates are also eligible for paid time off paid holidays and a 401k plan We are a rapidly growing brand and provide a variety of training and development opportunities so our associates can grow with us Our teams work hard and have fun together Burlington associates make a difference in the lives of customers colleagues and the communities where we live and work every day Burlington Stores Inc is an equal opportunity employer committed to workplace diversity LITG1 Posting Number 2024218320  Location USNJEdgewater Park  Address 4287 Route 130 S  Zip Code 08010  Workplace Type Remote  Position Type Regular FullTime  Career Site Category Corporate  Position Category Information Technology  Evergreen Yes  Min USD 6500000Annual  Mid USD 8300000Annual   ,\n",
       " Profile insightsFind out how your skills align with the job descriptionSkillsDo you have experience in SparkYesNo Job detailsHere’s how the job details align with your profilePayFrom 105700 a yearJob typeFulltime LocationSeattle WA BenefitsPulled from the full job descriptionHealth insurance Full job description 3 years of data engineering experience Experience with data modeling warehousing and building ETL pipelines Experience with SQL Experience in at least one modern scripting or programming language such as Python Java Scala or NodeJS  Sales Marketing and Global Services SMGS  AWS Sales Marketing and Global Services SMGS is responsible for driving revenue adoption and growth from the largest and fastest growing small and midmarket accounts to enterpriselevel customers including public sector The AWS Global Support team interacts with leading companies and believes that worldclass support is critical to customer success AWS Support also partners with a global list of customers that are building missioncritical applications on top of AWS services    The AWS Marketing Data Science and Engineering team is seeking an experienced Data Engineer to join our dynamic and innovative group In this role you will be responsible for designing building and optimizing data pipelines that power our cuttingedge marketing analytics and attribution capabilities You will work with complex data sets leveraging your expertise in data engineering to ensure highquality reliable and scalable data solutions    Key job responsibilities  Your primary responsibilities will include ingesting transforming and modeling sales and marketing data to enable multitouch attribution MTA analysis You will collaborate closely with crossfunctional teams including sales marketing and analytics to continuously enhance our MTA measurement and insights Additionally you will play a crucial role in building structured data pipelines conducting data analysis to improve MTA input ensuring data quality for attribution models and optimizing data systems for efficient MTA reporting    A day in the life  To be successful in this role you should possess strong technical skills in data engineering with proficiency in AWS technologies and experience working with largescale data sets Excellent communication and collaboration abilities are essential as you will work closely with various stakeholders to understand their requirements and deliver impactful solutions You should be a selfmotivated individual with a passion for problemsolving and a drive to stay uptodate with the latest data engineering trends and best practices    About the team    ABOUT AWS  Diverse Experiences  Amazon values diverse experiences Even if you do not meet all of the preferred qualifications and skills listed in the job description we encourage candidates to apply If your career is just starting hasn’t followed a traditional path or includes alternative experiences don’t let it stop you from applying    Why AWS  Amazon Web Services AWS is the world’s most comprehensive and broadly adopted cloud platform We pioneered cloud computing and never stopped innovating — that’s why customers from the most successful startups to Global 500 companies trust our robust suite of products and services to power their businesses  WorkLife Balance  We value worklife harmony Achieving success at work should never come at the expense of sacrifices at home which is why we strive for flexibility as part of our working culture When we feel supported in the workplace and at home there’s nothing we can’t achieve in the cloud  Inclusive Team Culture  Here at AWS it’s in our nature to learn and be curious Our employeeled affinity groups foster a culture of inclusion that empower us to be proud of our differences Ongoing events and learning experiences including our Conversations on Race and Ethnicity CORE and AmazeCon gender diversity conferences inspire us to never stop embracing our uniqueness  Mentorship and Career Growth  We’re continuously raising our performance bar as we strive to become Earth’s Best Employer That’s why you’ll find endless knowledgesharing mentorship and other careeradvancing resources here to help you develop into a betterrounded professional    We are open to hiring candidates to work out of one of the following locations    Austin TX USA  Irvine CA USA  Seattle WA USA     Experience with AWS technologies like Redshift S3 AWS Glue EMR Kinesis FireHose Lambda and IAM roles and permissions Experience with big data technologies such as Hadoop Hive Spark EMR  Amazon is committed to a diverse and inclusive workplace Amazon is an equal opportunity employer and does not discriminate on the basis of race national origin gender gender identity sexual orientation protected veteran status disability age or other legally protected status For individuals with disabilities who would like to request an accommodation please visit httpswwwamazonjobsendisabilityus    Our compensation reflects the cost of labor across several US geographic markets The base pay for this position ranges from 105700year in our lowest geographic market up to 205600year in our highest geographic market Pay is based on a number of factors including market location and may vary depending on jobrelated knowledge skills and experience Amazon is a total compensation company Dependent on the position offered equity signon payments and other forms of compensation may be provided as part of a total compensation package in addition to a full range of medical financial andor other benefits For more information please visit httpswwwaboutamazoncomworkplaceemployeebenefits This position will remain posted until filled Applicants should apply via our internal or external career site ,\n",
       " Profile insightsFind out how your skills align with the job descriptionCertificationsDo you have a valid CCNP certificationYesNoSkillsDo you have experience in VoIPYesNoEducationDo you have a Bachelors degreeYesNo Job detailsHere’s how the job details align with your profileJob typeFulltime Location901 W Trade St Charlotte NC 28202 Full job description Job Description   About us   At Bank of America we are guided by a common purpose to help make financial lives better through the power of every connection Responsible Growth is how we run our company and how we deliver for our clients teammates communities and shareholders every day   One of the keys to driving Responsible Growth is being a great place to work for our teammates around the world We’re devoted to being a diverse and inclusive workplace for everyone We hire individuals with a broad range of backgrounds and experiences and invest heavily in our teammates and their families by offering competitive benefits to support their physical emotional and financial wellbeing   Bank of America believes both in the importance of working together and offering flexibility to our employees We use a multifaceted approach for flexibility depending on the various roles in our organization   Working at Bank of America will give you a great career with opportunities to learn grow and make an impact along with the power to make a difference Join us   Job Description  This job is responsible for performing commoditized activities which may include monitoring managing events servicing requests and engineering Key responsibilities may include assisting with network systems applications access requests production support or security engineering and consistently performing activities independently   Overview   The role of the Data Network Implementation Engineer is to provide technical implementation services to support the evolution and ongoing support of the IP Network in response to projects all types upgrades service and feature enhancements and for remediationbreakfix services The work is always in alignment to the current and approved architectural roadmaps technology standards and templates governance and change management policies set forth by the firm While the role primarily has an implementation and validation engineering focus a strong understanding of design engineering concepts is required   The technology areas of focus for the role includes Data Center and end user networks public and private Network Transport and Optical systems and emerging technologies SwitchedEthernet LTE etc CorporateBranch and Building Networking including Wireless Knowledge in related technology areas such as Voice and Voice over IP VoIP solutions is a plus Network Appliance Video and Unified Communications knowledge are important   This role also provides networking technical support to Network Operations and partners with the Design and Architecture Engineering teams An understanding of the role of Operations troubleshooting practices and the use of proactive and reactive tools is important to the Data Network Implementation Engineer’s role They must be mindful of how their role impacts the firm’s business and reputation Concepts such as driving value always delivering quality and understanding how their work impacts service resiliency CR are important Understanding risk and having strong decisionmaking skills on assessing risk to the production network is essential to the success of the Network Implementation Engineer   This role is part of a global solutions and service delivery organization This position will interface with several collaborators internal and external customerssuppliersproviders architecture product engineering product management finance and business management and operations teams At times they may interface with various levels of senior management Strong written verbal and presentation skills are a must The candidate must be able to work on their own and successfully in team settings in various sizes and locations Adherence and use of standards product sets templates systems and artifacts are important to the success of the engineer the department and the firm at large   Responsibilities   Monitors all installed systems and infrastructure to ensure the highest levels of availability within a technical domain  Opens triage bridge lines and updates bridge boards engaging teams as required  Maintains solutions that align to security redundancy and archiving of blueprints and strategies  Owns event management and fulfilment items such as password resets and reporting requests  Supports client onboarding by familiarizing new clients with technology products and services as quickly and easily as possible  Writes and maintains documentation such as scripts and instructions and supports change activities  Candidate must understand how designs turn into Implementation Implementations that are based upon standards and predefined strategies  Works with Design and Architecture Engineering in a “knowledge sharing” capacity in support of the team’s adoption and successful delivery of technology new systems or process changes  Plays a strong role in project delivery lifecycle management Partners with the design Engineering team to create detailed implementation plans for all design test and Accept criteria BackOut and validation plans and procedures Adheres to project closeout practices such as asset tracking inventories chargeback documentation and the related systems tools and process updates  The Implementation Engineer stands between the project manager design engineer and operations They support initiatives as they transition between design implementation and operations They are active in all phases as an SME to support solve program and facilitates decision making The goal is to help the orderly and timely execution of projects and initiatives in an optimal strategic and low risk way  Role performs QA function prior to every implementation project Reviews a design and understands how it is based upon standards and how it matches to the “commission” details installation turnup Any questions must be review with the Design Engineer  Technical areas of focus include but are not limited to Core WANMAN Technologies – MPLSE MetroE Leased Line Broadband Direct Internet Access Dark Fiber DWDM Carrier Circuits Tunneling protocols – SSLTLS IPDESC GRE DMVPN MACSEC Routing Switching Firewalls Load Balancers LAN TCPIP DNS UDP Latency NAC QoS CAC EIGRP BGP ISIS OSPF Multicast NHRP ATM PPP IPv4 IPv6 MPLS ACL VNP Building WirelessWiFi solutions 802xx and carrier “inbuilding wireless services DAS etc Knowledge of Cable Systems a plus    Required Qualifications   2 years’ experience required in Data Networkingrelated disciplines in design operate and implementation services  Design Implementation Support SDWAN is required preferred if on Palo Alto Cloudgenix  Design Implementation Support SDACCESS is required preferred if on Cisco DNA Center  Design Implementation Support Wireless is required preferred if on HPE Aruba  Experience with CISCO NSO and general experience in Network Automation tools and processes  Strong skills in Scripting required Python Ansible Perl PowerShell  Strong Automation Skills – Expect Rancid RESTSOAP  Software development experience should think like a software developer  Strong knowledge of Network Security  Must adhere to global network design authority processes and procedures  Must demonstrate good computer skills and the use of various applications such as MS Office MS Visio  Ability to recognize opportunities for automation and process improvements  Ability to assemble professional documents and artifacts  Extensive knowledge and experience using both reactively and productive advanced tooling includes but is not limited to Snifferwire Shark Prognosis Scripting SolarWinds HP NAOpsWareOpenView etc  Application experience with an innovation “mindset” and how it impacts how engineering work gets done  VoiceVoIPUC and Video knowledge understanding of VoIPUC systems ie Cisco CUCM AVAYA Communications Manager Microsoft LYNC and Skype for Business etc    Desired Qualifications   Leadership Selfstarter selfdirected and shows initiative  Coding and application design experience  Wireless LAN Aruba  Crisis Management experience  Experience working in an Agile environment  Focused on execution delivery and commitment to dates  Can tie strategy and actions to business impact and results  Demonstrates ownership Is accountable and can hold others accountable professionally  Bachelor’s degree in engineering computer science related field and or technical training  Industry Certifications in CCDP CCNA CCNP and CCIE      Associated certifications JUNOSJNCP Cisco CCVP and CCIPVoice     Skills   Analytical Thinking  Collaboration  Influence  Production Support  Result Orientation  Adaptability  Business Acumen  Innovative Thinking  Solution Delivery Process  Solution Design  Automation  DevOps Practices  Project Management  Risk Management  Stakeholder Management    Shift 1st shift United States of America    Hours Per Week 40  ,\n",
       " Profile insightsFind out how your skills align with the job descriptionSkillsDo you have experience in StatisticsYesNoEducationDo you have a Masters degreeYesNo Job detailsHere’s how the job details align with your profilePay150000  300000 a yearJob typeParttimeFulltimeShift and scheduleMonday to Friday LocationRemote BenefitsPulled from the full job descriptionFlexible schedule Full job descriptionFounding Teams is a new AI Tech Incubator and talent platform We are supporting the next generation of AI startup founders with the resources they need including engineering product sales marketing and operations staff to create and launch their products The ideal candidate will have a passion for nextgeneration AI tech startups and working with great global startup talent Job Title  Lead Engineer Company Stealth AI Startup Remote 1620 hours per week Flexible hours  Yes Job Description  Build prototype AI ML models and tools to help us understand our customers and create personalised customer recommendations across multiple use cases and productize solutions to scale  Deeply understand customers their behaviours and pain points and develop a diversity of AI models addressing an array of customers’ needs  Translate business needs into AIML problems and create innovative solutions to advance our business goals  Determine the types and amount of data needed and work with data engineer to identify data sources and ingest into data lake  Structure standardise and annotate data into processable formats for ML enrich data with necessary attributes to allow sophisticated personalization  Help shape the way our data science team does work  researching and making key decisions about what we build how we build it and which tools are best for solving our problems  Work alongside software and data engineers to implement data processing and visualisation systems that make data readily available and simplify how insights are communicated  Evaluate the performance of AI models and make tradeoffs against quality metrics Investigate and resolve performance issues in a timely manner Requirements  Bachelor’s or Master’s degree in Mathematics ML statistics Computer Science SoftwareData Engineering or a related field  Strong mathematical background in probability statistics and optimization algorithms  Experience in building machine learning models and deploying them to production to make real decisions then measuring the impact of these decisions  Deep understanding of and have applied various machine learning techniques for solving realworld problems  Expertise with advanced programming skills in Python Java or any of the major languages to build robust algorithms  Proficient with SQL and can work “full stack” to integrate solutions with our data ecosystem  Confident in taking ownership of projects from start to finish and enjoy the process of turning nebulous ideas into reality  Excellent communication skills  A selfstarter who drives projects and builds strong relationships with stakeholders and teams to tackle large crossfunctional efforts  Thrive with minimal guidance and process  Worked in both small teamsincubators and large corporations Job Types Fulltime Parttime Salary 15000000  30000000 per year Schedule  Monday to Friday  Work Location Remote ,\n",
       " Profile insightsFind out how your skills align with the job descriptionSkillsDo you have experience in System designYesNoEducationDo you have a Bachelors degreeYesNo LocationArlington VA 22201 BenefitsPulled from the full job descriptionParental leaveTuition reimbursement Full job description Company Description  Publicis Sapient is a digital transformation partner helping established organizations get to their future digitallyenabled state both in the way they work and the way they serve their customers We help unlock value through a startup mindset and modern methods fusing strategy consulting and customer experience with agile engineering and problemsolving creativity United by our core values and our purpose of helping people thrive in the brave pursuit of next our 20000 people in 53 offices around the world combine experience across truly value Job Description  Publicis Sapient is looking for a Senior Associate Data Engineer Azure to be part of our team of topnotch technologists You will lead and deliver technical solutions for largescale digital transformation projects Working with the latest data technologies in the industry you will be instrumental in helping our clients evolve for a more digital future  Your Impact   Combine your technical expertise and problemsolving passion to work closely with clients turning complex ideas into endtoend solutions that transform our clients business  Translate clients requirements to system design and develop a solution that delivers business value  Lead designed develop and deliver largescale data systems data processing and data transformation projects  Automate data platform operations and manage the postproduction system and processes  Conduct technical feasibility assessments and provide project estimates for the design and development of the solution  Mentor help and grow junior team members   Set Yourself Apart With   Developer certifications in Azure cloud services  Understanding of development and project methodologies  Willingness to travel    Qualifications  Your Technical Skills  Experience   Demonstrable experience in data platforms involving implementation of end to end data pipelines  Handson experience with at least one of the leading public cloud data platforms Azure AWS or Google Cloud  Implementation experience with columnoriented database technologies ie Big Query Redshift Vertica NoSQL database technologies ie DynamoDB BigTable Cosmos DB etc and traditional database systems ie SQL Server Oracle MySQL  Experience in implementing data pipelines for both streaming and batch integrations using toolsframeworks like Azure Data Factory Glue ETL Lambda Spark Spark Streaming etc  Ability to handle module or track level responsibilities and contributing to tasks “handson”  Experience in data modeling warehouse design and factdimension implementations  Experience working with code repositories and continuous integration  Data modeling querying and optimization for relational NoSQL timeseries and graph databases and data warehouses and data lakes  Data processing programming using SQL DBT Python and similar tools  Logical programming in Python Spark PySpark Java Javascript andor Scala  Data ingest validation and enrichment pipeline design and implementation  Cloudnative data platform design with a focus on streaming and eventdriven architectures  Test programming using automated testing frameworks data validation and quality frameworks and data lineage frameworks  Metadata definition and management via data catalogs service catalogs and stewardship tools such as OpenMetadata DataHub Alation AWS Glue Catalog Google Data Catalog and similar  Code review and mentorship  Bachelor’s degree in Computer Science Engineering or related field    Additional Information  Pay Range103000 154000  The range shown represents a grouping of relevant ranges currently in use at Publicis Sapient Actual range for this position may differ depending on location and the specific skillset required for the work itself  Benefits of Working Here   Flexible vacation policy time is not limited allocated or accrued  16 paid holidays throughout the year  Generous parental leave and new parent transition program  Tuition reimbursement  Corporate gift matching program   As part of our dedication to an inclusive and diverse workforce Publicis Sapient is committed to Equal Employment Opportunity without regard for race color national origin ethnicity gender protected veteran status disability sexual orientation gender identity or religion We are also committed to providing reasonable accommodations for qualified individuals with disabilities and disabled veterans in our job application procedures If you need assistance or an accommodation due to a disability you may contact us at hiringpublicissapientcom or you may call us at 16176210200  ,\n",
       " Profile insightsFind out how your skills align with the job descriptionSkillsDo you have experience in SnowflakeYesNo Job detailsHere’s how the job details align with your profileJob typeFulltime LocationHouston TX 77056 Full job description SUMMARY  The Data Quality Engineer is a critical role within our Data Governance team you will work closely with functional Subject Matter Experts SMEs and report to the Manager of Data Stewards You will implement data quality capabilities and processes to mature the data quality practice at Westlake The ideal candidate will have a proven track record of implementing a firstgeneration data quality approach across master data domains using both third party and core application tool stack You will be expected to lead conversations on how to improve the data lifecycle for Master Data Objects as well as facilitate the resolution of data quality issues through a Data Stewardship Council model You will be viewed as the go to for the organization on data quality best practices This role requires a high level of technical expertise great attention to detail and strong communication skills to work together with all global business stakeholders   DUTIES AND RESPONSIBILITIES  May include but are not limited to the following   Create a Data Quality Playbook to standardize the roles  responsibilities of data stakeholders for executing source system remediation to drive data quality improvements  Collaborates with Business Leads IT and IS to ensure effective data management throughout the organization  Partner with Data Stewardship Manager and business SME’s to identify and iterate metrics to measure data quality and roll up to Executive Business Leaders  Focus on six areas of master data domains Finance Product Item Customer Account and Vendor  Build cleansing standardization enrichment and validation approaches for both functional and domainspecific data quality dimensions on master data  Complete analysis on adherence to the defined schema data volume data anomalies expected distribution of datapoints in a dataset  Monitor data quality metrics and perform root cause analysis of data quality issues that lead to data downtime and take appropriate steps to address these issues with stakeholders    EDUCATION EXPERIENCE AND QUALIFICATIONS   Degree in Computer Science Statistics Business Administration Computer Information Data Science or related area  8 years of related and progressive experience in Data Quality Management Business Intelligence BI Data Analytics and related fields  Thorough knowledge of data governance framework including data warehouse metadata management data quality reference datamaster data data quality and data modeling  Experience in managing master data domains customer supplier item finance product privacy etc and their integration in enterprise systems ie SAP SFDC JDE Snowflake Oracle etc  Excellent oral and written communication skills including the ability to effectively present technical topics to individuals and groups with potentially varied levels of technical sophistication  Proficiency programming and leveraging data quality tools ie SAP Information Steward BODS USPS Dunn and Bradstreet to support enterprise initiatives  Proficiency data profiling data mapping and with data integration to establish data quality checks and resolving data quality issues ie inconsistencies inaccuracies incompleteness in data products etc  Strong analytical skills to identify patterns trends in data and complete rootcause analysis to resolve data quality issues  Proficiency in programming languages ie SQL Python to help write and automate common functional DQ checks  Excellent communication skills are required to collaborate with stakeholders such as data analysts and data scientists  A good understanding of data governance concepts such as data ownership data privacy and data security is required to ensure compliance with regulations and standards  A mindset of continuous improvement    PHYSICAL DEMANDS  While performing the duties of this job the employee is frequently required to sit stand walk use hands to touch handle or feel reach with hands and arms and talk or hear The employee is occasionally required to stoop kneel or crouch The employee must regularly lift andor move up to 5 pounds frequently lift andor move up to 10 pounds and occasionally lift andor move up to 15 pounds Specific vision abilities required by this job include close vision distance vision color vision peripheral vision depth perception and ability to adjust focus Significant digital dexterity eg using computer keyboard is required Use of oral communication to perform work is required   WORK ENVIRONMENT  The noise level in the work environment is usually moderate as normally based in an open office concept Some of the work may be required in the operating units which can require usage of required PPE including safety glasses hearing protection etc May also result in exposure to outside elements and may require usage of stairs and elevators   ,\n",
       " Profile insightsFind out how your skills align with the job descriptionLicensesDo you have a valid TSSCI with Polygraph licenseYesNoCertificationsDo you have a valid AWS Certification certificationYesNoSkillsDo you have experience in Web servicesYesNoEducationDo you have a Masters degreeYesNo Job detailsHere’s how the job details align with your profileJob typeFulltime LocationAnnapolis Junction MD 20701 BenefitsPulled from the full job description401k matchingHealth insuranceHealth savings accountPaid time offPaid training Full job description  What you will be doing  The Software Engineer shall be responsible for collaborating with system and software engineers to design and develop custom Kubernetes operators to manage the deployment of various SQL databases in support of the Database as a Service DBaaS mission solution for the CASA Compute Environment  What do you need   Experience using the Linux CLI to perform file system operations and package management  Experience writing BashPython scripts to automate administrative tasks and workflows  Experience developing with multiple programming languages such as Java Python and Go in a Linux environment  Experience with containerization technologies such as Docker  Experience with SQL technologies such as MySQL MariaDB and PostgreSQL  Experience with Kubernetes operators to automate the management of complex applications throughout their lifecycle  Experience with creating Helm Charts for Kubernetes  Experience with CICD concepts principles methodologies and tools such as GitLab  Experience with Git Version Control System       Desired Skills    Familiar with container orchestration technologies such as Kubernetes  Experience with the Atlassian Tool Suite eg JIRA Confluence    Clearance Active TSSCI with an appropriate polygraph is required to be considered for this role   LCAT Description The Software Engineer designs develops tests deploys documents maintains and enhances complex and diverse software systems based upon documented requirements These systems might include but are not limited to processing intensive analytics novel algorithm development manipulation of extremely large data sets realtime systems business management information systems and systems which incorporate data repositories data transport services and application and systems development and monitoring Works individually or as part of a team Reviews and tests software components for adherence to the design requirements and documents test results Resolves software problem reports Utilizes software development and software design methodologies appropriate to the development environment Provides specific input to the software components of system design to include hardwaresoftware tradeoffs software reuse use of Open Source Software OSS andor Commercial OffTheShelf COTS Government OffTheShelf GOTS software in place of new development and requirements analysis and synthesis from system level to individual software components Experience developing in UNIX Ability to perform shell scripting Working knowledge of Configuration Management CM tools and Web Services implementation  The Level 2 Software Engineer SWE shall possess the following capabilities   Analyze user requirements to derive software design and performance requirements  Debug existing software and correct defects  Design and code new software or modify existing software to add new features  Write or review software and system documentation  Integrate existing software into new or modified systems or operating environments  Develop simple data queries for existing or proposed databases or data repositories  Software development using languages such as C C Python Ruby Perl JavaScript etc  Has experience with agile development processes  Has experience with source code control systems such as Git  Serve as team lead at the level appropriate to the software development process being used on any particular project  Design and development of relational and nonrelational database applications  Use of orchestration frameworks such as Spring and Kafka  Familiarization with queue management systems  Develop or implement algorithms to meet or exceed system performance and functional standards  Develop and execute test procedures for software components  Develop software solutions by analyzing system performance standards and conferring with users or system engineers analyzing systems flow data usage and work processes and investigating problem areas  Modify existing software to adapt to new hardware or to improve its performance  Design develop and modify software systems using scientific analysis and mathematical models to predict and measure outcomes and consequences of design decisions  Java development using the Eclipse IDE Integrated Development Environment  Development of Java 2 Enterprise Edition J2EE applications  Experience using collaboration and software development tools ie Atlassian  Software development using continuous integration practices  Experience with container technologies ie Docker  Unix shell scripting  Development of event driven or data driven analytics  Development of cloudbased solutions and technologies  Design or implement complex algorithms requiring adherence to strict timing system resource or interface constraints Perform quality control on team products  Recommend and implement suggestions for improving documentation and software development process standards  Oversee one or more software development teams and ensure the work is completed in accordance with the constraints of the software development process being used on any particular project  Confer with system engineers and hardware engineers to derive software requirements and to obtain information on project limitations and capabilities performance requirements and interfaces  Coordinate software installation on a system and monitor performance to ensure operational specifications are met    SWE2 Qualifications Masters degree in Computer Science or related discipline from an accredited college or university plus three 3 years of experience as a SWE in programs and contracts of similar scope type and complexity  OR  Bachelors degree in Computer Science or related discipline from an accredited college or university plus five 5 years of experience as a SWE in programs and contracts of similar scope type and complexity  OR  Seven 7 years of experience as a SWE in programs and contracts of similar scope type and complexity   Clearance Active TSSCI with an appropriate polygraph is required to be considered for this role   Who are we Praxis Engineering was founded in 2002 and is headquartered in Annapolis Junction MD  with growing offices in Chantilly VA and Aberdeen MD  Praxis Engineering is a consulting product and solutions firm dedicated to the practical application of software and system engineering technologies to solve complex problems  With over 300 employees supporting more than 50 contracts Praxis brings together world class engineers with proven engineering best practices domain expertise commercial technologies and proven agile management approaches to create high value solutions aimed at helping our customers meet their most critical business and mission objectives  Praxis Engineering is a wholly owned subsidiary of General Dynamics IT    Why Praxis  We are focused on continual learning and evolution We don’t do things because “that’s the way we’ve always done things” we listen to our employees and adapt to the changing marketplace We look at the big picture and encourage our engineers to get training and certifications in emerging technologies that will help shape our customer’s mission Weve been profitable year after year Were always on the lookout for great engineers to join the team and we recognize that our employees are the heart and soul of what we do We focus on recruiting talented people treating them right and then allowing them to do what they do best No red tape No micromanagement Smart people want to work with smart people and we love people who are passionate about what they do and finding ways to do it better   And then there is the   Benefits   Attractive total compensation package to include competitive salary and medical benefits with an option for FREE employee HSA medical plan   Office perks such as free soft drinks and snacks both healthy and notsohealthy  Praxis swag annual gift certificate to purchase top brand Praxis apparel  401k contributionmatch combination of profit sharecontribution 35 and employer match up to 45 for a total of 8  Annual bonus plan  4 weeks Paid Time Off  10 holidays  comp time eligibility 30 days of leave to start       We reward longevity On your 5th work anniversary – you will receive an additional week of PTO to 5 weeks of PTO Making it 35 days of leave altogether  On your 10th work anniversary – you will receive an additional week of PTO to 6 weeks of PTO Making it 40 days of leave altogether  At any time your unused PTO can be traded in for     Carryover a max of 380hours of leave from year to year You can choose to have a sabbatical one year or trade in your unused PTO for something nice   Training is a priority Take advantage of our endless inhouse training opportunities  or seek out vendor offered paid training opportunities like conferences certification courses and seminars      Conferences recently attended by Praxis employees AWS Summit IoT World Black Hat and DefCon  Training  Certifications Splunk AWS Big DataCloudera VMWare Scrum Masterthe list of certifications goes on and on  Praxis University Cyber Research Data Analytics IoT AWS and RedHat course offerings and handson training   We truly believe the right worklife balance can exist and its here at Praxis Our work is extremely important but your job is just a part of who you are When you enjoy your life outside of our walls youre at your best the next time you walk through our doors We do all we can to assure that happens every day   Praxis Engineering provides equal employment opportunities EEO to all employees and applicants for employment without regard to race color religion sex sexual orientation gender identity national origin disability or veteran status or any other protected class   ,\n",
       " Profile insightsFind out how your skills align with the job descriptionLicensesDo you have a valid TSSCI with Polygraph licenseYesNoSkillsDo you have experience in Systems engineeringYesNoEducationDo you have a Bachelors degreeYesNo Job detailsHere’s how the job details align with your profileJob typeFulltime LocationBethesda MD BenefitsPulled from the full job description401k matchingInternal mobility programPaid time off Full job description    Type of Requisition   Regular       Clearance Level Must Currently Possess   Top Secret SCI  Polygraph       Clearance Level Must Be Able to Obtain   Top Secret SCI  Polygraph       Suitability        Public TrustOther Required   None       Job Family   Systems Engineering       Job Qualifications       Skills   Data Transformation ETL Geospatial Software      Certifications       Experience   8  years of related experience      US Citizenship Required   Yes       Job Description       Seize your opportunity to make a personal impact as an ETL Developer supporting customer activities GDIT is your place to make meaningful contributions to challenging projects and grow a rewarding career        At GDIT people are our differentiator As an ETL Developer you will help ensure today is safe and tomorrow is smarter Our work depends on a an ETL Developer joining our highly skilled team to be a premier provider of cyber security services to the customer We provide consummate cyber security risk management “as a service” platform across multiple fabrics and centers We have responsibility to ensure operational IT capabilities provide the client with necessary timeliness accuracy and security of information demanded from all our highly professional roles Be the change lead our change – join us        HOW ETL DEVELOPER WILL MAKE AN IMPACT     Perform data processing and normalization extracttransformload on a number of Customerdirect data sources  Develop templates or scripts to automate everyday ETL operation functions  Identify new tools and processes to improve the ETL processing  Developing testing and monitoring connections via REST API to interfacing systems such as data feeds from external organizations  Become an expert on an AWS data workflow that includes Lambda S3 and other such technologies  Development of technical documentation and briefing materials to support program status reviews control gates and other presentations as directed by program management  Development will take place in an iterative fashion using scrum techniques with inputs from multiple stakeholders with adherence to all reporting requirements  Requires exceptional flexibility and technical skills  Work will be done in a dynamic environment with multiple stakeholders and changing requirements  Meeting with stakeholders analyzing requirements user stories and related artifacts to determine technical specifications for the system environments  Coordinating with technical teams responsible for the cloud hosting infrastructures in order to establish and maintain the environments used by the program for the development test and deployment of the demonstration capability and the final production system  Collaborate with team members to build and maintain positive productive team relationships  Coordinate andor participate in system integration andor user acceptance testing  Write unit and integration test  Monitor applications in production  Participate in code reviews       WHAT YOU’LL NEED TO SUCCEED     Education Bachelor’s Degree Computer Engineering Computer Science Electrical Engineering Information Systems Information Technology Cybersecurity or a closely related discipline  Required Experience 8 yrs  Technical skills  Knowledge of standard ETL tools such as Pentaho AWS Glue etc  Understanding of JAVA Microservices  Understanding of REST API  Understanding of AWS data workflow that includes Lambda S3 and other such technologies  Security Clearance Level TSSCI with active polygraph  Location Bethesda MD  On Customer Site       GDIT IS YOUR PLACE     401K with company match  Comprehensive health and wellness packages  Internal mobility team dedicated to helping you own your career  Professional growth opportunities including paid education and certifications  Cuttingedge technology you can learn from  Rest and recharge with paid vacation and holidays       OpportunityOwned       GDITCareers       WeAreGDIT       JET       SWDevpolyVA        Scheduled Weekly Hours   40       Travel Required   Less than 10       Telecommuting Options   Onsite       Work Location   USA MD Bethesda       Additional Work Locations    We are GDIT A global technology and professional services company that delivers consulting technology and mission services to every major agency across the US government defense and intelligence community Our 30000 experts extract the power of technology to create immediate value and deliver solutions at the edge of innovation We operate across 30 countries worldwide offering leading capabilities in digital modernization AIML Cloud Cyber and application development Together with our clients we strive to create a safer smarter world by harnessing the power of deep expertise and advanced technology   We connect people with the most impactful client missions creating an unparalleled work experience that allows them to see their impact every day We create opportunities for our people to lead and learn simultaneously From securing our nation’s most sensitive systems to enabling digital transformation and cloud adoption our people are the ones who make change real   GDIT is an Equal OpportunityAffirmative Action employer All qualified applicants will receive consideration for employment without regard to race color religion sex sexual orientation gender identity national origin disability or veteran status or any other protected class  ,\n",
       " Profile insightsFind out how your skills align with the job descriptionSkillsDo you have experience in Wine knowledgeYesNoEducationDo you have a Bachelors degreeYesNo LocationAtlanta GA 30339 BenefitsPulled from the full job description401k matchingCaregiver leaveDental insuranceDisability insuranceHappy hourHealth insuranceLife insuranceShow morechevron down Full job description Republic National Distributing Company RNDC is a familyowned business with roots extending before Prohibition that has evolved into one of the nation’s largest wine and spirits wholesalers Our success is grounded in our core values of Family Service Accountability Honesty and Professionalism We offer a vibrant inclusive culture and workplace experience for individuals who want a career that makes them feel accomplished and engaged RNDC values the health and wellbeing of our associates inside and outside the office offering dynamic health and wellness benefits that supply exceptional care and value RNDC is geared toward growing our footprint and our people Join our team of energetic professionals who believe in many happy hours and are experts in our craft     Summary    The Senior Data Engineer manages and organises RNDCs enterprise data They will translate requirements and designs into functional data pipelines while ensuring the continued quality and completeness of the information Senior Data Engineers will combine raw information from different sources to create consistent and machinereadable datasets that are easy to analyze and support company initiatives They will support other Data Engineers and Data Analysts on data initiatives and will ensure optimal data delivery architecture is consistent throughout ongoing projects They will also implement methods to improve data reliability and quality improve data visibility and reduce effort through automation      In this role you will     Contribute on a team of data engineers through design demand delivery code reviews release management implementation presentations and meetings  Mentor fellow data engineers and contribute to ongoing process improvements for the team  Evaluate business needs and objectives and align architecturedesigns with business requirements  Build the data pipelines required for the optimal extraction transformation integration and loading of raw data from a wide variety of data sources  Assemble large complex data sets and model our data in a way that meets functional  nonfunctional business requirements  Create data tools for analytics team members that assist them in generating innovative industry insights that provide our business a competitive advantage  Implement data tagging mechanisms and metadata management so data is accurately classified and visible to the organization  Build processes to help identify and improve data quality consistency and effectiveness  Ensure our data is managed in a way that it conforms to all information privacy and protection policies  Use agile software development processes to iteratively make improvements to our data management systems        What you bring to RNDC    BachelorsTech School degree in Computer Science Information Systems Engineering or equivalent andor commensurate years of realworld experience in software engineering 4 years of relevant experience in data management 3 years in data engineering with detailed knowledge of data warehouse technical architectures infrastructure components ETL ELT Experience with performance analysis and optimization Experience in data acquisition transformation and storage design using design principles patterns and best practices      Whats in it for you     401k with company matching  Medical dental and vision benefits  Generous paid time off program – work your way up to 5 weeks of PTO a year with the ability to carryover unused PTO  Paid volunteer time  Paid parental leave  Paid caregiver leave  Fertility benefits  Paid training  Company paid life insurance shortterm disability and companypaid holidays  Associate resource groups and diversity equity and inclusion programs available for all associates   Participation in these programs are subject to applicable wait periods and all plan and program terms and eligibility  COVID19 considerations      We follow CDC Guidelines and have a fun and safe environment for our teams         Bonus if you bring     Data engineering certification is a plus  Previous experience in the Wine and Spirits industry      Republic National Distributing Company and National Distributing Company are Equal OpportunityAffirmative Action employers It is our policy not to discriminate against any Employee or Applicant All qualified applicants will receive consideration for employment without regard to race religion color national origin sex age status as a protected veteran among other things or status as a qualified individual with disability This policy of nondiscrimination in employment includes but is not limited to recruitment hiring placement promotion transfer employment advertising or solicitations compensation layoff or termination of employment  RNDC is committed to providing reasonable accommodation to people with disabilities throughout the job application and interview process to the point of undue hardship  ,\n",
       " Profile insightsFind out how your skills align with the job descriptionSkillsDo you have experience in OracleYesNo Job detailsHere’s how the job details align with your profileJob typeFulltime LocationUnited States Full job description In response to increased concurrent projects for the design and delivery of our data centers Oracle is recruiting a Senior Data Center Design Electrical Engineer The role is a senior multidisciplinary data center design lead with an electrical background charged with the direct interface between Oracle and our data center partners in the Electrical design field including but not limited to power generation storage and delivery grounding lightening protection fire alarm etc systems for both new site builds and expansions or refurbishments of existing facilities With extensive experience designing and delivering mission critical facilities and professional qualifications in electrical engineering the role is responsible for all design decisions related to assigned data center projects site selection new construction phased expansion retrofits and upgrades and acquisition conversions  Career Level  IC5                                             1 Leads and manages a project or other design and engineering initiatives Provides guidance and engineering leadership in ensuring project or other design and engineering initiatives are meeting or exceeding company expectations                        2Expert operating knowledge of engineering systems to include advanced diagnostics and repairs Ability to apply knowledge of Oracle processes and procedures and industry standards to resolve nonroutine issues Utilizes safe working practices at an EXPERT level eg can apply procedure for lockouttag out can explain MSDS etc Evaluates and assures the safe working practices of others Interacts with other engineering disciplines Works with the colocation providers engineering teams to ensure electrical systems are adequately designed specified and installed to deliver robust operation for Oracle                        3 Contributes to identifying and developing training programs for newer members of the team as it grows Acquires knowledge by expanding experience with systems vendor training participation in industry groups or meetings and shadowing others Is SME with many systems and trains others inside and outside of the group                        4 Provides expert input for effective contract administration including generation and review of contracts change orders cost forecasts and other pertinent documents and documentation                        5 Contributes to mentoring junior team members Directs all internal and external project team members delivering data centers or partdata centers for Oracle Expert level communication to include cross functional SOP development and relevant technical writing Interactions are primarily to exchange information between departments within the organization                        6 Contributes to creating and maintaining best in class policies and procedures Participates in review of policy and procedure documents Develops policy documents with the input of others Assures adherence to developed standards and policy through review of documentation participation in commissioning activities design summits and datacenter commissioning or reviews                        7 Consistently solves complex crossfunctional issues requiring independent action and a high degree of initiative to resolve Makes recommendations for system level enhancements to eliminate potential problems Tests suitability of components or action plans for deployments                        8 Has an expert level system knowledge Is a subject matter expert to others in and outside of the group Extensive knowledge of multiple facets of the relevant engineering discipline Develops and executes projects Leads internal andor external engineering or construction related seminarsconferences1 Leads and manages a project or other design and engineering initiatives Provides guidance and engineering leadership in ensuring project or other design and engineering initiatives are meeting or exceeding company expectations                        2Expert operating knowledge of engineering systems to include advanced diagnostics and repairs Ability to apply knowledge of Oracle processes and procedures and industry standards to resolve nonroutine issues Utilizes safe working practices at an EXPERT level eg can apply procedure for lockouttag out can explain MSDS etc Evaluates and assures the safe working practices of others Interacts with other engineering disciplines Works with the colocation providers engineering teams to ensure electrical systems are adequately designed specified and installed to deliver robust operation for Oracle                        3 Contributes to identifying and developing training programs for newer members of the team as it grows Acquires knowledge by expanding experience with systems vendor training participation in industry groups or meetings and shadowing others Is SME with many systems and trains others inside and outside of the group                        4 Provides expert input for effective contract administration including generation and review of contracts change orders cost forecasts and other pertinent documents and documentation                        5 Contributes to mentoring junior team members Directs all internal and external project team members delivering data centers or partdata centers for Oracle Expert level communication to include cross functional SOP development and relevant technical writing Interactions are primarily to exchange information between departments within the organization                        6 Contributes to creating and maintaining best in class policies and procedures Participates in review of policy and procedure documents Develops policy documents with the input of others Assures adherence to developed standards and policy through review of documentation participation in commissioning activities design summits and datacenter commissioning or reviews                        7 Consistently solves complex crossfunctional issues requiring independent action and a high degree of initiative to resolve Makes recommendations for system level enhancements to eliminate potential problems Tests suitability of components or action plans for deployments                        8 Has an expert level system knowledge Is a subject matter expert to others in and outside of the group Extensive knowledge of multiple facets of the relevant engineering discipline Develops and executes projects Leads internal andor external engineering or construction related seminarsconferences                                           ,\n",
       " Profile insightsFind out how your skills align with the job descriptionSkillsDo you have experience in Model trainingYesNoEducationDo you have a Bachelors degreeYesNo Job detailsHere’s how the job details align with your profileJob typeFulltime LocationCollege Park MD Full job description SMX is looking for a Data Scientist If you are dedicated to fostering a positive company culture and interested in shaping and growing our communications capabilities SMX is an excellent place to grow your career This is a role that will have to report to the customers site This person will support DIA and will need to report to their facility This is a fulltime position with onsite work performed at a clients office 3 daysweek located in Washington DC or Reston VA or College Park MD with possibility for some flexibility to work remote  Essential Duties and Responsibilities    Create and write technical data design documents and participate in technical design discussions that transform operational requirements into data driven solutions Use your firm understanding of data model training and prediction in order to develop data models and analytical dashboards Formulate and complete endtoend data models that include data gathering analysis modeling and ongoing scaled deliverables and presentations Structurepreprocess datasets to find usable information and to prepare for modeling Review and collaborate on recommendations and designs with other subject matter experts Develop solutions actions items and issues and remain accountable for their completion Work in an agile environment to continuously deliver high outputs Have a high attention to detail working closely with plans operations and technical stakeholders to drive measurable results Produce highquality wellwritten technical documentation Work effectively within a deliverycentric multifunctional team Collaborate with crossfunctional stakeholders to understand their operational need Provide transparent and regular status updates in requested format Work in a fastpaced Agile environment with fluid requirements and changing priorities     Required SkillsExperience  Active TSSCI CI Poly clearance This is a fulltime position with onsite work performed 3 daysweek at a clients office located in Washington DC or Reston VA or College Park MD with possibility for some flexibility to work remote 3 years of technical experience Excellent written and verbal communication skills to both technical and nontechnical audiences for collaborating with team members and customers  Desired SkillsExperience  Bachelors degree in a technical field preferred or equivalent years of experience and certifications Knowledge of cloud servicestools   This position requires three days a week on site at customer location in Washington DC or Reston Virginia or College Park MD The rest of the week can be remote there is some flexibility     cjpost  LIonsite  LIhybrid     At SMX® we are a team of technical and domain experts dedicated to enabling your mission From priority national security initiatives for the DoD to highly assured and compliant solutions for healthcare we understand that digital transformation is key to your future success  We share your vision for the future and strive to accelerate your impact on the world We bring both cutting edge technology and an expansive view of whats possible to every engagement Our delivery model and unique approaches harness our deep technical and domain knowledge providing forwardlooking insights and practical solutions to power secure mission acceleration  SMX is committed to hiring and retaining a diverse workforce All qualified candidates will receive consideration for employment without regard to disability status protected veteran status race color age religion national origin citizenship marital status sex sexual orientation gender identity or expression pregnancy or genetic information SMX is an Equal OpportunityAffirmative Action employer including disability and veterans  Selected applicant will be subject to a background investigation   ,\n",
       " Profile insightsFind out how your skills align with the job descriptionSkillsDo you have experience in Supervising experienceYesNoEducationDo you have a Bachelors degreeYesNo Job detailsHere’s how the job details align with your profilePay90000  100000 a yearJob typeFulltime LocationArlington VA 22209 BenefitsPulled from the full job description401k401k matchingADD insuranceCell phone reimbursementDental insuranceFlexible spending accountHealth insuranceShow morechevron down Full job description      Trilogy Federal provides financial management information technology IT consulting program management services and strategic consulting to federal agencies Trilogy has an extensive history helping federal clients achieve their most ambitious business modernization and optimization goals with the ability to deliver targeted subject matter expertise and full life cycle support       Trilogy Federal is looking for a strategic and thoughtful Sr Data Analyst to consult and develop datacentered projects In keeping with this overarching aim the Sr Data Analyst will be required to outline work requirements quickly develop an understanding of our customer’s datarelated challenges provide solutions that consider the customer’s specific requirements and constraints and work with a crossfunctional team to deliver timely and tangible results You should also harness your mastery of data analysis to consult and directly participate in various aspects of these and other projects To be successful as a Sr Data Analyst you should use data to ultimately inform sound decisionmaking in support of automation efforts and efficiency The ideal candidate will also assist in the development of junior staff       Primary Responsibilities    Formulating suggesting and managing datadriven projects which are geared at furthering the businesss interests  Collating and cleaning data from various entities for later use by junior data scientists  Delegating tasks to Junior Data Scientists to realize the successful completion of projects  Monitoring the performance of Junior Data Scientists and providing them with practical guidance as needed  Selecting and employing advanced statistical procedures to obtain actionable insights  Crossvalidating models to ensure their generalizability  Producing and disseminating nontechnical reports that detail the successes and limitations of each project  Suggesting ways in which insights obtained might be used to inform business strategies  Staying informed about developments in Data Science and adjacent fields to ensure that outputs are always relevant  Assist clients on functional and data requirements to enhance reporting effectiveness  Develop Microsoft Forms to assist clients with gathering information Use analytics to evaluate and summarize responses  Provide subject matter experience for clients seeking to improve content management and versioning  Adhere to established methodologies while analyzing processes for improved performance and adaptability       Minimum Requirements    Able to obtain a Public Trust Clearance  Bachelor’s degree data science statistics computer science or similar preferred  10 years’ experience  Consultative mindset and demonstrated work experience providing solutions for clients and proactively collaborating with Stakeholders  Deep knowledge of statistics and linear algebra concepts ANOVA distributions PCA  Proficiency in R or Python  Proficiency in SQL  Familiar with machine learning principles and techniques  Demonstrable history of devising and overseeing datacentered projects  Ability to relay insights in laymans terms such that these can be used to inform business decisions  Capacity to work independently or collaboratively with a crossfunctional team       Preferred Qualifications    VA experience preferred  Advanced degree in data science statistics computer science or similar  Detailoriented with the ability to manage multiple tasksrequests  Strong written and verbal communications skills  Supervision and mentorship skills       Benefits including but not limited to    Health dental and vision plans  Optional FSA  Paid parental leave  Safe Harbor 401k with employer contributions 100 vested from day 1  Paid time off and 11 paid holidays  No cost group term lifeADD plan and optional supplemental coverage  Pet insurance  Monthly phone and internet stipend  Tuition and training reimbursement          90000  100000 a year         This range is not a guarantee of compensation or salary as Trilogy Federal conducts an individual equity review for every candidate based on experience location education industry experience and comparisons to internal pay bands In addition to salary Trilogy offers robust benefits including medicaldentalvision insurance coverage 401k match paid holidays paid time off tuition reimbursement and a very supportive worklife balance       Regarding remote positions Trilogy Federal is only able to offer virtual employment in the following states Colorado Connecticut Delaware DC Florida Illinois Indiana Maine Maryland Massachusetts New York South Carolina Texas and Virginia     Trilogy Federal is an Equal Employment Opportunity employer We do not discriminate based upon race religion color national origin gender including pregnancy childbirth or related medical conditions sexual orientation gender identity gender expression age status as a protected veteran status as an individual with a disability or other applicable legally protected characteristics    ,\n",
       " Profile insightsFind out how your skills align with the job descriptionSkillsDo you have experience in VisioYesNoEducationDo you have a Masters degreeYesNo LocationWashington DC BenefitsPulled from the full job descriptionDental insuranceDisability insuranceHealth insurancePaid time offParental leaveTuition reimbursementVision insurance Full job description    The Lead Data Scientist should have a demonstrated passion for data science and datadriven analytics to implement the National Cardiovascular Data Registry’s NCDR data science strategy The role will be responsible for contributing to the advancement of NCDR data analytics through the application of novel approaches using data science tools and techniques The role will coach junior data science team members and collaborate across groups to achieve NCDR goals   This position is based in Washington DC where we have a hybrid work environment roughly 40 of the time in the office    Major Duties and Responsibilities   Build and deploy data science products and share analytic insights using machine learning statistical modelling and NLP techniques for NCDR internal and external stakeholders    Coach and mentor the junior data scientists   Leverage Exploratory Data Analysis to analyze and gain insights from clinical registry data to provide critical results enable datadriven decisions enhance product offerings and reduce cost and complexity    Work collaboratively across groups NCDR business lines IT ACC members and other stakeholders to execute data science initiatives    Collaborate with the Data Quality Program to enhance data quality solutions and strategies    Adhere to the data science team documentation and coding best practices to facilitate collaboration and effective communication   Design and develop data visualization and dashboard solutions using standard tools such as Power BI   Integrate external data sources to discover relevant and informative trends External data sources are including but not limited to clinical claims registry and Patient Reported Outcomes PRO data   Research data science and analytic methodologies applicable to the realworld evidence RWE team   Understand NCDR platform architecture such as Common Data Model CDM and legacy star schema   Complete all mandatory privacy and security training requirements and comply with ACC privacy and security policies     Required Qualifications       Bachelor’s degree preferably in a related field   Masters with 5 years relevant experience or Bachelors with 7 years relevant experience    Proficiency in R or Python and SQL   Demonstrated experience with statistical modeling machine learning building and deploying machine models andor leveraging unstructured data    Proficiency with PowerBI or other data visualization tools Tableau ggplot plotly   Ability to communicate technical concepts and implications with nontechnical stakeholders   Proficient with Microsoft Office familiarity with Microsoft Access Visio SharePoint software and GitHub   Willingness to travel limited     Desired Qualifications     Experience with data analysis for healthrelated organizations including FDA NIH and the life science industry   Proactively identify and mitigate roadblocks and troubleshoot solutions   Familiarity with Agile life cycle methodology        About Us   At the American College of Cardiology we bring our hearts to work   We are a 500person organization dedicated and committed to our mission to transform cardiovascular care and improve heart health for the past 70 years When you join our team you become part of a passionate culture that envisions a world where innovation and knowledge optimize cardiovascular care and outcomes   Every day we are committed to supporting our more than 56000 members and their patients around the globe and in doing so ensure our staff have a positive environment of teamwork collaboration professionalism and excellence To learn more about why ACC has been recognized as one of Modern Healthcares Best Places to Work in Healthcare please visit our site at wwwaccorgjobs  What We Offer   ACC values all members of our College family including ACC staff As the foundation of the organization ACC staff enjoy worldclass benefits and a culture of worklife balance Our benefit offerings include insurance medical dental vision basic life and short and longterm disability and supplemental options generous paid time off preloaded vacation and sick 12 holidays and an organizational shutdown during the last week of the year parental leave 2 community service days and halfday summer Fridays tuition assistance and a very competitive 10 retirement contribution after a year of service and much more You can visit our careers site for an overview of our full offerings httpswwwaccorgaboutaccjobsattheacc Please note that these offerings may change at any time    COVID Considerations   As an employer in the public health space and an organization that serves members who are essential medical personnel ACC requires all staff to be fully vaccinated against COVID19 upon hire Proof of vaccination will be required Individuals can request an exemption from this requirement due to a medical condition or sincerely held religious belief and those requests for reasonable accommodations will be evaluated individually   ACC is proud to be an equal opportunity and affirmative action employer We celebrate diversity and are committed to creating an inclusive environment for all candidates and employees All employment is decided on the basis of qualifications merit and business need Equal Opportunity Employer including individuals with disabilities and veterans   ACC is committed to providing reasonable accommodations for qualified individuals with disabilities and disabled veterans in our job application procedures If you need assistance or an accommodation due to a disability you may contact Crystal Nott Sr Director People Resources  Engagement at cnottaccorg or 2023756423        ,\n",
       " Profile insightsFind out how your skills align with the job descriptionSkillsDo you have experience in TensorFlowYesNoEducationDo you have a Masters degreeYesNo Job detailsHere’s how the job details align with your profileJob typeFulltime LocationWaynesboro VA BenefitsPulled from the full job descriptionHealth insuranceReferral programRetirement planVision insurance Full job description Innovative Refrigeration Systems is looking to hire a Lead Machine Learning Engineer fulltime onsite in Waynesboro VA You would be joining our software engineering department to build machine learning models optimizing energy efficiency for heavy industrial refrigeration  cold storage facilities Our aim is to create a more sustainable future for our Fortune 1000 clients powering America’s food supply chain This is an extremely rewarding and impactful greenfield initiative with a company uniquely positioned to challenge the status quo Responsibilities  Building physicsbased reinforcement machine learning models around industrial refrigeration PLC  IoT data to optimize for energy efficiency and temperature safety Fine tuning and deploying ML models to our backend platform Working closely with our product energy and software teams to guide future development of our energy management platform  Qualifications  Bachelors degree Must be a selfstarter with ability to learn from our mechanical engineers and adapt their knowledge of refrigeration and thermodynamics to ML models 2 years of handson experience building and optimizing ML systems Comfortable in cloud infrastructure provider ML environments Expert in your ML tools of choice R Python Scikit Tensorflow etc  Bonus Skills  Masters or PhD in computer science mathematics mechanical or chemical engineering or any similarrelevant field Background education or otherwise in any of energy optimization predictive maintenance thermodynamics heatmass transfer industrial refrigeration or mechanicalchemical engineering Prior experience as a software engineer building backend systems around ML models  Benefits  Retirement plan we match dollar for dollar up to 15 Health insurance with 75 of monthly premium covered for employees and their families Dental  Vision  Life  Disability  Supplemental insurance Competitive vacation and holiday pay Employee referral incentives Professional development opportunities  About Innovative Refrigeration Systems We are a vertically integrated market leader in cold storage and industrial refrigeration providing engineering controls construction service and software solutions to America’s largest food and beverage corporations Our software team is responsible for multiple industrial softwareasaservice platforms in process safety environmental health  safety and energy management  ,\n",
       " Profile insightsFind out how your skills align with the job descriptionSkillsDo you have experience in SQLYesNoEducationDo you have a Bachelors degreeYesNo Job detailsHere’s how the job details align with your profileJob typeFulltime Location21931 Michigan Ave Dearborn MI 48124 BenefitsPulled from the full job descriptionDental insuranceEmployee discountHealth insurancePaid time offPrescription drug insuranceTuition reimbursement Full job description Do you believe data tell the real story We do   Global Data Insight  Analytics GDIA aspire to navigate Ford Motor Company through the disruptiveness of the information age harnessing the power of data and artificial intelligence to realize the enterprise’s known goals reveal hidden opportunities and achieve data superiority   Product Engineering and Management PEM is GDIA’s organization for creating analyticalinspired products and services at the intersection of the commercial customer service and connected vehicle domains Leveraging multidisciplinary product teams agile processes and methodologies technologies in the big data space and AIML   GDIA DataTech is looking for a GCP Cloud Data Engineer focused on deep diving into using stateoftheart development tools to understand ingest and present complex data from a series of sources internal and external to the enterprise   You should have a knack for implementing and learning required toolsets working with connected vehicle and legacy datasets to build and publish logical representations of data These wellmanaged and organized data platforms will empower the building of new technologies new applications or industrydisrupting new insights from visually appealing dashboards   Come and join this exciting and fastpaced role which requires exceptional technical data and analytics skills with the opportunity to create a huge impact on Ford’s business    The minimum requirements we seek   Bachelor’s Degree in Data Science Data Analytics Computer Science Computer Engineering Applied Mathematics Statistics Business Analytics Operations Research or related quantitative field  3 years’ experience in handling data and data processes  1 years of experience utilizing Python SQL and Google Cloud Ops  Experience with GCP native BigQuery andor Postgres  Experience building out GCP data pipelines of Data fusion from scratch in a highly distributed and faulttolerant manner  Experience with any of the following Astronomer  Airflow Dataflow Cloud Run DBT andor PubSub  Experience developing data standards  Experience creating Data Models and Data products Experience with unstructured data and streaming data     Our preferred requirements   Advanced Degree in Data Science Data Analytics Computer Science Computer Engineering Applied Mathematics Statistics Business Analytics Operations Research or related quantitative field  Demonstrated experience building visualizations using Looker  Ability to write complex SQL queries needed to query  analyze data  Experience with unstructured data and streaming data using Mongo DBAtlas andor Firestore  Knowledge of data management standards data governance practices and data quality  Demonstrated problem formulation with the ability to take complex problems and break them down to create and implement an action plan  Ability to communicate findings to make data analysis actionable and understandable by Data Operations team members and business partners including IT and analytic teams  Ability to effectively communicate information and ideas in written and verbal formats including process documentation  Highly effective in working with other technical experts Product Managers and business stakeholders  Excellent verbal and written communication skills with the ability to communicate effectively with all levels of management in varying areas of business and enterprise technology Strong collaboration and influencing skills and the ability to energize a crossfunctional team     What you’ll receive in return  As an established global company we offer the benefit of choice You can choose what your Ford future will look like will your story span the globe or keep you close to home Will your career be a deep dive into what you love or a series of new teams and new skills Will you be a leader a changemaker a technical expert a culture builder…or all the above No matter what you choose we offer a work life that works for you including Immediate medical dental and prescription drug coverage generous PTO retirement and savings plans incentive compensation tuition assistance a vehicle discount program and much more   For information on Fords salary and benefits please visit httpscorporatefordcomcontentdamcorporateusenusdocumentscareers2024benefitsandcompGSRsalplan2pdf   Candidates with Ford Motor Company positions must be legally authorized to work in the United States Verification of employment eligibility will be required at the time of hire Visa sponsorship is “not” available for this position   We are an Equal Opportunity Employer committed to a culturally diverse workforce All qualified applicants will receive consideration for employment without regard to race religion color age sex national origin sexual orientation gender identity disability status or protected veteran status In the United States if you need a reasonable accommodation for the online application process due to a disability please call 18883360660    As a GDIA GCP Cloud Data Engineer you will work in a Product Management Delivery model by collaborating directly and continuously with product managers product owners and software engineers and will follow industry best practices to perform and automate complex ETL functions   What you’ll be able to do   As a Data Steward consult with analytics teams IT partners and business partners to provide data domain expertise  Design develop create and production of Data Products for customers  Develop ELELTETL pipelines to make data available in BigQuery analytical data store from disparate batch streaming data sources  Develop and document the process to operationalize data management at Ford by collaborating with Data Governance and Data Acquisition teams  Work with Product Owners Product Managers and Product Teams to prioritize and land data sources in conjunction with Analytics Customer needs  Participate in information governance processes  Establish data standards and quality benchmarks and drive improvements to data quality to improve analytic outcomes  Provide expertise in the business domain required to deliver business objectives  Manage business information issues and problemresolution processes  Drive and be a catalyst for innovation  Persevere and persist in situations with multiple objectives and multivariable problems  Think flexibly in a complex highly interdependent environment with challenging financial technical and project management constraints  Drive longterm enterprise view against tactical requirements Tradeoffs between tactical expediency and longterm business improvements are difficult to negotiate and sustain  Support alignment between business IT and GDIA stakeholders to drive results issue resolution risk mitigation issue avoidance  Provide departmental feedback to other GDIA groups regarding processes and standards  Collaborate and motivate within the department including readily sharing best practices with other Data Operations and GDIA groups   ,\n",
       " Profile insightsFind out how your skills align with the job descriptionSkillsDo you have experience in StatisticsYesNo Location630 Komas Drive Salt Lake City UT 84108 Full job description  Your work will change lives Including your own    The Impact Youll Make  With treatments for hundreds of diseases in our sights weve built a data science team with domain expertise in computer science bioinformatics physics biology mathematics applied statistics and more We work sidebyside with biologists oncologists chemists software engineers and many others together we develop the tools and methods to turn our experimental data into treatments for pathologies that affect the lives of countless individuals As a data scientist supporting the development of our industrialized workflows youll work with a highly dynamic team that is focused on improving how we move from ideation through to advanced candidate drugs in a way that accelerates decisionmaking and automates as much as possible to scale the impact that we can have  Youll have access to unbelievable scales of data we currently run up to 22 million experiments each week our groundbreaking Phenom1 foundation model trained on  1 billion inhouse images and our maps of biology and chemistry that contain  5 trillion relationships across multiple biological and chemical contexts  In this role you will leverage this data as you  Develop methods metrics benchmarks and models to help drive drug discovery in a standardized way Convert exploratory analysis into productionquality functions that can be incorporated into inhouse Python packages and that support atscale generation of data packages to accelerate decisions on passing programs through internal stage gates Create and analyze enormous sets of connected data for a variety of programs to learn how best to advance drug discovery in an industrialized way Collaborate with engineering teams to mature your models and analyses and put them into productionized flows Deliver quickly and iteratively both supporting inflight programs and building improvements for the longterm in shortlived agile workstreams Learn to leverage new code packages and data science techniques as needed  Location  Making Salt Lake City your home base is ideal however we will consider onsite work in our Toronto Ontario offices as well  The Team Youll Join  We are an applicationoriented group whose goal is to discover drugs at scale using the toolkit of computational science in collaboration with our counterparts in other engineering software and data engineering laboratory automation scientific biology chemistry clinical science and operational laboratory operations regulatory affairs disciplines We are valuedriving  data science at Recursion is not just an accelerating function it is a core part of our value proposition As data scientists we are responsible for showing up as leaders and visionaries helping to shape how Recursion delivers on our mission We work on what matters and deliver in timescales of weeks not quarters We focus on the impact that we are trying to make and the why of what we are trying to deliver and are resilient if the how of what we are doing needs to change  The Experience Youll Need  2 years practical experience applying probability statistics and machine learning to realworld datasets in service of academic or business applications and recommendations  Strong preference for experience in the field of biosciences particularly pharmaceuticals or working on projects that require regular crossdisciplinary collaboration  Experience working within a fastpaced interdisciplinary team to solve businessrelevant problems and communicating complex concepts and methods to audiences with diverse technical backgrounds High fluency with the Python data stack numpy pandas scikitlearn etc Experience in collaborative data product development and peer code review including version control tools like git Experience developing releasing and maintaining data products in a continuoususe production environment Nice to have experience in creating compelling visualizations of highdimensional data that enable clear decisionmaking and interpretation prompt engineering for LLMs cheminformatics OR analysis of RNA sequencing data  How Youll be Supported  You will be assigned a peer trail guide to support you as you onboard and get familiar with Recursion systems Receive realtime feedback on code quality and best practices from a team of peer experts Ability to participate and learn from your colleagues in our regular allhands journal club  tech talks for Data Science Option to attend conferences to learn more from colleagues networks and more to better your skillset  LIEP1   The Values That We Hope You Share  We Care We care about our drug candidates our Recursionauts their families each other our communities the patients we aim to serve and their loved ones We also care about our work We Learn Learning from the diverse perspectives of our fellow Recursionauts and from failure is an essential part of how we make progress We Deliver We are unapologetic that our expectations for delivery are extraordinarily high There is urgency to our existence we sprint at maximum engagement making time and space to recover Act Boldly with Integrity No company changes the world or reinvents an industry without being bold It must be balanced not by timidity but by doing the right thing even when no one is looking We are One Recursion We operate with a company first team second mentality Our success comes from working as one interdisciplinary team  Recursion spends time and energy connecting every aspect of work to these values They arent static but regularly discussed and questioned because we make decisions rooted in those values in our daytoday work You can read more about our values and how we live them every day here  More About Recursion  Recursion is a clinical stage TechBio company leading the space by decoding biology to industrialize drug discovery Enabling its mission is the Recursion OS a platform built across diverse technologies that continuously expands one of the worlds largest proprietary biological and chemical datasets Recursion leverages sophisticated machinelearning algorithms to distill from its dataset a collection of trillions of searchable relationships across biology and chemistry unconstrained by human bias By commanding massive experimental scale — up to millions of wet lab experiments weekly — and massive computational scale — owning and operating one of the most powerful supercomputers in the world Recursion is uniting technology biology and chemistry to advance the future of medicine  Recursion is headquartered in Salt Lake City where it is a founding member of BioHive the Utah life sciences industry collective Recursion also has offices in London Toronto Montreal and the San Francisco Bay Area Learn more at wwwRecursioncom or connect on X formerly Twitter and LinkedIn  Recursion is an Equal Opportunity Employer that values diversity and inclusion All qualified applicants will receive consideration for employment without regard to race color religion sex sexual orientation gender identity national origin age disability veteran status or any other characteristic protected under applicable federal state local or provincial human rights legislation   ,\n",
       " Profile insightsFind out how your skills align with the job descriptionSkillsDo you have experience in UNIXYesNo Job detailsHere’s how the job details align with your profilePay50 an hourJob typeContractShift and schedule8 hour shift LocationAmerican Unit Inc in Irving TX 75061 BenefitsPulled from the full job description401kDental insuranceHealth insurance Full job descriptionData Scientist Irving Texas 6 Months CTH Customer VERIZON Job Description Project Details Verizon is seeking a Data Scientist to join its Data Operations and Targeting team This team is heavily focused on Data Analysis where they will be partnering with different stakeholders to help take in requirements From those requirements they will be tasked with pulling different data sets adding intelligence and trending analytics to help the team with targeting automation simplification of processes as well as ad hoc data manipulation and analysis to be used by marketing and strategy on sales plays In addition they will assist strategically in developing national and regional marketing campaigns both standalone and within a journey framework to help align solutions to strategy These campaigns can be complex and involve multiple database environments and marketing tools so this candidate will be expected to utilize specific approaches to ensure accurate implementation of regulatory legal and privacy policies Basic Qualifications for Consideration  57 years of experience in roles related to data engineering marketing analytics or similar fields SQL expertise Utilize advanced SQL skills to efficiently pull and manipulate data from various sources including cloud GCP and Teradata databases Previous work with very large databases and datasets Join Functions Tables Stored Procedures Python Expertise Machine learning application Ability to code from scratch creating tables and automating codedataprocesses Text analysis CommunicationWorking in CrossFunctional Teams Strong written and verbal communication skills with the ability to interact with many diverse work teams at various organizational levels ETL experience with large data sets Data extraction transaction and loading Other datasets in the ETL process  Preferred Skills  Experience using Alteryx to help automate and streamline different workflows Experience using Teradata  Unix – for data analytics  data warehousing Data Visualization specifically using Tableau Ability to take large data sets and understand what it is saying what information is the data telling you what the trends the data is presenting and being able to make an informed decision from the data Strong analytic skills to determine all required resources organize information and processes and execute the desired marketing targeting and strategy Marketing Background Preferred Customer and prospect targeting experience for marketing list development modeling andor analytics using SQL Experience with customer and prospect demographic data internally and externally sourced  Job Type Contract Salary 5000 per hour Expected hours 40 per week Benefits  401k Dental insurance Health insurance  Compensation package  Hourly pay  Experience level  10 years 11 years 5 years 6 years 7 years 8 years 9 years  Schedule  8 hour shift  Ability to Relocate  Irving TX 75015 Relocate before starting work Required  Work Location In person ,\n",
       " Profile insightsFind out how your skills align with the job descriptionSkillsDo you have experience in Statistical analysisYesNoEducationDo you have a Masters degreeYesNo Job detailsHere’s how the job details align with your profilePay92000  110000 a yearJob typeFulltime Location1830 West 38th Avenue Denver CO 80211 BenefitsPulled from the full job description401kDental insuranceEmployee assistance programHealth insurancePaid parental leaveParental leaveProfit sharingShow morechevron down Full job description Within our Corporate Technical Services  MES team located in Denver – Leprino has created a new opening for a Data Scientist I to elevate our manufacturing operations to new heights of manufacturing efficiencies through the use of IoT machine learning and artificial intelligence We take pride in our commitment to not only produce but to innovate for the future   At Leprino Foods starting compensation for this role typically ranges between 92000 and 110000 This position has an annual target bonus of 5    Develop predictive models that forecast production outcomes and pinpoint quality enhancements Engage in data collection employing advanced analytics to uncover optimization opportunities Lead indepth analyses to craft datadriven solutions for continuous process improvement Foster strong partnerships across functions to spearhead innovations in our manufacturing processes Stay at the forefront of data science continuously refining our practices with the latest methodologies Advocate for data literacy sharing insights that drive informed decisionmaking throughout Leprino Design experiments and interpret the results to draw detailed and actionable conclusions Implement advanced algorithms that enhance realtime decisionmaking capabilities Enhance data collection procedures to include information relevant to building analytic systems Apply quality control data validation and cleansing processes to ensure accuracy and integrity of data used for analysis Communicate complex data in a clear and articulate manner to crossfunctional teams and department leaders Proactively identify patterns and anomalies in large data sets to uncover valuable insights Innovate and refine machine learning infrastructure that supports complex model development Drive the adoption of data science methodologies in broader business practices Initiate and lead projects to advance the companys data science capabilities and vision Translate business objectives into actionable data projects and milestones     You Have At Least Required Qualifications  Bachelors in Data Science Computer Science Industrial Engineering or a related field Two years of applicable fulltime experience not internship or academia as a data scientist in a manufacturing environment Advanced programming experience using Python A strong foundation in statistical analysis machine learning and artificial intelligence as it applies to manufacturing operations The ability to work a weekly 32 officehome hybrid schedule     We Hope You Also Have Preferred Qualifications  A Master’s degree in one of the fields mentioned above R Programming experience Experience working with databases and SQL Demonstrated proficiency in collaborating across diverse teams to meet shared objectives A history of enhancing operations with actionable insights from complex data sets Strong communication skills to translate technical findings into understandable insights     Leprino Foods celebrates and supports diversity We believe in equal opportunity and do not discriminate on the basis of race religion ethnicity national origin gender sexual orientation age marital status veteran status or disability We know we are better together and are committed to creating an inclusive and supportive culture that uses the unique talents experiences background and perspectives of each individual employee   Offering You In Return A chance to be part of a global team of individuals passionate about producing and delivering highquality products that help feed and nourish families around the world Leprino Foods could not be where it is today without our incredible employees That is why we share in our success together by rewarding you for your hard work Hiring great people who are in it for the long run is our goal Through competitive salaries and bonuses life medicaldentalvision coverage voluntary benefits employee assistance programs wellness incentives tuition assistance vacation ten paid holidays sick time paid parental leave annual merit increases as well as the LFC ProfitSharing  401k plan Your impact will be noticed and rewarded as you seek to further our company our customers and one another   Our Story Leprino Foods’ history dates back over 70 years when Jim Leprino first started making small batches of mozzarella for local markets and eateries in the Little Italy neighborhood of Denver We’ve grown a bit since then Today Leprino Foods is the world’s largest manufacturer of mozzarella and lactose and a leading producer of whey protein Still owned by Jim and the Leprino family our sights are set to be the “World’s Best Dairy Food and Ingredient Company” To help us achieve that bold vision we’re looking for our secret ingredient You A motivated team member who is the best at what you do Three passionate individuals in a small corner grocery store in the early 1950s have now grown to well over 5000 employees throughout the globe Will you join us on our journey  ,\n",
       " Profile insightsFind out how your skills align with the job descriptionSkillsDo you have experience in SparkYesNo LocationRemote Full job description  A Little About Us  Innovative collaborative minds wanted The world loves Postgres We envision a world where organizations thrive by harnessing the full power of Postgres the worlds fastest growing and most loved and used open source database Our mission is to enable data teams everywhere to harness the full power of Postgres whether on premises or in the cloud with high availability reliability scalability and security  Were 1 in Postgres We aspire to become 1 in Postgres AI Weve been major contributors to Postgres since the beginning and we are proud to call thousands of boundarypushing customers our partners Proud though we are we are not resting on our laurels Theres plenty of work to do The good news is that everything we do will impact Postgres which is to say that it will impact the world No pressure  EDB empowers organizations to take control of their data As one of the leading contributors to the vibrant and fastgrowing Postgres community EDB is committed to driving innovation in AI data and enterprise database technology Our work is fueled by creative dedicated people who are committed to help our customers and the community take Postgres everywhere Join us   This position is 100 remote for candidates based in the US  We are looking for an experienced Analytics Software Engineer with significant Rust experience and a strong working knowledge of Postgres Ideal candidates will be able to demonstrate selfstarting skill sets alongside a proven track record of delivery in a complex Cloud andor onprem environment  Your impact will be  You will own delivery for key aspects of the EDB Analytics andor Data  AI capability You carry responsibility for designing engineering solutions to defined Customer Use Cases in the Analytics and AI space  What you will bring  5 years of experience working as a DevOps Engineer or a Software Engineer Experience in Rust Python GoLang JavaScript Bash or PowerShell etc Experience with Postgres is a must You feel at home with different types and formats of data Understanding of Kubernetes monitoring and environments Experience modeling and benchmarking Analytics workloads Experience with GitHub Jenkins Docker and Jira You are comfortable working in remote team setups  What will give you an edge  Experience buildingusing Analytics Machine Learning and AI Libraries particularly Apache Data fusion and Apache Spark to deliver business value Analyzing data and building visualizations Applied knowledge andor experience establishing customer requirements and turning that into delivered capability Experience with DBRE or DBA practices    EDB is committed to supporting our employees overall well being by offering a range of benefits and resources to promote a healthy worklife balance and wellness We provide access to Modern Health to aid employees in health and wellness tips and practices as well as Wellness Fridays extending to June 2024 Check out our career site for more information on perks and benefits and reach out to our Talent Acquisition team for region specific benefits  We know it takes a unique mix of people and skills to help us in our mission to supercharge Postgres and we understand that not everyone will check every box Wed love to hear from you and we want you to apply  EDB is proud to be an equal opportunity workplace We celebrate diversity and are committed to creating an inclusive environment for all employees EDB was built on a commitment to trust and respect each other and to embrace an array of people and ideas These values remain at the center of our culture and are key to our companys integrity  EDB does not seek or accept unsolicited resumes or CVs from recruitment agencies EDB and its affiliates are not responsible for and will not pay any fees commissions or any other similar payment related to unsolicited resumes or CVs except as required in a written signed agreement between EDB and the recruitment agency or party requesting payment of a fee  LIRemote BIRemote   ,\n",
       " Profile insightsFind out how your skills align with the job descriptionSkillsDo you have experience in TensorFlowYesNoEducationDo you have a Masters degreeYesNo Job detailsHere’s how the job details align with your profilePay119200  163900 a year LocationCalifornia BenefitsPulled from the full job description401k matchingDental insuranceHealth insurancePaid time offVision insurance Full job description    Splunk is here to build a safer and more resilient digital world The worlds leading enterprises use our unified security and observability platform to keep their digital systems secure and reliable While customers love our technology its our people that make Splunk stand out as an amazing career destination and why weve won so many awards as a best place to work If you become a Splunker we want your whole authentic self what we call your million data points So bring your work experience problemsolving skills and talent of course but also bring your joy your passion and all the things that make you you    Role Summary     As an Applied Scientist in the Artificial Intelligence group you will be responsible for developing the core AIML capabilities to power the entire Splunk product portfolio and help our customers to drive their journey to digital resiliency You will work on diverse projects that span Cybersecurity and Observability domains applying advanced machine learning techniques to solve complex problems and drive innovation    What youll get to do   Develop core AIML models and algorithms that drive our product’s key use cases in the cybersecurity and observability domains  Collaborate closely with software engineers data scientists and product managers to integrate generative AI solutions into our products and services  Stay up to date with the latest research and developments in the field of AIML and ensure that these advancements are properly incorporated into our technology roadmap   Musthave Qualifications   Bachelors or Masters degree in Computer Science Machine Learning Statistics or a related field   Nicetohave Qualifications     We’ve taken special care to separate the musthave qualifications from the nicetohaves “Nicetohave” means just that Nice To Have So don’t worry if you can’t check off every box We’re not hiring a list of bullet points–we’re interested in the whole you     Strong understanding of machine learning fundamentals and experience with popular frameworks eg TensorFlow PyTorch  Solid programming skills in languages such as Python  Experience working with Generative AI technology and Large Language Models LLM or time series analysis and anomaly detection in projects or internships  Strong problemsolving skills and the ability to think critically and creatively  Strong communication skills with the ability to articulate complex technical concepts to both technical and nontechnical audiences  Demonstrated ability to work effectively in a collaborative team environment    Splunk is an Equal Opportunity Employer      At Splunk we believe creating a culture of belonging isn’t just the right thing to do it’s also the smart thing We prioritize diversity equity inclusion and belonging to ensure our employees are supported to bring their best most authentic selves to work where they can thrive Qualified applicants receive consideration for employment without regard to race religion color national origin ancestry sex gender gender identity gender expression sexual orientation marital status age physical or mental disability or medical condition genetic information veteran status or any other consideration made unlawful by federal state or local laws We consider qualified applicants with criminal histories consistent with legal requirements     Note  Base Pay Range  SF Bay Area Seattle Metro and New York City Metro Area  Base Pay Range 11920000  16390000 per year  California excludes SF Bay Area Washington excludes Seattle Metro Washington DC Metro and Massachusetts  Base Pay Range 10728000  14751000 per year  All other cities and states excluding California Washington Massachusetts New York City Metro Area and Washington DC Metro Area  Base Pay Range 9536000  13112000 per year  Splunk provides flexibility and choice in the working arrangement for most roles including remote andor inoffice roles We have a marketbased pay structure which varies by location Please note that the base pay range is a guideline and for candidates who receive an offer the base pay will vary based on factors such as work location as set out above as well as the knowledge skills and experience of the candidate In addition to base pay this role is eligible for incentive compensation and may be eligible for equity or longterm cash awards     Benefits are an important part of Splunks Total Rewards package This role is eligible for a competitive benefits package which includes medical dental vision a 401k plan and match paid time off and much more Learn more about our comprehensive benefits and wellbeing offering at httpssplunkbenefitscom    ,\n",
       " Profile insightsFind out how your skills align with the job descriptionSkillsDo you have experience in XGBoostYesNoEducationDo you have a Masters degreeYesNo Job detailsHere’s how the job details align with your profilePay11440  17160 a monthJob typeFulltime LocationUnited States BenefitsPulled from the full job description401k matchingADD insuranceDental insuranceHealth insuranceMilitary leavePaid military leavePaid parental leaveShow morechevron down Full job description Job Description Summary Takes ownership and responsibility over major data science and operations research initiatives Directs a team responsible for modeling and development to support operations initiatives strategic programs and new products and solutions Strong background and experience in the use of sophisticated descriptive diagnostic predictive prescriptive and ensemble modeling advanced statistical techniques and sophisticated mathematical tools Uses expertise to manage a team that initiates and delivers projects and develops endtoend solutions that drive business results including proofsofvalue for new business problems and productionready solutions for operations and customerfacing products Understands and ensures development of solutions supporting the movement of data and information assets following APIFirst  Architecture principles Advances Dataworks’ broad capabilities to use and deploy innovative tools in Dataworks projects platforms and products Applies knowledge of ML Ops CICD processes and data engineering practices to ensure sustainable model development and provide recommendations on complex problems Provides consultation and thought leadership to senior management Mentors other team members to get results and effectively collaborates with multifunctional teams to deliver business goals  Job Description The Data Scientist Manager will supply to the creation and alignment of technical standards for data science and machine learning including the design and construction of reusable data assets They will work with large data sets and solve difficult analytical problems applying advanced methods They will lead implementation of solutions from concept to production using current and emerging technologies to evaluate trends and develop practical insights and recommendations Daytoday they will be deeply involved in code reviews and largescale deployments  Essential Job Duties  Responsibilities    We are seeking someone who has understanding in depth both the business and technical problems Dataworks aims to solve   Exploring data and crafting models to answer core business problems that may lack blueprints   Leading the invention of new approaches and algorithms for taking on data intensive problems   Pioneering RD efforts to rapidly understand and assimilate innovative methods   Scaling up from “laptopscale” to “cluster scale” problems by leading efforts to standardize and modernize solutions   Interacting with senior technologists from the broader enterprise and outside of FedEx partner ecosystems and customers to create room to collaborate and find opportunities for improvement   Codifying standard processes for future reuse in the form of accessible reusable patterns templates and code bases    SkillsKnowledge Considered a Plus    Technical background in computer science operations research data science machine learning artificial intelligence statistics or other quantitative and computational science   A compelling track record of Data Science  Engineer expertise designing and deploying large scale technical solutions which deliver tangible ongoing value   Direct experience having built and deployed robust complex production systems through Cloud technologies that implement modern data scientific methods at scale   Ability to contextswitch to provide support to dispersed teams which may need an “expert hacker” to unblock an especially significant technical obstacle   Demonstrated ability to deliver technical projects with a team often working under tight time constraints to deliver value   An ‘engineering’ mentality willing to make rapid pragmatic decisions to improve performance accelerate progress or magnify impact   Ability to work with distributed teams on codebased results using version control   Solid theoretical grounding in the mathematical core of the major ideas in data science   Sophisticated level of understanding of a class of modelling or analytical techniques often supported by Masters or Doctorallevel research in the subject   Deep fluency in the mathematical ‘primitives’ and generalizations of data science – eg expertise in Linear Algebra and Vector Calculus   Use of agile and devops practices for project and software management including CICD process improvement and quality management experience eg Lean Six Sigma QDM authority   We are looking for demonstrated expertise in working with some of the following common languages and tools   SKLearn XGBoost Tensorflow Pytorch MLlib and other core ML frameworks   Python Scala R C Java and other modern programming languages   MLFlow Databricks Spark Kafka Hive Hadoop and other data tools and frameworks   CPLEX Gurobi and other similar optimization modeling packages    Minimum Qualifications  Master’s Degree or equivalent in computer science operations research statistics applied mathematics or related quantitative subject area Directly related PhD preferred Five to eight 58 years’ work experience in applying data science machine learning artificial intelligence statistical analysis operations research optimization algorithms mathematical modeling and data analytics modeling to decrease cost increase profitability and improve customer experience Extensive knowledge in advanced data science statistical analysis and machine learning methods including the iterative development of analysis pipelines to provide insights at scale Extensive experience conducting endtoend analyses including data gathering and requirements specification processing analysis and presentation Strong familiarity with the transportation industry competitors and evolving technologies Experience providing leadership in a general planning or consulting setting Experience as a leader or a senior member of multifunctional project teams Strong human relations organizational  time management project management and software development skills Excellent interpersonal skills and the ability to present and communicate with impact to executive audiences    Domicile Information  This position can be domiciled anywhere in the United States The ability to work remotely within the United States may be available based on business need    Application Criteria  Upload current copy of Resume Microsoft Word or PDF format only and answer job screening questionnaire by April 8 2024   Additional Information  Colorado Nevada Connecticut New York California Rhode Island Washington Hawaii Illinois and New Jersey Residents Only  Compensation Monthly Salary 1144000  1716000 This compensation range is provided as a reasonable estimate of the current starting salary range for this role Factors that may be used to determine your actual salary may include but are not limited to your specific skills your work location how many years of experience you have and comparison to other employees already in this role   Born out of FedEx a pioneer that ships nearly 20 million packages a day and manages endless threads of information FedEx Dataworks is an organization rooted in connecting the physical and digital sides of our network to meet todays needs and address tomorrows challenges  We are creating opportunities for FedEx our customers and the world at large by   Exploring and harnessing data to define and solve true problems  Removing barriers between data sets to create new avenues of insight  Building and iterating on solutions that generate value  Acting as a change agent to advance curiosity and performance   At FedEx Dataworks we are making supply chains work smarter for everyone  Employee Benefits medical dental and vision insurance paid Life and ADD insurance tuition reimbursement paid sick leave paid parental leave paid vacation paid military leave and additional paid time off geographic pay ranges 401k with Company match and incentive bonus potential sales Incentive compensation for selling roles  Dataworks does not discriminate against qualified individuals with disabilities in regard to job application procedures hiring and other terms and conditions of employment Further Dataworks is prepared to make reasonable accommodations for the known physical or mental limitations of an otherwise qualified applicant or employee to enable the applicant or employee to be considered for the desired position to perform the essential functions of the position in question or to enjoy equal benefits and privileges of employment as are enjoyed by other similarly situated employees without disabilities unless the accommodation will impose an undue hardship If a reasonable accommodation is needed please contact DataworksTalentAcquisitioncorpdsfedexcom  ,\n",
       " Profile insightsFind out how your skills align with the job descriptionSkillsDo you have experience in Statistical softwareYesNoEducationDo you have a Bachelors degreeYesNo Job detailsHere’s how the job details align with your profileJob typeFulltime LocationStamford CT 06902 BenefitsPulled from the full job descriptionOpportunities for advancement Full job description          Responsible for assisting in the development of datadriven solutions to Charter’s business problems In partnership with seasoned Data Scientist utilize analytical statistical and programming skills to clean aggregate and analyze large data sets and interpret results Develop a strong command of statistical techniques and machine learning algorithms as well as a demonstrated practical ability to determine where to invest time synthesize actionable findings across diverse assignments and present findings to audiences with diverse agendas and varying levels of technical expertise             MAJOR DUTIES AND RESPONSIBILITIES        Actively and consistently supports all efforts to simplify and enhance the customer experience  Participate in the execution of the complete analytics lifecycle for problem solving including requirements gathering problem formulation data grooming data exploration model prototyping model validation and algorithm productionalization  Survey varied data sources for analytic relevance  Leverage knowledge in analytical and statistical algorithms to assist in helping stakeholders explore methods to improve their business  Assist in the design and implementation of statistical data quality procedures for existing and new data sources  Observe and assist in the communication of complex data science solutions concepts and analyses in a clear and effective manner to team members and business leaders  Establish links across existing data sources and find new interesting data correlations  Assist in the presentation of data insights and recommendations to key stakeholders  Achieve defined project goals within deadline proactively communicate status and escalate issues as needed  Helps to ensure testing and validation are components of all analytics solutions          REQUIRED QUALIFICATIONS        Required SkillsAbilities and Knowledge       Ability to read write speak and understand English  Ability to develop interpersonal communication verbal and written relationship management and customer service skills with a focus on working effectively in a team environment  Minimal experience with analytical and statistical software  Minimal experience using a data science toolkit such as Python or R  Basic level SQL skills  Effective analytical and problem solving skills with attention to detail and data accuracy  Ability to perform indepth research and analysis  Ability to maintain confidentiality and appropriately handle sensitive information  Knowledge of core computer science principles including algorithms data structures and design methodologies  Prior exposure to cloudbased infrastructures  Prior exposure to big data tools such as Spark and Hive           Required Education       Bachelors degree in computer science statistics operations research andor equivalent combination of education and experience                 Required Related Work Experience and Number of Years Number of Years       Data Analytics 03         Programming experience 02                  PREFERRED QUALIFICATIONS        Preferred SkillsAbilities and Knowledge           Preferred Education           Preferred Related Work Experience and Number of Years       Internship in a role as a data scientist                  WORKING CONDITIONS        Office environment            BDA302 202431383 2024     Here employees don’t just have jobs they build careers That’s why we believe in offering a comprehensive pay and benefits package that rewards employees for their contributions to our success supports all aspects of their wellbeing and delivers real value at every stage of life    A qualified applicant’s criminal history if any will be considered in a manner consistent with applicable laws including local ordinances    Get to Know Us Charter Communications is known in the United States by our Spectrum brands including Spectrum Internet® TV Mobile and Voice Spectrum Networks Spectrum Enterprise and Spectrum Reach When you join us you’re joining a strong community of more than 101000 individuals working together to serve more than 32 million customers in 41 states and keep them connected to what matters most Watch this video to learn more    Who You Are Matters Here We’re committed to growing a workforce that reflects our communities and providing equal opportunities for employment and advancement EOE including disabilityvets Learn about our inclusive culture  ,\n",
       " Profile insightsFind out how your skills align with the job descriptionSkillsDo you have experience in TensorFlowYesNoEducationDo you have a Bachelors degreeYesNo LocationSan Jose CA 95110 BenefitsPulled from the full job description401k matchingADD insuranceDisability insuranceEmployee assistance programFlexible spending accountHealth insuranceHealth savings accountShow morechevron down Full job descriptionResponsibilities  TikTok is the leading destination for shortform mobile video Our mission is to inspire creativity and bring joy TikTok has global offices including Los Angeles New York London Paris Berlin Dubai Singapore Jakarta Seoul and Tokyo    Creation is the core of TikToks purpose Our platform is built to help imaginations thrive This is doubly true of the teams that make TikTok possible Together we inspire creativity and bring joy  a mission we all believe in and aim towards achieving every day To us every challenge no matter how difficult is an opportunity to learn to innovate and to grow as one team Status quo Never Courage Always  At TikTok we create together and grow together Thats how we drive impact  for ourselves our company and the communities we serve  Join us    About the team  The Applied AI DCC Team is part of the Monetizing Integrity team in TikTok global business solutions We support Data Cycling Center to provide enterprises with affordable and trusted data and models    Responsibilities   Design and build core capabilities by leveraging content understanding capabilities such as natural language processing machine learning or computer vision to extract insights and improve monetization strategies Develop creative solutions and build prototypes for business problems using algorithms based on the latest deep learning machine learning statistics and optimization techniques Independently manage data projects from 0 to 1 and collaborate with product managers to define user stories and success metrics to guide the development process Verify the business value and estimated revenue of the project using methods such as AB testing Collaborate with engineering teams to deploy and scale data science solutions  Qualifications    Minimum Qualifications   BS or above in Computer Science Software Engineering Data Science or a related field Knowledge of underlying mathematical fundamentals in statistics machine learning and analytics 3 years experience in data modelinganalysis with industry experience in MLDL and one of CVNLPSpeech Experience with exploratory data analysis statistical analysis hypothesis testing and model development Fluency in SQL Hive Presto or Spark and having experience working with large datasets High proficiency in Python and SQL and MLDL frameworks such as TensorFlow PyTorch  Preferred qualifications   Experience in CICD such as git and cloud services such as AWSGCPAzure will be highly desirable Intellectual curiosity along with excellent problemsolving and quantitative skills including the ability to desegregate issues identify root causes and recommend solutions  TikTok is committed to creating an inclusive space where employees are valued for their skills experiences and unique perspectives Our platform connects people from across the globe and so does our workplace At TikTok our mission is to inspire creativity and bring joy To achieve that goal we are committed to celebrating our diverse voices and to creating an environment that reflects the many communities we reach We are passionate about this and hope you are too    TikTok is committed to providing reasonable accommodations in our recruitment processes for candidates with disabilities pregnancy sincerely held religious beliefs or other reasons protected by applicable laws If you need assistance or a reasonable accommodation please reach out to us at httpsshorturlatcdpT2  Job Information  The base salary range for this position in the selected city is 128000  290000 annually    ​    Compensation may vary outside of this range depending on a number of factors including a candidate’s qualifications skills competencies and experience and location Base pay is one part of the Total Package that is provided to compensate and recognize employees for their work and this role may be eligible for additional discretionary bonusesincentives and restricted stock units    ​    Our company benefits are designed to convey company culture and values to create an efficient and inspiring work environment and to support our employees to give their best in both work and life We offer the following benefits to eligible employees    ​    We cover 100 premium coverage for employee medical insurance approximately 75 premium coverage for dependents and offer a Health Savings AccountHSA with a company match As well as Dental Vision ShortLong term Disability Basic Life Voluntary Life and ADD insurance plans In addition to Flexible Spending AccountFSA Options like Health Care Limited Purpose and Dependent Care    ​    Our time off and leave plans are 10 paid holidays per year plus 17 days of Paid Personal Time Off PPTO prorated upon hire and increased by tenure and 10 paid sick days per year as well as 12 weeks of paid Parental leave and 8 weeks of paid Supplemental Disability    ​    We also provide generous benefits like mental and emotional health benefits through our EAP and Lyra A 401K company match gym and cellphone service reimbursements The Company reserves the right to modify or change these benefits programs at any time with or without notice ,\n",
       " Profile insightsFind out how your skills align with the job descriptionSkillsDo you have experience in TableauYesNo LocationSan Francisco CA Full job description  About Pinterest  Millions of people across the world come to Pinterest to find new ideas every day Its where they get inspiration dream about new possibilities and plan for what matters most Our mission is to help those people find their inspiration and create a life they love In your role youll be challenged to take on work that upholds this mission and pushes Pinterest forward Youll grow as a person and leader in your field all the while helping Pinners make their lives better in the positive corner of the internet  Creating a life you love also means finding a career that celebrates the unique perspectives and experiences that you bring As you read through the expectations of the position consider how your skills and experiences may complement the responsibilities of the role We encourage you to think through your relevant and transferable skills from prior experiences  Our new progressive work model is called PinFlex a term thats uniquely Pinterest to describe our flexible approach to living and working Visit our PinFlex landing page to learn more   As a Data Scientist on the Sales Analytics team you will serve as a goto expert on data and analytics within the SMB Sales team and with key XFN partners Team members are trusted to drive efficiency and revenue growth by enabling datadriven decisions for deepcomplex problems developing accurate reporting and forecasting models and building scalable data infrastructure  What youll do  Serve as an analytics expert for your partners using data to help them make better decisions Work directly with sales leaders and XFN partners on critical strategic and analytical projects designed to increase revenue sales productivity andor operational efficiency Own the endtoend process of gathering and synthesizing data using relevant tools eg SQL Python testing hypotheses and developing final recommendations Translate analysis results into actionable insights or improvement opportunities to influence decisions made my sales leadership and the broader organization Work with large complex data sets to solve complex problems applying advanced analytical methods as needed Develop and automate reporting and forecasting models iteratively build and prototype dashboards as needed to provide insights at scale Build and maintain business critical data pipelines and workflows develop comprehensive knowledge of internal data structures and metrics advise on changes where needed  What were looking for  3 years of professional experience analyzing data in a fastpaced datadriven environment Extensive experience solving analytical problems using quantitative approaches including in the fields of Statistical Modelling Forecasting Econometrics or other related fields Expertlevel knowledge of SQL with strong data exploration and manipulation skills Experience with one or more programming languages such as Python or R Experience with Tableau or similar data visualization tools Excellent communication skills and ability to explain learnings to both technical and nontechnical partners A scientifically rigorous approach to analysis and data and a welltuned sense of skepticism attention to detail and commitment to highquality resultsoriented output  Relocation Statement   This position is not eligible for relocation assistance Visit our PinFlex page to learn more about our working model  LIHYBRID  LIAT6   Our Commitment to Diversity  Pinterest is an equal opportunity employer and makes employment decisions on the basis of merit We want to have the best qualified people in every job All qualified applicants will receive consideration for employment without regard to race color religion sex sexual orientation gender identity national origin disability protected veteran status or any other characteristic under federal state or local law We also consider qualified applicants regardless of criminal histories consistent with legal requirements If you require an accommodation during the job application process please notify accessibilitypinterestcom for support   ,\n",
       " Profile insightsFind out how your skills align with the job descriptionSkillsDo you have experience in XGBoostYesNoEducationDo you have a Masters degreeYesNo Job detailsHere’s how the job details align with your profileJob typeFulltime Location7501 West Memorial Road Oklahoma City OK 73142 Full job description The Staff Data Scientist will translate business problems and opportunities into data science projects Conduct data analysis and build machine learning models for internal and clientfacing applications Present findings to key stakeholders Deploy production models This position will work closely with software development to provide valuable insight to improve business operations   RESPONSIBILITIES   Meet with business leaders to understand business challenges and opportunities and then frame these as data science problems  Identify data sources and evaluate suitability for use in analysis and modeling  Manage complex projects by demonstrating scope of data science projects by defining and planning steps  Extract data from enterprise systems and clean the data for analysis and modeling  Conduct analysis to derive insights from data  Develop visualizations of analytics and models for communicating findings  Build test and validate predictive models  Put models into production  Present insights to key business stakeholders  Mentor junior data scientists  Identify opportunities to collect data from new sources or improve existing processes to allow for better analysis and modeling  Implements new or enhanced software designed to access and handle data more efficiently  Identifies creative solutions to challenging data science problems determines project requirements and model requirements and delivers a solution through the lifecycle to the production environment   EducationCertification   Bachelor’s Degree in Computer Science Data Science Business Analytics or similar quantitative field   Experience   5 years in a data scientist role   SkillsAbilities   R andor Python SQL statistical analysis and modeling including linear and generalized linear models time series analysis and forecasting machine learning models such as random forests XGBoost and SVM Spark in Scala or from R or Python  Natural language processing including topic modeling intent  entity extraction andor building domainspecific language models  Demonstrate a high level of autonomy and ability to produce high quality work with minimal guidance  Demonstrated ability to communicate data science findings and recommendations to technical and nontechnical audiences including senior and executive leadership  Experience monitoring models in production  Experience in data mining  Understanding of machine learning  Strong analytical skills and business acumen    PREFERRED QUALIFICATIONS  EducationCertification   Master’s degree in Computer Science Data Science Business Analytics or similar quantitative field   Experience   7 years in a data scientist role   SkillsAbilities   Neural networks including CNN and RNN architectures  Building production APIs in Flask FastAPI or similar frameworks  Experience deploying models in Docker containers on Kubernetes  Experience deploying models ondevice for iOS and Android    Paycom is an equal opportunity employer and prohibits discrimination and harassment of any kind Paycom makes employment decisions on the basis of business needs job requirements individual qualifications and merit Paycom wants to have the best available people in every job Therefore Paycom does not permit its employees to harass discriminate or retaliate against other employees or applicants because of race color religion sex sexual orientation gender identity pregnancy national origin military and veteran status age physical or mental disability genetic characteristic reproductive health decisions family or parental status or any other consideration made unlawful by applicable laws Equal employment opportunity will be extended to all persons in all aspects of the employeremployee relationship This policy applies to all terms and conditions of employment including but not limited to hiring training promotion discipline compensation benefits and separation of employment The Human Resources Department has overall responsibility for this policy and maintains reporting and monitoring procedures Any questions or concerns should be referred to the Human Resources Department To learn more about Paycoms affirmative action policy equal employment opportunity or to request an accommodation  Click on the link to find more information paycomcomcareerseeoc   LIHybrid  ,\n",
       " Profile insightsFind out how your skills align with the job descriptionSkillsDo you have experience in Software developmentYesNo Job detailsHere’s how the job details align with your profileJob typeFulltime LocationPeoria IL BenefitsPulled from the full job description401kBenefits from day oneDental insuranceHealth insurancePaid time offVision insurance Full job description Career Area Business Technologies Digital and Data   Job Description  Your Work Shapes the World at Caterpillar Inc  When you join Caterpillar youre joining a global team who cares not just about the work we do – but also about each other We are the makers problem solvers and future world builders who are creating stronger more sustainable communities We dont just talk about progress and innovation here – we make it happen with our customers where we work and live Together we are building a better world so we can all enjoy living in it  The Opportunity   Embedded within the Global Machine Pricing organization gathers and documents userclient requirements supports the development and testing of new products or services collects feedback from clients and recommends improvements Also performs analytical tasks and initiatives on pricing merchandising and commercial data for Caterpillar machine products to support datadriven business decision and development  Responsibilities    Assisting in the development testing and delivery of analytics and digital solutions Analyzing existing offerings preparing technical documentation and recommending upgrades  Identifying userclient requirements for a product or service and defining technical specifications Preparing technical documentation and sharing them with senior analysts and technical teams  Handle the complete development of new dashboards including concept design backend development data validation frontend visualization and publication with proper security  Work with various business partners to understand business needs and devise the appropriate solution whether that is a dashboard a onetime report an automated report or other similar solution  Supporting senior analysts by fulfilling their data requests preparing reports and providing technical assistance Participating in initiatives to improve processes efficiency and employee productivity  Directing the data gathering data mining and data processing processes in huge volume creating appropriate data models  Leading to define requirements and scope of data analyses presenting and reporting possible business insights to management using data visualization technologies Conducting research on data model optimization and algorithms to improve effectiveness and accuracy on data analyses    Skill Descriptors   Accuracy and Attention to Detail Understanding the necessity and value of accuracy ability to complete tasks with high levels of precision   Level Extensive Experience   Evaluates and makes contributions to best practices  Processes large quantities of detailed information with high levels of accuracy  Productively balances speed and accuracy  Employs techniques for motivating personnel to meet or exceed accuracy goals  Implements a variety of crosschecking approaches and mechanisms  Demonstrates expertise in quality assurance tools techniques and standards   Business Data Analysis Knowledge of business data analysis ability to collect identify analyze and interpret business data using various kinds of techniques to meet business needs and requirements  Level Extensive Experience   Sets standards for business data analysis tools and techniques advises on their application and ensures compliance  Provides solutions to data requirements in the business data analysis process  Directs the implementation of business data collection processes and educates junior employees on new data sources  Evaluates the quality of business data collected and the effectiveness of data analysis methods  Oversees the use of business data analysis software and troubleshoots for common errors Suggests conclusions with results drawn from business data analysis     Analytical Thinking Knowledge of techniques and tools that promote effective analysis ability to determine the root cause of organizational problems and create alternative solutions that resolve these problems  Level Working Knowledge   Approaches a situation or problem by defining the problem or issue and determining its significance  Makes a systematic comparison of two or more alternative solutions  Uses flow charts Pareto charts fish diagrams etc to disclose meaningful data patterns  Identifies the major forces events and people impacting and impacted by the situation at hand Uses logic and intuition to make inferences about the meaning of the data and arrive at conclusions    Effective Communications Understanding of effective communication concepts tools and techniques ability to effectively transmit receive and accurately interpret ideas information and needs through the application of appropriate communication behaviors  Level Extensive Experience   Reviews others writing or presentations and provides feedback and coaching  Adapts documents and presentations for the intended audience  Demonstrates both empathy and assertiveness when communicating a need or defending a position  Communicates well downward upward and outward  Employs appropriate methods of persuasion when soliciting agreement Maintains focus on the topic at hand     Programming Languages Knowledge of basic concepts and capabilities of programming ability to use tools techniques and platforms in order to write and modify programming languages  Level Working Knowledge   Participates in the implementation and support of specialized programming languages  Highly proficient in Power BI SQL and Snowflake Experience with Python and Data Science preferred  Conducts basic reviews on writing a specific programming language within a specific platform  Assists with the design and development of specialized programming languages  Follows an organizations standards policies and guidelines for structured programming specifications Diagnoses and reports minor or routine programming language problems     Query and Database Access Tools Knowledge of data management systems ability to use support and access facilities for searching extracting and formatting data for further use  Level Working Knowledge   Defines creates and tests simple queries by using associated command language in a specific environment  Applies appropriate query tools used to connect to the data warehouse  Obtains and analyzes query access path information and query results  Employs tested query statements to retrieve insert update and delete information Works with advanced features and functions including sorting filtering and making simple calculations     Business Assessment Knowledge of the activities tasks practices and deliverables for assessing and documenting business opportunities ability to assess the benefits risks and success factors of potential applications  Level Working Knowledge   Applies tools and techniques for gathering business requirements  Defines the activities deliverables and tools of a business assessment process  Documents best practices and techniques for assessing application opportunities  Participates in conducting and documenting business assessments Participates in the preparation of risk assessment and benefits analysis     Requirements Analysis Knowledge of tools methods and techniques of requirement analysis ability to elicit analyze and record required business functionality and nonfunctionality requirements to ensure the success of a system or software development project   Level Working Knowledge   Follows policies practices and standards for determining functional and informational requirements  Confirms deliverables associated with requirements analysis  Communicates with customers and users to elicit and gather client requirements  Participates in the preparation of detailed documentation and requirements Utilizes specific organizational methods tools and techniques for requirements analysis     This Job Description is intended as a general guide to the job duties for this position and is intended for the purpose of establishing the specific salary grade It is not designed to contain or be interpreted as an exhaustive summary of all responsibilities duties and effort required of employees assigned to this job At the discretion of management this description may be changed at any time to address the evolving needs of the organization It is expressly not intended to be a comprehensive list of “essential job functions” as that term is defined by the Americans with Disabilities Act  Additional Information  This employer is not currently hiring foreign national applicants that require or will require sponsorship tied to a specific employer such as H L TN F J E O As a global company Caterpillar offers many job opportunities outside of the US which can be found through our employment website at wwwCaterpillarcomCareers   Employee benefit details  Our goal at Caterpillar is for you to have a rewarding career Our teams are critical to the success of our customers who build a better world  Here you earn more than just an hourly wage because we value your performance we offer a total rewards package that provides day one benefits medical dental vision RX and 401K along with a yearly STIP bonus  Additional benefits include paid vacation days and paid holidays prorated based upon hire date  Final details  Please frequently check the email associated with your application including the junkspam folder as this is the primary correspondence method If you wish to know the status of your application – please use the candidate login on our career website as it will reflect any updates to your status  LI  Posting Dates April 1 2024  April 14 2024   Any offer of employment is conditioned upon the successful completion of a drug screen  EEOAA Employer All qualified individuals  Including minorities females veterans and individuals with disabilities  are encouraged to apply  Not ready to apply Join our Talent Community   ,\n",
       " Profile insightsFind out how your skills align with the job descriptionSkillsDo you have experience in TensorFlowYesNoEducationDo you have a Bachelors degreeYesNo Job detailsHere’s how the job details align with your profileJob typeFulltimeShift and scheduleMonday to Friday LocationArlington VA Full job descriptionAre you an Artificial Intelligence Expert working at a Large Financial Institution and being told by your leadership that you are too handson or detailoriented or think and work like a startup Imagine working at Intellibus to engineer platforms that impact billions of lives around the world With your passion and focus we will accomplish great things together We are seeking an experienced Artificial Intelligence AI Technical Advisor to provide expert guidance and strategic direction in AIrelated initiatives and projects The AI Technical Advisor will play a key role in advising senior leadership collaborating with crossfunctional teams and driving the development and implementation of AI solutions The ideal candidate will have a deep understanding of AI technologies industry trends and best practices along with a proven track record of successfully implementing AI projects in complex environments We are looking for someone who can  Strategic Guidance Provide strategic advice and insights to senior leadership on leveraging AI technologies to achieve business objectives and drive innovation Apply knowledge in quantitative analysis machine learning statistical modeling and software development to data analysis problems for our sponsors Work independently and on teams to engineer automated solutions for sponsor mission challenges Advise and lead large AI teams Explore promising research and maintaingain the technical edge required for projects Share and develop new approaches and methods Collaborate to document and support software analytics and clearly present status and results to internal and external stakeholders Collaborate with stakeholders to identify AI opportunities and define strategic AI initiatives aligned with organizational goals Technical Expertise Stay abreast of the latest advancements and trends in AI technologies machine learning natural language processing computer vision and related fields Evaluate emerging AI technologies and assess their potential impact on the organizations business processes and competitive advantage Project Leadership Led the design and implementation of AI projects from conception to deployment ensuring alignment with business requirements and technical feasibility Provide technical leadership and guidance to crossfunctional teams including data scientists engineers and developers throughout the project lifecycle Solution Architecture Collaborate with architecture teams to design scalable and robust AI solutions that meet performance security and scalability requirements Develop architectural patterns and best practices for AI development and deployment in enterprise environments Technical Evaluation and Due Diligence Conduct technical evaluations and due diligence on AI platforms tools and thirdparty vendors to assess their suitability for integration into the organizations ecosystem Provide recommendations and make informed decisions based on technical assessments and evaluations Collaboration and Communication Foster collaboration and knowledge sharing across teams by providing technical guidance training and mentorship in AI technologies and methodologies Communicate complex technical concepts and insights to nontechnical stakeholders clearly and understandably Quality Assurance and Governance Establish quality assurance processes and governance frameworks for AI projects to ensure adherence to best practices regulatory requirements and ethical guidelines Monitor and evaluate AI models and solutions to ensure ongoing performance reliability and compliance  Qualifications  Bachelors degree in Computer Science or a related field is preferred Relevant work experience may be considered in lieu of a degree Excellent communication and interpersonal skills with the ability to effectively collaborate with crossfunctional teams and stakeholders Proven leadership abilities with experience mentoring junior developers and driving technical excellence within the team  We work closely with  Artificial Intelligence Machine learning Tensorflow Caffe CNTK Python Java C  C  Our Process  Schedule a 15minute Video Call with someone from our team 4 Proctored GQ Tests  2 hours 3045 mins Final Video Interview Receive Job Offer  If you are interested in reaching out to us please apply and our team will contact you within the hour Job Type Fulltime Schedule  Monday to Friday  Experience  Artificial Intelligence 7 years Preferred Machine learning 7 years Preferred Java 7 years Preferred  Ability to Relocate  Arlington VA Relocate before starting work Required  Work Location In person ,\n",
       " Profile insightsFind out how your skills align with the job descriptionSkillsDo you have experience in PythonYesNoEducationDo you have a Masters degreeYesNo LocationNew York NY 10001 BenefitsPulled from the full job descriptionDisability insuranceHealth insuranceRetirement planWellness program Full job description Every great story has a new beginning and yours starts here  Welcome to Warner Bros Discovery… the stuff dreams are made of   Who We Are…  When we say “the stuff dreams are made of” we’re not just referring to the world of wizards dragons and superheroes or even to the wonders of Planet Earth Behind WBD’s vast portfolio of iconic content and beloved brands are the storytellers bringing our characters to life the creators bringing them to your living rooms and the dreamers creating what’s next…   From brilliant creatives to technology trailblazers across the globe WBD offers career defining opportunities thoughtfully curated benefits and the tools to explore and grow into your best selves Here you are supported here you are celebrated here you can thrive   Every great story has a new beginning   Were excited to announce that Discovery and WarnerMedia have combined to become Warner Bros Discovery Were a premier global media and entertainment company offering audiences the worlds most differentiated and complete portfolio of content brands and franchises across television film sports news streaming and gaming Our mission is simple To be the worlds best storytellers with worldclass products for consumers  From brilliant creatives to technology trailblazers and beyond join us as we step into the next chapter   Warner Bros Discoverys DTC technology and product organization sits at the intersection of tech entertainment and everyday utility We are continuously leveraging new technology to build immersive and interactive viewing experiences Our platform covers everything from search content catalog and video transcoding to personalization global subscriptions and more We are committed to delivering unique and quality user experiences ranging from video streaming to applications across connected TV mobile web and consoles As a pure tech organization we are essential to Warner Bros Discovery’s continued growth building worldclass streaming products from the groundup for our iconic brands like HBO Max Discovery Channel CNN Food Network HGTV Eurosport MotorTrend and many more   About You  We are looking for a passionate Machine Learning Engineer to build and scale the DTC personalization systems and services for our new global streaming app Max as well as any future DTC streaming apps You will be in the unique role of acting as a leader who can work seamlessly with modeling and engineering teams and can build and contribute to architecting a system that serves millions of users worldwide As an engineering leader you are excited about working in an environment that fosters innovation via prototyping development experimentation and productionalization You will bring the right balance between rapid feature iteration and building a common set of platforms and tools to move quickly in the future   Responsibilities     Architect build and scale a recommendation system that powers a state of the art personalization experience to users across Max HBO Discovery and other WBD offerings  Collaborate with other MLOps engineers to develop and improve core components infrastructure and architecture to train deploy and serve models at scale  Lead architecture improvements for our personalization services and infrastructure  Collaborate with data scientists engineers product teams and other key stakeholders and drive ML projects from conception to completion  Author test review and optimize productionlevel code in Python Go and Java while executing best practices in version control and code integration  Use and build upon opensource cloud computing technologies  Participate and support engineering leaders in strategic planning and demonstrate good judgment in setting and delivering against strategic goals for the team  Mentor influence engineers across organizations and lead by example with high quality examples of your work at the organization level  Motivate inspire and create a culture of experimentation and datadriven innovation while constantly striving to be an advocate for doing what is right for our customers    Requirements   6 years of industry experience with 3 years as tech lead experience preferred  Deep practical knowledge of large scale recommender systems or large scale ML rankingretrievaltargeting systems  Knowledge of largescale distributed application architecture design implementation and performance tuning     Good practical knowledge in modern machine learning lifecycle  5 years of programming experience using PythonJava with ability to rapidly prototype ideas and refine towards production  Ability to drive roadmap and directions of scalable production quality systems endtoend  Excellent written and verbal communications skills be comfortable presenting to large audiences     Advanced degree MS or PhD or equivalent industry experience in software engineering computer science machine learning or related fields    How We Get Things Done…   This last bit is probably the most important Here at WBD our guiding principles are the core values by which we operate and are central to how we get things done You can find them at wwwwbdcomguidingprinciples along with some insights from the team on what they mean and how they show up in their day to day We hope they resonate with you and look forward to discussing them during your interview   The Legal Bits… In compliance with local law we are disclosing the compensation or a range thereof for roles in locations where legally required Actual salaries will vary based on several factors including but not limited to external market data internal equity location skill set experience andor performance Base pay is just one component of Warner Bros Discovery’s total compensation package for employees Pay Range 14560000  27040000 salary per year Other rewards may include annual bonuses short and longterm incentives and programspecific awards In addition Warner Bros Discovery provides a variety of benefits to employees including health insurance coverage an employee wellness program life and disability insurance a retirement savings plan paid holidays and sick time and vacation   Warner Bros Discovery embraces the opportunity to build a workforce that reflects the diversity of our society and the world around us Being an equal opportunity employer means that we take seriously our responsibility to consider qualified candidates on the basis of merit without regard to race color religion national origin gender sexual orientation gender identity or expression age mental or physical disability and genetic information marital status citizenship status military status protected veteran status or any other category protected by law   If you’re a qualified candidate and you require adjustments or accommodations to search for a job opening or apply for a position please contact us at recruitadminwbdcom  ,\n",
       " Profile insightsFind out how your skills align with the job descriptionSkillsDo you have experience in VBAYesNoEducationDo you have a Masters degreeYesNo Job detailsHere’s how the job details align with your profilePay100000  110000 a yearJob typeFulltimeShift and schedule8 hour shiftDay shiftMonday to Friday LocationRemote Full job descriptionOverviewWe are seeking a skilled Statistician to join our team As a Statistician you will play a crucial role in analyzing and interpreting data to provide valuable insights and support decisionmaking processes This is an exciting opportunity to apply your expertise in statistical analysis and contribute to clinical quality measure CQM and electronic CQM eCQM development at CMS Duties Collect clean and organize large datasets for analysis Develop statistical models and algorithms to analyze data and identify trendspatterns Apply advanced statistical techniques to solve complex problems Collaborate with crossfunctional teams to design experiments and conduct hypothesis testing Create visualizations and reports to effectively communicate findings to stakeholders Stay uptodate with industry trends and advancements in statistical methodologies Requirements Masters degree in Statistics Mathematics or a related field Doctoral degree preferred Strong proficiency in statistical software eg R Python and programming languages eg SQL Java Experience with VBA Hadoop and machine learning techniques Knowledge of natural language processing and quantum engineering is a plus Solid understanding of experimental design hypothesis testing and regression analysis Excellent analytical skills with the ability to interpret complex data sets Strong attention to detail and problemsolving abilities Effective communication skills to present findings to both technical and nontechnical stakeholders Join our dynamic team of statisticians and contribute your expertise to drive datainformed decisions We offer competitive compensation packages professional development opportunities and a collaborative work environment Apply now to be part of our innovative team Job Type Fulltime Pay 10000000  11000000 per year Experience level  7 years  Schedule  8 hour shift Day shift Monday to Friday  Work Location Remote ,\n",
       " Profile insightsFind out how your skills align with the job descriptionSkillsDo you have experience in UNIXYesNoEducationDo you have a Masters degreeYesNo Location2225 Lawson Ln Santa Clara CA 95054 BenefitsPulled from the full job description401k matchingEmployee stock purchase planFamily leaveFlexible spending accountHealth insurance Full job description Company Description  At ServiceNow our technology makes the world work for everyone and our people make it possible We move fast because the world can’t wait and we innovate in ways no one else can for our customers and communities By joining ServiceNow you are part of an ambitious team of change makers who have a restless curiosity and a drive for ingenuity We know that your best work happens when you live your best life and share your unique talents so we do everything we can to make that possible We dream big together supporting each other to make our individual and collective dreams come true The future is ours and it starts with you With more than 7700 customers we serve approximately 85 of the Fortune 500® and were proud to be one of FORTUNE 100 Best Companies to Work For® and Worlds Most Admired Companies™ Learn more on Life at Now blog and hear from our employees about their experiences working at ServiceNow Unsure if you meet all the qualifications of a job description but are deeply excited about the role We still encourage you to apply At ServiceNow we are committed to creating an inclusive environment where all voices are heard valued and respected We welcome all candidates including individuals from nontraditional varied backgrounds that might not come from a typical path connected to this role We believe skills and experience are transferrable and the desire to dream big makes for great candidates Job Description   Experience in quality assurance andor application development Strong test automation skills in Java  Python Handson experience testing largescale production systems in Python or Java Excellent communication collaboration reporting analytical and problemsolving skills Ability to take a project from scoping the requirements and building the test cases Maintain existing automation test frameworks Familiarity with testing AIML models and evaluation of the model quality Ability to analyze results from the test set and create defects based on result patterns Work with developers to design specific testing strategies for features being developed and automate them Create comprehensive test plans execute and automate them Support engineering organizations in troubleshooting or addressing issues with applications and devtest environments    Qualifications   Bachelors in Computer Science  Computer Engineering or related subjects with 3 years of work experience Masters in Computer Science  Computer Engineering or related subjects with 2 years of work experience 2 years of experience with technologies relevant to SN and coding skills with highquality results Experience working within different automated testing frameworks including Java JUnit Python Selenium TestNG and other opensource projects Experience with the agile methodology for software development teams Ability to understand several testing techniques eg performance unit integration automated their strengths and weakness and ability to use them to best effect  including tracking and addressing of any discovered issues Ability to use tools such as IDE debugger build tools source control ServiceNow instances profilers system administrationUnix tools to assist with daily tasks For positions in the Bay Area we offer a base pay of 121600  188400 plus equity when applicable variableincentive compensation and benefits Sales positions generally offer a competitive On Target Earnings OTE incentive compensation structure Please note that the base pay shown is a guideline and individual total compensation will vary based on factors such as qualifications skill level competencies and work location We also offer health plans including flexible spending accounts a 401k Plan with company match ESPP matching donations a flexible time away plan and family leave programs subject to eligibility requirements Compensation is based on the geographic location in which the role is located and is subject to change based on work location    Additional Information  ServiceNow is an Equal Employment Opportunity Employer All qualified applicants will receive consideration for employment without regard to race color creed religion sex sexual orientation national origin or nationality ancestry age disability gender identity or expression marital status veteran status or any other category protected by law At ServiceNow we lead with flexibility and trust in our distributed world of work Click here to learn about our work personas flexible remote and requiredinoffice If you require a reasonable accommodation to complete any part of the application process or are limited in the ability or unable to access or use this online application process and need an alternative method for applying you may contact us at talentacquisitionservicenowcom for assistance For positions requiring access to technical data subject to export control regulations including Export Administration Regulations EAR ServiceNow may have to obtain export licensing approval from the US Government for certain individuals All employment is contingent upon ServiceNow obtaining any export license or other approval that may be required by the US Government Please Note Fraudulent job postingsjob scams are increasingly common Click here to learn what to watch out for and how to protect yourself All genuine ServiceNow job postings can be found through the ServiceNow Careers site   From Fortune © 2022 Fortune Media IP Limited All rights reserved Used under license Fortune and Fortune Media IP Limited are not affiliated with and do not endorse products or services of ServiceNow  ,\n",
       " Profile insightsFind out how your skills align with the job descriptionSkillsDo you have experience in SQLYesNoEducationDo you have a Masters degreeYesNo Job detailsHere’s how the job details align with your profileJob typeFulltime LocationRemote BenefitsPulled from the full job description401k matchingDental insuranceHappy hourHealth insurancePaid time offTuition reimbursementVision insurance Full job description Founded in 2003 IT Concepts’ core values – customercentricity teamwork driven to deliver innovation and integrity – ensure we work together to be the best realize objectives and make a positive impact in our communities We intentionally created and sustain our ITC culture that embraces change experimentation continuous learning and improvement We bring our design thinking problem solving approach that challenges assumptions prioritizes curiosity and invites complexity to deliver innovative efficient and effective solutions As we continue to grow in the support of our government customers we are looking for driven and innovative individuals to join our team  IT Concepts Inc ITC is seeking an experienced Data Scientist to join our team of diverse technical professionals to assist the Department of Veterans Affairs VA in analyzing clinical data and Informatics solutions delivered to the VA enterprise to support organizational learning and a HighReliability Organization  The qualified applicant will become part of ITC’s team supporting our Department of Veterans Affairs client The candidate should be skilled in reporting and analytics tools and methods and communicate effectively with executive leadership  Responsibilities  Develops and manages information to support strategic decisionmaking Performs complex analyses and communicates findings to business owners and senior leaders Conducts and facilitates and educates and trains on analyses data research data manipulation risk assessment solution development and strategic alignment Provides consulting and analytic services to leadership Provides technical support mentoring and training to less senior analysts Collaborates with crossfunctional teams to develop data visualizations with meaningful insights Analyzes and interprets data trends and patterns with performance objectives in mind Defines data assets to develop performance measurements key performance indicators and objectives and key results   Requirements   BS degree plus 9 years of relevant experience or a Master’s degree plus 7 years of relevant experience or a Doctoral degree plus 5 years of relevant experience Relevant experience creating and analyzing clinical data and creating data visualizations that communicate clinical outcomes improvements and costs   Excellent written and oral communication skills must provide examples if chosen for an interview Must have experience with  Creating custom reports using Power BI Power BI pipelines SQL Python R DAX   Preferred  Experience in Agile SAFe Agile VA experience VistACPRS a plus  Clearance Requirements  Must be able to obtain and maintain a public trust clearance  Benefits  The Company  We believe in generating success collaboratively enabling longterm mission success and building trust for the next challenge With you as our partner let’s solve challenges think innovatively and maximize impact As a valued member of our team you have the unique opportunity to work in a diverse range of technology and business career paths all while supporting our nation and delivering innovative technology solutions We are a close community of experts that pride ourselves on creating an environment defined by teamwork dedication and excellence We hold three ISO certifications 270012013 2000012011 90012015 and two CMMI ML 3 ratings DEV and SVC Industry Recognition Growth  Inc 5000’s Fastest Growing Private Companies DC Metro List Fastest Growing Washington Business Journal Fastest Growing Companies Top Performing Small Technology Companies in Greater DC Culture  Northern Virginia Technology Council Tech 100 Honoree Virginia Best Place to Work Washington Business Journal Best Places to Work Corporate Diversity Index Winner – MidSize Companies Companies Owned by People of Color Department of Labor’s HireVets for our work helping veterans transition SECAF Award of Excellence finalist Victory Military Friendly Brand Virginia Values Veterans V3 Cystic Fibrosis Foundation Corporate Breath Award  Benefits  We offer great benefits – Competitive Paid Time Off Medical Dental and Vision Insurance Identity Theft Protection Legal Resources Coverage 401k with company matching with NO vesting period ITC Health benefits have a 0 premium for certain plans for eligible employees We invest in our employees – Every employee is eligible for education reimbursement for certifications degrees or professional development Reimbursement amounts may fluctuate due to IRS limitations We want you to grow as an expert and a leader and offer flexibility for you to take a course complete a certification or other professional growth and networking We are committed to supporting your curiosity and sustaining a culture that prioritizes commitment to continuous professional development We work hard we play hard ITC is committed to incorporating fun into every day We dedicate funds for activities – virtual and inperson – eg we host happy hours holiday events fitness  wellness events and annual celebrations In alignment with our commitment to our communities we also host and attend charity galasevents We believe in appreciating your commitment and building a positive workspace for you to be creative innovative and happy  AAEO  VEVRAA  ITC is an Affirmative ActionEqual Opportunity employer and a VEVRAA Vietnam Era Veterans Readjustment Assistance Act Federal Contractor As such any personnel decisions hire promotion job status etc on applicants andor employees are based on merit qualifications competence and business needs not on race color citizenship status national origin ancestry sexual orientation gender identity age religion creed physical or mental disability pregnancy childbirth or related medical condition genetic information of the employee or family member of the employee marital status veteran status political affiliation or any other factor protected by federal state or local law ITC maintains a strong commitment to compliance with VEVRAA and other applicable federal state and local laws governing equal employment opportunity We have developed comprehensive policies and procedures to ensure our hiring practices align with these requirements As a part of our VEVRAA compliance efforts ITC has established an affirmative action plan that outlines our commitment to the recruitment hiring and advancement of protected veterans This plan is regularly reviewed and updated to ensure its effectiveness We encourage protected veterans to selfidentify during the application process This information is strictly confidential and will only be used for reporting and compliance purposes as required by law Providing this information is voluntary and it will not impact your eligibility for employment Our commitment to equal employment opportunity extends beyond legal compliance We are dedicated to fostering an inclusive workplace where all employees including protected veterans are treated with dignity respect and fairness  How to Apply  To apply to IT Concept Positions Please click on the “Apply for this Job” button at the bottom of this Job Description or the button at the top “Application” Please upload your resume and complete all the application steps You must submit the application for IT Concepts to consider you for a position If you need alternative application methods please email careersuseitccom and request assistance  Accommodations To perform this job successfully an individual must be able to perform each essential duty satisfactorily Reasonable Accommodations may be made to enable qualified individuals with disabilities to perform the essential functions If you need to discuss reasonable accommodations please email careersuseitccom   ,\n",
       " Profile insightsFind out how your skills align with the job descriptionLicensesDo you have a valid Secret Clearance licenseYesNoSkillsDo you have experience in Statistical analysisYesNoEducationDo you have a Bachelors degreeYesNo Job detailsHere’s how the job details align with your profilePay150000  180000 a yearJob typeFulltime LocationSan Diego CA 92101 Full job description ActioNet has an opportunity for a Data Scientist requiring a Secret clearance located in San Diego County CA ActioNet is an IT service provider and solutions integrator headquartered in Vienna VA that works with the Federal Government and Department of Defense In this role you will  Salary Range 150K180K  As the Data Scientist your tasks will include   Work with stakeholders throughout the organization to identify opportunities for leveraging MCTSSA data to drive business solutions  Mine and analyze data from MCTSSA databases to drive optimization and improvement of product development marketing techniques and business strategies  Assess the effectiveness and accuracy of new data sources and data gathering techniques  Develop custom data models and algorithms to apply to data sets  Use predictive modeling to increase and optimize customer experiences revenue generation ad targeting and other business outcomes  Develop data testing framework and test model quality  Coordinate with different functional teams to implement models and monitor outcomes  Develop processes and tools to monitor and analyze model performance and data accuracy  Conduct data transformation   Basic Qualifications   Ability to apply Data Scientist expertise through technology processes methodologies standards or frameworks  Expertise in applying Data Scientist tools and developing methodologies in an integrated test andor garrison environment  Experience using statistical computer languages R Python SLQ etc to manipulate data and draw insights from large data sets  Experience with programming languages such as C C Java JavaScript etc  Experience working with and creating data architectures  Experience using machine learning techniques clustering decision tree learning artificial neural networks etc and identifying realworld advantages and drawbacks  Experience using advanced statistical techniques and concepts regression properties of distributions statistical tests and proper usage etc      Desired Position Qualifications     Bachelor’s degree in computer science Statistics Mathematics Computer Engineering or related field  Knowledge and experience in statistical and data mining techniques  Experience with distributed data and computing tools  Experience creating and using advanced machine learning algorithms and statistics regression simulation scenario analysis modeling clustering decision trees neural networks etc  Experience visualizing and presenting data for stakeholders   ,\n",
       " Profile insightsFind out how your skills align with the job descriptionSkillsDo you have experience in TableauYesNo Job detailsHere’s how the job details align with your profileJob typeFulltime LocationSan Francisco CA BenefitsPulled from the full job descriptionADD insuranceCaregiver leaveDental insuranceEmployee stock purchase planFlexible spending accountHealth insuranceHealth savings accountShow morechevron down Full job description Company Description  It all started with an idea at Block in 2013 Initially built to take the pain out of peertopeer payments Cash App has gone from a simple product with a single purpose to a dynamic ecosystem developing unique financial products including AfterpayClearpay to provide a better way to send spend invest borrow and save to our 47 million monthly active customers We want to redefine the world’s relationship with money to make it more relatable instantly available and universally accessible  Today Cash App has thousands of employees working globally across office and remote locations with a culture geared toward innovation collaboration and impact We’ve been a distributed team since day one and many of our roles can be done remotely from the countries where Cash App operates No matter the location we tailor our experience to ensure our employees are creative productive and happy  Check out our locations benefits and more at cashappcareers Job Description  Cash Security is a securityenabling engineering organization focused on scaling security as a discipline through innovation As a security team Security Governance develops implements and promotes frameworks and standards aimed at securing our customer’s data giving privacy and security considerations a voice across the organization and simplifying Cash’s securityrelated regulatory and compliance obligations  Governance Partners act as a bridge between the Cash App functional area they support and Leadership across security engineering and compliance teams to drive security enablement The Security Governance Partner for Cash App Machine Learning and Data Science MLDS works directly with the teams that build Cash App’s machine learning pipelines and infrastructure and the Cash data scientists to identify and communicate constraints and to evaluate potential solutions while partnering closely with MLDS Security Engineering to communicate requirements and shape the security posture of the MLDS organization  You will   Act as a security domain expert in partnership with Compliance Legal and Engineering  Collaborate deeply across roles and functions with Security Engineering Machine Learning Engineering and Modeling and Data ScienceBusiness Intelligence  Identify prioritize and balance security efforts with other objectives  Help Cash automate governance and compliance functions and develop reusable tools for common tasks using scripting languages like Python or data tools like Prefect  Participate in technical design discussions evaluate security properties of systems and services drive risk decisions and influence technical architecture  Understand challenges and roadblocks to achieving the desired security posture and push requirements to Security Engineering to drive longterm change  Develop implement and promote security standards and frameworks  Interpret and communicate security and compliance constraints to key stakeholders  Monitor applicable changes to security and privacy related laws regulations and industry standards with an eye towards Generative AI and other forwardlooking technologies    Qualifications  You have   3 years of experience leading projects or programs in a security environment  5 years working in a securityfocused role in a technologyheavy industry  Proficiency with at least one programming language eg Python Kotlin Java  Conceptual understanding of machine learning and data science tools and processes  Solid technical background with cloud computing architectures and security patterns  Ability to drive alignment and change in a matrixedenvironment with minimal supervision  Boundless curiosity persistence and a grounded approach to getting things done  Process orientation and an efficiency mindset to keep the organization unblocked and accountable to security  Working knowledge of one or more relevant compliance regulations such as SECFINRA CCPA CPRA GDPR PCI DSS SOX   Tech stack we use and teach   Java and Kotlin  Python  AWS GCP and Kubernetes  SQL Snowflake  Apache Spark  DynamoDB Kafka Apache Beam and Google DataFlow  Tableau Airflow Looker Mode Prefect  Tecton  Jupyter notebooks    Additional Information  Block takes a marketbased approach to pay and pay may vary depending on your location US locations are categorized into one of four zones based on a cost of labor index for that geographic area The successful candidate’s starting pay will be determined based on jobrelated skills experience qualifications work location and market conditions These ranges may be modified in the future  Zone A USD 148700  USD 223100 Zone B USD 141300  USD 211900 Zone C USD 133800  USD 200800 Zone D USD 126400  USD 189600   To find a location’s zone designation please refer to this resource If a location of interest is not listed please speak with a recruiter for additional information  Fulltime employee benefits include the following   Healthcare coverage Medical Vision and Dental insurance  Health Savings Account and Flexible Spending Account  Retirement Plans including company match  Employee Stock Purchase Program  Wellness programs including access to mental health 11 financial planners and a monthly wellness allowance  Paid parental and caregiving leave  Paid time off including 12 paid holidays  Paid sick leave 1 hour per 26 hours worked max 80 hours per calendar year to the extent legally permissible for nonexempt employees and covered by our Flexible Time Off policy for exempt employees  Learning and Development resources  Paid Life insurance ADD and disability benefits   These benefits are further detailed in Blocks policies This role is also eligible to participate in Blocks equity plan subject to the terms of the applicable plans and policies and may be eligible for a signon bonus Sales roles may be eligible to participate in a commission plan subject to the terms of the applicable plans and policies Pay and benefits are subject to change at any time consistent with the terms of any applicable compensation or benefit plans  We’re working to build a more inclusive economy where our customers have equal access to opportunity and we strive to live by these same values in building our workplace Block is a proud equal opportunity employer We work hard to evaluate all employees and job applicants consistently without regard to race color religion gender national origin age disability veteran status pregnancy gender expression or identity sexual orientation citizenship or any other legally protected class  We believe in being fair and are committed to an inclusive interview experience including providing reasonable accommodations to disabled applicants throughout the recruitment process We encourage applicants to share any needed accommodations with their recruiter who will treat these requests as confidentially as possible Want to learn more about what we’re doing to build a workplace that is fair and square Check out our ID page  Additionally we consider qualified applicants with criminal histories for employment on our team assessing candidates in a manner consistent with the requirements of the San Francisco Fair Chance Ordinance    We’ve noticed a rise in recruiting impersonations across the industry where individuals are sending fake job offer emails Contact from any of our recruiters or employees will always come from an email address ending with blockxyz squareupcom tidalcom or afterpaycom clearpaycouk  Block Inc NYSE SQ is a global technology company with a focus on financial services Made up of Square Cash App Spiral TIDAL and TBD we build tools to help more people access the economy Square helps sellers run and grow their businesses with its integrated ecosystem of commerce solutions business software and banking services With Cash App anyone can easily send spend or invest their money in stocks or Bitcoin Spiral formerly Square Crypto builds and funds free opensource Bitcoin projects Artists use TIDAL to help them succeed as entrepreneurs and connect more deeply with fans TBD is building an open developer platform to make it easier to access Bitcoin and other blockchain technologies without having to go through an institution  While there is no specific deadline to apply for this role on average US open roles are posted for 70 days before being filled by a successful candidate  ,\n",
       " Profile insightsFind out how your skills align with the job descriptionSkillsDo you have experience in SQLYesNoEducationDo you have a Masters degreeYesNo LocationLancaster PA 17602 Full job description Clark Associates a distinguished leader in the foodservice equipment and supplies industry is seeking a dedicated and visionary individual to join our Augmented Inventory Management AIM team As the foremost and rapidly expanding foodservice equipment and supplies dealer in the USA we leverage a network of over 20 strategically positioned national distribution centers to promptly deliver an extensive catalog of 70000 products to our valued customers within an efficient 12 business day timeframe   Role Overview  As a member of our Augmented Inventory Management team you will play a pivotal role in shaping the future of inventory management within our dynamic organization This team composed of highly analytical professionals is at the forefront of employing cuttingedge techniques to streamline decisionmaking processes enhance accuracy and achieve remarkable scalability through the integration of machine learning technologies   Responsibilities   Model Development Create advanced statistical and machine learning models that optimize inventory management processes fostering efficient allocation and utilization of resources  Collaboration Interface with stakeholders in procurement and operations to devise systematic solutions for intricate inventory management challenges  Continuous Enhancement Research and implement enhancements to existing models keeping abreast of emerging methodologies in the field  Actionable Insights Extract meaningful insights from data and formulate actionable recommendations that tangibly bolster the companys financial performance  Solution Validation Implement robust monitoring mechanisms to validate the efficacy of deployed solutions    Minimum Qualifications   Experience Over 3 years of practical experience using SQL and optimizationstatisticalmachine learning programming Python preferred R and Matlab accepted  Education Bachelors degree in operations research data science statistics or a closely related quantitative field alternatively over 4 years of experience with an optimization data research or applied science team  Adaptability Demonstrated ability to swiftly acclimate to evolving environments rapidly learn new skills and apply them to intricate problemsolving scenarios    Preferred Qualifications   Supply Chain Expertise Familiarity with supply chain and warehouse stock optimization practices  Operations Research Experience Familiarity with building optimization models Eg ORTools CPLEX  Forecasting Acumen Exposure to time series forecasting models  Reporting Proficiency Experience with reporting tools like Power BI and Excel for sharing results  Communication Exceptional written and verbal communication skills with the ability to translate technical processes for nontechnical audiences  Advanced Education Masters degree in data science statistics operations research industrial engineering or a closely related highly quantitative field    Remote work qualifications   Access to a reliable and secure highspeed internet connection Cable or fiber internet connections at least 75mbps download10mbps upload are preferred as satellite connections often cannot support the technologies used to perform daytoday tasks  Access to a home router and modem  A dedicated home office space that is noise and distractionfree The space should have strong wireless connection or a wired Ethernet connection wired connection is preferred if possible  A valid physical address apartment suite etc PO Boxes are not supported as a physical address is required for you to receive your computer equipment  The desire and ability to work and communicate with other team members via chat webcam etc  Legal residents of one of the following states  H1B Visa Sponsorship Not Available W2 only   ,\n",
       " Profile insightsFind out how your skills align with the job descriptionSkillsDo you have experience in PythonYesNoEducationDo you have a Masters degreeYesNo LocationSeattle WA BenefitsPulled from the full job descriptionDental insuranceEmployee stock purchase planHealth insuranceRSURetirement plan Full job description Summary   Posted Mar 1 2024    Role Number200540711   Apple is where individual imaginations gather together committing to the values that lead to great work Every new product we build service we create or Apple Store experience we deliver is the result of us making each other’s ideas stronger That happens because every one of us shares a belief that we can make something wonderful and share it with the world changing lives for the better It’s the diversity of our people and their thinking that inspires the innovation that runs through everything we do When we bring everybody in we can do the best work of our lives Here you’ll do more than join something  you’ll add something Apple Vision Pro is a revolutionary spatial computer that seamlessly blends digital content with your physical space It will allow us to do the things we love in ways never before possible  all while staying connected to the people around us In this position you will join a team of computer vision and machine learning researchers and engineers to discover and build solutions to previouslyunsolved challenges and push the state of the art We are looking for a selfdriven and motivated computer visionmachine learning engineer experienced in applying machine learning to mobile computer vision algorithms As a member of a fastpaced prototyping team you have the unique and rewarding opportunity to shape upcoming products that will delight and inspire millions of people every day    Key Qualifications    Track record of successfully building and shipping products  Strong experience in mobile machine learning and pipelining  Strong experience in 3D geometry and computer vision  Experience in 3D Reconstruction is a plus  Experience in modern Novel View Synthesis methods suchas NeRF Gaussian Splatting etc is a plus  Excellent coding skills  Excellent communication and collaboration skills  Excellent problem solving and analytical thinking skills  Creativity and curiosity for solving highly complex problems  Experience in Python and C Experience with GPU programming or Metal is a plus      Description   You’ll be working in a team of computer vision and machine learning researchers and engineers to prototype and ship world class algorithms that pushes the state of the art Your job responsibilities will include Inventing and implementing state of the art computer vision algorithms to solve cutting edge problems Designing such algorithms to work reliably and efficiently on mobile devices Collaborating with other teams in software and hardware to ensure the full pipeline runs efficiently and utilizes Apple hardware effectively Cooperating with your teammembers to prepare presentations papers and talks to explain your inventions    Education  Experience   MS or PhD in computer vision machine learning computer science computer engineering or relevant industry experience with a track record of successful projects    Additional Requirements   Pay  Benefits      At Apple base pay is one part of our total compensation package and is determined within a range This provides the opportunity to progress as you grow and develop within a role The base pay range for this role is between 13150000 and 24330000 and your base pay will depend on your skills qualifications experience and location  Apple employees also have the opportunity to become an Apple shareholder through participation in Apple’s discretionary employee stock programs Apple employees are eligible for discretionary restricted stock unit awards and can purchase Apple stock at a discount if voluntarily participating in Apple’s Employee Stock Purchase Plan You’ll also receive benefits including Comprehensive medical and dental coverage retirement benefits a range of discounted products and free services and for formal education related to advancing your career at Apple reimbursement for certain educational expenses  including tuition Additionally this role might be eligible for discretionary bonuses or commission payments as well as relocation Learn more about Apple Benefits  Note Apple benefit compensation and employee stock programs are subject to eligibility requirements and other terms of the applicable plan or program  Apple is an equal opportunity employer that is committed to inclusion and diversity We take affirmative action to ensure equal opportunity for all applicants without regard to race color religion sex sexual orientation gender identity national origin disability Veteran status or other legally protected characteristics    ,\n",
       " Jessica    Claire                                   609 Johnson Ave       49204     Tulsa     OK   100 Montgomery St 10th Floor    H   555 4321000    C       resumesampleexamplecom    Date of Birth         India                      single                    Summary      Logical Data Analyst skilled in requirement analysis software development and database management Selfdirected and proactive professional with 5 years of vast experience collecting cleaning and interpreting data sets Natural problemsolver possessing strong crossfunctional understanding of information technology and business processes        Skills           Query Tools  Analytical Problem Solving  Reporting Tools  Data Mining  Data Quality      Data Analysis  Data Visualization and Presentations  Database Programming and SQL  Linear and Logistic regression  R and Python                       Experience       Data Analyst        012022      Current     Granicus    –    Chicago     Il Or Denver            Conducted data analysis to prepare forecasts and identify trends  X13ARIMASEATS model to seasonal adjustment for time series analysis 2 delinquencies  Generated reports and obtained data to develop analytics on key performance and operational metrics  Partnered with data scientists to support ongoing research and analytics initiatives  Worked with internal teams to understand business needs and changing strategies  Created and designed business intelligence databases spreadsheets or outputs  Recommended metrics and models based on observed trends  Generated standard or custom reports summarizing business financial or economic data  Managed diverse projects for data capture storage and forecast analysis  Developed a new credit scoring matrix to target personal loans using linear and logistic predictive models  Machine learning using descriptive models in analyzing the internal scoring model for personal loans  Use descriptive analytics to implement new credit criteria for personal loans DebttoIncome ratio to Free Cash Flow  Experience using YeoJohnson Transformation and centerscale a vector to attempt normalization  Implemented internal reporting using power bi to Forecasting using 2  delinquency comparisons  Built compelling data stories and visualizations to influence decision makers           Data Specialist       022021      122021     Ascension Health    –    Wichita     KS            Worked with internal processes using various modeling and machine learning in R to analyze inpatient care to hospice  Generated customized reports on client data providing valuable insights into requested data points  Audited data regularly to guarantee data integrity and quality  Reconciled data to identify anomalies  Corrected data errors and entered missing information into new data parcels being processed for clients maintaining compliance with guidelines  Reviewed and updated account information in company computer system  Extracted imported and exported data into various database applications  Gathered data from multiple sources to assimilate meaningful inputs for databases  Created reports and audited charts to maintain concise records  Utilized Microsoft Power BI to create interactive and reporting dashboards used for internal operations  Developed and implemented a new payroll system using SSRS  Imported and implemented new data by creating a linked server with Microsoft SQL Server Management Studio           Report Developer       052020      102020     Cgi Group Inc    –    Springfield     VA            Monitored and reported on key performance indicators and shared results with management team  Assessed and prioritized departmental reporting needs functions and strategies and reported findings to management  Streamlined reporting processes by evaluating data sources compiling data and redesigning output  Drafted and formatted reports in alignment with data quality requirements           Data Analyst       102017      032020     Granicus    –    Columbus     OH            Audited internal data and processes to identify and manage initiatives improving business performance  Generated reports and obtained data to develop analytics on key performance and operational metrics  Created impactful business reports utilizing large datasets and Crystal Reports SQL and MS Excel  Worked in a close team to build data support and report generation used for both internal and external reporting  Assisted in the administration and auditing of SQL databases  Created and maintained custom queries views and stored procedures using TSQL for data and driven datasets  Assisted in change management validation and verification to ensure data quality  Managed Crystal to distribute daily weekly and monthly reports and dashboards for internal clients  Generated standard or custom reports summarizing business financial or economic data          Education and Training       Bachelor of Science       Business Administration – MIS       Expected in   052017                Utah Tech University       St George UT          GPA        Status                  Master of Science       Business Analytics       Expected in                   University of Utah      Salt Lake City     UT     GPA        Status                 Technical Skills  Certifications       Microsoft Technology Associate in Database Administration Fundamentals  Predictive analytics R and Python Machine learning Modeling using KNN linear and logistic regression X13ARIMASEATS  Crystal Reports Business Objects SSRS TSQL MYSQL server 2008 Oracle plsql,\n",
       " Jessica    Claire                        San Francisco     CA      609 Johnson Ave       49204     Tulsa     OK       H   555 4321000    C       resumesampleexamplecom    Date of Birth         India                      single                    Accomplishments       Diversity Committee at University of Illinois at UrbanaChampaign  PROJECT LEAD Data Visualization Final Course Project CONSULTANT Business Intelligence Group School of Information Sciences INFORMATION TECHNOLOGY LEAD Association for Computing Machinery INSTRUCTOR Jeevan Jyot NGO Mumbai India Projects Yelp Data Analysis University of Illinois at UrbanaChampaign          Jan  2018  Apr2018 Built a simple text classifier using Pythons Pandas NLTK and Scikitlearn libraries  Created a sentiment analysis model that predicts whether a user liked a local business or not based on their review on Yelp  Performed analysis on businesses as well as users data and outlined the analysis using interactive visualizations in python  Evaluating Thought Leadership in Insurance University of Illinois at UrbanaChampaign   Oct  2017  Dec  2017 Helped the client in Accessing Thought Leadership Reports of their Competitors in the Insurance industry  Performed regressive analysis of the reports generated visualizations to depict complex data and processes  Data Visualization Final Course Project UIUC          Sep  2017  Dec 2017 Designed dashboards to display visualizations with interactive components of IPywidgets  Performed data aggregation and audio integration using Python  Distributed Document Clustering Using a Hybrid Approach University of Mumbai Sept  2016  Apr  2017 Developed a Hybrid algorithm comprising of KMeans Particle Swarm Optimization PSO Latent Semantic IndexingLSI Algorithms for distributed clustering of documents  Used Hadoop MapReduce Framework for clustering 20000 documents 20NewsGroups and 21578 documents Reuters21578 on single and multiple nodesmachines  Android Joystick Shri Bhagubhai Mafatlal Polytechnic          Sept  2013  Apr  2014 Developed an Android Application that turned smart phones into Computer Remote Controllers to allow users to wirelessly operate a remote desktop via Bluetooth connectivity  Provided different features for customizing the controller for user flexibility and comfort         Professional Summary      Experienced Data Analyst committed to maintaining cutting edge technical skills and uptodate industry knowledge        Skills           Python and R  proficient  Tableau Power BI  SQL MySQL Hadoop  Microsoft Excel proficient  Excellent communication skills      Photoshop SharePoint Adobe Creative  Suite  HTML5 CSS3 JavaScript  Java Android  Excellent problemsolving abilities                       Work History       Data Analyst       012018      Present         –    Long Island City                 Implementing data preprocessing using python to clean a dataset containing over million entries and generating valuable insights from the clean dataset through visualizations  Using Natural Language Processing toolkit NLTLK package to perform topic segmentation and analyzing the trends in equipment features over years at John Deere  Using Google Analytics to analyze data of the mobile applications and make data driven decisions to improve customer support and experience           Technology Consultant       012018      Present     Jones Lange Lasalle Inc    –                     Providing strategic consulting for a leading company in the electrical data networking industry to implement a governance framework on their intranet portal  Developing a business model for the client to improvise their intranet design optimizing item placement usability and searchability           Data Analyst Intern       112017      012018     Hewlett Packard Enterprise    –                     Worked with AACSB process manager for data extraction and cleaning using R and analyzed the data using descriptive visualizations in Tableau  Compiled information on faculty activities collected data for surveys performed data quality control activities using Microsoft Excel  Transformed the data using data wrangling in a format specified by the management           Application Developer and Content Management Intern       122015      012016     Do It Best Corp    –              India       Interacted with senior professionals to develop and design business processes to enhance the functionality of the Android application  Implemented the business processes on the backend using JSON  Used Tableau for data collected from multiple sites to generate insights for the senior professionals to carry out decision making          Certifications     Data Visualization Applied Business Research Data Statistics  Information Big Data Analytics Cloud computing Data Mining  Business Intelligence Data Structure  Algorithms Advanced Database Management Systems Software Project Management Programming for Analytics and Data Processing Competitive Intelligence  Knowledge Management        Education       MS       Information Management       Expected in   Dec 2018                University of Illinois      Urbana Champaign     IL     GPA        Status         Information Management GPA 350         BE       Information Technology       Expected in   May 2017                University of Mumbai      Mumbai          GPA        Status         Information Technology GPA 395         Diploma       Information Technology       Expected in   May 2014                Shri Bhagubhai Mafatlal Polytechnic                GPA        Status         Information Technology GPA 375        Publications     Published a technical paper on the project Android Joystick IJARCCE Journal Vol 5Issue11 Nov 2016       Skills     Adobe Illustrator Photoshop Big Data BI Business Intelligence business processes Business Research Competitive Intelligence consulting CSS3 Client customer support Data Processing Data Mining Data Modelling Data Visualization Database Management decision making features Google Analytics HTML5 Java JavaScript JSON Knowledge Management lEADERSHIP Microsoft Excel Microsoft Office SharePoint MySQL Natural Language Processing networking Programming Project Management Python quality control SQL Statistics strategic surveys Tableau,\n",
       " Jessica    Claire               Montgomery Street       San Francisco     CA  94105    609 Johnson Ave       49204     Tulsa     OK      Home   555 4321000        Cell           resumesampleexamplecom                  Professional Summary     Highly motivated Sales Associate with extensive customer service and sales experience Outgoing sales professional with track record of driving increased sales improving buying experience and elevating company profile with target market       Core Qualifications         Customer Service Focused        SAP Experience Organized          Team leadership Typing 60 WPM          Process implementation Data management          Microsoft Office Suite Staff development          Microsoft Outlook                       Experience      102012   to   Current     Data Analyst          –    Nashua     NH             Complete weekly financial reporting for multiple agents and upper management Calculate and disburse large dollar weekly funding to agent companies Load and maintain agent and customer contract information into our systems Internal and external customer service Field inbound calls from customers Process outgoing and incoming mailings Process customers credit card ACH and check payments Respond to and track all credit chargebacks for our department within a tracking system I designed with IT team Respond promptly and accurately to email ticketing requests Created Spartas first employee manuals including training and development Trained new employees and outside users on our PBS system Assist with meeting schedules and travel arrangements for the CIO Oversaw daily office operations for Sparta Performed accounts receivable duties including invoicing researching chargebacks discrepancies and reconciliations Review multiple reports to determine the status of collections and agent reserve balances Effectively communicate with sales marketing management and administrative teams on a daily basis Ensure superior customer experience by addressing customer concerns demonstrating empathy and resolving problems on the spot Direct calls to appropriate individuals and departments          122009   to   102012     Inventory Planner      Lockheed Martin Corporation    –                      Bel Ridge M O Proactively managed multiple supplier lines for over two hundred locations within the SAP system Monitored inventory and placed orders to ensure proper stocking levels were maintained Managed a major line conversion from Metallics to LH  Dottie Worked with branch district and corporate management on key inventory aspects Achieved and maintained exceptional performance numbers Internal and external customer service Completed new stock recommendation workflows Worked closely with suppliers to obtain special deals Developed and improved vendor relationships Reviewed forecasts and various reports to maintain proper inventory levels Eliminated excess and unwanted merchandise by working with suppliers to secure returns of DNO materials Recruited to Corporate Purchasings Training Group in charge of training new employees and revamping training manuals Accepted into the Corporate Purchasing Leadership program LEAP designed to foster and develop future company leaders Member of the Positive Outlook Program POP responsible for organizing employee morale building events Assisted with planning and scheduling internal employee blood drives with the American Red Cross          122007   to   122009     Purchasing Assistant      Assurant    –              Bel        Expedited purchase orders Tracked inventory shipments Internal and external customer service Completed new stock recommendation workflows Prepared spreadsheets detailing item information Communicated with vendors regarding inventory needs Entrusted to mentor new hire Purchasing Assistants Completed reporting for Inventory Planners Receptionist duties Compiled and maintained up to date company information and contacts          052006   to   122007     Office Assistant      Pacific Office Automation    –    La Jolla     CA             Receptionist duties Prepared statements for billing company Completed insurance precertifications Scheduled patient appointments Promptly answered all incoming phone calls Followed up on patient billing questions Acquired and maintained patient charts Enforced high level of patient and office confidentiality Managed several physicians daily appointments and workflow Developed training office and procedural documents Assisted in completing employee evaluations Created and managed employees weekly work schedules Managed inventory and office supplies Facilitated record retrieval and access by maintaining organized chart filing system Composed and drafted all outgoing correspondence and reports for physicians Oversaw daily office operations          Education      Expected in        Technical Diploma                          GPA               Expected in   March 2006     Medical Billing and Coding          SanfordBrown College      Collinsville     IL     GPA               Professional Affiliations              Skills     accounts receivable administrative billing charts conversion credit addressing customer concerns Customer Service Data management email filing financial reporting insurance Inventory inventory levels invoicing Leadership Team leadership marketing materials Medical Billing mentor access Microsoft Office Suite office Microsoft Outlook Outlook organizing Coding Purchasing Receptionist reporting researching sales SAP scheduling spreadsheets Staff development phone training manuals travel arrangements Typing 60 WPM workflow,\n",
       " Jessica    Claire                   Montgomery Street     San Francisco     CA  94105    609 Johnson Ave       49204     Tulsa     OK       Home   555 4321000    Cell       resumesampleexamplecom              Professional Summary     Qualitydriven leader successfully led crossfunctional teams in operations maintenance logistics and optimization activities  History of using innovative approached to production efficiency and accuracy including training programs and resource allocation 20 years of US Naval Aviation Logistic Experience including     Supply Chain and Warehouse Management     Financial Analyst     Lean Six Sigma – Green Belt      Inventory Analyst Manager     Quality Assurance and Auditor Lead     Aviation Consolidated Allowance List     Command Inspector Team Lead 12 years of Documented Superior Senior Leadership experience 5 years experience as a member of the Quality ImprovementAssurance Inspection Team Leader Recognized expert as a “Material Analyst”   Reviewed and analyzed usage trends for the consumable and repairable aircraft material  Set high and low material levels Created and updated as needed “Route Stop Spares” and Deployment packups for the Navy C130 and F18 platforms Located mission critical material by the utilizing resources such as  OneTouch DoD EMALL FEDLOG ILS Naval Aviation Control Point item managers and numerous commercial vendors Solicited quotes negotiated and procured material from commercial vendors Extensive Knowledge of the Naval Aviation Logistics Command Management Information System NALCOMIS MS Word Excel PowerPoint Access Relational Supply Base Level Item Tracking System Electronic Retrograde Management SystemERP  and Fund Administration and Standardized Document Automatic SystemFASTDATA Security Clearance Secret        Core Qualifications           Guest services  Inventory control procedures  Merchandising expertise      Loss prevention  Cash register operations  Product promotions                       Experience       Data Analyst       012009   to   Current     Nelnet    –                      for the Command Fleet Logistics Support Command  Gather information from numerous Naval Aviation Enterprise databases 15 squadrons and several other resources  Analyze and explained trends to created PowerPoint and Excel Current Readiness briefs for the Commodore to delivery up line to the Naval Aviation Admiral           Senior Leading Chief Petty Officer       011989   to   012009     US Navy    –                      for the Aviation Supply Department managed and mentored 56 Sailors Marines and Civilians with Program Management  and Logistic Specialists in support of  C130  FA18 Aircraft  AIMD Test Bench Maintenance Assist Modules and IMRLGround Equipment requirements  Participated in several Lean Six Sigma process Improvement Events  Tracked and analyzed the delivery time for material to be pulled from the warehouse shelf and delivered to the squadron  Increased delivery time by 20 by utilizing a second printer and having the repairable manager pull and stage the material  Completed a Six month Individual Augment assignment in Bagram Afghanistan  As the only Humanitarian Assistance HA Officer in Afghanistan managed a team of 4 Service Members and 20 local nationals to procure and distribute 9 million worth of critical HA supplies to families and villages throughout the country  Commander Naval Air Reserve Force Command  Aviation Supply Logistics Leading Chief Petty Officer  I was responsible for guiding and assisting over 400 personnel in 23 Reserve Squadrons AE6B C130 C130 FA18 and HELO with technical supply support  Successfully researched and resolved over 200 high priority “supply assist” requests a month  Thoroughly completed 10 Quality Inspection Visits and Quality Assist Visits to 5 Reserve Air Stations  Completed training for over 400 personnel and conducted process improve requirements for each site  Performed 4 Aviation Consolidated Allowance Lists for 3 air stations that supported the FA18 aircraft  Analyzed and projected repairable aircraft asset requirements for the next 2 years           Material Control Chief          to            –                      Researched and procured aviation material that supported the maintenance of repairable assets for C130 P3 and 2 FA18 squadrons  Assigned as the “Supply Assistance” expediter for fleet squadrons  I thoroughly researched the critical and hard to find aviation items by utilizing all available resources  ILS vendors item managers Material Control clerk  responsible for the ordering tracking of all material to support the squadron  Expedited the mission critical documents and maintained constant communication with station supply  Operating Target Manager  validated monthly financial reports ensured all charges were valid  Reviewed and analyzed spending trends for the Aircraft Operations and Maintenance AOM and Navy Working Capital Funds budgets  Developed several Excel charts and graphs as a tool to improve the financial metrics and spending          Education       Graduate          Expected in   1 1988     Anchor Bay High School      New Baltimore     MI     GPA       1988  Aviation Supply “A” School         1994  Hazardous Material Control Management Technician NEC 9595 1997  Primary Leadership Development Program 1999  Joint Aviation Maintenance Material Management Course 2000  Computer Peripheral Equipment Operator 2000hr Apprenticeship 2001  Advanced Leadership Development Program      Business Administration Economics     Expected in   1 2004     Northwood University                GPA       Relational Supply Force Advance Technical Specialist NEC 2830        Professional Affiliations              Skills     budgets C charts databases delivery financial Funds graphs hr Leadership Development Logistics Excel PowerPoint 2000 Navy Naval NEC Enterprise next 2 personnel printer process Improvement Program Management Quality Six Sigma Technician,\n",
       " Jessica    Claire                   Montgomery Street     San Francisco     CA  94105    609 Johnson Ave       49204     Tulsa     OK       H   555 4321000    C       resumesampleexamplecom    Date of Birth         India                      single                    Summary     tyee       Highlights         Microsoft Excel Word Outlook Power Point FileZilla QuickCap                       Accomplishments              Experience       Data Analyst       092015      062016     Altice Usa    –    Tyler     TX            Loading daily weekly or monthly enrollment files into QuickCap and performing a reconciliation on members added  subtracted vs  the previous file  Performing a monthly reconciliation on enrollment files vs  capitation payments  Performing a monthly reconciliation of per member per month utilization and costs by client  Creating canned and custom reports via Data Reporting Services with the assistance of the Director of Data Analytics for the purpose of analyzing all aspects of business performance           Security Analyst       092014      011     Cisco Systems Inc    –    MinneapolisSt Paul     MN            Allocated billions in trades by end of the day Monitor an average of 200 trade breaks daily with a 6070 settlement rate at end of day Traded confirmation and allocation to client sub accounts Ensure accuracy and timeliness of real time customer trade confirmations to clients Allocated monitored and settled across all global markets for equity and fixed income trades Manages exceptions relating to suballocated trades Created and analyzed report dashboards and metrics for various daily weekly and monthly reporting Facilitation of the account opening and documentation process with Operations           Site Supervisor       082010      012014     Bay City School District    –    Bay City     MI            Tutored Junior and High School students grades improved 20 following tutoring  Planned and scheduled monthly activities for afterschool programs and boxing gym           Customer Service Coordinator       052007      122010     Swift Refrigerated    –    Chicago     IL            Scored 100 on productivity and awarded best worker for the month  Assisted in car reservations and developed great customer service  Managed international and domestic car reservation portfolios          Education       Bachelor of Science       Economics French       Expected in   May 2014                Westminster College      Salt Lake City     UT     GPA        Status         Economics French Mens Soccer team  devoted 20 hours and gained valuable leadership and teambuilding experience  Fourth Year Senior Senator as a member of the Education SubCommittee worked with undeclared students to help determine their major         Associates of Science              Expected in   Jun 2012                Salt Lake City Community College      Taylorsville     UT     GPA        Status         Public Relations Officer assisted with college activities and marketing        Interests     Soccer Rugby Reading Travel  Fashion       Skills     client clients customer service documentation equity fixed income leadership teambuilding Director marketing Microsoft Excel Outlook Power Point Word Public Relations real time reporting tutoring       Additional Information       InterestsHobbies Soccer Rugby Reading Travel  Fashion,\n",
       " Jessica    Claire                   Montgomery Street     San Francisco     CA  94105    609 Johnson Ave       49204     Tulsa     OK       Home   555 4321000    Cell       resumesampleexamplecom              Summary      Experienced Data Analyst who responds to shifting business needs and priorities in a systematic and effective way  Excels at implementing operational assessments and conducting functional requirements analysis for businesses of all sized  Committed to maintaining cutting edge technical skills and uptodate industry knowledge        Skills           Technical help desk experience  Database design  Excellent communication skills  Strong analytical skills       Technical specification creation  LANWAN Network upgrades  Enterprise Technology  Excellent diagnostic skills  Crosstier components implementation                        Experience       Data Analyst       082016   to   092016     Lockheed Martin Corporation    –    Jacksonville     FL             Worked with SAP removing duplicatesWorked with CRM interface to correct dataAnalysis of customer dataAssisted with cleaning 442 000 customer account records  Extract Install Base data from the centralized repository and evaluateprioritize refresh opportunities based Developed and implemented complex Internet and Intranet applications on multiple platforms  Performed analysis and identified cost saving opportunities and potential program enhancements  Certificate of Completion  Architectural DraftingAutoCAD and Civil Engineering           Business Analyst       112015   to   072016     Halo Branded Solutions    –    Toledo     OH             Extracted Install Base data from the centralized repository and evaluateprioritize refresh opportunities  Packaged prioritized customer data for insidefield sales consumption   Managed research and reporting of customer install base for BDM Sales team  Created metrics associated with funnel build and conversion rates and value   General field and inside sales support   Daily use of SAP to pull serial data to create client reports  Daily use of Sales Force to create and maintain client account information  Excel used daily to analyse and create client reports   ​Microsoft Server used in conjunction with Access to pull large data sets for analytical reporting           Data Analyst       022009   to   072015     Lockheed Martin Corporation    –    San Antonio     TX             Excel and Access reports creation   Acted as a questionanswer source for client   Maintained client Database   Identified process inefficiencies through gap analysis   Performed monthly data cleanup of all Carrier invoices input into system   Recommended operational improvements based on tracking and analysis   Performed analysis and identified cost saving opportunities and potential program enhancements            Database Administrator       012006   to   012009     Lockheed Martin Corporation    –    Vineyard     UT             Acted as a questionanswer source for client  Was responsible for monthly analysis of data input  Analyzed and made recommendations on data when necessary  Was responsible for monthly metrics reports  Was responsible for process improvements  Was responsible for root cause and corrective action analysis          Accomplishments       Led a 6person team of multicountry analysts in completing a 400 million Asset Recovery project  Led team to meet 100 of SLAs by streamlining business processes and identifying areas for improvement  Boosted customer service ratings by 90 by developing new processes and improving work flow         Education and Training            Architectural Design     Expected in        New York Institute of Technology      New York     NY     GPA         Fine Arts coursework  Emphasis in Architectural Design  Arts Education coursework  Economics coursework  Computer Information Systems coursework  2D and 3D design coursework           Certificate of Completion     CAD     Expected in        Porter  Chester Institute      Stratford     CT     GPA         Emphasis on Automated Computer Aided Drafting  Coursework included Manual Drafting and Civil Engineering focus  Electrical Mechanical and Structural Engineering coursework  Computer Information Systems coursework  Construction training  2D and 3D design coursework  Course on Lighting Design,\n",
       " JC     Jessica    Claire                             San Francisco     CA    94105             555 4321000                 resumesampleexamplecom                         Experience        102019   to   062019   Data Analyst    Angi Homeservices Inc         Rockledge     FL            Built an end to end analyticsbased solution for animal shelters to verify optimality of current capacity with a vision to deliver recommendations to improve animal outcomes and health in the future  Created a cloudbased AWSFlaskHTML UI to source animal shelter data  present optimal solution  Utilized Delphi method to generate synthetic data for missing values using information from animal experts  Leveraged SQLPython to preprocess and optimize animal shelter data  Dealt with a tricky client with unclear outcomes and impacted by COVID19 times  yet delivered a complete extendable analytics UI solution  Predicted the outcome of animals with 73 accuracy based on characteristics of the animals at the time of intake            012019   to   062019   Analyst    Ameresco         Half Moon Bay          IND       Traders of import export licenses in India Operationalized and negotiated the pricesrate of various MEISSEIS by predicting the price of the MEISSEIS licenses using Timeseries analysis and supervised machine learning model resulting in savings of INR 1000000  Created a new billing system from scratch to increase efficiency and reduce time spent in creating bills using Excel VLOOKUP HLOOKUP and Formulas which resulted in time spent in creating bills reducing by 50            062018   to   092018   Analyst Intern    Spencer Stuart         Chicago          IND       Although junior quickly earned responsibility for creation of data architecture  automation for BSEs Mutual Funds  Processed 1 million weekly transactions to enable audits executive reporting  Presented to CXOs weekly          Work History        102019   to   062019   Data Analyst    UC Davis Koret Shelter Medicine       San Francisco     CA     Built an end to end analyticsbased solution for animal shelters to verify optimality of current capacity with a vision to deliver recommendations to improve animal outcomes and health in the future  Created a cloudbased AWSFlaskHTML UI to source animal shelter data  present optimal solution  Utilized Delphi method to generate synthetic data for missing values using information from animal experts  Leveraged SQLPython to preprocess and optimize animal shelter data  Dealt with a tricky client with unclear outcomes and impacted by COVID19 times  yet delivered a complete extendable analytics UI solution  Predicted the outcome of animals with 73 accuracy based on characteristics of the animals at the time of intake            012019   to   062019   Analyst    Sanghvi International Pvt Ltd       Mumbai IND          Traders of import export licenses in India Operationalized and negotiated the pricesrate of various MEISSEIS by predicting the price of the MEISSEIS licenses using Timeseries analysis and supervised machine learning model resulting in savings of INR 1000000  Created a new billing system from scratch to increase efficiency and reduce time spent in creating bills using Excel VLOOKUP HLOOKUP and Formulas which resulted in time spent in creating bills reducing by 50            062018   to   092018   Analyst Intern    MarketPlace Technologies Pvt Ltd Bombay Stock Exchange       Mumbai IND          Although junior quickly earned responsibility for creation of data architecture  automation for BSEs Mutual Funds  Processed 1 million weekly transactions to enable audits executive reporting  Presented to CXOs weekly          Accomplishments       Predicting Heart Disease Using Classification Trees  Used classification trees to predict whether a person has heart disease classifying those without heart disease True Negatives and with heart disease True Positives with accuracy rates of 81 and 85 respectively Car Brands Mapping  Built a position map for car brands using Principal Component Analysis PCA and Principal Component Regression PCR in R and gave recommendations as to what Infinity should do to improve its car design Airbnb in San Francisco Opportunities  Possibilities  Constructed a random forest classifier to discern aspects of a listing affecting ratings received on Airbnb  Built a linear regression model to understand factors affecting price of a rental on Airbnb ACTIVITIES  LEADERSHIP President IT Students Associations VIT July 2016  August 2017  Orchestrated 3 Python and 2 R workshops for over 250 student attendees and organized LAN gaming events with 300 participants Joint Sports Secretary Student Council VIT July 2016  August 2017  Led and managed a team of 100 volunteers and organized a 5day long Sports Festival with 28 events and 3000 entries         Education        Expected in   July 2018   Bachelor of Engineering       Information Technology    University of Mumbai Vidyalankar Institute of Technology     Mumbai           GPA                 Expected in   June   Master of Science       Business Analytics    University of California     San Francisco     CA      GPA               Summary     A motivated data enthusiast with 5 years of SQL and data analysis experience 3 years of ObjectOriented Programming experience and 2 years of Python and R experience Selftaught Machine Learning and Big Data and applied to various settings by taking 3 Coursera Courses 3 Udacity Courses 2 Udemy Courses and am an AWS Certified Cloud Practitioner Motivated to make a difference and hence currently analyzing publicly available animal shelter data       Highlights           Tools SQL Python Jupyter Notebook Flask R Tableau Spark MongoDB Excel HTML MapReduce  Skills AB Testing Data Analysis Database Management Data Mining Data Visualization Hypothesis Testing Modeling Machine Learning Statistical Analysis Dashboards  Automation  Billing system  Client      Data Analysis  Data Mining  Data Visualization  Database Management  Delphi  Funds  HTML  Machine Learning  Excel  Modeling  MongoDB  Python  Reporting  SQL  Statistical Analysis  Tableau  Vision                       Skills      Tools SQL Python Jupyter Notebook Flask R Tableau Spark MongoDB Excel HTML MapReduce  Skills AB Testing Data Analysis Database Management Data Mining Data Visualization Hypothesis Testing Modeling Machine Learning Statistical Analysis Dashboards  Automation billing system client Data Analysis Data Mining Data Visualization Database Management Delphi Funds HTML Machine Learning Excel Modeling MongoDB Python reporting SQL Statistical Analysis Tableau vision,\n",
       " Jessica  Claire                             resumesampleexamplecom                      555 4321000                       Montgomery Street     San Francisco     CA      94105                                                                                                                                                                                                             Summary     Seeking an accounting position with a corporation where my analytical customer service and problem solving skills will increase profitability Selfmotivated individual with the ability to multitask Driven hard worker with the ability to adapt to changing environments           Highlights       Microsoft Word Microsoft Excel PowerPoint QuickBooks and Peachtree                     Education       Texas Southern University    Houston     Texas      Expected in   May 2015     –      –       Bachelors of Business Administration        Accounting          GPA           Accounting         Houston Community College    Houston     Texas      Expected in   May 2010     –      –       Associate of Arts        Accounting          GPA           Accounting          Accomplishments              Experience       The Nielsen Company      Data Analyst   Atlanta     GA                   062015      Present     Critically evaluates information gathered from multiple sources reconciles conflicts classifies the information in logical categories  Uses different visualization techniques and present the results of data exploration exercises  Understands the flow of data business processestechnical interfaces that would be created or impacted  Identifies and documents sources of existing data as well as the new data  Understands use of master and reference data including sources and contributors           International Paper Company      Customer Service Supervisor   San Antonio     TX                   052015      062015     Drive the delivery of exceptional customer service Expedite front lines direct flow of customers Communicate customer requests to management Maintain appearance of register area and keep supplies stocked Monitor compliance of cashiers with established Company policies and standards Ensure the accuracy and efficiency in ringing sales Maintaining all cash and media at the registers Follow guidelines prescribed by the Customer ServiceLogistics Manager Ensure validity of customer returns exchanges check authorizations and voids Monitor all areas of possible loss           Hcl Technologies Ltd      Junior Analyst   Morris     NJ                   042015      042015     Documented client organizations direction structure business processes and requirements  Researched client organizations industry position  Assisted in the collection and consolidation of required information and data  Assisted with the preparation of an Audit certification in which the company passed           Keiser University      Administrative Assistant   Port Saint Lucie     FL                   012015      032015     Administrative support including answering telephones completing processing and purging  filing paperwork associated with client accounts with the as400 software           Archer Daniels Midland Company      Hardlines Sales Associate   Abilene     TX                   092014      012015     Provides exemplary customer service to all guests and patrons support with inventory merchandising           Aimbridge Hospitality      Accounting Intern   Plano     TX                   052012      072013     Operate computers programmed with accounting software to record store and analyze information Classify record and summarize numerical and financial data to compile and keep financial records using journals and ledgers or computers Receive record and bank cash checks and vouchers Comply with federal state and company policies procedures and regulations Compile statistical financial accounting or auditing reports and tables pertaining to such matters as cash receipts expenditures accounts payable and receivable and profits and losses Reconcile or note and report discrepancies found in records           Archer Daniels Midland Company      Tax Intern   Alpharetta     GA                   012013      032013     Prepared or assisted with tax returns for individuals Maintained a customer base relationship Calculate form preparation fees according to return complexity Interviewed clients to obtain information on taxable income and deductible expenses allowances and due diligence Computed taxes owed or overpaid using tax software to complete entries on forms following tax form instructions and tax tables Checked data input and verify totals on forms to detect errors in arithmetic data entry or procedures           Orix      Work Study Assistant   Boston     MA                   082012      112012     Made sure the Satisfactory Academic Progress SAP Appeal decisions of the appeals committee was conveyed and mailed to each student Answered phone calls and assisting or referring the caller appropriately Delivered documents to the Presidents Office for signatures Filed confidential documents Retrieve required information from Banner software           NATIONAL ASSOCIATION OF MINORITY CONTRACTORS      Accounting Intern   City     STATE                   112011      052012     Operate computers programmed with accounting software to record store and analyze information Check figures postings and documents for correct entry mathematical accuracy and proper codes Debit credit and total accounts on computer spreadsheets and databases using specialized accounting software Operate 10key calculators typewriters and copy machines to perform calculations and produce documents Comply with federal state and company policies procedures and regulations Code documents according to company procedures Reconcile or note and report discrepancies found in records           HOUSTON INDEPENDENT SCHOOL DISTRICT      Audit Intern   City     STATE                   062011      082011     Audited cash receipts and disbursement vouchers for accuracy in purchasing procedures  Verified internal fund transfers in compliance with Houston Independent School District finance procedures manual  Examined fundraising activities conducted throughout a fiscal audit period using an activity fund program          Skills     10key Academic accounting accounting software accounts payable and receivable administrative Administrative support analytical skills as400 auditing business processes calculators cash receipts credit client clients Excellent customer service Customer Service data entry databases Debit delivery direction due diligence filing finance financial forms fundraising inventory Logistics Manager merchandising Microsoft Excel Office PowerPoint Microsoft Word organization skills Peachtree copy machines policies Progress purchasing QuickBooks sales SAP spreadsheets tables tax taxes tax returns telephones phone typewriters,\n",
       " Jessica    Claire               Montgomery Street       San Francisco     CA  94105    609 Johnson Ave       49204     Tulsa     OK      Home   555 4321000        Cell           resumesampleexamplecom                  Summary     Highly talented and accomplished professional with extensive skills and experience in complex work environments Coordination planning and support of daily operational and administrative functions Detailoriented and well organized when completing projects able to multitask effectively Experienced working in fast paced environments demanding strong organizational technical and interpersonal skills       Skills         Microsoft Word Excel Publisher PowerPoint Outlook Lawson Time Matters and Internet                       Experience      072012   to   Present     Data Analyst      Lewis Pr    –    New York     NY             Collect and compile data for statefederal requirements which includes audit documentation regarding professional learning activities  Assist the Title II Department with the allocation management and tracking of Title II  Part A program funds  Maintains and develops electronic files records for easy access of reports  Prepare spend down reports for various departments that use Title II funds  Enter requisitions for activities allowable under Title IIA  Provides ongoing technical support to publicprivate school and other district personnel including conducting meetings regarding compliance  Compiles and summarizes program data for all required Federal and State reports  Assist with the preparation of documents for meetings involving stake holders  Assist in preparation of presentations and meetings  Assist with procurement process of compliance with documentation  Conduct surveys with personnel and stakeholders to assess the needs of the district and compile data for reports  Works closely with various departments to track expenditures and gather information necessary as requested by Title II Department          062012   to   112012     Data Analyst      Lewis Pr    –    Chicago     IL             Compiled and evaluated student data for the purpose of assessing program effectiveness student growth and provider quality including completion of federal and state reports  Assisted with the development of district policies and procedures for effectively implementing monitoring and evaluating the Title I Supplemental Educational Service program in accordance with federal law  Evaluated and processed vendor invoices against student attendance reports and performance data to ensure reliability and validity  Assisted with preparation processing and review of contractual agreements for all vendors as well as enter contract information in Lawson system  Developed and created marketing programs to effectively communicate with parents district personnel and the community regarding the SES program services  Facilitated training and workshops for schooldistrict personnel parents vendors and community members regarding Title I program guidelines  Monitored school sites where tutorials take place to ensure that providers are in compliance with guidelines set forth          092009   to   112012     Administrative Assistant      Primrose School    –    Oldsmar     FL             Provided administrative support for the Supplemental Educational Services Program including acting as a liaison between the tutorial providers school personnel and parents adhering to and interpreting state and federal program guidelines and relaying that information to the public and meeting deadlines for reports  Prepared spreadsheets and data reports summarizing enrollment data by schoolprovider  Monitored school sites where tutorials take place to ensure that providers are in compliance with guidelines set forth  Prepared correspondence create email distribution lists maintain calendars organize mass mailings and file management  Maintained and track database of over 2400 students  Verified freereduced lunch status of students requesting to participate in the program  Assisted with completion of all state reportssurveys regarding SES  Provided executivelevel administrative support to the Program Director of Title I Office with a demonstrated ability to improvise improve procedures and meet demanding deadlines  Collaborated and met with other departments to complete special projects including summer school  Conducted surveys regarding summer school and compile data for reports          042002   to   122008     Legal Assistant      State Of Ohio    –    Wayne County     OH             Provided administrative support to Managing Partner and Associates in general practice law firm with a demonstrated ability to improvise improve procedures and meet demanding deadlines  Acted as a liaison between clients and attorneys arranged meetings maintained calendars drafted correspondence maintained and organized files sent documents by facsimile photocopied proofread prepared memos sent documents by overnight mail scanned documents and downloaded documents  Managed client files opening and closing files maintaining client databases and attorney billing  Prepared and interpreted legal documents such as but not limited to Contracts of Sale Promissory Notes and Powers of Attorney  Assisted accounting department in maintaining bank accounts including managing subaccounts for clients writing checks and communicating with the bank regarding deposits and wire transfers  Supervised and trained parttime and summer employees including delegating responsibilities overseeing and reviewing tasks completed and collecting time sheets  Provided support to the office manager in handling payroll and accounts payablereceivable responsibilities  Assisted with firm marketing including preparation of packets for presentations building and fostering working relationships with affiliated companies to increase clientele          Education and Training      Expected in   May     Juris Doctor          ATLANTAS JOHN MARSHALL LAW SCHOOL                GPA               Expected in   May 2001     BS     Business Administration     CHEYNEY UNIVERSITY OF PENNSYLVANIA                GPA       magna cum laude Business Administration        Interests     Notary Public Commissioned in the State of Georgia       Skills     accounting accounts payable administrative support Attorney billing closing Computer experience Contracts clientele client clients databases database documentation email facsimile file management forth funds IIA Lawson law legal documents Notes Director Managing marketing meetings access Excel mail Office Outlook PowerPoint Publisher Microsoft Word Works office manager payroll personnel policies presentations procurement quality spreadsheets surveys technical support workshops       Additional Information       LICENSES Notary Public Commissioned in the State of Georgia,\n",
       " Jessica  Claire                             resumesampleexamplecom                      555 4321000                       Montgomery Street     San Francisco     CA      94105                                                                                                                                                                                                             Professional Summary     5  years of experience on Database development and administration knowledge of relational database on SQL Server particularly on SSMS SSRS SSIS TransactSQL and SQL Server Agent Extensive exposure to creation of Database Objects Stored Procedures Triggers Views User Defined Functions and Cursors           Core Qualifications         SQL  Server Tools          SQL Server Management Studio SSMS  Data Warehouse Tools          MS SQL Server 200520082012 Integration Services  Business Intelligence Tools        SQL Server 200520082012 Business Intelligence Development Studio  Programming Languages\t     TSQL  Reporting Tools          SQL Server 200520082012 Reporting Services  Development Environment        Visual Studio 200520082012  Operating Systems\t         Windows XP20032008 Server Win 3x9598 Vista Win 7  Advanced Excel          Vlookup Subtotal Pivot table and Chart                       Education       Admas University               Expected in        –      –       BSc Degree        Information Science          GPA           Information Science          Experience       Liberty Healthcare Corporation      Data Analyst        OK                   112014      Current     Experience in Constraints rules and default setting Primary Foreign Unique and Default Key  Developed Joins and SubQueries to simplify complex queries involving multiple tables  Experienced in using temporary tables table variables common table expression CTE to enhance optimized SQL queries form improved performance of queries  Experience in crating and updating Clustered and NonClustered Indexes to keep up the SQL Server Performance  Well versed in Normalization DeNormalization techniques both in OLTP and OLAP system  Experienced in using Try catch block introduced in SQL Server 2005 and error handling  Great deal of experience on authoring managing and deploying ad hoc enterprise advance and interactive reports using SQL Server Reporting Servers  Expert in Data Extraction Transforming and Loading ETL using various tools such as SSIS DTS Bulk Insert data cleansing and profiling  Well experienced using different transformations tools like Aggregate Cache Transformation Conditional split Copy columns Sort column Data conversion Derived column Merge Merge join Union all Import and Export columns and OLE DB command  Data Extraction form OLE DB server encrypt and compressed with the TF PGP and TF compression task to the remote server location and FTP Server on the CSV format  Implementation of point in time backup and recovery of databases executing package scheduling and managing jobs on SQL Server Agent and maintain good documentation  Managed and maintained users security and permissions and migration database objects form one server to another server database to another database  Exposure to Business Analysis and requirements gathering in Business and Health Care Domains mainly on HIPAA  Knowledge of complete Software Development Life Cycle and work experience in Agile and environment  Strong research analytical coordination interaction skills team player and able to quickly grasp new technologies and products           EBS      Data Analyst SQL Server DeveloperSSISSSRS                           092012      102014     EBSEthiopian Broad Casting Service aims to promote Ethiopian and African countries values Cultures and traditions on a global scale  The muchneeded information provided by EBS would  Help bridge the cultural divide and narrow the communication gap for Ethiopians residing in  North America and around and world  Involved in gathering business requirements  Installation and configuration of SQL Server  Created database tables wrote stored procedures for developers and users  Created SQL scripts and defined functions check constraints indexes and views  Created triggers to enforce data and referential integrity  Create new SSIS package 2008R2 to extract date from legacy to SQL Server objects  Extensively used SSMS and SSIS ImportExport system for performing ETL operations  Performed data conversion from fat file and excel in to a normalized database structure  Configured Server for sending automatic mails  Developed monitored and deployed SSIS packages 2008R2  Installation and configuration of reporting server  Generated Snapshot Drill Down and parameterized reports using SSRS Prepared Adhoc reports through report builders and published through Report Manager Design and created different types of reports like Sub Reports DrillThrough Cascading Drill Down adhoc Reports in visual Studio and deploy and manage on Microsoft SQL Server Reporting Services Configuration Manager  Ethiopian Magical Farm PLC Jessica Ababa Ethiopia                 SQL ETL DeveloperSSISSSRS                           022010      072012     Responsibility Designed and developed the databases  Created store procedures views and tables and generated TSQL script for application  Business Intelligence Development Studio BIDS to create edit and deploy SSRS and SSIS  Designed deployed and maintained of various SSRS Reports in SQL Server 2008R2  Created ETL packages using SSIS to extract data from relational database and then transform and load in to the database  Developed deployed and monitored SSIS packages including upgrades DTS to SSIS  Developed executed documented and maintained appropriate BI procedures  Collaborated with network operators application developers and DBAs to enhance end user experience  Scheduling Jobs and Alerting using SQL Server Agent          Professional Affiliations              Skills     Ad Agile aims automate backup Business Analysis BI Business Intelligence business management Hardware data collection Data conversion Data migration data modeling DTS data warehouse databases database delivery documentation edit ETL fat FTP logic managing Access MS Excel excel Excel          V Microsoft SQL Win 7 Win 3x 9598 Windows XP migration enterprise network OLAP OLE Operating Systems DB Pivot table PLC Programming quality relational database reporting requirement requirements gathering research Scheduling Servers scripts script Software Development sorting MS SQL Server Microsoft SQL Server SQL SQL  Server SQL Server tables team player TSQL TSQL translating Unique upgrades Vista Visual Studio,\n",
       " Jessica    Claire                                   609 Johnson Ave       49204     Tulsa     OK   100 Montgomery St 10th Floor    H   555 4321000    C       resumesampleexamplecom    Date of Birth         India                      single                    Summary      Logical Data Analyst skilled in requirement analysis software development and database management Selfdirected and proactive professional with over 10 years of vast experience collecting cleaning and interpreting data sets Natural problemsolver possessing strong crossfunctional understanding of information technology and business processes Selfmotivated Data Analyst offering over 10 years of leadership experience across various industries Methodical with significant experience in data mining and statistical analysis Excellent problemsolver with history automating processes and driving operational enhancements        Skills           Data Warehousing  Attention to Detail  Reporting Tools  Data Quality  Gap Analysis  Report Writing  Defect Tracking  Data Modeling  Python Programming  Strong Work Ethic  Simulation Modeling  Flexible Schedule  Informatica Platform  Data Mining  Process Improvement  Configuration Management  Software Development Life Cycle SDLC  Microsoft Visio  Data Validation  Process Mapping  Requirements Definition  Search Engine Optimization  Business Performance Analysis  Statistical Analysis  Oracle Business Intelligence      Product Development  Analytical Problem Solving  Sequence Diagrams  Enterprise Application Integration  Project Management  Technical Writing  Data Analysis  Technical Analysis  Data Integrity Validation  Data Science With R Programming  Clear and Concise Communication  Usability Testing  Business Management  Bug Life Cycle BLC  Database Maintenance  Statistics and SAS  Microsoft Access  Report Preparation  Business Needs Analysis  Tableau  Data Visualization and Presentations  Database Management  Query Tools  Data Mapping                       Experience       Data Analyst       112022      Current     Leidos    –    Laughlin Air Force Base     TX            Generated reports and obtained data to develop analytics on key performance and operational metrics  Worked with internal teams to understand business needs and changing strategies  Conducted data analysis to prepare forecasts and identify trends  Collected tracked and reviewed data to evaluate business and market trends  Utilized data analysis to monitor process efficiencies and identify data integrity exceptions  Interacted with nontechnical stakeholders to deliver analyses and answer questions on deliverables  Audited internal data and processes to identify and manage initiatives improving business performance  Leveraged software to compile and model data  Audited initial datasets to confirm validity of imported data corroborating changes against updates in data tapes  Recommended metrics and models based on observed trends  Assisted integration of internal and external data tools and products maintaining stability and performance across systems  Synthesized business intelligence or trend data to support recommendations for action  Provided technical support for existing reports dashboards or other tools  Analyzed and tracked data to prepare forecasts and identify trends  Gathered and organized data to analyze current industry trends  Maintained or updated business intelligence tools databases or dashboards  Generated standard or custom reports summarizing business financial or economic data  Identified needs of customers promptly and efficiently  Managed diverse projects for data capture storage and forecast analysis  Collected tracked and evaluated current business and market trend data  Identified or monitored current and potential customers using business intelligence tools  Managed timely flow of business intelligence information to users  Assessed programs to identify risks or problems to determine appropriate responses  Created or reviewed technical design documentation to drive accuracy of reporting solutions  Analyzed competitive market strategies through related product market or share trends  Communicated with customers competitors and suppliers to stay abreast of industry or business trends  Maintained library of model documents templates or other reusable knowledge assets  Identified and analyzed industry or geographic trends with business strategy implications  Synthesized current business intelligence or trend data to support recommendations for action  Disseminated information regarding tools reports or metadata enhancements           Data Analyst       102018      102022     Leidos    –    Lehigh     KS            Generated reports and obtained data to develop analytics on key performance and operational metrics  Worked with internal teams to understand business needs and changing strategies  Collected tracked and reviewed data to evaluate business and market trends  Utilized data analysis to monitor process efficiencies and identify data integrity exceptions  Provided supporting information to substantiate research findings  Assisted with efforts to track evaluate and report on impact of programs using multiple data sources  Audited initial datasets to confirm validity of imported data corroborating changes against updates in data tapes  Recommended metrics and models based on observed trends  Assisted integration of internal and external data tools and products maintaining stability and performance across systems  Synthesized business intelligence or trend data to support recommendations for action  Analyzed and tracked data to prepare forecasts and identify trends  Provided technical support for existing reports dashboards or other tools  Identified needs of customers promptly and efficiently  Generated standard or custom reports summarizing business financial or economic data  Managed diverse projects for data capture storage and forecast analysis  Identified or monitored current and potential customers using business intelligence tools  Collected tracked and evaluated current business and market trend data  Disseminated information regarding tools reports or metadata enhancements  Synthesized current business intelligence or trend data to support recommendations for action           Data Analyst       102013      102018     Leidos    –    Lexington     KY            Generated reports and obtained data to develop analytics on key performance and operational metrics  Worked with internal teams to understand business needs and changing strategies  Conducted data analysis to prepare forecasts and identify trends  Utilized data analysis to monitor process efficiencies and identify data integrity exceptions  Collected tracked and reviewed data to evaluate business and market trends  Provided supporting information to substantiate research findings  Assisted with efforts to track evaluate and report on impact of programs using multiple data sources  Audited internal data and processes to identify and manage initiatives improving business performance  Leveraged software to compile and model data  Disseminated information regarding tools reports or metadata enhancements  Synthesized current business intelligence or trend data to support recommendations for action  Identified and analyzed industry or geographic trends with business strategy implications          Education and Training       Master of Science       Science       Expected in   052013                Mercer University      Macon     GA     GPA        Status                  Bachelor of Science       Science       Expected in   052004                University Of Ibadan      Ibadan Nigeria          GPA        Status   ,\n",
       " JC     Jessica    Claire                      Montgomery Street       San Francisco     CA    94105             555 4321000                 resumesampleexamplecom                         Career Overview      Over  5 years  of experience  in a technical support role  electro mechanical maintenance IT and customer service Exceptional in troubleshooting installation configuration and desktop hardware support OS support for ATMs Proficient in the installation of customer proprietary software on different PCs Performed preventive maintenance on equipment when performing site visits Provided technical support and training for other technicians within the company across the country as well as customers Knowledge of LANWAN and printer network setups Knowledge of Active directory user setup Strong attention to detail Very well organized and able to escalate to the proper channels on issues that need more resources         Qualifications          MS Win 2000 XP 7 and 81  Other Applications MS Office Suite 20032007 and 2010 Excel Word Power Point Outlook Desktop Support TCPIP DNS Configuration Network setup Pinging LANWAN Configuration PC hardware and operating systems maintenance and troubleshooting Network Security Able to provide tech support over the phone Familiar with servicing printers Strong analytical skills  Proficiency in TCPIP protocols  Excellent problem solving skills                         Work Experience        092011   to   Current   Data Analyst    CH Robinson Worldwide Inc         Omaha     NE            LEAN trained on process improvement for developing new GEN paperwork process  Currently analyze data for changes adds and deletes onto the transaction switch  Verify to make sure all data elements related to their account is correct prior to the system change  Also provide technical support to ATM clients and vendors  Help customers trouble shoot minor issues with their ATMs to minimize down time  Also provide hardware and software support to customer vendor to help resolve technical issues  Managed network platform conversion for ATM clients from one processor to another migrating 1000 terminals in 6 months  Also provided support for ADA compliance standards for all ATM clients            082008   to   012011   Field Service Manager    Dish Network Corporation         Spokane     WA            Managed 37 technicians between Texas and Oklahoma  Assisted with 7 ATM software and hardware upgrades for financial institutions  Provided customer support for ADA compliance standards  Also performed upgrades from software to hardware to make ATMs ADA compliant  Provided tech support for both customers and technicians across the country  Performed work load balance between other technicians with my service area  Prioritized service calls to meet customer SLAs Hired and trained new staff when necessary  Traveled to other areas for tech and customer visits or to provide support on ATMs that have been down for long periods of time  Met with area tech leads every other week via conference calls to discuss any issues or changes coming to any of the areas            032008   to   072008   Customer Service Technician    Ametek Inc         Warrendale     PA            Performed software and hardware maintenance on Wincor ATMs  Used diagnostic software on PCs to troubleshoot hardware issues on ATMs to help pin point where errors could be found  Performed PMs on ATMs when time permitted to prevent calls backs            032005   to   032008   Sr Field Customer Service Engineer    Hyperoptic         Field     KY            Provided leadership to technicians in the Houston area and other areas that didnt have any leadership  Helped hire and train new technicians across the country  Help support 6 hardware and software upgrades for financial institutions  Provided tech support for both customers and technicians across the country  Prioritized service calls to meet customer SLAs  Traveled to other areas for tech and customer visits or to provide support for on ATMs that have been down for a long period of time  Performed PMs on ATMs and their PCs if time permitted to prevent call backs            022004   to   032005   Customer Service Engineer    Tecniflex         City     STATE            Serviced bank pneumatic tube systems for financial institutions  Serviced safe electronic and mechanical locks  Opened safety deposit boxes for financial institutions when requested  Performed PMs on safe doors every 6 months  Serviced ATM machines and PCs          Education and Training        Expected in   1996   Associates       Applied Science Electronics Engineering    Itt Tech     Houston     Tx      GPA        Applied Science Electronics Engineering           Expected in   2017   Bachelor of Science       Information Systems    University of Houston Downtown     Houston     TX      GPA               Languages      Bilingual in Spanish        Skills      ADA ATM balance hardware upgrades hardware conversion clients customer support DNS doors financial LAN leadership mechanical Excel MS Office Suite Outlook Power Point Win 2000 Word Network setup Network Security network Operating Systems PCs PC hardware printers process improvement safety SLA Spanish switch TCPIP technical support tech support software support Desktop Support phone troubleshoot troubleshooting upgrades WAN,\n",
       " Jessica    Claire                                   609 Johnson Ave       49204     Tulsa     OK   100 Montgomery St 10th Floor    Home   555 4321000    Cell       resumesampleexamplecom              Professional Summary      Dependable resultsdriven Data Analyst with extensive experience in collecting organizing interpreting and disseminating various types of statistical figures and strong focus on detail accuracy collaboration and delivering unparalleled client service Expertise in data analysis reporting structures and product and customer analytics Key strengths include excellent organizational skills effective time management and willingness to assist peers and colleagues during peak workload periods Proven ability to exercise good judgment and work well with minimal supervision and being able to make quick decisions in high pressure situations Strong technical project management and negotiation skills Knowledgeable about business process improvement methodology and productivity optimization strategies Recognized for integrity trustworthiness work ethic  objectivity My goal is to develop new skills and utilize my current skills to gain graduate assistantship to develop advocacy and leadership skills        Skills           SQL  Tableau  Python      MS Office Suite AccessProjectExcelPowerPointWordOutlook  Data Science Research Methodologies  Pattern and Trend Identification                       Work History       Data Analyst       082020   to   012022     Consumertrack    –    Los Angeles     CA             Analyzed Clients Financial Data and performed reconciliations to verify completeness of data sets  Providing support for data acquisition and extraction from clients’ accounting systems  Carrying out the manipulation and upload of more complex data sets from a variety of finance systems across various business areas and clients into deloitte’s platform  Carrying out Data manipulation using tools such as Excel and Microsoft SQL  Performing reconciliations to verify the completeness of datasets provided to clients  Carrying out data quality checks which will need to be raised to the Audit practice or client as appropriate  Assisting and guiding audit teams with data extraction from client systems  Been the engagement teams first point of call when using Analytics platform for troubleshooting or general functionality queries providing them with assistance and guidance in the use of our platform  Having a highlevel understanding of the system being supported and using Microsoft SQL to troubleshoot any issues raised by the Audit practice via the help desk system  Possible development and maintaining of various bespoke pieces of work built outside of our analytics platform on a client by client basis  Created reports for audit parameters using PowerBI  Hands on experience in Performance Tuning Query Optimization  Strong Knowledge on Power BI to import data from various sources such as SQL Server Azure SQL DB SQL Server Analysis Services Tabular Model MS Excel etc           Data Analyst       082017   to   012020     Consumertrack    –    Chicago     IL             Analyzed client’s sales marketing and finance departments to automate processes implement internal and external reporting structures and develop cost effective solutions  Conducted needs assessment to define user requirements  Identified overlaps and established metrics and database structure to support all organizational reporting requirements  Prepared regular status reports to enable continuous improvement and improve the overall performance  Collated data and performed volume calculations to present complex solutions in simple terms to clients and enable decision making  Designed implemented and analyzed results of marketing initiatives including email and onsite promo campaigns recommending most effective selling strategies and contributing to additional revenues of more than 29 Million  Developed a route optimisation tool for a leading retailer in India who serves millions of customers in more than 400 cities in every state of the country through digital platforms and over 1500 stores that cover over 16 million square feet of retail space  Improved collections process for a leading retail bank that reached more than Rs 245 million monthly outstanding on a portion of its unsecured credit portfolio during the economic downturn this was classified as early stage delinquents  Built analytical models to obtain the probability of collection from customers based on various actions  The client was able to realign call center agents to more impactful areas such as late stage delinquency and reduce staffing levels in early stage delinquency by 35  Resulted in annual cost savings of Rs 85MM without impacting the collection ratio of 98 for the early stage delinquents           HR Intern       072016   to   032017     American Modern Insurance Group    –    Evansville     IN             Worked with HR team to coordinate company events  Assisted human resources and recruiting teams by scheduling phone screens and onsite interviews and planning recruitment related events  Filed paperwork sorted and delivered mail and maintained office organization  Developed strong written and verbal communication skills  Supported efforts to optimize employee engagement diversity and inclusion to enhance performance management and retention           Programmer Analyst       032012   to   062015     Packaging Corporation Of America    –    Harrisonburg     VA             Developed programs and created files using SQL PLSQL  Created group data warehouse for distribution  Designed various management forecasting and end user reports  Analyzed business requirements and leveraged my technical skills to automate scripts to provide enduser support and regular maintenance to the databases  Previously index fragmentation on each index per table in the properties were checked manually and if it met a certain threshold we executed rebuilding of the index  Saved 45 of the time reducing the time spent on repetititve activities  Reducing 30 of the cost spent on repetitive activities  Used the time saved to solve quality issues which resulted in 45 increase in efficiency  Determined the right stored procedures views and functions for the application  Createddocumented specs and test cases for each PLSQL procedure          Education       Master of Science     Data Science     Expected in   012024     University of Memphis      Memphis     TN     GPA                MBA     Human Resources and Marketing Management     Expected in   072017     Bharathiar University                GPA                Bachelors of Engineering     Computer Science and Engineering     Expected in   042011     Anna University      ChennaiIndia          GPA               Certifications       Python for Data Analytics and AI Coursera – authorized by IBM  Data Science Methodology Coursera – authorized by IBM  Database and SQL for Data Science Coursera – authorized by IBM,\n",
       " Jessica  Claire                             resumesampleexamplecom                      555 4321000                                         100 Montgomery St 10th Floor                                                                                                                                                                                                           Summary      Qualityfocused Data Entry Clerk experienced in data processing coding and transcription Skilled at entering data quickly with strong attention to detail and accuracy Team player with outstanding communication skills and flexibility in working with others            Skills         Requirements Definition  Statistical Analysis  Data Quality  Configuration Management  Reporting Tools  Analytical Problem Solving  Attention to Detail  Data Analysis  Flexible Schedule  Strong Work Ethic  Data Visualization and Presentations  Stakeholder Communication  Decision Making  Customer Communication  Business Analysis      Database Building  Mail Management  Accounting Support  Meeting Planning  Data Entry Documentation  Excel Spreadsheets  Research and Analytical Skills  Microsoft Office Suite  Microsoft Office  Schedule Management  Computers and Technology  Document and File Management  Strong Organizational Skills  Multitasking and Time Management  Verbal and Written Communication                     Education and Training       Data Science Certificate    Plano TX           Expected in   072022     –      –               Data Science          GPA                    Udemy    Plano TX           Expected in   072022     –      –               Project Management Certificate          GPA                    ISTA    Safi Morocco           Expected in   062012     –      –               Information Technology          GPA                    Salah Eddin    Safi Morocco           Expected in   072010     –      –       High School Diploma                  GPA                    Ibno Zohr University    Agadir Morocco           Expected in        –      –               Business Economics          GPA                     Experience       Humana Inc      Data Analyst   Clermont     FL                   012022      042023     Worked with internal teams to understand business needs and changing strategies  Conducted data analysis to prepare forecasts and identify trends  Utilized data analysis to monitor process efficiencies and identify data integrity exceptions  Collected tracked and reviewed data to evaluate business and market trends  Analyzed and tracked data to prepare forecasts and identify trends  Provided technical support for existing reports dashboards or other tools  Gathered and organized data to analyze current industry trends  understand the business analyze process the data using python           Columbia Academy      Infant and Toddler Teacher   Fulton     MD                   062019      042020     Supervised circle time free play outside play and learning and developmental activities  Communicated with childrens parents and guardians about daily activities behaviors and problems  Taught children foundational skills in colors shapes and letters  Controlled classroom environments with clearly outlined rules and positive reinforcement techniques  Implemented handson playbased strategies for experiential learning  Organized and led activities to promote physical mental and social development  Read aloud and played alphabet games to encourage early literacy  Developed and enforced positive strategies to encourage good behavior  Supported childrens emotional and social development by adapting communication tactics for differing client needs  Introduced learning activities and imaginative play to teach children to explore  Sparked creativity and imagination by helping children discover new things each day  Monitored childrens play activities to identify additional learning opportunities or behavioral issues  Enhanced sensory abilities by giving children access to numerous textures and shapes  Observed behavioral issues to alert parents or guardians  Engaged with children on individual basis to build positive trusting relationships  Read stories to children and taught painting drawing and crafts  Organized creative and fun activities enhancing childrens physical emotional and social wellbeing  Built and strengthened positive relationships with students parents and teaching staff  Participated in workshops trainings and conferences to improve educational skills  Incorporated music and art activities to encourage creativity and expression           Salient Crgt      Administrative Assistant   Tampa     FL                   062014      112014     Answered phone calls and emails to provide information resulting in effective business correspondence  Provided secretarial and office management support while building cooperative working relationships  Scheduled appointments meetings and events for management staff  Responded effectively to sensitive inquiries or complaints  Coordinated appointments meetings and conferences  Managed physical and digital files monitored spreadsheets and updated reports to coordinate project materials  Developed administrative processes to achieve organizational objectives and improve office efficiency  Prepared and prioritized calendars and correspondence  Composed correspondence reports and meeting notes  Created spreadsheets in Microsoft Excel for recordkeeping and reporting  Kept office equipment functional and supplies wellstocked to promote efficient operations  Sorted and distributed incoming faxes letters and emails for office distribution           Dignity Health      Front Desk Receptionist   Chandler     AZ                   012014      042014     Handled payment processing and provided customers with receipts and proper bills and change  Welcomed patrons to front desk and engaged in friendly conversations while conducting checkin process  Input customer data into reservation systems and updated to reflect room changes  Greeted visitors to provide information and direct to appropriate personnel  Explained policies and procedures to visitors  Completed basic bookkeeping and document filing  Prepared daily shift close reports and balanced cash register to accurately reflect transactions          Languages       English                 Full Professional          Negotiated                               French                 Full Professional          Negotiated                               Arabic                 Native Bilingual          Negotiated     ,\n",
       " JC     Jessica    Claire                                        100 Montgomery St 10th Floor           555 4321000                 resumesampleexamplecom                         Summary      Selfmotivated Data Analyst offering 8 years of leadership experience across various industries Methodical with significant experience in data mining and statistical analysis Excellent problemsolver with history automating processes and driving operational enhancements        Skills           Data entry  Organization and efficiency  Leadership  Troubleshooting  Data mining  Database management  Data mapping  HTML      Scrum  UIUX  Design and development  Application development  JavaScript  CSS  Python                       Experience        032017   to   032019   Data Analyst    Tendril         Seattle     WA            Improved pattern recognition ability by 250 by analyzing patterns within signals of interest and tracking electronic signatures for 56 vessels over three years  Spearheaded and increased workflow improvements by 80 by designing and developing fullstack systems which include extracting data from different sources developing multiple formatting and structuring programs that can take large pools of unformatted data entries creating structured databases and application interfaces navigable by the untrained eye  These databases are utilized fleetwide by military personnel and AI systems to improve pattern recognition and predictive analysis for mission planning and operations  Achieved 100 operational effectiveness without fault by managing maintenance checks on all components of passive radar and jamming suite  Increased situational awareness and improved efficiency of operations by creating and distributing intelligence products fleetwide  Chaired 10 Subject Matter Expert SME boards and amplified electronic warfare watch conditions leading to 20 increase in operation proficiency in vital watch  Trained and mentored sailors in OPELINT and refined combat systems training team drill guides resulting in the qualification of 100 sailors in vital watch position  Solidified MOC certification of ComThirdFleet by deriving operational intelligence through evaluations of signal quality radar capabilities and life patterns within ELINT  Enhanced electronic intelligence by performing fusion analysis and analyzing radar capabilities from electronic intelligence  Managed timesensitive Indications and Warnings IW giving technical and tactical guidance to Warfare Commanders and national consumers in support of surface subsurface air and special warfare operations  Increased team productivity and improved task performance by publishing detailed stepbystep technical guides utilizing years of firsthand experience and disseminating psychological operations materials  Steered cryptologic and intelligence briefs radar cross section testing and electronic warfare training events  Assigned information operation data collection responsibilities  As a knowledge manager introduced and created work center SharePoint sites across three domains TSSCI GENSER and UNCLASS allowing precise and effective progress tracking log safekeeping and project management within the workplace  Successfully launched and established military deception plans decoy handling signals intelligence operation and cross fix on electronic intelligence intercepts electronic intelligence collection plans and order of battle  Conceptualized developed and briefed 48 intelligence products on SIGINTrelated patterns of life and findings to fleetlevel commands and strike group information operation operational directives  Generated and managed proforma signals analysis reports tactical and operational electronic intelligence reports and communications electronic warfare reports using electronic intelligence national databases and electromagnetic spectrum research  Extracted data from record message traffic and identified essential elements of friendly information violations  Deciphered mission threats fused multisource and electronic support data and correlated electronic intelligence signals to specific platforms  Resolved and minimized identification conflicts in collected electronic intelligence  Devised rapid evaluation guidelines and electronic order of battle to support warfare commanders’ requirements  Recommended and administered changes to emission control plans and conditions and electronic warfare countermeasures  Decoded tactical transmissions and determined onboard weapons systems limitations  Supervised information operations preplanned response electronic warfare status boards ships weapons passive countermeasure system status availability and frequency deconfliction  Constructed and managed online emitter libraries electronic warfare control ship procedures electronic support and electronic support collection logs  Monitored strategic and tactical situations and prioritized electronic intelligence collection efforts  Controlled access to restricted areas and safeguarded handled and stored classified materials regularly  Increased productivity through by implementing Microsoft Excel Visual Basic for Applications software program to streamline operational processes  Evaluated historical current and forecast data to determine opportunities for development and enhancement  Worked with serverside and frontend technologies and leveraged common design patterns to code dynamic and userfriendly systems  Harnessed version control tools to coordinate project development and individual code submissions  Mentored entrylevel Python development personnel providing both internal and external positions with technical guidance and education  Prepared forecasts and identified trends through data analysis and tracking  Maintained security and data integrity of databases  Organized subsystems to execute proper collection of data  Mined data to uncover insights and identify market trends and inflection points  Spearheaded diverse projects for data capture storage configuration and forecast analysis  Directed field studies and data collection to support sophisticated analysis            072015   to   032017   Data Entry Operator    Md Anderson         Sugar Land     TX            Raised procedural compliance in the 3M and Hazmat programs by training sailors in QA Craftsman  Awarded as “ingenious planner” for efforts in garnering 4 outstanding zone inspection scores and successful host ship events for a People’s Liberation Army Navy Surface Action Group visit  Responsible for the operation of the ANSLQ32 Electronic Warfare Suite  Scheduled reviewed and supported over 263 training sessions and evolutions on 185 topics leading to the advancement of all eligible OT Division Sailors  Recommended for advancement to First Class Petty Officer  Worked closely with team members to deliver project requirements develop solutions and meet deadlines  Identified corrected and reported data entry errors  Completed accurate and efficient data entry and database updates to support business operations  Input client information into spreadsheets and company database to provide leaders with quick access to essential client data  Documented data entry completions in corresponding logbooks  Executed data verification to ensure expedient error detection  Maintained records by creating monthly reports closing terminated records and performing chart audits  Verified and logged deadlines in response to daily inquiries and requests  Supported document reviews and auditing by locating and providing required data reporting on input procedures and other relevant circumstances as necessary  Coordinated scheduled and executed indepth data entry projects  Drafted reports to deliver information to upper management  Compiled data from source documents prior to data entry  Adhered to strict data confidentiality policies to prevent information leakage            012014   to   072015   Technician    Fox Corporation         Charlotte     NC            Led and managed the accomplishment of 130 preventative maintenance checks on vital electronic sensors and computer systems within the passive radar and active jamming suites ensuring 100 operational effectiveness and safety without fault  Identified evaluated and provided vital signals of interest to forces while conducting operations during strike group exercises giving situational awareness and enhancing strike group tactical operator efficiency  Piloted the training environment from for 22 sailors on professionalism maintenance damage control and SLQ32 Operations resulting in 28 individual qualifications  Operated and maintained electronic sensors and computer systems  Collected analyzed and exploited Electronic Intelligence ELINT in accordance with fleet and national tasking  Maintained machines in good working order by cleaning lubricating and adjusting  Collaborated with technicians to diagnose equipment breakdowns and address quality issues  Posted and adhered to lockouttagout hazardous material handling and hearing and eye standards  Demonstrated excellent mechanical knowledge of machine design use repair and maintenance  Assembled parts using bolts screws speed clips rivets and other fasteners  Inspected equipment and systems to identify issues and reported problems to repair technicians  Prepared operational reports and provided information to supervisors  Worked from complex and detailed manufacturing documentation and verbal instructions          Education and Training        Expected in             Full Stack Developer    San Diego Global Knowledge University     San Diego     CA      GPA               Websites Portfolios Profiles        httpswwwlinkedincominJessicaClaire4140031a3                      Certifications     Operational Risk Management and TimeCritical Risk Management  Navy Planning and Foreign Liaison Training  ILDC Leadership Course  San Diego Global Knowledge UniversityApril 2021 – November 2021  Full Stack Developer,\n",
       " Jessica  Claire                             resumesampleexamplecom                      555 4321000                       Montgomery Street     San Francisco     CA      94105                                                                                                                                                                                                             Profile       Has a Master’s of Science Degree in Management Information Systems with Business Intelligence Concentration  Has  5  years of experience working as a SQL server Developer SQL DBA and Data Analyst with excellent analytical and problemsolving skills to work with minimal supervision  Strong knowledge and experience of RDBMS like MS SQL Server 2008 R22012 MS Access MySQL and TSQL queries stored procedures   Strong knowledge and experience in Business Intelligence –SSIS SSRS SSAS Power BI  Power Pivot Power Query Power View Power Map and Pivot Table  Experience in Windows server 20082012 Active Directory AdministrationUsers and Computers DNS DHCP  Experience with data analysis and visualization tools like Excel and Tableau              Core Qualifications         Business Intelligence Data Analytics  Database Development Administration  Windows Server Administration  Windows Azure      Data warehouseData Mining  Microsoft Office  Web Design  Amazon Web Services                     Education       Nova Southeastern University    Fort Lauderdale     FL      Expected in   2015     –      –       Master of Science        Management Information Systems          GPA           Concentration Business Intelligence         Miami Dade College    Miami     FL      Expected in   2003     –      –       Associate of Science        Computer Programming and Analysis          GPA                    Haremaya University Of Agriculture    Haremaya     Harer      Expected in   1988     –      –       Bachelor of Science        Agriculture Plant Science          GPA                     Technical Skills       SQL Server MS Access MS Excel MYSQL   SSIS SSAS SSRS Power BI  TSQL VBA MS Access Excel Macros  Tableau      RapidMiner XLMiner Data Mining   HTML CSS WordPress Dreamweaver Photoshop JavaScript         Professional Experience       Market Footwear Fred Lurie Associate Inc      SQL DevloperDBAData Analyst   City     STATE                   092012      032015    Responsibilities   Created ETL packages involving various data sources SQL Server Flat Files Excel source files  etc  using MS SSIS  Developed data quality solution using SQL Server data services DQS as part of ETL  Analyzed data using using SSAS Excel Tableau and Power BI tools for decision making process  Built Self Service Business Intelligence  dashboards using Power BI tools in Excel  Wrote TSQL queries  for data Analysis and Reporting  Developed reports using MS SQL Server Reporting Services SSRS and Excel  Helped decision makers to understand data on reports and dashboards and gain insights  Installed administered and maintained MS SQL Server 20082012 including upgrades security configuration and service packs   Designed implemented and maintained SQL Server databases   Designed and implemented tables views functions stored procedures and triggers in SQL Server  Planned and implemented SQL Server Security and database permissions   Performed  Database Performance Analysis and Tuning using Database Engine Tuning Advisor SQL Server Profiler and SQL Server Extended Events  Setup HighAvailability as part Disaster Recovery Strategy for the SQL server 2012 databases Failover Clustering Database Mirroring Log Shipping and Replication             Cifra Systems      SQL Server developerDBA   City     STATE                   072009      082012     Responsibilities    As a midlevel DBA Installed configured administered and secured SQL servers 20082008 R2   Created and optimize database objects eg Tables Views indexes cursors stored procedures functions and Triggers   Scheduled and automated maintenance plans using SQL Server Job Agent   Scheduled and automated fulldifferentialtransactional backups and implemented recovery strategies   Configured and monitored database Mirroring Replication and Log Shipping as HADR strategy  Planned and implemented SQL Server Security and database permissions   Extensively used Joins and subqueries for complex queries involving multiple tables  Created indexes clustered and nonclustered  to speed up query performance  Designed Excel dashboard  for tabular and chart reports with drill down  functionality           Miami Christians Fellowship      Web DesignerSQL DBADeveloperMedia Specialist   City     STATE                   022005      042009     Designed desktop database application in MS Access using VBA  Developed financial report using MS Access and Excel  Created website for the organization utilizing HTML WORDPRESS CSS PHP MSSSQL and MYSQL  Performed regular website maintenance and update while also designing graphics for banners flyers and posters  Recorded and edited videos to be distributed in DVD  CD format and upload them to organization’s website  Trained staff members how to utilize computers use software to maintain website and other media support services            Hotsilhouette Inc      Web Developer and Database Support   City     STATE                   072003      2005    Responsibilities   Developed and maintained  companys websites using Dreamweaver HTML CSS ASPNET JavaScript  Designed and managed backend SQL Server databases for web applications  Wrote complex TSQL queries to manipulate  data  Designed and edited graphics and photos for websites using Photoshop     Installed Configured and managed SQL Server and Access databases  Analyzed sales data from different sources and created dashboards using MS Excel  Provided technical computer support to end users,\n",
       " JC     Jessica    Claire                      Montgomery Street       San Francisco     CA    94105             555 4321000                 resumesampleexamplecom                         Summary      Experienced Data Analyst versed in analyzing and manipulating various data in MercuryGate Transportation Management System and providing Support to Corporate and Independent Business Offices for multiple TMS issues  Excellent interpersonal and troubleshooting skills        Highlights           MercuryGate TMS  Resolve TMS Support Issues  Customer Enterprise Set up and Configuration  Regression Testing      Troubleshooting  Analytical Problem Solving Skills  Customer serviceoriented                       Experience        082008   to   Current   Data Analyst    Verizon Communications         Greensburg     PA            Troubleshoot various data issues in TMS for independent offices and implement solutions to resolve the issues  Coordinate with internal and external team members to meetbeat deadlines  Perform Regression Testing prior to TMS upgrades  Set up and configure new customer enterprises in TMS as needed  Create repeatable documented processes and tools for systematically manipulating data  Analyze and maintain various shipment data in MercuryGate TMS for independent offices including rail and drayage rates truckload and LTL rates and fuel schedules as received  Utilize Microsoft Access and Excel to manipulate data into standard format as provided by independent offices  Utilize Business Intelligence and Mercury Edge to create reports for customers and independent offices as requested  Manipulate and load all data correctly into TMS prior to the testing and golive deadlines for new customers  Prepare and implement plan for maintaining data as needed with external team members for time period between initial load and golive as well as postgolive            052008   to   082008   Cell Site Transport Analyst at TMobile    E  J Gallo Winery         Fort Lauderdale     FL            Develop Adhoc reports in Business Objects to proactively analyze possible risks of missing deadlines Risk Analysis Reports and to provide status to upper management   Provide backup support to Transport Engineers to ensure deadlines are continuing to be met during heavy workload periods              2001   to   022008   Engineering Support Analyst    SPRINT NEXTEL CORP         City     STATE            Provided support to Engineering teams by compiling data for reporting in Access and Excel proactively identifying possible delays in the T1 ordering process flow  Managed cell site projects from order initiation to installation  Coordinated T1 ordering process activities  Tested T1s for cell sites           Education        Expected in   2008   Bachelor of Science       Business Administration Business Information Systems    DeVry University     Irving     Texas      GPA   Magna Cum Laude GPA 3740    Business Administration Business Information Systems Magna Cum Laude GPA 3740 Team Leader for Senior Project and ECommerce Project        Skills     MercuryGate TMS Excellent Customer Service Skills Strong Troubeshooting Skills Support Multitasking Meeting deadlines Excellent Written and Oral Communication Skills,\n",
       " JC     Jessica    Claire                      Montgomery Street       San Francisco     CA    94105             555 4321000                 resumesampleexamplecom                         Summary     Incredibly motivated professional with a variety of academic and civilian administrative experience Possesses analytical research and problem solving skills Detail oriented organized and able to manage projects to meet deadline requirements Proficient written and oral communication skills with extended experience utilizing various forms of correspondence Precise judgment and decisionmaking skills to ensure the client’s needs are being met Effective while working within a group or independently       Skills           Problem Solving  Communication  Critical Thinking      Analytical   Attention to Detail  MultiTasking                       Experience        042014   to   Current   Data Analyst    Atlas Executive Consulting         Washington     DC            Utilized SQL Developer to streamline processes and reports obtained from the Enterprise Data Warehousing EDW and Enterprise Resource Planning ERP information systems  Responsible for maintaining and updating multiple tables with in the EDW application  Constructed and modified SQL queries to support data reporting initiatives  Reviewed and validated financial statements including but not limited to balance sheets and statements of revenue to identify and correct data discrepancies that impact financial reports  Presented project and reporting results to senior management and clients to assess reporting issues and provide solutions  Managed the CORPROD inbox to receive feedback concerning financial reports and queries  Worked closely with Subject Matter Experts SMEs and Database Administrators DBA to provide status updates and technical guidance to run financial and inventory reports  Utilized project management skills to ensure weekly reports and on going project objectives are met            062011   to   042014   Financial Management Analyst    Department Of Justice         Batavia     NY            Budgeted allocated and monitored the use of financial resources that support the supply chain and operational strategic plans  Analyzed business requirements to prepare and coordinate various budget proposals and exhibits with clients and Headquarters for submission  Provided guidance to management concerning financial management policies and procedures  Allocated and reallocated funds to the appropriate fund centers to ensure sufficient monies are available when and where needed at the execution level  Analyzed key business indicators including sales obligations net operating revenue and cash and financial statements to identify variances  Collaborated with multiple departments to articulate budget variances financial performance and corrective actions to the supply chain and operational management in order to improve business performance  Received validated accepted funding documents and identified the need to create reimbursable internal orders to track costs incurred in ERP systems  Utilized Navy Enterprise Resource Planning system to allocate execute and control funds identify weaknesses within financial areas  Reviewed program manager budget requests to evaluate estimates and requirements  Supervised two Financial Technicians on completing funding documents and other financial matters            032009   to   062011   Financial Management Intern    American Advanced Management Inc         Coalinga     CA            Developed financial analysis skills including but not limited to balance sheet reconciliation components of financial contracts accounting principles for government entities and the financial audit process  Assisted with generating and analyzing monthly financial reports and physical inventory  Participated in the yearly forecasting initiatives  Developed and utilized spreadsheets databases and other applications to complete assignments            022001   to   082004   Personnel Clerk    United States Marine Corp         City     STATE            Performed personnel and general administrative duties utilizing           manual and automated information systemsPrepared documents           maintained personnel records retrieved pay and personnel           information  Developed and maintained working knowledge of the Marine Corps           Total Force System MCTFS which encompasses the online Diary           SystemOLDSthe Unit DiaryMarine Integrated Personnel System           UDMIPS  Created entries for individual service records audited service           records for required entries and documentation completed various           personnel and pay related forms and documents  Researched proper unit diary entry requirements entered           transactions into MCTFS via the unit diary audited and corrected           feedback reports from the MCTFS system and prepared individual           pond and allotment request          Education and Training        Expected in   2016   Master of Science       Business Administration    University of Mary Washington     Fredericksburg     VA      GPA       335400          Expected in   2008   Bachelor of Arts       Business Management    Charleston Southern University     Charleston     SC      GPA       300400,\n",
       " Jessica  Claire                             resumesampleexamplecom                      555 4321000                       Montgomery Street     San Francisco     CA      94105                                                                                                                                                                                                             Summary     Obtain a position where I can utilize my Accounting and Financial Concept skills Customer Service skills French Speaking skills and Critical Thinking skills to better and improve the growth of the Company           Highlights       Excel Word and Power Point Microsoft Outlook CMS program  Deans List for 6 consecutive quarters                     Education       Stephens Henager College    Orem     Utah      Expected in   2015     –      –       Forensic Accounting                  GPA                                   Expected in        –      –       Bachelor Degree                  GPA                     Accomplishments      Graduated Suma Cum Laude with a Bachelor Degree in Forensic Accounting at Stephens Henager College   Honor student and earn the deans list 9 times during the school year        Experience       Altice Usa      Data Analyst   Prestonsburg     KY                   012014      012014     Review and analyze clients Application in compliance with Companys Guidelines  Determine Clients qualification by reviewing and analyzing clients Credit Report and Financial Statements  Enrolled Clients information in Data System           Landmark Aviation      Monitoring Agent   Kahului     HI                   012012      012014     Monitor residential and commercial security systems  Assist to handle individuals crisis as they come up           Emd Millipore      Executive Coordinator   Breinigsville     PA                   012007      012012     Provide and process travel service to Delta Air Lines Executive Members  Provide and process travel service to Hearing Impaired  Provide and process travel service to Federal Air Martials           Incharge Institute      Credit Counselor   City     STATE                   012000      012006     Assess clients financial situation  Determine the optimal solution in resolving clients financial distress  Offer and explain possible programs such as credit counseling bankruptcy options budgeting improvement and debt management          Work History       Dispatch Police Department Emergency Medical Service and Fire Department                                  Languages     Write and Read French       Skills     Accounting budgeting CMS counseling Credit Client clients financial Financial Statements Read French Excel Microsoft Outlook Power Point Word,\n",
       " Jessica  Claire                             resumesampleexamplecom                      555 4321000                                         100 Montgomery St 10th Floor                                                                                                                                                                                                           Summary      Selfmotivated Research Manager offering over 22 years of leadership experience in the animal biomedical field Methodical with significant experience in data organization and analysis Excellent problemsolver with a history of automating processes and driving operational enhancements            Skills         Analytical Problem Solving  Attention to Detail  Data Compiling  Database Building      Data Quality  Microsoft Office  SelfDriven and Motivated  Working Collaboratively                     Education       Towson State University    Towson MD           Expected in   011992     –      –       Bachelor of Arts        PsychologyInterdisciplinary Study Animal Behavior          GPA            Relevant coursework Behavioral Statistics Behavioral Endocrinology Chemistry         Certifications       Certified Manager of Animal Resources  2017  Manager Development Program  2015           Experience       Emprise Bank      Data Analyst   Chanute     KS                   032022      Current     Determines future data and analytical needs to ascertain the effectiveness of colony management strategies  Constructed a MS Access database and developed the data table and form structure that accommodates information from historical records and to meet future data entry and analytical needs  Performs quality assurance to assess data validation on 26 years of historical data Transfers data from those records into newlydeveloped data tables           Emory University Yerkes National Research Center      Colony Manager Research Lab Manager   City     STATE                   072012      022022     Managed colony data for over 2200 nonhuman primates from 2 species optimized and maintained distinct data tracking spreadsheets for viral test history reproduction social history and animal housing allocation  Assessed and established colony management practices eg safety and training guidelines  Directed the development of plans for the breeding program eg introduction of breeder males into 15 social groups per year and social group management eg introduction or removal of animals group moves Influenced strategic planning to reach department and Center goals  Restructured the unit for improved organizational order creation of professional growth opportunities and effective management of nine technicians  Expanded data skills eg designed population projection tool increased Excel skillset to include pivot tables and formulas MS Access database and form design Visio to build timelines and matrilines and beginner RStudio and Cytoscape use  Orchestrated research support activities eg biological specimen requests grant and protocol management research design and budget preparation Strengthened relationships with scientists for effective collaboration           Emory University Yerkes National Research Center      Supervisor Research Specialist   City     STATE                   081999      012009     Successful growth of the SPF rhesus macaque colony and met program aims eg genetic characterization increased frequency of viral testing  Coordinated collection of specimens for research and colony needs  Increased collaboration to meet the needs of animal assignment requests Made animal data eg social hierarchy demographic and reproductive assessable to researchers and arranged animal training for safer procedures  Compiled researchrelated and colony data eg census reproductive success population growth for the Centers base grant and regulatory oversight           Emory University Yerkes National Research Center      Lead Research SpecialistResearch Specialist   City     STATE                   101996      081999     Executed the derivation of a Specific Pathogen Free SPF rhesus macaque colony and a SIVSTLV negative sooty managabey colony  Entrusted with funded research project objectives eg data collection and analysis for Dr Deborah Gusts two funded grants  Mastered technical abilities eg venipuncture animal training animal access and behavioral observation data collection  Designed and developed a record management system for the animal colony eg demographics reproductive parameters socializations and health interventions          Additional Information       Presenter at Americal Society of Primatologists and Breeding Colony Management Consortium national conferences  Contributing author in over 15 profession research publications including BBeisner etal Factors influencing the success of male introductions into groups of female rhesus macaques Introduction technique male characteristics and female behavior Americal Journal of Primatology 2021 and AChahroudi etal Target cell availability rather than breast milk specific factors dictates mothertoinfant transmission of SIV Journal of Medical Primatology 2014 Complete list upon request,\n",
       " Jessica  Claire                             resumesampleexamplecom                      555 4321000                                         100 Montgomery St 10th Floor                                                                                                                                                                                                           Summary      A passionate researcher and learner with ten years of experience supporting IT activities analyzing data translating longterm and shortterm goals into business solutions such as data modeling and design data architecture design process automation flow data ingestion and migration data Warehousing data lake business intelligence data quality to drive optimal operation processes for seamless data batch flow efficiency using Agile and scrum framework My solutions are deployed in a premise and cloud base environment for cost saving availability reliability and manageability            Skills         Skills  Business Tools  Microsoft Excel  SSRS PowerBI Tableau  SQL with Microsoft SQL server MySQL  Data Modelling  Data Warehouse  Snowflake Oracle  Hardware troubleshooting      AWS Services  JIRA for backlog managment  VLookup Pivot Tables XLookup  ETL ELT Operations  Data Lake Engine – Dremio  Process management                     Education and Training       Scrum Master Training               Expected in   082022     –      –       Scrum Master Training                  GPA                                   Expected in   012015     –      –       Business and Financial Data Modelling                  GPA                    University of Lagos    Lagos Nigeria           Expected in   062006     –      –       Bachelor of Science        Computer Engineering          GPA                     Experience       Ebay Inc      Data Analyst   Portland     OR                   082019      Current     Responsible for cross functional business requirements capture and translating them into data models to drive key operational risk management and CRM models  Responsible for data discovery ETL processes from RDBMS to data lakes and bulk insert big data into RDBMS  Developed reports on business position management billing forecast operational exceptions  Currently the IT interface for various department in setting up reports modifying rebuilding optimizing subscribe user existing reports in PowerBI Tableau and SSRS  Designed monitor data validation checks to ensure consistence between source and destination pre and post load  Work with crossfunctional to scale and optimize cloud solutions in production systems  Using cost explorer compute optimizer to advice engineering team on resizing and providing cost visibility  Work with engineering team on the best approach to optimally size their production system considering impacts and complexities  Liaises with key management to drive optimization cost within the organization  Working with engineering team to adequate provision low and complex resources such as s3 ec2 instance in nonproduction environment  Injecting CloudWatch logs and metrics through API calls into data lake s3 for KPI reporting on various AWS resources for cost tracking and optimization  Curate enterprise to create different LOB semantic layersmaterialized views and Communicate findings to the stakeholders through standard and ad hoc reports  Work with cloud engineering Team and Cloud Core on the identified costsavings opportunities as well as propose new ones  Developed a PowerBITableau application reports for various sections of the business for decision making  Work with the software development team to understand their various data model requirements develop test and deployed  Design document develop test and deploy of various business intelligence applications dashboards and reports for risk evaluation on gross margin forecasting and customer analytics reports  Curate data using MS Excel to create Pivot Tables VLOOKUP joins and other advanced functions for adhoc reports  Worked with multiple databases servers such as MySQL SQL Server Snowflake for creating various data model  Designed developed and maintained 360 customer profile snapshot enterprise active new existing and inactive contacts  Managed setting up multiple connection driver between data sources and analytics engine  Tableau  Developed KPI trends report for management insights decision support           Zippin      BI Analyst   Salt Lake City     UT                   062018      082019     Responsible for cross functional business requirements capture and translating them into data models to drive key operational risk management and CRM models  Developed reports on business position management billing forecast operational exceptions  Interface for various department in setting up reports modifying rebuilding optimizing subscribe user existing reports in PowerBI  Designed monitor data validation checks to ensure consistence between source and destination pre and post load  Work with crossfunctional to scale and optimize cloud solutions in production systems  Using cost explorer compute optimizer to advice engineering team on resizing and providing cost visibility  Work with engineering team on the best approach to optimally size their production system considering impacts and complexities  Injecting CloudWatch logs and metrics through API calls into data lake s3 for KPI reporting on various AWS resources for cost tracking and optimization  Curate enterprise to create different LOB semantic layersmaterialized views and Communicate findings to the stakeholders through standard and ad hoc reports  Developed a PowerBI application reports for various LOB of the business for decision making  Work with the software development team to understand their various data model requirements develop test and deployed  Manage various business intelligence applications dashboards and reports for risk evaluation on gross margin forecasting and customer analytics reports  Curate data using MS Excel to create Pivot Tables VLOOKUP joins and other advanced functions for adhoc reports  Worked with multiple databases servers such as MySQL SQL Server Oracle for creating various data model  Designed developed and maintained 360 customer profile snapshot enterprise active new existing and inactive contacts  Managed setting up multiple connection driver between data sources and analytics engine PowerBI  Developed KPI trends report for management insights decision support           Ebay Inc      Data Analyst   New York     NY                   052014      062018     Responsible for cross functional business requirements capture and translating them into data models to drive key operational risk management and CRM models  Developed reports on business position management billing forecast operational exceptions  Interface for various department in setting up reports modifying rebuilding optimizing subscribe user existing reports in PowerBI  Designed monitor data validation checks to ensure consistence between source and destination pre and post load  Work with crossfunctional to scale and optimize cloud solutions in production systems  Using cost explorer compute optimizer to advice engineering team on resizing and providing cost visibility  Work with engineering team on the best approach to optimally size their production system considering impacts and complexities  Injecting CloudWatch logs and metrics through API calls into data lake s3 for KPI reporting on various AWS resources for cost tracking and optimization  Curate enterprise to create different LOB semantic layersmaterialized views and Communicate findings to the stakeholders through standard and ad hoc reports  Developed a PowerBI application reports for various sections of the business for decision making  Work with the software development team to understand their various data model requirements develop test and deployed  Design document develop test and deploy of various business intelligence applications dashboards and reports for risk evaluation on gross margin forecasting and customer analytics reports  Curate data using MS Excel to create Pivot Tables VLOOKUP joins and other advanced functions for adhoc reports  Worked with multiple databases servers such as MySQL SQL Server Oracle for creating various data model           HiiT PLC      IT Business Technical Engineer   City     STATE                   012011      052014     Provides remote hands assistance to technical teams and customers  Managed system hardware upgrades  Participates in testing evaluation and implementation of related software products including new products software packages operating systems and facilities in order to ensure the software used in the project is compatible from endtoend  Knowledge of tape management systems including handling of media inventory control and offsite storage  Performs user Administration of report distribution  Maintains asset record updates tracking and assigning assets to their location and status registered deployed etc  Support end users’ requests in an area of reportssubscription automation and enlisting users in a report distribution list  Monitoring the performance of individual applications to ensure systems perform efficiently  Ensure adequate performance and operation of the systems  monitor the performance operation diagnose and address any problem  Interfaces with internal clients vendors managers IT and Product Development to resolve problems  Assist in monitoring all computer systems within the organization that are operational throughout an associate’s workday  Assist Revenue Systems Senior Analysts with architecting designing developingcoding testing and delivering moderately complex revenue systems  Responsible for the implementation and remediation of the client device security including patch management antivirus intrusion prevention and access control in line with regional guidance  Maintain a strong working relationship internally and externally across different global IT function groups business functions and international external service vender,\n",
       " Jessica    Claire                   Montgomery Street     San Francisco     CA  94105    609 Johnson Ave       49204     Tulsa     OK       Home   555 4321000    Cell       resumesampleexamplecom              Summary      Flexible and versatile Data Analyst specializing in developing innovative solutions to organizational problems Advanced knowledge of Business Intelligence tools experienced in confirming the accuracy of data in various systems and developing manage and understanding complex spreadsheets Strong organizational technical and analytical skills        Highlights           Microsoft Excel certified Advanced Excel modeling  Data Analyst Business Intelligence Spreadsheet management  Ability to quickly comprehend complex spreadsheetsdata  QlikView and Qlik Sense      Visual Basic for Applications Bilingual in Spanish and English  Analytical thinking  Responsibility  Leadership  Fast learning of new concepts  Excellent communication skills  Resultsoriented                       Accomplishments         Led successfully a 3person team of India analysts in transferring a report process Hewlett Packard   Reduced processing time by 70 in reports implementing macros  Promoted to Lead Analyst after just 14 months of employment ITESO         Experience       Data Analyst       082012   to   Current     Atlas Executive Consulting    –    San Diego     CA            Responsabilities Manipulation of data running pivot tables Vlookups and formulas in Excel creating reports that managers consume  Analyzing business data to develop Key Performance Indicators  and building dashboards to visualize important trends and goals for decision making  Provide strategic recommendations to managers  attend administrative assistants requests providing them information of their   Tools Excel QlikviewVBA   Achievements    Automation of 4 reports which reduced the processing time  response time and risk of error  Develop Qlickview dashboards  Several recognition by my supervisor           PSG MX Supply Chain – Planning Support of Costumer Laptops       112010   to   082012     Hewlett Packard    –    City     STATE            ResponsibilitiesTracked vendors orders by several reports Backlog Shipped Deliveries Inventory and in Transit to ensure the ontime delivery and the customers satisfaction Placed Purchase Orders in a certain instance of SAP based on Planner demands     Tools  SAP Constant Velocity use VA02 VA03 ME21N Excel     Achievements    Identified bottlenecks and implemented new and improved processes and policies  Implement HP GBS India transferring weekly supply planning activities and supervising the process November 2010 – March 2011            Information Management – Developer  Support       092010   to   112010     Hewlett Packard    –    City     STATE             Responsibilities  Developed metrics used to determine inefficiencies and areas for improvement Provide Support to users via SharePoint with any problem within a specific tool to ensure quality data    Tools  Microsoft Excel SharePoint         Education       Bachelor of Information Technology     Information Technology      Expected in   2010     ITESO      Guadalajara     Jalisco     GPA               Languages      Bilingual SpanishEnglish        Certifications      •Visual Basic for Applications  •Qlikview Developer and Desinger        Skills       •Microsoft Excel and Access Reporting Formulas macros  5 years  Advanced •Visual Basic for Applications 1 year Intermediate•Qlikview Developer and Desinger 1 year Intermediate,\n",
       " Jessica    Claire               Montgomery Street       San Francisco     CA  94105    609 Johnson Ave       49204     Tulsa     OK      Home   555 4321000        Cell           resumesampleexamplecom                  Summary      Senior system engineer with 20 years of experience in software design development and architecture Full software development life cycle requirement gathering prototyping design implementation testing release and maintenance Has strong customer interfacing experience Has strong project lead and vendor management experience Capable of working with various teams to drive requirement gathering analysis and application design Polished communication and presentation skills able to demo products and solutions to both internal and external audience        Highlights          Performance and scalability optimization  Development environment software  Complex problem solver  Strong decision maker  Excellent communicator     Strong in C C  Microsoft Visual C  PHP MySQL   Linux Scripting   Cloudera Hadoop Certified  Ceph storage clustering  Apache Mesos   Docker and Linux Containers                       Accomplishments      Promoted to Lead Engineer after 18 months of employment at Dell  Promoted to strategist position at Dell after 5 years of employment  Holder of several US issued patents  US patent 20090100194  httpwwwfaqsorgpatentsapp20090100194   US patent 20130086262  httpwwwfaqsorgpatentsapp20130086262   US patent 20120198349  httpwwwfaqsorgpatentsapp20120198349         Experience      022013   to   072015     Data Center Cloud EngineerArchitect      Abbott Laboratories    –    Madison     MS             Solid experience with Mesosphere and the latest offering of DCOS Data Center Operating System Currently integrating DCOS on cloud hardware using Chef as a configuration management tool   Experience with Data Center Cloud Servers Responsible for designing and building a rack level softwarehardware solution for hyperscale cloud customers   Responsible for evaluating ARM 64 bit as a server solution in a data center   Evaluating CoreOS and Docker containers as a solution for Dell servers in a data center   Experience with Ceph as a cold storage server solution  Currently working as a solution architect to support the sales team by providing technical guidance on Dell cloud servers  Responsible for proposing solutions to customers and responding to customer RFI and RFP  Travel to customer site to present about Dell cloud servers          2007   to   022013     Principal Engineer      Johnson  Johnson    –    Athens     GA             Worked on competitive analysis to compare the Cisco UCS solution to Dells Active System solution  Worked on automating OS deployment using WSMAN and Dells life cycle controller The solution was intended to help services team in the field to have a quick tool to deploy the Active System solution  Worked on integrated solutions using PowerEdge servers PowerConnect switches and Compellent storage array The integrated solution is intended to build a business ready configuration called vStart  Was Responsible for the integration of Hadoop Big Data with HPC clustering stack  Was the lead technical engineer to lead an engineering group of 10 The team was responsible for developing custom solutions to address unique customer requirements  Was responsible to support the sales team in EMEA by providing technical insight into Dell products  Developed plugins for Microsoft SCOM System Center Operation Manager Most development was done using C Visual Basic scripting and XML  Traveled to Dell India to train group of engineers on Dell system management products  Interface and interlock between several teams to lock down requirements and drive to results  Worked with Dell marketing on new feature requirements  Developed a Windows and Linux solution to monitor Dell systems for storage and BMC alerts and send SNMP traps to a system management console          032000   to   2007     Senior Software Engineer      Transcore    –    Hayward     CA             Developed firmware using C and C to authenticate users via Active Directory using industry standard LDAP protocol  Have a good working knowledge of USB protocols Worked with CATC to debug several USB devices  Developed a USB Linux kernel mode mass storage stack to make a USB slave device appear as a USB disk  Was the lead engineer of a group that developed Voice over IP clientserver application that allowed chat over the network The technology used GSM610 Audio Codec and Win32 Wave API  Developed Internet Explorer plugin using ActiveX technology to be used with Dell Remote Access Cards remote media feature  Worked on defining a protocol to send SCSI commands over  TCPIP The protocol was used as the basis for the remote media feature on Dells Remote Management Card DRAC   Developed application software for remote KVM keyboard video and mouse to provide the console redirection feature for Dells Remote Management Card DRAC   Was responsible for the integration of a high performance serial device driver using Microsoft DDK for Windows NT as well as Windows 20002003 following the WDM architecture          041999   to   032000     Software Engineer      Transcore    –    Miramar     FL             Was responsible for the design implementation and integration of tools such as compiler linker and assembler in an integrated development environment IDE  The IDE is used by firmware programmers to develop on Zilogs family of microcontrollers  This project required intense use of C MFC and Multithreaded Programming          031997   to   031999     Software Engineer      Transcore    –    Peachtree Corners     GA             Was the primary engineer responsible for developing Windows 98 and Windows NT device driver using WDM Win32 Driver Model Microsofts SDK and Microsofts DDK Driver Development Kit to allow host to target communication between Kodaks digital camera and the PC  Successfully developed application and interface software using C and object oriented techniques that allowed interfacing a digital camera to the IEEE 1394 high performance serial bus  Was part of the team to develop firmware embedded software for Kodaks high end digital camera  Was part of the team to develop the camera SDK software development kit using multithreaded concepts and Visual C the SDK was used by outside developers to control and acquire images from the Kodak digital camera          111994   to   031997     Software Engineer      ULTRA SCANCALSPAN CORPORTATION    –    City     STATE             Was part of the team responsible for coding and maintaining fingerprint match software using C and C on a UNIX workstation  Developed Windows 95 driver using C to allow communication with an ultrasonic fingerprint scanner from a PC over the parallel port  Integrated fingerprint match software into several applications using Visual C MFC and the Win32 SDK Software Development Kit  Designed and implemented firmware using Assembly and C to interface the MOTOROLA DSP56166 to an ultrasonic fingerprint scanner  Successfully developed firmware to allow transfer of images from a scanner to the PC over the parallel and the serial port Assembly and C were used in this project          Education      Expected in        BS     Electrical and Computer Engineering     State University of New York      Buffalo     New York     GPA   with Cum Laude GPA 3640            Skills      Win32 API ActiveX Big Data IPMI WSMAN C  C Visual C Visual Basic Visual Source Safe ClearCase Linux gnu tools  storage clustering competitive analysis  Database Dell servers device drivers XML Windows Audio API  PHP ASP  JAVA LDAP Active Directory MySQL Microsoft SQL MFC API Windows 2000  Windows 2008 Windows 20012  networking object oriented  Programming Red Hat Linux Ubuntu Linux  technical sales  SCSI protocols  Storage technology  scripting SNMP   UNIX USB VB scripting Voice over IP,\n",
       " Jessica    Claire                   Montgomery Street     San Francisco     CA  94105    609 Johnson Ave       49204     Tulsa     OK       Home   555 4321000    Cell       resumesampleexamplecom              Professional Summary      Energetic Data Engineer in developing robust code for highvolume businesses Strong decisionmaker with 6 years of experience in Data engineering and help firms in designing and executing solutions for complex business problems involving large scale data warehousing realtime analytics and reporting solutions Ability to translate business questions and concerns into specific quantitative questions that can be answered with available data using sound methodologies        Skills           Python 3x R SQL  Hadoop Apache Spark  Hive Pig Kafka Sqoop Oozie  Teradata Snowflake      Amazon S3EMRLambda  Git Jenkins Splunk  MS Office  Microsoft Visual CNET                       Work History       Data Engineer       042020   to   Current     Avanade    –    Bangor     ME             Combining data from multiple source systems Profile Systematics etc and multiple platforms Snowflake OneLake Hubs and computing canonical goldstar metrics “once and for all” to cut operational costs  Develop Spark jobs to transform data and apply business transformation rules to loadprocess data across enterprise and application specific layers  Experience in buildingoperatingmaintaining fault tolerant and scalable data processing integrations using AWS  Configured S3 buckets with various life cycle policies to archive the infrequently accessed data based on requirement  Good working experience on submitting the Spark jobs which shows the metrics of the data which is used for Data Quality Checking  Working on building efficient data pipelines that transform high volume data into a format used for analytical fraud prevention and ML use cases  Extensively used Splunk Search Processing Language SPL queries Reports Alerts and Dashboards  Excellent knowledge of source control management concepts such as Branching Merging LabelingTagging and Integration with tool like Git  Performing Data Quality checks like row count schema validation Hash key validation for all data movement between applications           Data Engineer       082019   to   042020     Avanade    –    Burlington     NC             Responsible for designing and developing various analytical solutions for gaining analytical insights into large data sets by ingesting and transforming these datasets in the Big Data environment using technologies like Spark Sqoop Oozie HIVE  Scheduling jobs to automate the process for regular executing jobs worked on using Oozie  Developed Oozie workflow schedulers to run multiple Hive and Pig jobs that run independently with time and data availability  Familiar with data architecture including data ingestion pipeline design Hadoop information architecture data modeling and data mining  machine learning and advanced data processing  All the projects which I have worked for are Open Source Projects and has been tracked using JIRA  Parallel copying of files between various clusters using Distcp Kafka in Hadoop           Data Scientist Intern       092018   to   122018     Ascend Learning    –    Memphis     TN             Acquire clean integrate analyze and interpret disparate datasets using a variety of statistical data analysis and data visualization methodologies reporting and authoring findings where appropriate  Developed Linear Mixed Effects Models for Boston Edfi dataset to estimate the teacher contribution to the student test scores  Random intercept model which utilized a preposttest design and included fixed effects for student demographics and a growth model where students were nested by time random slope and intercept and teacher was tested  Generated various Clustering models for entire West Virginia department of education and evaluated cluster’s performance           Big Data Engineer       012014   to   072017     Verizon    –                      Identify customers digital analytical needs and engage with customer and principal architects daily understand the business requirements for big data analytical solutions and break down large scale requirements into detailed system specifications  Moving data to HDFS framework using SQOOP from Teradata SQL Server  Good working experience on Hadoop tools related to Data warehousing like Hive Pig and also involved in extracting the data from these tools on to the cluster using Sqoop  Solved performance issues in Hive with understanding of joins groups bucketing partitions and working on them using HiveQL  Deployed programs written in PySpark to run Spark MLlib for analytics and reduced customers churn rate by 25          Education       Master of Science     Business Analytics     Expected in   4 2020     The University Of Texas At Dallas      Richardson     TX     GPA               Websites Portfolios Profiles        httpswwwlinkedincominJessicaClaire    httpwwwgithubcomJessicaClaire                  Skills       Python 3x R SQL  Hadoop Apache Spark  Hive Pig Kafka Sqoop Oozie  Teradata Snowflake    Amazon S3EMRLambda  Git Jenkins Splunk  MS Office  Microsoft Visual CNET         Work History       Data Engineer     042020   to   Current     Capital One Financial Corp   –   Wilmington     DE      Combining data from multiple source systems Profile Systematics etc and multiple platforms Snowflake OneLake Hubs and computing canonical goldstar metrics “once and for all” to cut operational costs  Develop Spark jobs to transform data and apply business transformation rules to loadprocess data across enterprise and application specific layers  Experience in buildingoperatingmaintaining fault tolerant and scalable data processing integrations using AWS  Configured S3 buckets with various life cycle policies to archive the infrequently accessed data based on requirement  Good working experience on submitting the Spark jobs which shows the metrics of the data which is used for Data Quality Checking  Working on building efficient data pipelines that transform high volume data into a format used for analytical fraud prevention and ML use cases  Extensively used Splunk Search Processing Language SPL queries Reports Alerts and Dashboards  Excellent knowledge of source control management concepts such as Branching Merging LabelingTagging and Integration with tool like Git  Performing Data Quality checks like row count schema validation Hash key validation for all data movement between applications           Data Engineer     082019   to   042020     Verizon Wireless   –   Tampa     FL      Responsible for designing and developing various analytical solutions for gaining analytical insights into large data sets by ingesting and transforming these datasets in the Big Data environment using technologies like Spark Sqoop Oozie HIVE  Scheduling jobs to automate the process for regular executing jobs worked on using Oozie  Developed Oozie workflow schedulers to run multiple Hive and Pig jobs that run independently with time and data availability  Familiar with data architecture including data ingestion pipeline design Hadoop information architecture data modeling and data mining  machine learning and advanced data processing  All the projects which I have worked for are Open Source Projects and has been tracked using JIRA  Parallel copying of files between various clusters using Distcp Kafka in Hadoop           Data Scientist Intern     092018   to   122018     Hoonuit   –   Minneapolis     MN      Acquire clean integrate analyze and interpret disparate datasets using a variety of statistical data analysis and data visualization methodologies reporting and authoring findings where appropriate  Developed Linear Mixed Effects Models for Boston Edfi dataset to estimate the teacher contribution to the student test scores  Random intercept model which utilized a preposttest design and included fixed effects for student demographics and a growth model where students were nested by time random slope and intercept and teacher was tested  Generated various Clustering models for entire West Virginia department of education and evaluated cluster’s performance           Big Data Engineer     012014   to   072017     Tata Consultancy Services   –              Identify customers digital analytical needs and engage with customer and principal architects daily understand the business requirements for big data analytical solutions and break down large scale requirements into detailed system specifications  Moving data to HDFS framework using SQOOP from Teradata SQL Server  Good working experience on Hadoop tools related to Data warehousing like Hive Pig and also involved in extracting the data from these tools on to the cluster using Sqoop  Solved performance issues in Hive with understanding of joins groups bucketing partitions and working on them using HiveQL  Deployed programs written in PySpark to run Spark MLlib for analytics and reduced customers churn rate by 25,\n",
       " Jessica    Claire                                   609 Johnson Ave       49204     Tulsa     OK   100 Montgomery St 10th Floor    H   555 4321000    C       resumesampleexamplecom    Date of Birth         India                      single                    Summary       Data Engineering  with experience in Design Development Implementation and support of  Data Warehousing  for over  8 years  Experienced in complete  Software Development Life Cycle SDLC   software Testing Life Cycle STLC   SDLC methodologies  Extensively worked on  Informatica Designer Tools  Source Analyze Warehouse Designer Mapping Designer Mapplet Designer and Transformation Developer and Workflow Manager Tools Task Developer Worklet and Workflow Designer Workflow Monitor and informatica Power exchange Experience in working with using Informatica in  SAP HANA   Oracle   MS SQL   Teradata  and  DB2 environments  Hands on experience in migrating on premise ETL to  Google Cloud PlatformGCP  using cloud native tools such as  BIG Query   Cloud Data Proc   Google Cloud Storage   Composer   Practical understanding of the Data modeling concepts like  Star  Schema Modeling snowflake Schema Modeling Fact and Dimension tables  Also experience in Optimizing Database querying data manipulation using SQL and  PLSQL  in Oracle flat files and SQL server database Experienced in implementing  Change Data Capture CDC  using informatica Power Center for Oracle and SAP Systems Experienced in debugging mapping by analyzing the data flow and evaluating transformations Experienced in performance tuning of data flow through source target sessions and mappings  identifying and resolving performance bottlenecks at various stages  using techniques like Database tuning and Session Partitioning Experienced in test strategy developing test plan details test cases and writing test scripts by decomposing business requirements and developing test scenarios to support quality deliverables Involved in test planning and execution for various Test Phases  Unit Test   System and User Acceptance Testing  Expert in  analyzing designing developing installing configuring  and  deploying  MS SQL Server suite of products with Business Intelligence in SQL Server Reporting Services SQL Server Analysis Services and SQL Server Integration Services Performed data profiling data cleansing data conversion exception handling and data matching using  informatica IDQ   Excellent communication skills good organizational skills selfmotivated hardworking ability to grasp quickly and learn fast and open to new technologies         Skills  Tools           ETL Tools Informatica Power Center 1051 Power Exchange 961901 Informatica Data Quality 961 Power connect for SAP BW power connect for JMS power connect for IBM MQ series power connect for Mainframes DTS MDM ERWIN  Scheduling TIDAL UC4 CONTROLM AUTOSYS OpCon  Oracle SAP HANA MS SQL Server Snowflake MongoDB Teradata DB2 AWS  Python Java SQL UNIX Unix Shell Scripts HTML XML JSON Microsoft Office Apache Spark Kafka Kubernetes Hive Scala  Data analysis Data management Data warehouse Big Data PLSQL RDBMS NoSQL Vertica Spark Kafka Oozie Maven      Debugging Coding Designing Quality analysis ETL SAP BW  AWS Cloud Tools EC2 Elastic Loadbalancers Elastic Container Service Docker Containers S3 Elastic Beanstalk Cloud Front Elastic Files System RDS Dynamo DB DMS VPC Direct Connect Route53 Cloud Watch Cloud Trail Cloud Formation IAM EMR ELB Lambda functions REST API Airflow Data Pipeline RedShift  Google Cloud Platform GCP Cloud Storage Big Query Composer Cloud Dataproc Cloud SQL Cloud Functions Cloud PubSub Dataflow AI Building Blocks Looker Cloud Data Fusion Dataprep Firestone  Azure Azure Storage Database Azure Data Factory Azure Analysis Services                       Experience       Data Engineer       082019      Current     Lockheed Martin    –    Eagan     MN            Responsible in Identifying all the Legacy systems analyze their  data models  mathematical and  Scientific models and all the business components to be migrated to Arkansas Integrated Eligibility system ARIES  NexGen solution   Business and Data Mapping Analyst worked with Client to gather business and functional requirements  Experience in building largescale data pipelines and datacentric applications using Big Data tooling like Hadoop Spark Hive and Airflow in a production setting  Experience in working with Rest APIs for data extraction  Designing and coordinating with  Informatica Power center  admin to set up services users Groups database components like tables indexes procedures and synonyms Unix groups and User access for ARIES system  Designing all the components of ARIES system and step by step conversion approach using the  Ralph Kimball  and  Bill Inmom  data warehouse design methodologies to determine the feasibility of the design within the time and cost constraints  Development of  ETL  Extract Transform and Load code components like mappings Workflows Sessions and database objects like stored procedures functions and  Unix shell scripts  from business requirements and design plan  Designing and developing the mathematical models and analytical reports in  Cognos  analyze  Developing integrations using  Informatica Cloud  Data Integration  IICS  –  CDI  Service  For Google Analytics  Responsible Identifying the performance bottleneck in the ARIES systems during Integrated  Testing  IT and  System Testing  ST and PT  Performance Testing  phases and implement Performance tuning techniques  Confer with the scrum master client partners Business Managers and adhere to the  agile   Experience in multiple database technologies such as traditional RDBMS MS SQL Server Oracle MySQL PostgreSQL MPP AWS Redshift Snowflake Teradata Distributed Processing Spark Hadoop EMR NoSQL MongoDB DynamoDB Cassandra Neo4J Titan  Conduct code review sessions with peer developers to ensure code quality  Wrote scripts and processes for  data integration  and bug fixes  Utilized  Python  to handle debugging and automation scripting tasks  Created and implemented complex business intelligence solutions  Create  Managing buckets on  S3  and store DB and log backup upload images for CND server  Setup databases on  Amazon RDS  or  EC2 Instances  as per requirements  Handson experience with snowflake utilities SnowSQL SnowPipe Big data model techniques using python  Expert in migrating data from various systems into Salesforce CRM using ETL tools   Informatica   Hands on Experience in  Data Management Data Security Data Modeling Data Quality Workflow Automation Formulas  Validations   Collaborated with Legacy team to define data extraction methodologies and data source tracking protocols  Used  SparkSQ L to read parquet data and create tables in  Hive  using  Scala API   Hands on experience with data ingestion tools like  Sqoop Kafka Flume   Used various  spark transformations  and  Actions  for cleansing the input data  Installed and configured  Apace Airflow  for workflow management and created workflow in python  Worked on Tableau Desktop versions 782 Tableau Reader and Server  Build data pipelines in Airflow in GCP for ETL related jobs using different airflow operators  Experience in GCP Dataproc GCS Cloud functions BigQuery           BIETL Developer       112018      072019     Wells Fargo    –    Loveland     CO            Analyzing the source data coming from Mainframe sources and working with business users and developers to develop the Model  Created xsd and used it in  xml generator Transformation   Also called  WSDL  files using web consumer transformation in  Informatica   Effectively and efficiently communicated systems solutions to business problems to team members business unit representatives management and other impacted project teams  Analyze and modify existing stored procedures functions and queries in order to integrate them into previously built reporting application utilizing  SSIS  and  SQL Server Management Studio   Change ETL process from  importing flat files  and  COBOL  as source for previously built application utilizing informatica Power center 96 to read data from existing Reporting Server SQL Server databases  Interface with report users to determine requirements for new and existing reports  Develop test and deploy  ETL  jobs with reliable errorexception handling and rollback framework Manage automation of file processing as well as all ETL processes within a job  workflow   Worked as a Data Analysts to match the current data mappings with old mainframe mappings  Created Design Documents Context Diagrams on every Projects and did code review  Created Reusable lookup to send emails Notification to Users  This Lookup was used by multiple developer in multiple Projects  STOP and START the  Netezza  appliances in case of issues  Prepared best practices documentation for teams in writing  NOSQL   Conducted sessions to help explain teams about the  Netezza  architecture and design  As a part of Informatica decommission objects Project Used  SVN  to archive the ETL Code and delete the unwanted mappings and workflows  Extracted data from  flat file  and staged into a single place and applied business logic to load them in the  Teradata database   Lead in few complex Projects and Performed Unit testing and created  QA documents   Participated in solution brainstorming and provided technical instruction and coaching to others within organization  Developed technical project deliverables  Created spreadsheets using  Power BI  and  Power Pivot  by importing data from the sources directly  Created visually impactful dashboards in Excel and  Tableau  for data reporting using  PivotTables  and  VLOOKUP   Involved in migrating ETL code lower environments to like dev testLoad to production environment  Used  Debugger  for debugging Mappings  Created  Tidal  Jobs and  Runbooks  to schedule jobs in Tidal  Scheduling ETL Jobs using  UC4 scheduler   Migrated ETL code using Deployment Groups from Dev to Prod environments  Created SSIS package for loading the data coming from various interfaces like OMS Orders Adjustments and Objectives and also used multiple transformation in SSIS to collect data from various sources  Worked on SSIS Package DTS ImportExport for transferring data from Database Oracle and Text format data to SQL Server  Created  SSIS  packages for File Transfer from one location to the other using FTP task  Manage and document our platform infrastructure This can go from installing a new Consul server to resolving performance issues in a MongoDB cluster through setting up a continuous integration pipeline           Informatica Developer       122017      102018     Cognizant Technology Solutions    –    Horsham     PA            Involved in all the phases of the development like Analysis Design Coding  Unit Testing  System Testing and UAT  Extracted data from  heterogenous sources  and performed complex transformations to load data into the target systems  Resolved various performance issues by examining the logs current design and  removing the bottlenecks   Created reusable ETL components which need to be run at the mapping session and workflow levels  Wrote complex SQL queries and performed extensive data analysis in  Oracle 11g   Peer reviewed developers code and ensured they fall into the enterprise guidelines  Worked extensively with session parameters Mapping Parameters Mapping Variables and Parameter files for Incremental Loading  Created Informatica mappings to load Payment flow BT cash data Currency conversion data from  SAP HANA DSL layer  to  SAP HANA DPL layerDLL SAP BA layer  Implemented SAP BW and  BOBJ  with different SAP data source  Used  Qlik  and Informatica for  ETL   reporting  Worked closely with  SAP ABAP  team to create logical systems RFC destinations and to create tRFC port for RFC destinations  Followed best practices that were defined at the enterprise level and also peer reviewed the code for the same  Created and reviewed scripts to create new tables queries for new enhancements and bug fixes in the existing  data warehouse   Used Debugger and various other techniques like tracing to fix the defects errors and data issues  Extensively worked with various Lookup caches like  Static cache Dynamic cache and Persistent cache   Involved in developing the Deployment groups for deploying the code between various environment Dev QA  Worked in the Data Integration Team to perform data and application integration with a goal of moving more data more effectively efficiently and with high performance to assist in businesscritical projects coming up with huge data extraction  Migrated data from SQL Server to  Netezza using NZMigrate utility   Experience in integration of various data sources like  Oracle DB2 SQL server csv XML and Flat Files  into staging area  Developed code to extract transform and load ETL data from inbound flat files and various databases into outbound  flat files  and  XML  files using complex business logic  Involved in deploying objects from DEV to UATPROD during monthlyquarterly releases  Developed Slowly Changing Dimension Mappings for  Type 1  SCD  and  Type 2 SCD  Monitored and improved query performance by creating views indexes and sub queries Extensively involved in enhancing and managing Unix Shell Scripts  Developed workflow dependency in  Informatica  using Event Wait Task Command Wait  Involved in  L3 Support  by fixing load failures and defects during peak and offPeak hours  Working with Informatica and  SAP ECC   We are extracting data in Informatica from  SAP ECC  via  Business Content Data sources  Design the ETL architecture for the conversion of source from legacy to new  ERP SAP   Built Sqoop scripts to extract data from the SAP  Responsible for data integration  Epicor and SAP  and data management  Validated DW data with standard  SAP reports            ETL Informatica Developer       082013      122015     ObjectOne Information Systems    –    City     STATE           · Responsible for developing ETL mappings for the reporting requirement  for data feeds  · Created mapplets and many other reusable components reduce redundancy  · Provided the best solution for their requirement Help the Clients in designing of the system and process to make it more robust and meaningful  · Created the ETL component and test scripts Involved in client meetings for their inconsistent requirements  · Sourced data from  SAP HANA  using  SAP Adapter  in Informatica Target Tables  · End to end processing from the source to target Load the data from various File systems to the  DWH  and  DM  Maintain the Versioning for the objects by using  VSS   · Successfully conducted Load Testing and Performance Testing  · Resolve the issues coming from the end to end processing Perform the enhancements if required by the business users requirement  for data feeds  · Involved in preparing Source to Target mappings and Application Design Document Worked closely with all upstream and downstream application owners to make sure interface agreement documents are clear  · Successfully conducted Load Testing and Performance Testing Automated regression test suite for actuate reporting and true portal  · Used  ALM  to track and report system defects and bugs writing modification request for the bugs in the application and helped developers to track the problem and resolve the technical issues         Education and Training       Master of Science       Computer And Information Systems       Expected in   122017                New England College      Henniker     NH     GPA        Status   ,\n",
       " Jessica    Claire                                   609 Johnson Ave       49204     Tulsa     OK   100 Montgomery St 10th Floor    Home   555 4321000    Cell       resumesampleexamplecom              Summary       Dynamic and motivated IT professional with around 7 years of experience as a Big Data Engineer with expertise in designing data intensive applications using Hadoop Ecosystem  Big Data Analytical  Cloud Data engineering  Data Warehouse  Data Mart Data Visualization  Reporting  and Data Quality solutions   In  depth knowledge of Hadoop architecture and its components like YARN  HDFS Name Node Data Node Job Tracker Application Master Resource Manager  Task Tracker and Map Reduce programming paradigm  Extensive experience in Hadoop led development of enterprise level solutions utilizing Hadoop components such as Apache Spark MapReduce HDFS Sqoop PIG Hive HBase Oozie Flume NiFi Kafka Zookeeper and YARN  Profound experience in performing Data Ingestion Data Processing Transformations enrichment and aggregations  Strong Knowledge on Architecture of Distributed systems and Parallel processing Indepth understanding of MapReduce programming paradigm and Spark execution framework  Experienced with the Spark improving the performance and optimization of the existing algorithms in Hadoop using Spark Context  SparkSQL  Dataframe API  Spark Streaming MLlib  Pair RDD s and worked explicitly on PySpark and Scala   Handled ingestion of data from different data sources into HDFS using Sqoop Flume and perform transformations using Hive Map Reduce and then loading data into HDFS  Managed Sqoop jobs with incremental load to populate HIVE external tables Experience in importing streaming data into HDFS using Flume sources and Flume sinks and transforming the data using Flume interceptors  Experience in Oozie and workflow scheduler to manage Hadoop jobs by Direct Acyclic Graph  DAG  of actions with control flows  Implemented the security requirements for Hadoop and integrating with Kerberos authentication infrastructure KDC server setup creating realm domain managing  Experience of Partitions bucketing concepts in Hive and designed both Managed and External tables in Hive to optimize performance   Experience with different file formats like Avro  parquet  ORC  Json and XML   Expertise in Creating Debugging Scheduling and Monitoring jobs using Airflow and Oozie  Experienced with using most common Operators in Airflow  Python Operator Bash Operator Google Cloud Storage Download Operator Google Cloud Storage Object Sensor  Handson experience in handling database issues and connections with SQL and NoSQL databases such as MongoDB  HBase  Cassandra  SQL server  and PostgreSQL   Created Java apps to handle data in MongoDB and HBase Used Phoenix to create SQL layer on HBase  Experience in designing and creating RDBMS Tables Views User Created Data Types Indexes Stored Procedures Cursors Triggers and Transactions  Expert in designing ETL data flows using creating mappingsworkflows to extract data from SQL Server and Data Migration and Transformation from OracleAccessExcel Sheets using SQL Server SSIS   Expert in designing Parallel jobs using various stages like Join Merge Lookup remove duplicates Filter Dataset Lookup file set Complex flat file Modify Aggregator XML  Handson experience with Amazon EC2 Amazon S3 Amazon RDS VPC IAM Amazon Elastic Load Balancing Auto Scaling CloudWatch SNS SES SQS Lambda EMR and other services of the AWS family  Created and configured new batch job in Denodo scheduler with email notification capabilities and Implemented Cluster setting for multiple Denodo node and created load balance for improving performance activity  Instantiated created and maintained CICD continuous integration  deployment pipelines and apply automation to environments and applications  Worked on various automation tools like GIT Terraform Ansible Experienced in fact dimensional modeling  Star schema Snowflake schema  transactional modeling and SCD Slowly changing dimension  Experienced with JSON based RESTful web services and XMLQML based SOAP web services and also worked on various applications using python integrated IDEs like Sublime Text and PyCharm   Efficient Cloud Engineer with years of experience assembling cloud infrastructure Utilizes strong managerial skills by negotiating with vendors and coordinating tasks with other IT team members Implements best practices to create cloud functions applications and databases         Skills          ·  Big Data Technologies  Hadoop MapReduce HDFS Sqoop PIG Hive HBase Oozie Flume NiFi Kafka Zookeeper Yarn Apache Spark Mahout Sparklib  ·  Databases  Oracle MySQL SQL Server MongoDB Cassandra DynamoDB PostgreSQL Teradata Cosmos  ·  Programming  Python PySpark Scala Java C C Shell script Perl script SQL  ·  Cloud Technologies  AWS Microsoft Azure  ·  Frameworks  Django REST framework MVC Hortonworks  ·  Tools  PyCharm Eclipse Visual Studio SQLPlus SQL Developer TOAD SQL Navigator Query Analyzer SQL Server Management Studio SQL Assistance Eclipse Postman  ·  Versioning tools  SVN Git GitHub    ·  Operating Systems  Windows 78XP20082012 Ubuntu Linux MacOS  ·  Network Security  Kerberos  ·  Database Modelling  Dimension Modeling ER Modeling Star Schema Modeling Snowflake Modeling  ·  Monitoring Tool  Apache Airflow  ·  Visualization Reporting  Tableau ggplot2 matplotlib SSRS and Power BI  ·  Machine Learning Techniques  Linear  Logistic Regression Classification and Regression Trees Random Forest Associative rules NLP and Clustering                      Experience       AWS Data Engineer       012022   to   022022     Deloitte    –    Gilbert     AZ             Designed and setup Enterprise Data Lake to provide support for various uses cases including Analytics processing storing and Reporting of voluminous rapidly changing data  Responsible for maintaining quality reference data in source by performing operations such as cleaning transformation and ensuring Integrity in a relational environment by working closely with the stakeholders  solution architect  Designed and developed Security Framework to provide fine grained access to objects in AWS S3 using AWS Lambda DynamoDB  Set up and worked on Kerberos authentication principals to establish secure network communication on cluster and testing of HDFS Hive Pig and MapReduce to access cluster for new users  Performed end toend Architecture  implementation assessment of various AWS services like Amazon EMR Redshift S3  Implemented the machine learning algorithms using python to predict the quantity a user might want to order for a specific item so we can automatically suggest using kinesis firehose and S3 data lake  Used AWS EMR to transform and move large amounts of data into and out of other AWS data stores and databases such as Amazon Simple Storage Service Amazon S3 and Amazon DynamoDB  Used Spark SQL for Scala  amp Python interface that automatically converts RDD case classes to schema RDD  Import the data from different sources like HDFSHBase into Spark RDD and perform computations using PySpark to generate the output response  Creating Lambda functions with Boto3 to deregister unused AMIs in all application regions to reduce the cost for EC2 resources  Importing  exporting database using SQL Server Integrations Services SSIS and Data Transformation Services DTS Packages  Coded Teradata BTEQ scripts to load transform data fix defects like SCD 2 date chaining cleaning up duplicates  Developed reusable framework to be leveraged for future migrations that automates ETL from RDBMS systems to the Data Lake utilizing Spark Data Sources and Hive data objects  Conducted Data blending Data preparation using Alteryx and SQL for Tableau consumption and publishing data sources to Tableau server  Developed Kibana Dashboards based on the Log stash data and Integrated different source and target systems into Elasticsearch for near real time log analysis of monitoring End to End transactions  Implemented AWS Step Functions to automate and orchestrate the Amazon SageMaker related tasks such as publishing data to S3 training ML model and deploying it for prediction  Integrated Apache Airflow with AWS to monitor multistage ML workflows with the tasks running on Amazon SageMaker  Environment AWS EMR S3 RDS Redshift Lambda Boto3 DynamoDB Amazon SageMaker Apache Spark HBase Apache Kafka HIVE SQOOP Map Reduce Snowflake Apache Pig Python SSRS Tableau  Assessed organization technology infrastructure and managed cloud migration process  Configured computing networking and security systems within cloud environment  Implemented cloud policies managed technology requests and maintained service availability           Data Engineer       012016   to   112019     Cognizant Technology Solutions    –    Hatboro     PA             Worked on Azure Data Factory to integrate data of both onprem MY SQL Cassandra and cloud Blob storage Azure SQL DB and applied transformations to load back to Azure Synapse  Managed Configured and scheduled resources across the cluster using Azure Kubernetes Service  Monitored Spark cluster using Log Analytics and Ambari Web UI  Transitioned log storage from Cassandra to Azure SQL Datawarehouse and improved the query performance  Involved in developing data ingestion pipelines on Azure HDInsight Spark cluster using Azure Data Factory and Spark SQL  Also Worked with Cosmos DB SQL API and Mongo API  Develop dashboards and visualizations to help business users analyze data as well as providing data insight to upper management with a focus on Microsoft products like SQL Server Reporting Services SSRS and Power BI  Performed the migration of large data sets to Databricks Spark create and administer cluster load data configure data pipelines loading data from ADLS Gen2 to Databricks using ADF pipelines  Created various pipelines to load the data from Azure data lake into Staging SQLDB and followed by to Azure SQL DB  Created Databrick notebooks to streamline and curate the data for various business use cases and also mounted blob storage on Databrick  Utilized Azure Logic Apps to build workflows to schedule and automate batch jobs by integrating apps ADF pipelines and other services like HTTP requests email triggers etc  Worked extensively on Azure data factory including data transformations Integration Runtimes Azure Key Vaults Triggers and migrating data factory pipelines to higher environments using ARM Templates  Ingested data in minibatches and performs RDD transformations on those minibatches of data by using Spark Streaming to perform streaming analytics in Data bricks  Environment Azure SQL DW Databrick Azure Synapse Cosmos DB ADF SSRS Power BI Azure Data lake ARM Azure HDInsight Blob storage Apache Spark  Adept in troubleshooting and identifying current issues and providing effective solutions  Managed performance monitoring and tuning while identifying and repairing issues within database realm  Identified key use cases and associated reference architectures for market segments and industry verticals  Designed surveys opinion polls and assessment tools to collect data  Tested validated and reformulated models to foster accurate prediction of outcomes  Created graphs and charts detailing data analysis results  Recommended data analysis tools to address business issues  Developed new functions and applications to conduct analyses  Cleaned and manipulated raw data  Collaborated with solution architects to define database and analytics engagement strategies for operational territories and key accounts           Big Data Engineer  Hadoop Developer       102013   to   122015     Novogradac  Co Llp    –    Long Beach     CA           AnsibleDenodoDenodoCloudWatchAvroPySparkPySparkPySparkMLlibDataframeNiFiNiFi  Interacted with business partners Business Analysts and product owner to understand requirements and build scalable distributed data solutions using Hadoop ecosystem  Developed Spark Streaming programs to process near real time data from Kafka and process data with both stateless and state full transformations  Worked with HIVE data warehouse infrastructurecreating tables data distribution by implementing partitioning and bucketing writing and optimizing the HQL queries  Built and implemented automated procedures to split large files into smaller batches of data to facilitate FTP transfer which reduced 60 of execution time  Worked on developing ETL processes Data Stage Open Studio to load data from multiple data sources to HDFS using FLUME and SQOOP and performed structural modifications using Map Reduce HIVE  D eveloping Spark scripts UDFS using both Spark DSL and Spark SQL query for data aggregation querying and writing data back into RDBMS through Sqoop  Written multiple MapReduce Jobs using Java API Pig and Hive for data extraction transformation and aggregationAvrom multiple file formats including Parquet Avro XML JSON CSV ORCFILE and other compressed file formats Codecs like gZip Snappy Lzo  Strong understanding of Partitioning bucketing concepts in Hive and designed both Managed and External tables in Hive to optimize performance  Developed PIG UDFs for manipulating the data according to Business Requirements and also worked on developing custom PIG Loaders  Developing ETL pipelines in and out of data warehouse using combination of Python and Snowflakes SnowSQL Writing SQL queries against Snowflake  Experience in report writing using SQL Server Reporting Services SSRS and creating various types of reports like drill down Parameterized Cascading Conditional Table Matrix Chart and Sub Reports  Used DataStax Spark connector which is used to store the data into Cassandra database or get the data from Cassandra database  Wrote oozie scripts and setting up workflow using Apache Oozie workflow engine for managing and scheduling Hadoop jobs  Worked on implementation of a log producer in Scala that watches for application logs transform incremental log and sends them to a Kafka and Zookeeper based log collection platform  Used Hive to analyze data ingested into HBase by using HiveHBase integration and compute various metrics for reporting on the dashboard  Transformed tPySpark using AWS Glue dynamic frames with PySpark cataloged the transformed the data using Crawlers and scheduled the job and crawler using workflow feature  Worked on installing cluster commissioning  decommissioning of data node name node recovery capacity planning and slots configuration  Developed data pipeline programs with Spark Scala APIs data aggregations with Hive and formatting data JSON for visualization and generatiPySpark     Environment AWS Cassandra PySpark Apache Spark HBase Apache Kafka HIVE SQOOP FLUME Apache oozie Zookeeper ETL UDF Map Reduce Snowflake Apache Pig Python Java SSRS  Onfidential  Developed and implemented Hadoop code while observing coding standards  Optimized and tuned Hadoop environments and modified hardware to meet prescribed performance thresholds  Developed new functions and applications to conduct analyses  Created graphs and charts detailing data analysis results  Tested validated and reformulated models to foster accurate prediction of outcomes           Python Developer        092012   to   102013     Fiserv    –    City     STATE             AWS S3 EC2 LAMBDA EBS IAM Datadog CloudTrail CLI Ansible MySQL Python Git Jenkins DynamoDB Cloud Watch Docker Kubernetes  Leveraged open communication collective decisionmaking and thorough reviews to create performant and scalable systems  Worked with serverside and frontend technologies and leveraged common design patterns to code dynamic and userfriendly systems  Implemented new API routes architected new ORM structures and refactored code to boost application performance  Harnessed version control tools to coordinate project development and individual code submissions  Introduced cloudbased technologies into Python development to expand onpremise deployment options  Wrote clear and clean code for use in projects  Resolved customer issues by establishing workarounds and solutions to debug and create defect fixes          Education and Training       Post Graduate      Data Engineering      Expected in   022022     Purdue University      West Lafayette     IN     GPA                Post Graduate      Data Science And Business Analytics      Expected in   092021     University of Texas At Austin      Austin     TX     GPA                Bachelor of Arts     Business Administration And Management     Expected in   122009     Califonia State University       Fullerton CA          GPA,\n",
       " Jessica    Claire                   Montgomery Street     San Francisco     CA  94105    609 Johnson Ave       49204     Tulsa     OK       H   555 4321000    C       resumesampleexamplecom    Date of Birth         India                      single                    Summary       Over 3 years of professional IT experience in  Data Engineering  and  Data Analytics  using various languages and tools like  SQL Python BigHadoop   Extensive experience on Data Engineering field including Ingestion Datalake Datawarehouse Reporting and Analytics  Strong knowledge and experience on Data Analysis Data Lineage Big Data pipelines Data quality Data Reconciliation Data transformation rules Data flow diagram including Data replication Data integration and Data orchestration tools  Knowledge and experience on AWS services like RedshiftRedshift spectrumS3GlueAthena Lambdacloudwatch and EMRs like HIVE Presto  Extensively used ETL methodology for performing Data Migration Extraction Transformation and loading using  Talend  and designed data conversions from wide variety of source systems  Experienced in Data Ingestion projects to inject data into  Data lake  using multiple sources systems using Talend Bigdata  Good technical Skills in  SQL Server   ETL  Development using  Informatica tool   Expertise in writing  SQL   PLSQL  to integrate of complex OLTP and OLAP database models and data marts worked extensively on  Oracle SQL SERVER   Experience in all the life cycle phases of the projects on  large data sets  and experience with performance  tuning  and  troubleshooting   Ability to work effectively with associates at all levels within the organization  Strong background in mathematics and have very good analytical and problemsolving skills         Skills           Big Data Ecosystems  HDFS MapReduce Spark Kafka Hive Airflow Stream Sets HBase Flume Zookeeper Nifi Sentry Ranger  Scripting Language  Python PowerShell Scripting Pig Latin HiveQL  Cloud Environment  Amazon Web Services AWS Microsoft Azure  NoSQL Database  Database  MySQL Oracle Teradata MS SQL SERVER PostgreSQL DB2  Version Control  Git SVN Bitbucket  ETL Tools  Tableau Microsoft Excel Informatica Power BI R Google Data Studio                        Experience       Data Engineer       012022      Current     Honeywell    –    Michigan     ND            Worked on Architecture Design for Multistate implementation or deployment  Implement One time Data Migration of Multistate level data from SQL server to Snowflake by using Python and SnowSQL  Day today responsibility includes developing ETL Pipelines in and out of data warehouse develop major regulatory and financial reports using advanced SQL queries in snowflake  Stage the API or Kafka Datain JSON file format into Snowflake DB by FLATTENing the same for different functional services  Build Docker Images to run airflow on local environment to test the Ingestion as well as ETL pipelines  BuildingMaintaining Docker container clusters managed by Kubernetes Utilization of Kubernetes and Docker for the runtime environment of the CICD system to build test and deploy  Created Airflow DAGs to schedule the Ingestions ETL jobs and various business reports  Created  Airflow  Scheduling scripts in Pythonx  Cluster capacity planning along with operations team and management team and Cluster maintenance as well as creation and removal of nodes  HDFS  support and maintenance  Strong knowledge of  Rack awareness  topology in the  Hadoop cluster   Involved in Loading data from  LINUX file system  to  Hadoop Distributed File System   Responsible for building scalable distributed data solutions using  Hadoop   Experience in managing and reviewing  Hadoop log files   Data migration from  RDMS  to  Hadoop  using  Sqoop  for analysis and implemented  Oozie  jobs for automatic data imports from source  Created  HBase  tables to store various data formats of  PII  data coming from different portfolios  Strong in Exporting the analyzed and processed data to the  Relational databases  using  Sqoop  for visualization and for generation of reports for the team           Data Engineer       012021      122021     Honeywell    –    Nashville     TN            Prepared ETL design document which consists of the database structure change data capture Error handling restart and refresh strategies  Worked with different feeds data like JSON CSV XMLDAT and implemented Data Lake concept  Developed Informatica design mappings using various transformations  Designing and building multiterabyte full endtoend Data Warehouse infrastructure from the ground up on Confidential  Redshift  for large scale data handling Millions of records every day  Optimizing and tuning the  Redshift  environment enabling queries to perform up to 100x faster for Tableau and SAS Visual Analytics  Wrote various data normalization jobs for new data ingested into  Redshift   Advanced knowledge on Confidential  Redshift  and MPP database concepts  Migrated on premise database structure to Confidential  Redshift  data warehouse  Developed UDF in Scala to implement the business logic  Developed spark applications in Scala on distributed environment to load huge number of JSON files with different schema in to Hive tables  Most of the infrastructure is on AWS used   AWS EMR  Distribution for Hadoop   AWS S3  for raw file storage   AWS EC2  for Kafka  Used  AWS Lambda  to perform data validation filtering sorting or other transformations for every data change in a DynamoDB table and load the transformed data to another data store  Created  Airflow  Scheduling scripts in Python  Programmed  ETL functions  between Oracle and Amazon Redshift           SQL Developer       062019      122023     Ihs Markit    –    Southfield     MI            Gathered business requirements and converted them into new TSQL stored procedures in visual studio for database project  Performed unit tests on all code and packages  Analyzed requirement and impact by participating in Joint Application Development sessions with business client online  Performed and automated SQL Server version upgrades patch installs and maintained relational databases  Performed front line code reviews for other development teams  Modified and maintained SQL Server stored procedures views adhoc queries and SSIS packages used in the search engine optimization process  Updated existing and created new reports using Microsoft SQL Server Reporting Services Team consisted of 2 developers  Created files views tables and data sets to support Sales Operations and Analytics teams  Monitored and tuned database resources and activities for SQL Server databases          Education       Master of Science       Data Analytics Engineering       Expected in   122022                George Mason University      Fairfax     VA     GPA        Status           38 GPA           Bachelor of Science       Electronics  Communication Engineering       Expected in   062019                KL University      Guntur          GPA        Status   ,\n",
       " JC     Jessica    Claire                      Montgomery Street       San Francisco     CA    94105             555 4321000                 resumesampleexamplecom                         Profile     Professional and dedicated worker committed to delivering high quality performance and superior customer service to insure team success Utilize strong ethics customer relations and training  Over 8 years of experience in Storage management including designing installing configuring  and administering TSM  Netbackup Experience in both UNIX and Windows environment       Core Qualifications           Extensive knowledge of TSM administration procedures    Adept at server software installation and maintenance      Familiar with UNIX and Perl scripting     Good problem solving skills                          Professional Experience        072015   to   Present   Data Protection Engineer    Bmo         Pleasant Prairie     WI            TSM Implementation and administration TSM 6X 5X Implementation and administration on AIX Linux Solaris Windows platforms Tivoli data Protection for Oracle SQL implementation Bare metal Recovery implementation IBM 3592 EO5 LTO2LTO3 and LTO4  DataDomain configuration Tivoli Storage Management Disaster Recovery Implementation Installing TSM client on Unix and Win 200x servers TSM tuning for faster backup and restore Server to server configuration Expertise in TSM DR implementation and recovery Lanfree configuration  on UnixAixLinuxHPUX TSM library manager and library client configuration and Implementation Managing 8 TSM server environment with 2000 clients different site with Data Doman and physical library TSM administration and node backup centralized scheduling and reporting Avamar Client registration and configuration Avamar Client backup and restore Participate in SRT Schedules Retention and Targets yearly review with customers            042012   to   052015   Data Protection Engineer    Bmo         Portage     WI            TSM 6X 5X Implementation and administration on AIX Linux Solaris WinTel platforms Tivoli data Protection for Oracle SQL implementation Bare metal Recovery implementation IBM 3592 EO5 LTO2LTO3 and LTO4  DataDomain configuration Tivoli Storage Management Disaster Recovery Implementation Installing TSM client on Unix and Win 200x servers TSM tuning for faster and backup and restore Server to server configuration Expertise in TSM DR implementation and recovery Lanfree configuration  on UnixAixLinuxHPUX TSM library manger and library client configuration and Implementation Managing 10 TSM servers environment with 3000 clients different site with Data Doman and physical library            042007   to   052012   IT Specialist    Autodesk Inc         Colorado     TX            Netbackup 5x 6x implementation and administration on Window and Unix Netbackup client installation and configuration Provided  247 oncall support rotation Responsible for troubleshooting and daily backup issues Monitored and maintained tape volumes Troubleshot ACSLStape library software  issues Wrote a Runbook for both TSM and Netbackup Netbackup to TSM migration Netbackup client implementation Backup and restore using TSM Tivoli data Protection for Oracle SQL implementation            122006   to   042007   System Administrator    Advantest America Corporation         Fremont     CA            Coordinated hardware and software installations and upgrades to insure work is performed in accordance with Agency policy  Coordinated and monitored troubleshooting to isolate and diagnose command system problems  Daily system checks of all TSM servers tape library devices and server backup operations  Improved processes by writing scripts to automate task that is done on regular base            042000   to   062005   Design Automation Engineer    Intel Corp         Multiple Cities     NJ            Extensive experience in gate level simulation  Evaluated and QA new simulation tools  Assisted Design Engineers with tool issues they encountered and solve the problem  Interfaced between Intel and tool vendors to resolve issues and new releases  Provided automation and made improvements to existing flows  Trained new users on Gate Level Simulation tools and any new methodology  Experience in test vector generation test bench writing and regression running  Supported GLS and RTL VTPSIM Vector Test Pattern Simulation for all CPD Components Platform Division and tool owner for VTPSIM  Supported Design Engineering Environment for all Chipset Engineering including Software and License installations  Responsible for Local DBA Database Administration for TIBETBug tracking tool  Developed utility to generate indicator data for managers  Created Auto clone feature for Design Group which enabled them to submit bugs in two different projects at the same time  Provided training for Design Product Design Automation and Marketing Engineers on bug tracking tool  Setup training class for Design Automation Group            051997   to   042000   Test Engineer    Drs Technologies         Johnstown     PA            Sole author of STIL2S9K tool that generated all S9K test mode patterns for Camino MCH MTH and Carmel MCH  This tool was the first tool that enabled PCG Platform Components  Group to generate scan transition fault vectors with multiple timing sets  Kafka tool owner and support  This tool converts VCD Variable Change Dump file to STIL Standard Test Interface Language format  It was the first tool that enabled PCG to convert VCD to STIL  Worked with Teradyne Engineers to develop a STIL2J973 vector generation tool for J973 testers  Ran tests and gave feedback to the vendor  Helped out Product Engineers in generating test mode and functional vectors and validated the pattern before silicon arrived  Site owner for software tools Fabio and Purify  These tools were required to be run on the products test tape for white paper process          Education        Expected in   1994   Bachelor of Science       Computer Engineering    California State University     Sacramento     CA      GPA       Computer Engineering        Skills     AIX Agency automate Automation Backup hardware Client clients Database Administration DBA Disaster Recovery functional HP UX IBM Intel Linux Managing 8 Marketing Win WinTel Windows Window 2000 migration Oracle processes QA reporting scheduling server configuration servers scripts Simulation Solaris SQL Tivoli troubleshooting TSM TSM 6X Unix upgrades Netbackup Netbackup 5x author,\n",
       " Jessica    Claire                                   609 Johnson Ave       49204     Tulsa     OK   100 Montgomery St 10th Floor    H   555 4321000    C       resumesampleexamplecom    Date of Birth         India                      single                    Summary      Selfmotivated Data Engineer offering 5 years of leadership experience across various industries Methodical with significant experience in data mining and statistical analysis Excellent problemsolver with a history of automating processes and driving operational enhancements Effective at making important team decisions focused on moving products through planning preproduction and production phases        Skills           Data Integrity Validation and Analysis  Database Programming and SQL  Product Planning      Analytical Problem Solving  Strong Work Ethic  Application Support                       Experience       Data Engineer II        032021      Current     Usaa    –    Argyle     TX            Work with stakeholders to identify improvements to processes and data delivery using technical aptitude to deliver ad hoc tools reporting and analytics with a focus on the needs of the Residential Portfolio  Collaborated with solution architects to define database and analytics engagement strategies for operational territories and key accounts  Maintain JIRA projects and workflows to meet project metrics  Work with Residential Portfolio to reduce CIP Construction InProgress by 69 across Residential Cox Business and Network Transformation programs by developing clear processes to mitigate risk providing visibility through enhanced reporting and database aligning  Build and validate the hypothesis of product ideas and infrastructure improvements for Fiber Reinforcement New Build Rebuild and Expansion Projects  Provide for database management to support the integrity of data for enterprisesupported tools and applications  Work with software development team to design and customize applications SiteTracker applications and trackers to meet market exceptions  Utilized existing reporting to perform data blending as needed to serve business needs  Develop processes to improve workflow and department efficiency  Designed and developed data quality dashboards with visualization in Tableau Power BI and Salesforce  Work with the development team to define and implement customer change requests to enhance product functionality  Complete pilot testing implement best data practices and optimize workflow to enhance performance and drive efficiencies in the organization to meet or exceed customer and business expectations  Utilize WATTS and SiteTracker experience as a user andor report development  Identify strengths and weaknesses of existing reports suggests areas of improvement and help enhance existing data reports to meet evolving requirements  Interpret and analyze data using exploratory mathematic and statistical techniques based on scientific methods           ANALYTICS CONSULTANT       032019      042021     Syndigo    –    Boise     ID            Partnered with WBS developers to automate manual processes decreasing errors and saving time creating a 6 increase in margins 2021 fiscal year  Managed performance monitoring and tuning while identifying and repairing issues within database realm  Worked to create UI mockups and prototypes that illustrate how sites function and look like  Provided executives with analytics and decisionsupport tools used a basis for reorganization consolidation and relocation strategies  Executed tests collected and analyzed resulting data and identified trends and insights to achieve maximum ROI in paid search campaigns  Evaluated project requirements and content standards for each project to produce copy in line with a creative structure  Recommended changes to website architecture content and linking to improve SEO positions           DATA QUALITY ANALYST       052018      092020     Illumina    –    Virginia     MN            Worked mainly with wellknown engineering clients to provide customers with quality products  Dashboard development for project projection project closing and project profit  Responsible for estimating negotiating and agreeing on budgets and times lines while overseeing the production process  Responsible for drafted proposals per specifications and estimation skeleton with a focus on Data Centers  Developed RPAs that work alongside ERP to run cost analytics and tracked quality data metrics  Provide code compliance knowledge and enforcement for both owner and contractor  Drive and own backlog grooming and management prioritize iteration and drive acceptance testing and delivery of iterations  Defining road maps and prioritizing backlogs of work to meet with a vision of providing services that meet customers standards  Prioritized functionality backlog after golive to resteer team to achieve the desired ROI  Performed root cause analysis based on rework data to create corrective and preventive measures throughout the product development  Collaborated with Business Analysts and the software development team to identify and convert business goals into data requirements  Developed and streamlined productivity tracker to provide 34month predictions  Responsible for managing the progression of a project from RFP to  CO          Education and Training       Master of Science       Computer Science  Analytics        Expected in                   Georgia Tech Master of Science in Computer       Atlanta GA          GPA        Status                  Bachelor of Science       Civil Engineering   Industrial Microbiology       Expected in                   University of Georgia      Athens     GA     GPA        Status                 Activities and Honors       GatherUp  Nonprofit organization working with the community to provide recourses for further growth  NAMIC  Marketing  2021 2H Synergy Award,\n",
       " Jessica    Claire                                   609 Johnson Ave       49204     Tulsa     OK   100 Montgomery St 10th Floor    Home   555 4321000    Cell       resumesampleexamplecom              Summary       Strong IT experience in AWS cloud computing Bigdata  Data warehousing  Strong Business Domain Knowledge in Sales Segmentation  Territory Planning  Strong Coding  SQL experience in Python and Redshift  Having an experience in Agile and deliver the results based on stories and task assigned on the sprint  Implementation Knowledge in Serverless Architecture using AWS Cloud Computing  Having Good Hands on experience in GIT as well as CICD pipeline Integration  Having Good Hands on Experience in building Data Model based on requirements         Skills           Programming Languages Java Python Unix Unix Shell Scripting  Cloud Technologies Amazon Web Services AWS  Version Control AWS CodeCommit GIT GitHub Repositories      Continuous IntegrationContinuous DeliveryCICD AWS CodeDeploy AWS CodePipeline  Databases and SQL Redshift Oracle Netezza NoSQL DDB  Elasticsearch  Big Data Technologies Hadoop Hive Ozzie AirFlow Spark PySpark Scoop Flume                       Experience       Senior Data Engineer       012018   to   Current     Splunk    –    Bloomington     MN             Collaborated with product owners to gather requirement to help build a solution for Sales Segmentation  Identified key use cases and associated reference architectures for market segments and industry verticals  Worked as part of project teams to coordinate database and pipeline development and determine project scopes and limitations  Collaborated with solution architects to define database and analytics engagement strategies for operational territories and key accounts  Developed and managed enterprisewide big data environments  Specified user access levels for each database segment to protect database integrity and company information  Developed and implemented security initiatives to protect important company data  Established hardware requirements and devised storage capacity solutions and choose wisely on the AWS services by outweigh the requirement and business usecase           Big Data Engineer       122015   to   122017     Nike Inc    –    Gurnee     IL             Perform as a Big Data Developer and work in various phases like Data Ingestion Data Integration and Transformation  Create a Sqoop import command and pull the data both tables and all tables in DBs from MySQL DB to HDFS as part of Data Ingestion  Creates a MapReduce Programs as well as Spark programs to parse analyze and implement the solutions based on its customer need  Perform operations to filter the records from DB boundary query incremental update or insert in the Sqoop import commands  Perform operations to insert the data directly to Hive tables Change the delimiters and end line character and Change the formats like textFile AvroDataFile ORC file into HDFS systems using Sqoop Import commands  Perform Sqoop Eval function to evaluate the data in MYSQL  Perform Sqoop Export function to export the data from HDFS and loaded it into MYSQL and understand the delimiter of the file define the no of mapper to perform etc  Create a Flume config file to ingest the data from various source systems like Spool Directory NetCat Exec Sequence etc and loaded it into Avro HDFS etc  Define a proper channelsMemory File etc and loaded all the data comes from Source to Sinks  Used the interceptor to modify the data comes from Source like Filtering Regex Include the Timestamp Search and Replace etc  Create a MapReduce Program using Eclipse IDE and execute it through jar file  Create a Mapper Class and using Map method generate the key value pair as nodewithdate system utilization by writing in Context application  Create a Reducer Class and using reduce method generate the final output of system utilization per nodewithdate  Implements custom based writable class to get the two values in the mapOutputValue class  Implements custom based partitioner class to assign a appropriate data to the right reducerBasically try to achieve multilevel group by function with MR limitations  Implements Pattern Matching Logic for semistructured Data and routed the good and bad records separately  Create a custom based input format as well as record reader to parse the XML file  Handson in creating the Broadcast Variables  Handson in SparkSQL DataFrame creation DF via class object in Scala Convert DF to RDD TempTable Schema creation and So on           ETL Developer       092009   to   042015     Allegis Group    –    Jacksonville     FL             Created and implemented complex business intelligence solutions  Created conceptual logical and physical data models for use in different business areas  Developed and managed enterprisewide data analytics environments  Identified protected and leveraged existing data  Monitored multiple databases to keep track of all company inventory  Assisted maintenance team with completion of preventive maintenance and unscheduled service needs  Monitored installations to ensure compliance with local codes and industry best practices          Education and Training       Master of Science     Information Technology     Expected in        Amity University      Noida India          GPA                Bachelor of Engineering          Expected in   052008     College of Engineering Guindy Anna University      Chennai India          GPA,\n",
       " Jessica    Claire                   Montgomery Street     San Francisco     CA  94105    609 Johnson Ave       49204     Tulsa     OK       H   555 4321000    C       resumesampleexamplecom    Date of Birth         India                      single                    Summary     Involving in various projects related to Data Modeling Data Analysis Design and Development for Data warehousing environments Practical understanding of the Data modeling Dimensional  Relational concepts like StarSchema Modeling Snowflake Schema Modeling Fact and Dimension tables Comprehensive knowledge and experience in process improvement normalizationdenormalization data extraction data cleansing data manipulation Exceptional troubleshooting skills with ETL Technologies        Highlights         Hadoop Hive Avro Kafka MapReduce Looker Programming Languages SQL Java Scala PHP Shell Script HTML Database Tools Aster Database PostgreSQL MySQL Operating Systems Linux Unix Microsoft Windows                       Accomplishments              Experience       Data Engineer       082012      Current     Avanade    –    Greenville     NC            Experience with full development cycle of a Data Warehouse including requirements gathering design implementation and maintenance  Data modeling based on Kimball methodology developed and architected ETL processes for different projects RMA inventory purchase order etc Reengineer some of the current ETL processes to streamline the data acquisition and integration process using our homegrown ETL tools  Built eventdriven data pipeline that comprises multiple steps to gather high volume and velocity data from both push based and pull based sources which includes design and implement web service to collect data JSON object over http request convert data in JSON format into Avro then feed into Kafka land data in Kafka on Hadoop and Aster  Designed and built Looker API using Scala which makes other teams access the data in data warehouse more easily and gracefully  Establish and maintain SQL queries and routines  Write adhoc queries based upon the schema understanding for diverse needs of our business users           Java Intern       022012      032012     Dominion Enterprises    –    Fredericksburg     VA            Implemented code for small features  bugfixes in Java           PHP Developer       062011      092011     Meetoncruise    –    City     STATE            Implemented the backend logic using PHP  Utilized JQuery and AJAX to provide dynamic and interactive user interface  Designed and implemented data model in MySQL database to support the website          Education       Master of Science       Electrical and Computer Engineering       Expected in   2012                Polytechnic Institute of New York University      Brooklyn     NY     GPA        Status         Electrical and Computer Engineering         Bachelor of Science       Automation Engineering       Expected in   2010                Nanjing University of Aeronautics and Astronautics      Nanjing     Jiangsu     GPA        Status         Automation Engineering        Skills     streamline ad AJAX API data acquisition Data modeling data warehouse Database engineer ETL features HTML http PHP inventory Java JQuery JSON Linux logic access Microsoft Windows MySQL Operating Systems PostgreSQL processes Programming requirements gathering Shell Script SQL Unix user interface website,\n",
       " Jessica    Claire                   Montgomery Street     San Francisco     CA  94105    609 Johnson Ave       49204     Tulsa     OK       Home   555 4321000    Cell       resumesampleexamplecom              Summary      Over 5 years of engineering and finance experience as a Data Developer with cross platform integration experience using Hadoop and Spark architecture Handson experience configuring as well as installing Hadoop Ecosystem  HDFS MapReduce Pig Hive Oozie Flume HBase Spark Sqoop Flume and Oozie Strong understanding of various Hadoop services MapReduce and YARN architecture Vast knowledge in importing as well as exporting data in HDFS using SQOOP Automated transfer of data from Hbase by developing Map Reduce jobs Expertise in analysis using PIG HIVE and MapReduce Experience in HDFS data storage and support for running mapreduce jobs Involved in Infrastructure set up and installation of HDP stack on Amazon Cloud Experienced with ingesting data from RDBMS such as SQL Teradata into HDFS using Sqoop and Oracle Expertise in Hadoop architecture HDFS Mapreduce Oozie Sqoop Spark Hive Zookeeper and NoSQL databases Deployed and configured clusters in Cloudera Manager Set up backups and disaster recovery for Data Node and Name Node metadata as well as sensitive data on clusters Expertise in implementing and designing HDFS access controls directory and file permissions user authorization that facilitates stable secure access for multiple users in a large multitenant cluster Knowledge on exporting as well as importing stream data into HDFS using Flume Spark and Kafka messaging systems Utilized various schedulers on the Job tracker to share resources within clusters for Map Reduce jobs such as FIFO scheduler Fair Scheduler and Capacity Scheduler Monitored jobs with YARN and provisioned configured and installed HBase Kafka Hive Oozie Sqoop Ranger Storm Flume Spark as well as maintained total architecture AWS services for cloud migration such as S3 Redshift EMR Glue Athena and DynamoDB Expertise in Vertica DB architecture High Availability and column orientation Great knowledge of Agile and Scrum methodologies Behavior Driven Development Domain Driven DesignTest Driven Development and continuous integration as well as delivery Skilled in defining functional and gathering user interface requirements for applications and websites Expertise in real time analysis by utilizing RDD Datasets Data Frames and Streaming API in Apache Spark Expertise in using Spark Resilient distributed datasets and dataframe APIs over the Cloudera platform to perform analytics on Hive data by integrating Hadoop with Kafka Expertise in uploading Click stream data from Kafka to HDFS Expert in utilizing Kafka for messaging and publishing subscriber based messaging systems  Worked with NoSQL databases such as Cassandra HBASE PostgreSQL MongoDB Redis DynamoDB        Skills           SQL transactional replications  SAN technologies  Reverse engineering skills  Warehouse models  Security Protocols  Enterprise information architecture      Quality analysis  Deep learning  Data mining  Data analytics  Critical thinking                       Experience       Data Engineer       072021   to   Current     Principal Financial Group    –    Pittsburgh     PA            Analyze design and build Modern data solutions using Azure PaaS service to support visualization of data  Understand current Production state of application and determine the impact of new implementation on existing business processes  Extract Transform and Load data from Sources Systems to Azure Data Storage services using a combination of Azure Data Factory TSQL Spark SQL and USQL Azure Data Lake Analytics Data Ingestion to one or more Azure Services  Azure Data Lake Azure Storage Azure SQL Azure DW and processing the data in In Azure Databricks  Created Pipelines in ADF using Linked  ServicesDatasetsPipeline to Extract Transform and load data from different sources like Azure SQL Blob storage Azure SQL Data warehouse writeback tool and backwards  Developed Spark applications using Pyspark and  SparkSQL for data extraction transformation and  aggregation from multiple file formats for analyzing  transforming the data to uncover insights into the  customer usage patterns  Responsible for estimating the cluster size monitoring  and troubleshooting of the Spark databricks cluster  Experienced in performance tuning of Spark  Applications for setting right Batch Interval time  correct level of Parallelism and memory tuning   Adept in troubleshooting and identifying current issues and providing effective solutions  Managed performance monitoring and tuning while identifying and repairing issues within database realm  Contributed to maintaining  Type  databases in conjunction with data development and software engineering teams  Assisted solution providers with definition and implementation of technical and business strategies  Collaborated with solution architects to define database and analytics engagement strategies for operational territories and key accounts           Data Engineer       072020   to   062022     Principal Financial Group    –    Portland     OR             Worked on MongoDB by using CRUD Create Read Update and Delete Indexing Replication and Sharding features  Involved in designing the row key in HBase to store Text and JSON as key values in the HBase table and designed row key in such a way to getscan it in sorted order  Oozie was integrated with the Hadoop stack which consists of MapReduce Hive Sqoop and Pig and Unix shell scripts  While working on Hive tables used Hive QL designed and Implemented PartitioningStatic Dynamic Buckets on Hive  Performed Cache and Persist as well as Checkpointing when utilizing Spark Streaming APIs to build common learning data models to get near realtime data from Kafka and persisted into Cassandra  Conducted cluster coordination services with Zookeeper and monitored the workload capacity planning and job performance through Cloudera Manager  Built applications by utilizing Maven and integrated with Continuous Integration servers such as Jenkins to build jobs  Deployed maintained and configured Test and multinode Dev Kafka Clusters as well as handled clusters and implemented data ingestion for real time processing in Kafka  Created cubes in Talend for various aggregation types of data from PostgreSQL and MS SQL server to visualize data  Monitored Name Node health status in Hadoop as well as the number of Data Nodes and Task trackers running along with automating jobs to pull data from various MySQL data sources to push result set data to HDFS  Created story telling dashboards through Tableau Desktop to publish on Tableau Server and integrated GitHub for version control tools to maintain the versions in projects  Deployed Spark applications in python and utilized Datasets and DataFrames in Spark SQL for processing data faster  Loaded transactional data with Sqoop from Teradata created managed and external tables in Hive and worked with semistructured and structured data of 5 Petabytes in size  Constructed MapReduce jobs to validate clean and access data and worked with Sqoop jobs with incremental load to populate and load into Hive External tables  Designed strategies to optimize distribution of weblog data over clusters in addition to exporting and importing stored web log data into Hive and HDFS through Sqoop  Responsibilities of building scalable data solutions that are distributed through Hadoop and Cloudera as well as developed and designed automated test scripts in Python  Integrated Apache Storm with Kafka to perform web analytics and to perform clickstream data from Kafka to HDFS  Developed SQL scripts and designed solutions to implement Spark with Hive Generic UDFs for incorporating business logic within Hive queries  Developed data pipelines in AWS using S3 EMR Redshift to extract data from weblogs to store into HDFS  Transmitted streaming data from Kafka to HBase Hive and HDFS by integrating Apache Storm and wrote Pig scripts for transforming raw data from various data sources to form baseline data  Participated in Agile meetings Ford Credit Customer Data domain conducted daily scrum meetings and spring planning  Expanded and optimized data pipelines and architecture as well as optimized data flow and collection  Created pipelines from scratch using PySpark and scheduled jobs using Airflow  Stream processed data in Kafka streaming wrote Producer Consumer Connector and Streams API to handle stream of records subscription of topics consume input and build reusable producers and consumers  Worked with unstructured datasets such as IoT sources sensor data XML and JSON document sources  Worked with on prem clusters as well as clusters on the cloud and used GCP Big Query Data Fusion and DataFlow  Scaled up architecture with Google Kubernetes and set up load balancing  Worked on various optimization techniques in Spark such as cache and persist using accumulators  bucketing and partitioning garbage collection tuning data serialization windowing functions and broadcast variables  Used numerous Spark transformations such as groupByKeyreduceByKey flatMap filter sample union etc  Utilized Dataproc to spin up clusters Dataprep for data analysis and Dataflow for streaming data using Apache Beam  Dealt with VPC controls on Google Cloud Platform and CMEK encryption for data security  Environment Hadoop HDFS HBase SparkPython and Scala Azure Databricks Scala Hive Kafka MapReduce Sqoop ETL Java Python PostgreSQL SQL Server Teradata UnixLinux           Big Data Developer       052017   to   052020     Cognizant Technology Solutions    –    Mount Laurel     NJ             Performed query tuning in HiveQL as well as performance tuning transformations in Pyspark using Spark RDDs and Python  Used lambda functions to create a Serverless Data intake pipeline on AWS  Using python constructed a Spark Streaming pipeline to receive realtime data from Apache Kafka and store it in DynamoDB  Implemented Apache Spark data processing module to handle data from multiple RDBMS and Streaming sources then compiled Apache Spark applications using Scala and Python  Extensive experience designing and scheduling multiple Spark Streaming  batch Jobs in Python pyspark and Scala  Achieved highthroughput scalable faulttolerant stream processing of live data streams using Apache Spark Streaming  Involved with the use for creating and saving data frames using various Python modules with pyspark  Sqooped data and performed Hive queries for data ingestion from relational databases to analyze historical data  Experienced with Elastic MapReduce EMR as well as setting up environments on amazon AWS EC2 instances for pipelines in AWS  Expertise in handling Hive queries using Spark SQL such as window functions and aggregations  Ran Spark applications on Docker using EMR and used AWS Glue data catalog as the metastore in Spark SQL  Configured different File Formats like Avro parquet for HIVE querying and processing based on business logic  Utilized Sequence files RC files Map side joins bucketing partitioning for Hive performance enhancement and storage improvement  Implemented Hive UDF to implement business logic and performed extensive data validation using Hive  Involved in loading the structured and semi structured data into spark clusters using Spark SQL and Data Frames API  Utilized AWS CloudWatch to monitor the performance environment instances for operational and performance metrics during load testing  Scripting Hadoop package installation and configuration to support fully automated deployments  Involved in chefinfra maintenance including backupsecurity fix on Chef Server  Deployed application updates using Jenkins  Installed configured and managed Jenkins  Triggering the SIT environment build of the client remotely through Jenkins  Deployed and configured Git repositories with branching forks tagging and notifications  Worked on MongoDB database concepts such as locking transactions indexes Shading replication schema design  Viewing the selected issues of web interface using SonarQube  Developed a fully functional login page for the companys user facing website with complete UI and validations  Installed Configured and utilized AppDynamics Tremendous Performance Management Tool in the whole JBoss Environment Prod and NonProd  Installed and installed Hive in a Hadoop cluster and assisted business usersapplication teams in finetuning their HIVE QL for optimal performance and efficient use of cluster resources  Utilized Oozie workflow for ETL Process for critical data feeds across the platform  Configured Ethernet bonding for all Nodes to double the network bandwidth  Configured Kerberos Security Authentication protocol for existing clusters  Constructed the use of Zookeeper failover controller ZKFC and Quorum Journal nodes for high availability for significant production clusters and automatic failover controller created  Installation and deployment of many Apache Hadoop nodes on an AWS EC2 system as well as development of Pig Latin scripts to replace the old traditional process with Hadoop and data feeding to AWS S3  Experience with AWS CloudFront including the creation and management of distributions that provide access to an S3 bucket or an HTTP server running on EC2 instances  Developed Python scripts UDFs using both Data framesSQL and RDDMapReduce in Spark 16 for Data Aggregation queries and writing data back into OLTP system through Sqoop And Developed enterprise application using Python  Constructed Spark application performance optimization including determining the appropriate Batch Interval time Parallelism Level and Memory Tuning  Experience and handson knowledge in Akka and LIFT Framework  Used PostgreSQL and NoSQL database and integrated with Hadoop to develop datasets on HDFS  Environment HDFS Map Reduce Hive 110 Kafka Hue 390 Pig Flume Oozie Sqoop Apache Hadoop 26 Spark SOLR Storm Cloudera Manager Red Hat MySQL Prometheus Docker Puppet YARN SparkSQL Python Amazon AWS Elastic Search Tableau Linux  Key Skills SQL Apache hive Apache SparkDatabricks Jupyter Notebook Anaconda Python Django Pandas Flask Keras NumPy Scikitlearn MatPlotLib Tensorflow  Time Series Forecasting AB testing Bayesian methods PowerBI MicrosoftWord Excel Powerpoint Java Data Visualization Analytical Skills Cost Accounting Corporate Finance Knowledge Statistical AnalysisRStudio          Education and Training       Bachelor’s     Computer Science     Expected in        Uttara Institute of Business and Technology                GPA,\n",
       " Jessica    Claire               Montgomery Street       San Francisco     CA  94105    609 Johnson Ave       49204     Tulsa     OK      Home   555 4321000        Cell           resumesampleexamplecom                  Professional Summary      Business Intelligence Consultant with a 10year career in data warehousing business intelligence reporting and data management architecture Progressive developer and technical team lead with a strength in design  development as well as driving performance reducing inefficiencies and cutting costs Possess comprehensive knowledge and hands on experience in both ETL and Reporting tools Knowledge of Credit Card account life cycle management in Finance domain Functional knowledge of Collections and Recovery operations Expertise in planning executing and spearheading various SDLC and Agile Scrum projects in compliance to quality standards Known for effective communication with excellent relationship building  interpersonal skills strong analytical problem solving  organizational abilities Proven track record of taking ownership and diving deeper into issues to identify the root cause and troubleshoot towards resolution        Skills           ETL Tools  Ab Initio  Scripting Languages  Unix shell scripting Python SparkScala  Cloud Services Microsoft Azure Cloud Services Data Lake  DataBricks and Data Pipelines Azure Data Factory  BI Reporting Skills  Tableau Desktop Tableau Server Power BI Reporting  SAP Business Objects SAP BOUniverse Designer Tool SAP BO XI WEBI ReportingSAP BO XI Deski Reporting  Database  Oracle  Teradata Hive      Scheduler tools  Autosys ControlM  Relational Database Management  Business Intelligence Reporting  Project Management  Data Analysis and Visualization                       Work History      062017   to   Current     Senior Data Engineer      Thoughtworks    –    Memphis     TN            A multitenure loyalty program across all Williams Sonoma brands – the first time that customers can earn points by purchasing across the multiple brands WSI Pottery Barn West Elm etc I work in the customer data warehouse CDW which is Teradata and work with their 3rd party marketing systems vendor There are various data points and integrations with the data warehouse which holds all customer information points transactions loyalty IDs etc   Worked with Requirements Analysts and PDMs to identify understand and document business needs for data flow Analyze requirementsUser stories at business meetings and strategize impact of requirements on different platformsapplications Worked with Project Management in creation of project estimates for each Agile story  Engaged in projects that uses Scala and Azure DatabricksDatafactoryDatalake to extract process and load Adobe Clickstream data received for Williams Sonoma ECOM website Deployed custom codes in Scala to read JSON extract CSV files from Adobe add column headers handle badmalformed records handle invalid records before finally writing cleansed data into ParquetDelta file format partitioned by date and hour  Build and review design deliverables Perform dependency analysis between new objects created in Ab Initio graphs Conduct IT and UAT testing of each of these graphs Record errors reported during Unit and Integrated testing  Prepare production Implementation Plan to deploy codes successfully to production environment  Coordinate daily standups short meetings where teammates talk through whats being worked on yesterday what was done today and if blocked Involved in variety of other scrum meetings such as planning meetings where team pulls in stories requirements grooming meeting to look at backloglist of stories and flush out timeline and work expected demo show work that was completed in sprint etc  Reporting  Visualization in Tableau and Power BI  Design and deploy rich Graphic visualizations with Drill Down and Drop down menu option Prepare Dashboards using calculations parameters Apply various reporting objects like Filters prompts Calculated fields Groups Parameters Work on the development of Dashboard reports for the Key Performance Indicators for the top management          032010   to   062017     Senior DeveloperTechnical Team Lead      Tech Mahindra Synchrony Financial Services    –    City     STATE            Synchrony Financial is a consumer financial services company offering consumer financing products including credit promotional financing and loyalty programs and installment lending through Synchrony Bank its wholly owned subsidiary Synchrony is the largest provider of private label credit cards in the US The company provides private label credit cards for such brands as Amazon JC Penney CheapOAir OneTravel Sams Walmart Lowe’s Guitar Center Gap BP We as Data warehouse solution providers store this credit card holder information from the instance a credit card is applied till the account is closedcharged off   Understanding the full scope of requirements from business Estimating time and effort involved from gathering project requirements till project implementation  Answering technical queries driving product initiatives and metric collection and analysis  CoOrdinating between project stake holders – Business Client and offshore teams during all phases of project  Preparing design documentation design reviews development performing code reviews to ensure coding standards are followed testing and deployment of application enhancements  Experience in Ab Initio toolsets including the following  o Parallel and serial flow batch graphs conditional components other components like reformat normalize and join lookup and graphs processing ASCII and EBCDIC layouts  o Knowledge on Abinitio architecture including the GDE Cooperating system EME and other related items  o Fine tuning of Abinitio graphs based on performance enhancement by proper usage of memory in the components  o Well versed with various Ab Initio components such as Join Rollup Partition Departition Dedup sorted Scan Normalize DeNormalize  o Expertise knowledge improving Performance and Troubleshooting of the AbInitio graphs and monitoring ABInitio run time statistics  o Experience with advanced Abinitio metaprogramming air commands and other admin related tasks including the creation of save and performing migration from one server to the other  Establish support such as acquiring conditioned test data support from third partyteam etc for Integration Testing to simulate production environment and to ensure correctness and quality of buildparameter set up  Getting sign off from IT managers for deploying parameterset up onto production environment  Documenting implementation plan and Hour by Hour plan listing down the tasks in sequence of their execution on the date of implementation  Coordinate release activities across multiple teams          Education      Expected in   4 2008     Bachelors     Information Technology     College of Engineering Bhubaneswar      India          GPA               Accomplishments      • Tableau Desktop Specialist Certified No expiration  These are Open Badges that I have been awarded and that attest to my skills  httpswwwyouracclaimcombadges556948fdd8114f8097d245ab6c530d9clinkedinprofile   o Tableau Desktop Specialist title use their foundational knowledge of Tableau Desktop and data analytics to solve problemsDesktop Specialists can connect to prepare explore and analyze data and share their insights        Skills       ETL Tools  Ab Initio  Scripting Languages  Unix shell scripting Python SparkScala  Cloud Services Microsoft Azure Cloud Services Data Lake  DataBricks and Data Pipelines Azure Data Factory  BI Reporting Skills  Tableau Desktop Tableau Server Power BI Reporting  SAP Business Objects SAP BOUniverse Designer Tool SAP BO XI WEBI ReportingSAP BO XI Deski Reporting  Database  Oracle  Teradata Hive    Scheduler tools  Autosys ControlM  Relational Database Management  Business Intelligence Reporting  Project Management  Data Analysis and Visualization         Work History      062017   to   Current     Senior Data Engineer       Kforce Inc Williams Sonoma Inc   –   San Francisco     CA     A multitenure loyalty program across all Williams Sonoma brands – the first time that customers can earn points by purchasing across the multiple brands WSI Pottery Barn West Elm etc I work in the customer data warehouse CDW which is Teradata and work with their 3rd party marketing systems vendor There are various data points and integrations with the data warehouse which holds all customer information points transactions loyalty IDs etc   Worked with Requirements Analysts and PDMs to identify understand and document business needs for data flow Analyze requirementsUser stories at business meetings and strategize impact of requirements on different platformsapplications Worked with Project Management in creation of project estimates for each Agile story  Engaged in projects that uses Scala and Azure DatabricksDatafactoryDatalake to extract process and load Adobe Clickstream data received for Williams Sonoma ECOM website Deployed custom codes in Scala to read JSON extract CSV files from Adobe add column headers handle badmalformed records handle invalid records before finally writing cleansed data into ParquetDelta file format partitioned by date and hour  Build and review design deliverables Perform dependency analysis between new objects created in Ab Initio graphs Conduct IT and UAT testing of each of these graphs Record errors reported during Unit and Integrated testing  Prepare production Implementation Plan to deploy codes successfully to production environment  Coordinate daily standups short meetings where teammates talk through whats being worked on yesterday what was done today and if blocked Involved in variety of other scrum meetings such as planning meetings where team pulls in stories requirements grooming meeting to look at backloglist of stories and flush out timeline and work expected demo show work that was completed in sprint etc  Reporting  Visualization in Tableau and Power BI  Design and deploy rich Graphic visualizations with Drill Down and Drop down menu option Prepare Dashboards using calculations parameters Apply various reporting objects like Filters prompts Calculated fields Groups Parameters Work on the development of Dashboard reports for the Key Performance Indicators for the top management          032010   to   062017     Senior DeveloperTechnical Team Lead       Tech Mahindra Synchrony Financial Services   –   Chicago     IL     Synchrony Financial is a consumer financial services company offering consumer financing products including credit promotional financing and loyalty programs and installment lending through Synchrony Bank its wholly owned subsidiary Synchrony is the largest provider of private label credit cards in the US The company provides private label credit cards for such brands as Amazon JC Penney CheapOAir OneTravel Sams Walmart Lowe’s Guitar Center Gap BP We as Data warehouse solution providers store this credit card holder information from the instance a credit card is applied till the account is closedcharged off   Understanding the full scope of requirements from business Estimating time and effort involved from gathering project requirements till project implementation  Answering technical queries driving product initiatives and metric collection and analysis  CoOrdinating between project stake holders – Business Client and offshore teams during all phases of project  Preparing design documentation design reviews development performing code reviews to ensure coding standards are followed testing and deployment of application enhancements  Experience in Ab Initio toolsets including the following  o Parallel and serial flow batch graphs conditional components other components like reformat normalize and join lookup and graphs processing ASCII and EBCDIC layouts  o Knowledge on Abinitio architecture including the GDE Cooperating system EME and other related items  o Fine tuning of Abinitio graphs based on performance enhancement by proper usage of memory in the components  o Well versed with various Ab Initio components such as Join Rollup Partition Departition Dedup sorted Scan Normalize DeNormalize  o Expertise knowledge improving Performance and Troubleshooting of the AbInitio graphs and monitoring ABInitio run time statistics  o Experience with advanced Abinitio metaprogramming air commands and other admin related tasks including the creation of save and performing migration from one server to the other  Establish support such as acquiring conditioned test data support from third partyteam etc for Integration Testing to simulate production environment and to ensure correctness and quality of buildparameter set up  Getting sign off from IT managers for deploying parameterset up onto production environment  Documenting implementation plan and Hour by Hour plan listing down the tasks in sequence of their execution on the date of implementation  Coordinate release activities across multiple teams,\n",
       " Jessica    Claire                                   609 Johnson Ave       49204     Tulsa     OK   100 Montgomery St 10th Floor    H   555 4321000    C       resumesampleexamplecom    Date of Birth         India                      single                    Summary      I am an Automation Developer with a love for troubleshooting and electronics This passion for automation started at Micro Center in 2017 where I began finding ways to simplify my reports to upper management These reports took several hours to compile and took the time I could have spent guiding my agents Eventually I started finding ways to gather that data through an API After discovering I could collect this information and use APIs to simplify tasks I started programming software to do these things This new skill helped change how I approached my teams problems  complaints and eventually led to me creating tools to improve our efficiency and productivity Since then my passion has grown into a career that keeps me wanting to learn more        Skills           Systems Engineering  Lab Test Technician  Cybersecurity  Data Engineering      API Design  Deployment  Software Developer Python NodeJS PHP Bash Git Etc  Automation  Disaster Recovery                       Experience       Data Engineer       062021      112023     Bank Of America Corporation    –    Aurora     IL            Deployed Linux cloud servers and applications to meet the needs of the company PostgreSQL Metabase Apache Spark TableAU  Secured servers and applications using ACLsﬁrewallsIDSIPS and following standard security practices  Built several ETLs in PythonPHPJavaScript for several ticketing platforms  Designed disaster recovery plans for our systems  Constructed complex SQL queries to aid in reporting and automation  Tested data regularly to ensure accurate reporting  Managed several PostgreSQL databases  Automated reports and redundant tasks through the use of APIs and databases  Created and implemented complex business intelligence solutions  Created conceptual logical and physical data models for use in different business areas  Adept in troubleshooting and identifying current issues and providing effective solutions  Managed performance monitoring and tuning while identifying and repairing issues within database realm  Identified protected and leveraged existing data  Planned and installed database management system software upgrades to enhance systemic performance           Test Engineering Technician       082020      062021     General Atomics    –    Houlka     MS            Traveled daily to integrators to provide quality assurance for PowerSpec systems and review the build process  Compiled reports for integrators to log and classify defects  Answered product questions for PowerSpec systems  Regularly assisted neighboring departments on build projects and quality controlled parts for buyers  Worked directly with vendors for BIOS updates and patches on PowerSpec systems  Created and deployed system images for PowerSpec products  Built extensive QC reports through rigorous testing methodologies including benchmarking components and testing for compatibility  Performed problem solving and resolution for technical quality inspection and customer quality issues  Developed and maintained solutions for integration and testing phases  Tested functionality performance and compliance of each product against design specifications to maintain strong development standards and high customer satisfaction  Completed unit and regression tests on software and individual modules  Created and optimized automated testing tools for repetitive tasks  Created and maintained database of common and known testing defects  Worked with offsite teams to complete timely tests and facilitate smooth product releases  Promoted high customer satisfaction by resolving problems with knowledgeable and friendly service           Call Center Lead       012019      082020     Metlife    –    Omaha     NE            Encouraged team members to improve productivity and service levels by modeling correct behaviors and coaching employees  Resolved team support issues with efficient approach to keep call center operating smoothly and customers satisfied with services  Routinely updated guides to reduce questions on the ﬂoor  Provided accurate and detailed reports for management  Handled customer escalations and ensured they went to the appropriate team  Maintained Zendesk and the ticketing procedures to ensure both a smooth and efficient experience for my agents  Worked with management to update legacy procedures and remove redundant processes through automation  Managed customer concerns with calm demeanor and knowledgeable service  Created an efficient workflow in order to provide a better experience for consumers  Kept records of customer interactions or transactions thoroughly recording details of inquiries  Worked directly with stores and customer relations team to improve customer retention  Built and maintained call center server to house reports and automations           Technical Consultant       092017      012019     Applied Systems Inc    –    University Park     IL            Troubleshot and resolved problems with programs and systems  Utilized knowledge of applications programming and systems functionality to assist employees with technical needs  Assisted customers with various types of technical issues via email live chat and telephone  Handled customer service issues by providing guidance or escalating for advanced support  Served as first point of contact for escalated technical service calls emails and live chat  Troubleshot hardware issues and worked with service providers to facilitate repairs for end users  Developed and maintained strong relations with customers to meet quality expectations  Documented customer complaints and inquiries for use in technical documentation and bug tracking  Reviewed support cases for technical and troubleshooting accuracy and identified needed process improvements  Maintained uptodate case documentation for future reference  Demonstrated advanced product knowledge to solve customer issues  Delivered remote assistance for technical issues using screen sharing mouse and keyboard control and other tools          Education and Training       High School Diploma       Electronic Classroom       Expected in   062012                Electronic Classroom of Tomorrow      Columbus OH          GPA        Status   ,\n",
       " Jessica    Claire               Montgomery Street       San Francisco     CA  94105    609 Johnson Ave       49204     Tulsa     OK      Home   555 4321000        Cell           resumesampleexamplecom                  Experience      012015   to   Present     System Services Representative Data Center Engineer      Bridger Steel    –    Evansville     WY             Hired and trained by IBM to perform multiple tasks including hardware breakfix warranty repair in a multivendor environment  I am responsible for setting up coordinating and monitoring the operation of server equipment at two Delta Airline datacenters located at the airport  I run diagnostic tests to detect machine malfunctions  Independently handle high impact critical ticketsincidents  I use my connectivity skills to connect to the servers management port with SSH or Telnet  Other duties include but not limited to the following Rack stack cable configure and provision servers  Perform installation of wiring patch panel cables network switches hubs and KVMs  Deploy Cisco Layer 23 networking equipment  Installupgradereplacedeinstall servers devices and network components  Resolve issues  Execute planned changes  Use ServiceNow to follow change management requests until completion  Be accountable for ensuring a high level of client satisfaction with service delivery  Perform required site inspections  Perform audits  Problem analysis and remediation          012012   to   012014     IT Manager      City Of Atlanta    –    City     STATE             Hired by City of Atlanta to ensure reliability and availability of City of Atlanta data centers  Provided ongoing identification diagnosis and resolution of issues for users and City departments  Collaborated with internal teams and vendors at all technical levels to troubleshoot and resolve issues  Managed Windows Update Services for enterprise wide patches and security updates  Provided Exchange 2003 and 2010 administration  Upgraded maintained and installed servers and switch equipment  Provided server searches for open records act requests and litigation discovery searches  Involved in domain migration  Installed and maintained the security system for new and existing Windows servers  Proactively monitored production systems with a sense of urgency when issues arose  Worked with enterprise network loadbalancers Juniper Palo Alto and Cisco devices  Experience working with multiple server hardware platforms including IBM Dell Sun EMC and HP  Performed data center security monitoring  Successful citywide migration of Windows XP to Windows 7  Successfully implemented security software for City of Atlanta open records requests          012003   to   012012     Remote System x Server Technical Support Specialist      IBM    –    City     STATE             Hired by IBM to ensure reliability and availability of servers for IBM customers  This role participates in remote technical support of IBM hardware and software products andor systems and include the following  Provided remote troubleshooting and analysis assistance for installation or reinstallation usage and configuration questions  Provided answers for general usage and operation questions  Provided problem determination  problem source Identification  Reviewed diagnostic information to assist in isolation of a problem cause which could include assistance interpreting traces and dumps  Identify known defects and fixes to resolve problems  Identify suspected defects and engage development teams to assist in resolution  Helped with questions regarding product documentation related to the supported products  Interpreted online manuals regarding IBM code and application interfaces  Collaborated with other support centers and business units to provide seamless problem resolution  Demonstrated proficiency in the hardware and software platform supported by maintaining applicable technical certifications  Provided technical support service delivery within established guidelines demonstrating soft skills and technical skills that contribute to client satisfaction  Demonstrated excellent oral and written communication skills  Acquired industry certification and skills training  Exceeded customer satisfaction and case resolution metrics  Supported product lines including eSeries xSeries Intellistation Blade Center AIX iDataPlex fiber switches QLOGIC Emulex Cisco Brocade Quantum tape backup libraries  Provided additional support for FastT DASD fiber channel cabling ServeRAID Manager and management processors          Education      Expected in   2011     Associates of Applied Science Degree     Cyber Security     Chattahoochee Technical College      Marietta     GA     GPA       Cyber Security        Expected in        Security Certified Professional Network Certified Professional Server Certified Professional A Certified Professional Cisco Certified Technician                           GPA               Expected in        Blade eSeries xSeries AIX NAS SAN Certified          IBM University                GPA               Summary     Committed to ongoing professional development with CompTIA A Network Server and Security certifications  Also extensive academic training in network administration tracking intrusion detection firewall configuration OS administration cloud computing High level of technical proficiency with network utilities Master level of providing upperlevel support to management Master level of providing remote troubleshooting support to ensure continual operations of critical customer network systems Master experience in fastpaced high volume call environment with 12 years experience supporting IBM xSeries Blade Center Lenovo EMC AS400 DASD fiber NAS SAN RAID network appliances and tape library products Exceptional root cause analysis skills        Highlights         MS Server 2008 MS Server 2012 MS Windows 7 MS Windows 10 VMware Redhat Enterprise UNIX Networking  TCPIP SSL TLS SSH Telnet FTP HTTPS DHCP DNS WPA2 Ping Tracert TACACS Kerberos RADIUS RAS NAS IDSIPS Firewalls ToolsApplications  Solarwinds WireShark Snort Tera Term PuTTY MS Windows Security Templates MS Windows Security Update Service Microsoft Exchange 20032010 MS Windows Active Directory LDAP Terminal Services MS Windows Access Control MegaRAID Microsoft Office Lotus Notes Visual Basic 2010                       Skills     A Certified Active Directory AIX tape backup cables cable cabling change management Cisco Cisco Certified excellent oral hardware client customer satisfaction DASD delivery Dell DHCP diagnosis documentation DNS Firewalls FTP HP hubs IBM IBM hardware IDS LDAP litigation Lotus Notes Access Exchange Microsoft Exchange 2003 Microsoft Office Windows 7 Windows MS Windows 7 MS Windows Windows XP migration Enterprise NAS Network Networking Problem analysis problem resolution processors RAS Redhat SAN SSH servers SSL Sun switches switch TCPIP technical support Technician Telnet troubleshoot troubleshooting UNIX upgrade Visual Basic wiring written communication skills,\n",
       " Jessica    Claire                   Montgomery Street     San Francisco     CA  94105    609 Johnson Ave       49204     Tulsa     OK       H   555 4321000    C       resumesampleexamplecom    Date of Birth         India                      single                    Summary     Desktop and Server Support Application Server Technician Offer my Windows Server 20122008 R22003 Windows XP78 Mac OS X Linux Application Server Microsoft Office 2010 and Office Mac 2011 Active Directory and Network LANWAN switches and routers experience Desktop and server hardware and software technical support experience Strong analytical troubleshooting communication and customer service skills  Skilled Windows System Administrator offering 10 years of experience building and maintaining multiplatform technology services with a solid understanding of current Windows Mac and UNIX application systems       Highlights           Systems\tWindows XP78 Desktop\tMax OS X 108 109 1010\tiO78 mobile and tablet  Windows 20032008 Server\tAndroid mobile\t\tRed Hat Enterprise Linux  Unix web applications\tLANWAN  Mobile Phone\tiPhoneiPad Apple\tBlackberry\t\tAndroid  Applications\tMicrosoft Office 20072010\tOffice Mac 2010\t\tFinal Cut 7 and 10  Microsoft Office 365\tPages OS X\t\tNumbers OS X  Adobe Creative Suite cloud\tAdobe Acrobat XXI\tAdobe Lighthouse 45  Parallels\tWebEx  Utilities\tSymantec Antivirus\tVoltage Email Encryption\tBarracuda Backup Cloud  PGP DesktopServer\tSymantec Ghost  Server Applications\tActive Directory\tPowerShell Scripting\tWINS\tDFS  DHCP\tFilePrint Services\tLDAP\tGroup Policy GP  Exchange 2010\tNTFS security\t\tHyperV\tDNS                         Accomplishments       Requirements Analysis    Completed business requirements analysis including the evaluation of systems specifications for the Soundview Throgs Neck Community Health Center     Strategy and Planning    Developed and communicated Electronic Health Record security policies and standards to all users  Established policies and procedures for medical record documentation     IT Training    Successfully trained all employees to use Electronic Health Record and Billing systems     Network Support    Acted as first point of contact for all major technical issues including power outages system failures and disaster recovery  Oversaw infrastructure of three offices and acted as support for helpdesk technicians of Yeshiva University          Experience       Data Support Services Engineer       072013      092013     Montefiore Medical Center formally SVTNCMHC Health Care Services    –    City     STATE            Managed the daytoday IT operations for the Montefiore Medical Center  Assisted in the migration of technology services from Yeshiva Universitys servers to Montefiores servers including computers user logins data files printer settings software applications and email archives  Provided QA testing in the migration of the centers Electronic Health Record Mindlinc and Billing IMA system  Trained all staff in the use of Montefiores technical services including clerical registration billing electronic health record and emailprintingdata file usage           Technical System Support Engineer       072003      072013     Yeshiva University Health Care Services Soundview Throgs Neck Community Health Center SVTNCMHC    –    City     STATE            Desktops Mobile Phones Printers and Application Servers Provided all levels of enduser desktop server mobile phonetablet and printer technical support for 2 healthcare center locations in the Bronx  Backend technical support for all server and network services  Responsible for managing 15 application servers including 4 domain controllers  Deployed and maintained a Windows 2008R2 and 2003 Active Directory environment  Managed all aspects of server and application security using Active Directory LDAP and Linux  Planned and implemented the physical deployment and migration of Windows 7 desktops from Windows XP  Consulted daily with the executive clinical and administrative staff concerning the overall quality and possible improvement of technology systems for the medical center  Trained all staff in the use of SVTNYeshiva Universitys technical services including clerical registration billing electronic health record and emailprintingdata file usage  Provided QA support and testing of our internal and external billing system IMA  Work closely with outside vendors to design and maintain the EHR Billing and Backup applications  Implemented and maintained the centers data backup system using Barracuda Cloud Backup  Identified designed and implemented the requirements for the centers disaster recovery system  Responsible for managing and maintaining the centers audiovideo conference room system          Education       Graduate Certificate       Digital Media and Project Management       Expected in                   The New School      New York     NY     GPA        Status                  BBA       Computer Information Systems       Expected in                   Baruch College City University of New York      New York     NY     GPA        Status                  Skills      Active Directory administrative Adobe Adobe Acrobat Antivirus Apple audio Backup Billing billing system clerical Encryption Desktops DHCP disaster recovery DNS Email Ghost LAN LDAP Linux Mac managing Max Exchange Microsoft Office Office Windows 7 Windows Windows XP migration Enterprise network OS printer Printers quality QA Red Hat Servers Scripting Symantec technical support Phones Phone Unix Utilities video WAN web applications,\n",
       " Jessica    Claire                                 609 Johnson Ave       49204     Tulsa     OK   100 Montgomery St 10th Floor   Home   555 4321000        Cell           resumesampleexamplecom                  Summary      · Seasoned data engineer professional adept at understanding mandates developing plans leading and implementing enterprisewide solutions Complex problemsolver with an innovative approach A proven track record with experience in all facets of data engineering from ETL to data consumption  Extensive experience in Hadoop and cloud computing platforms with focus on automated CICD Strong programming skills in design and implementation using JavaJ2EE Scala SQL and other scripting languages Excellent leadership management qualities with excellent communication and interpersonal skills        Skills          · Design and Create scalable platforms and products in data realm including ETL in hadoop ecosystem data services and SQLNoSql databases  · Create and review high level design documentation architecture diagrams  · Design and create automated CICD for various data platform both onprem and cloud ecosystems    · Lead and participate in all aspects of SDLC collaborating with product owners engineering devops and delivery teams to align and deliver products  · Test software products to ensure that the software products developed by the engineering team meet the companys quality and standards  · Guide and mentor engineering team on technical matters including design architecture coding practices                      Experience      022020   to   Current     Lead Data Engineer      Transamerica Life Insurance Company    –    Charlotte     NC            · Managing 3 scrum teams of ETL services and devOps across data platforms  · Oversaw and develop the Largescale real data processing pipelines to handle transaction and real time data using kafka and spark to various databases as part of Data Management Platform team  · Leading migration from hbase to aerospike and solr to elasticsearch which including 30TB historical data migration using spark  · Collaborate with devOps network infra teams to create data plaform architecture and establish project plans and timeline  · Design and create seamless CICD pipelines and provide solutions to all application both onprem and cloud applications And also manage build engineering team  · Managing entitlement of the applications and tools extensively working with security risk and architecture teams to define and implement RBACs across data platform  · Working closely with security infrastructure and vendors to remediate software and infrastructure vulnerabilities including in house and third party applications part of data platform   Recipient of Values Champions Award for 2021 at Early Warning         112012   to   022020     Senior Data Engineer      Change Healthcare    –    Kennesaw     GA            · Developed Batch and streaming spark application in scala to load data kafka hbase and solr on cloudera based Hadoop platform in DMP  · Explored with the Spark improving the performance and optimization of the existing algorithms in Hadoop using Spark Context Spark SQL Data Frame PairRDDs Spark YARN  · Developed ETL pipelines using Streamsets to move data from kenisiskafka to various datastores  · Extensive experience in designing and implementation of continuous integration continuous delivery continuous deployment through Chef ansible bamboo gitlab and harness  · Setup full CICD pipelines so that each commit a developer makes will go through standard process of software lifecycle and gets tested well enough before it can make it to the production  · Created Streamsets pipelines to consume data from Amazon Kinesis and Redhsift for data processing         042011   to   092012     Software Engineer      General Motors    –    West Chester     OH            · Involved in analyzing system specifications designing and development for multiple J2EE wholesale applications  · Performed a shakeout test to the code migrated to UAT for the new customer setups defects and for the enhancements  · Performed acceptance testing and conducted functional testing for the customer using WebMethods and UNIX environment  · Extensively worked on PM Online application project from scratch  · Conducted full lifecycle software development from planning to deployment and maintenance  · Reviewed and modified unit and integration tests to improve software quality and reliability  · Performed backend testing using SQL queries to validate the data in the backend database Used SQL to validate backend database changes deletes and update         122007   to   032011     Software Developer      Walt Disney Co    –    Cincinnati     OH            · Delivered code to meet functional or technical specifications  · Designed frontend and backend solutions for testdriven development  · Participated in code review meetings providing input on bugs inefficiencies and potential solutions to emergent issues  · Modified existing software systems to enhance performance and add new features  · Performed regression and performance tests for updated systems         Education and Training      Expected in        Bachelor of Science     Electrical Engineering     University of South Alabama      Mobile     AL     GPA,\n",
       " Jessica    Claire                                   609 Johnson Ave       49204     Tulsa     OK   100 Montgomery St 10th Floor    H   555 4321000    C       resumesampleexamplecom    Date of Birth         India                      single                    Summary      Practical Database Engineer possessing indepth knowledge of data manipulation techniques and computer programming paired with expertise in integrating and implementing new software packages and new products into system Offering 12year background managing various aspects of development design and delivery of database solutions Techsavvy and independent professional bringing outstanding communication and organizational abilities Hardworking and reliable Data Engineer with strong ability in building Data pipelines Highly organized proactive and punctual with teamoriented mentality        Skills           Requirements Gathering  Analysis and Modeling  Data Warehousing  SQL Reporting  Business Intelligence      Data Management  Microsoft SQL  Database Analysis  SQL Tuning  Critical Thinking                       Experience       Senior Data Engineer       122017      Current     Splunk    –    Dallas     GA            Adept in troubleshooting and identifying current issues and providing effective solutions  Managed performance monitoring and tuning while identifying and repairing issues within database realm  Worked as part of project teams to coordinate database development and determine project scopes and limitations  Trained nontechnical users and answered technical support questions  Collected outlined and refined requirements led design processes and oversaw project progress  Created conceptual logical and physical data models for use in different business areas  Wrote and coded logical and physical database descriptions specifying identifiers of database to management systems  Applied Conceptual Logical and Physical  DimensionalRelational model designs to ETL tasks  Managed endtoend operations of ETL data pipelines maintaining uptime of 95  Assisted in User Acceptance Testing for accountingmarketing users verifying ETL jobs complied with assigned parameters achieving desired results  Worked successfully with diverse group of coworkers to accomplish goals and address issues related to our products and services  Worked closely with team members to deliver project requirements develop solutions and meet deadlines           Senior Database Consultant       022013      122017     AmazonCom Inc    –    Lewisville     TX            Created Informatica mappingsETL’s using  Informatica Power Center  to load the data from Oracle MySQL databases to SQL Server 2016 databases hosted on AWS cloud  Performed the data manipulations using various  Informatica  Transformations like Expression Lookup Update Strategy Router and SQL transformation  Designed  Informatica  workflows with many sessions with Event with task Event raise task and Email task Scheduled the created workflowsjobs using  Informatica Scheduler   Created multiple  TSQL  objects mainly Stored procedures and Functions for new and existing software application requirements  Created multiple Linked Servers for ease of the users to execute commands on remote servers  Developed new code and finetuned existing Stored procedures to improve performance while utilizing the SQL Server Profiler and Database engine tuning wizard  Created SSIS packages to migrate data from legacy systems such as Oracle MySQL HP Vertica SQL Server flat files to centralized IT destination Created SSIS packages utilizing different SSIS transformations like  Script component Merge Join Look Up  and implemented error handling and logging  Performed unit testing and QA testing at various levels of the ETL’s and actively involved in team code reviews  Developed Report Models using report builder and distributed reports in multiple formats using SQL Server Reporting Services SSRS in Business intelligence development studio BIDS and SQL Server Data ToolsSSDT Created  Parameterized Cascaded Drilldown Crosstab and Drillthrough Reports  using SSRS 2008 R22012  Created Ad hoc Queries in TSQL Stored Procedures and Views to store the data of third parties and use them in SSRS reports to generate reports on the fly Worked with multivalued parameters for parameterized reports in SSRS  Developed VBA scripts for periodic Financial Daily Weekly reports generated directly from Excel utilizing Power Pivot options in Excel  Managed report delivery based on  Time driven and Data driven subscriptions  and  report security  for providing SSRS report  server level folder level and item level  permissions to various users across the organization based on role based access controlRBAC  Worked on resolving any performance issues with SSIS packages and SSRS reports and fine tune them for better performance  Worked on cleaning up users on SQL server and audit the access level Revoke Inappropriate access setting up AD groups and grant access based on the created groups  Worked on database  performance  and  maintenance  duties  such as  tuning   backup   restoration   Provide OnCall support for Production job failures Resolve and close the time critical Incidents in an appropriate way Perform root cause analysis create Problem report and work on any subsequent code changes to stop them from reoccurring           Database Consultant       082011      022013     AmazonCom Inc    –    Lithia Springs     GA            Involved in gathering business requirements definition and design of the data sourcing and data flows data quality analysis working in conjunction with the data warehouse architect on the development of logical data models  Using  TSQL  created complex  Stored Procedures Functions Cursors Tables and Views  and used other SQL joins and statements for applications in SQL Server 20052008  Developed standalone  SSIS  packages to extract data from different sources like  SQL Server Flat Files Excel Oracle and Sybase  transform and load the data onto required databases  Using  SSIS  transformations filtered bad data from different sources using  Derived Column Lookup Fuzzy lookup and Conditional split   Involved in creation of Technical Specs Design Documents Implementation Documents and Unit testingTest case test plan documents and maintained Issue logs  Using Script Component in  SSIS  wrote  C  NET  code to generate dynamic file names and create a text files Debugged and verified the values getting stored in  variables  in runtime using  C  code  Created dynamic  SSIS  packages through Variables and Script task components C  and VBNET and scheduled the packages using SQL Server Agent to process and load the data  Scheduled the package based on the Enterprise Calendar through SQL Server Agent Created several onetime and recurring jobs for package scheduling  Created XML file for package configurations and implemented parentchild package configuration in  SSIS  packages Implemented error and event handling precedence Constraints Break Points data grid and Logging in  SSIS  packages  Using  SSRS  developed multiple types of reports including Sub Reports Parameterized and Drill Down Reports using global variables expressions and functions based on the requirements provided  Deployed  SSRS  rdl reports on to the report server and created time driven subscriptions on the deployed reports  Created cubes with multiple fact measures groups and multiple dimension hierarchies based on the reporting needs using  SSAS   Modified existing dimensions and created new dimensions as per new business requirements  Created GUI interfaces using CNET and NET Framework to simplify the database access to end business users Enhanced existing GUI interfaces based on new requirements and improved efficiency  Resolved and closed production incident tickets generated because of failure of Daily Jobs          Education and Training       Master of Science       Electrical Engineering       Expected in   012011                California State University  Sacramento      Sacramento     CA     GPA        Status   ,\n",
       " Jessica    Claire               Montgomery Street       San Francisco     CA  94105    609 Johnson Ave       49204     Tulsa     OK      Home   555 4321000        Cell           resumesampleexamplecom                  Professional Summary      Business Intelligence Consultant with a 10year career in data warehousing business intelligence reporting and data management architecture Progressive developer and technical team lead with a strength in design  development as well as driving performance reducing inefficiencies and cutting costs Possess comprehensive knowledge and hands on experience in both ETL and Reporting tools Knowledge of Credit Card account life cycle management in Finance domain Functional knowledge of Collections and Recovery operations Expertise in planning executing and spearheading various SDLC and Agile Scrum projects in compliance to quality standards Known for effective communication with excellent relationship building  interpersonal skills strong analytical problem solving  organizational abilities Proven track record of taking ownership and diving deeper into issues to identify the root cause and troubleshoot towards resolution        Skills           ETL Tools  Ab Initio  Scripting Languages  Unix shell scripting Python SparkScala  Cloud Services Microsoft Azure Cloud Services Data Lake  DataBricks and Data Pipelines Azure Data Factory  BI Reporting Skills  Tableau Desktop Tableau Server Power BI Reporting  SAP Business Objects SAP BOUniverse Designer Tool SAP BO XI WEBI ReportingSAP BO XI Deski Reporting  Database  Oracle  Teradata Hive      Scheduler tools  Autosys ControlM  Relational Database Management  Business Intelligence Reporting  Project Management  Data Analysis and Visualization                       Work History      062017   to   Current     Senior Data Engineer      Thoughtworks    –    Memphis     TN            A multitenure loyalty program across all Williams Sonoma brands – the first time that customers can earn points by purchasing across the multiple brands WSI Pottery Barn West Elm etc I work in the customer data warehouse CDW which is Teradata and work with their 3rd party marketing systems vendor There are various data points and integrations with the data warehouse which holds all customer information points transactions loyalty IDs etc   Worked with Requirements Analysts and PDMs to identify understand and document business needs for data flow Analyze requirementsUser stories at business meetings and strategize impact of requirements on different platformsapplications Worked with Project Management in creation of project estimates for each Agile story  Engaged in projects that uses Scala and Azure DatabricksDatafactoryDatalake to extract process and load Adobe Clickstream data received for Williams Sonoma ECOM website Deployed custom codes in Scala to read JSON extract CSV files from Adobe add column headers handle badmalformed records handle invalid records before finally writing cleansed data into ParquetDelta file format partitioned by date and hour  Build and review design deliverables Perform dependency analysis between new objects created in Ab Initio graphs Conduct IT and UAT testing of each of these graphs Record errors reported during Unit and Integrated testing  Prepare production Implementation Plan to deploy codes successfully to production environment  Coordinate daily standups short meetings where teammates talk through whats being worked on yesterday what was done today and if blocked Involved in variety of other scrum meetings such as planning meetings where team pulls in stories requirements grooming meeting to look at backloglist of stories and flush out timeline and work expected demo show work that was completed in sprint etc  Reporting  Visualization in Tableau and Power BI  Design and deploy rich Graphic visualizations with Drill Down and Drop down menu option Prepare Dashboards using calculations parameters Apply various reporting objects like Filters prompts Calculated fields Groups Parameters Work on the development of Dashboard reports for the Key Performance Indicators for the top management          032010   to   062017     Senior DeveloperTechnical Team Lead      Tech Mahindra Synchrony Financial Services    –    City     STATE            Synchrony Financial is a consumer financial services company offering consumer financing products including credit promotional financing and loyalty programs and installment lending through Synchrony Bank its wholly owned subsidiary Synchrony is the largest provider of private label credit cards in the US The company provides private label credit cards for such brands as Amazon JC Penney CheapOAir OneTravel Sams Walmart Lowe’s Guitar Center Gap BP We as Data warehouse solution providers store this credit card holder information from the instance a credit card is applied till the account is closedcharged off   Understanding the full scope of requirements from business Estimating time and effort involved from gathering project requirements till project implementation  Answering technical queries driving product initiatives and metric collection and analysis  CoOrdinating between project stake holders – Business Client and offshore teams during all phases of project  Preparing design documentation design reviews development performing code reviews to ensure coding standards are followed testing and deployment of application enhancements  Experience in Ab Initio toolsets including the following  o Parallel and serial flow batch graphs conditional components other components like reformat normalize and join lookup and graphs processing ASCII and EBCDIC layouts  o Knowledge on Abinitio architecture including the GDE Cooperating system EME and other related items  o Fine tuning of Abinitio graphs based on performance enhancement by proper usage of memory in the components  o Well versed with various Ab Initio components such as Join Rollup Partition Departition Dedup sorted Scan Normalize DeNormalize  o Expertise knowledge improving Performance and Troubleshooting of the AbInitio graphs and monitoring ABInitio run time statistics  o Experience with advanced Abinitio metaprogramming air commands and other admin related tasks including the creation of save and performing migration from one server to the other  Establish support such as acquiring conditioned test data support from third partyteam etc for Integration Testing to simulate production environment and to ensure correctness and quality of buildparameter set up  Getting sign off from IT managers for deploying parameterset up onto production environment  Documenting implementation plan and Hour by Hour plan listing down the tasks in sequence of their execution on the date of implementation  Coordinate release activities across multiple teams          Education      Expected in   4 2008     Bachelors     Information Technology     College of Engineering Bhubaneswar      India          GPA               Accomplishments      • Tableau Desktop Specialist Certified No expiration  These are Open Badges that I have been awarded and that attest to my skills  httpswwwyouracclaimcombadges556948fdd8114f8097d245ab6c530d9clinkedinprofile   o Tableau Desktop Specialist title use their foundational knowledge of Tableau Desktop and data analytics to solve problemsDesktop Specialists can connect to prepare explore and analyze data and share their insights        Skills       ETL Tools  Ab Initio  Scripting Languages  Unix shell scripting Python SparkScala  Cloud Services Microsoft Azure Cloud Services Data Lake  DataBricks and Data Pipelines Azure Data Factory  BI Reporting Skills  Tableau Desktop Tableau Server Power BI Reporting  SAP Business Objects SAP BOUniverse Designer Tool SAP BO XI WEBI ReportingSAP BO XI Deski Reporting  Database  Oracle  Teradata Hive    Scheduler tools  Autosys ControlM  Relational Database Management  Business Intelligence Reporting  Project Management  Data Analysis and Visualization         Work History      062017   to   Current     Senior Data Engineer       Kforce Inc Williams Sonoma Inc   –   San Francisco     CA     A multitenure loyalty program across all Williams Sonoma brands – the first time that customers can earn points by purchasing across the multiple brands WSI Pottery Barn West Elm etc I work in the customer data warehouse CDW which is Teradata and work with their 3rd party marketing systems vendor There are various data points and integrations with the data warehouse which holds all customer information points transactions loyalty IDs etc   Worked with Requirements Analysts and PDMs to identify understand and document business needs for data flow Analyze requirementsUser stories at business meetings and strategize impact of requirements on different platformsapplications Worked with Project Management in creation of project estimates for each Agile story  Engaged in projects that uses Scala and Azure DatabricksDatafactoryDatalake to extract process and load Adobe Clickstream data received for Williams Sonoma ECOM website Deployed custom codes in Scala to read JSON extract CSV files from Adobe add column headers handle badmalformed records handle invalid records before finally writing cleansed data into ParquetDelta file format partitioned by date and hour  Build and review design deliverables Perform dependency analysis between new objects created in Ab Initio graphs Conduct IT and UAT testing of each of these graphs Record errors reported during Unit and Integrated testing  Prepare production Implementation Plan to deploy codes successfully to production environment  Coordinate daily standups short meetings where teammates talk through whats being worked on yesterday what was done today and if blocked Involved in variety of other scrum meetings such as planning meetings where team pulls in stories requirements grooming meeting to look at backloglist of stories and flush out timeline and work expected demo show work that was completed in sprint etc  Reporting  Visualization in Tableau and Power BI  Design and deploy rich Graphic visualizations with Drill Down and Drop down menu option Prepare Dashboards using calculations parameters Apply various reporting objects like Filters prompts Calculated fields Groups Parameters Work on the development of Dashboard reports for the Key Performance Indicators for the top management          032010   to   062017     Senior DeveloperTechnical Team Lead       Tech Mahindra Synchrony Financial Services   –   Chicago     IL     Synchrony Financial is a consumer financial services company offering consumer financing products including credit promotional financing and loyalty programs and installment lending through Synchrony Bank its wholly owned subsidiary Synchrony is the largest provider of private label credit cards in the US The company provides private label credit cards for such brands as Amazon JC Penney CheapOAir OneTravel Sams Walmart Lowe’s Guitar Center Gap BP We as Data warehouse solution providers store this credit card holder information from the instance a credit card is applied till the account is closedcharged off   Understanding the full scope of requirements from business Estimating time and effort involved from gathering project requirements till project implementation  Answering technical queries driving product initiatives and metric collection and analysis  CoOrdinating between project stake holders – Business Client and offshore teams during all phases of project  Preparing design documentation design reviews development performing code reviews to ensure coding standards are followed testing and deployment of application enhancements  Experience in Ab Initio toolsets including the following  o Parallel and serial flow batch graphs conditional components other components like reformat normalize and join lookup and graphs processing ASCII and EBCDIC layouts  o Knowledge on Abinitio architecture including the GDE Cooperating system EME and other related items  o Fine tuning of Abinitio graphs based on performance enhancement by proper usage of memory in the components  o Well versed with various Ab Initio components such as Join Rollup Partition Departition Dedup sorted Scan Normalize DeNormalize  o Expertise knowledge improving Performance and Troubleshooting of the AbInitio graphs and monitoring ABInitio run time statistics  o Experience with advanced Abinitio metaprogramming air commands and other admin related tasks including the creation of save and performing migration from one server to the other  Establish support such as acquiring conditioned test data support from third partyteam etc for Integration Testing to simulate production environment and to ensure correctness and quality of buildparameter set up  Getting sign off from IT managers for deploying parameterset up onto production environment  Documenting implementation plan and Hour by Hour plan listing down the tasks in sequence of their execution on the date of implementation  Coordinate release activities across multiple teams,\n",
       " Jessica    Claire                   Montgomery Street     San Francisco     CA  94105    609 Johnson Ave       49204     Tulsa     OK       Home   555 4321000    Cell       resumesampleexamplecom              Summary      Technical Customer Service Specialist with a vast knowledge of web applications software and framework seeking to assist clients in all troubleshooting endeavors Outstanding networking adept at developing customer relationships looking for an opportunity to bring exceptional team building skills to a management position in a vibrant customer service department          Highlights           RoutersHubsSwitches        Juniper Nexus Cisco 2600 2800 3600 3700 3800 7200 2900 3500  Authentication TACACS  RADIUS  Network Analyzers Ethereal Sniffer Pro  Network Technologies        STP RSTP HSRP VRRP IRB Port Channel Cisco ASA 5500 SA  Operating Systems Windows20002003 Win98ME2000 proxp  Routing Protocols TCPIP RIP EIGRP OSPF and BGP  WAN Technologies T1E1 DS3 FrameRelay DSL MPLS leasedline  LAN Technologies 8021q ISL Patching up BackupRestoration DNS Infoblox DHCP  VOIP SIPH323 MGCPTDMSS7 Avaya  Voice gateways                         Accomplishments       10 years of IT experience in design development implementation troubleshooting and maintenance of mediumto large scale Network infrastructure Experience in Static Routing and configuring dynamic Routing Protocols  RIP v1 and v2 IGRP EIGRP OSPF and BGP Expertise in network protocols Switching Routing and Security technologies Experience on Cisco Catalyst Series 6500 Switches and Virtual switching system  Deployed the switches in high availability configuration  Good knowledge of Spanning Tree Protocol  IEEE 8021d IEEE 8021w IEEE 8021s PVST Well experienced in VLAN implementation VTP domain settings Stacking Load balance and Redundancy technologiesXRRP VRRP HSRP PAGP LACP Configuration of Access Control Lists ACL Quality of  ServiceQoS VPN NATPAT policies Experience in implementation of  PPP ISDN HDLC Frame Relay  T1 DS3 MPLS Installation and maintenance of RADIUS TACACS    Cisco Secure ACS Good understanding of the OSI Reference Model and the TCPIP Model Network Management CiscoWorks LMS ProCurve Manager Plus PCM  SonicwallOpen View Network analysis and troubleshooting tools  Sniffer Pro Wireshark Agilent Network and analysis tools Experience working with Cisco Nexus 2148 Fabric Extender and Nexus 5000 series to provide a Flexible Access Solution for a datacenter access architecture  Experience configuring Virtual Device Context in Nexus 7010  Experience convert PIX rules over to the Cisco ASA solution  Worked on Extensively on Cisco Firewalls Cisco PIX 506E515E525  ASA     550055105540 Series  Proficient in the operation and administration of Juniper NetScreenISGSSGbased firewalls Juniper SRXseries services gateways Juniper JMMXseries routers Juniper SAseries SSL VPN appliances F5 loadbalancing products LTM GTM FirePass and various Cisco IOSbased platform  Assisted in converting PIX rules over to the Cisco ASA solution  Good knowledge on VOIP protocols like H323 SIP MGCP and SS7 and interfacing of TDM to VOIP system    Worked on Avaya  Voice gateways for VOIP implementation using Cisco Catalyst switches Experience in System Software installations Implementation of DNS TCPIP DHCP and IAS in Network environments Windows 2003 Windows 2000 and Windows 9598 Sound knowledge of networking methods techniques and processes Extensive knowledge of installing advanced configurations on Cisco Call Manager platforms Possess good working knowledge of TCPIP networks Comprehensive knowledge of Cisco network protocols and transport systems Indepth knowledge of Cisco Unified Communications like UCM UCCX MPE Unity NSTS and DRSN Well experienced in Planning Designing implementation and management of mediumtolarge scale of enterprise networks         Experience       Voice  Data Network Engineer       012015   to   Current     Criterion Systems    –    Washington     DC             Responsible for presales and postsales support for the design and implementation of call center and corporate voice solutions  Implemented call routing call management and computer telephony integration  Configured installed and supported Cisco Unified Communication Manager CallManager 8x Cisco Messaging Systems UnityUnity Connection 8x CER VoiceGateways Cisco routers and switches  Performed system upgrades and patches based on request schedule or events  Created dialplans route patterns route groups route lists calling search space partitions  Patched and upgraded Cisco Unified Communications applications  Created Voice Mail boxes call handlers create and reset passwords MWIs administered and maintained Active Directory on Unity  Used tools such as Advanced Settings Tool Message Store manager DOH PropTest Services Tools Depot  Checked Outlook accounts in Exchange servers to view warning and limits text messages associated w Unity Voice Mail created Subscriber services skill sets and prompts for UCCX deployment  Created Subscriber services skill sets prompts for UCCX deployment  Established and maintained collaborative relationships with customers recognized for consistently providing excellent customer service and retention  Instrumental in developing telecommunications departmental Service Level Agreements SLAs and standard processes which optimized daily operations           Network Engineer       072012   to   112014     Criterion Systems    –    Beltsville     MD             Performed responsibilities of assisting voice engineer in designing and installing Cisco network equipment  Handle first level of designing and installing Cisco Call Manager and associated Voice applications  Responsible for the administration configuration and implementation of IP Telephony systems  Handle the tasks of designing and maintaining documentation related to network layout  Perform responsibilities of maintaining security policies on Cisco firewall solutions  Monitor and ensure that the requirements of high availability are in place for Cisco environment  Manage team tasks against SLAs as well as work with project plans adhering to project timelines resource constraints and within budget  Primary support for Cisco Unity Unity Connection Unity Express AIM and NMCUE Call Manager VOIP Migration Project Involved in migrating Lehmans Branches to centralized VOIP platform that will replace the existing Standalone phone system  Cisco router 3745 series and switch series 3560 are used to support to add VLANs to all the routers and switches to support the VOIP phones  Worked on Avaya Gateway equipment is added to the network to support the ports from Cisco Switches across the network  Successfully performed installation and configuration for IPSEC VPN on Cisco routers PIX series VPN Concentrator 3000 and ASA 5500 security appliances  Worked extensively in Configuring Monitoring and Troubleshooting Ciscos ASA 5500PIX security appliance Failover DMZ zoning  configuring     VLANsroutingNATing with the firewalls as per the design  Assisted in migration of centralized voice mail system based on Cisco Unity connection and support interfacing of legacy TDM PBX of the sited in voice network system  Familiar with H323 IOS gateways and SRST telephony design and implementation and call manager deployment in the voice network  Hands on experience on implementation and troubleshooting of ACLs and QoS for the networks Involved in supporting voice infrastructure including call routing the voice gateways and its troubleshooting methods  Worked on updating CATOS for that switches and IOS for the routers to support the VOIP standalone system for 6500 Multilayer switch and 3500 switch series  HP Openview SNMP network node manager is used to monitor the network and in the times of green zones and DMZ zones           Sr Voice Data Analyst       2012   to   062012     Criterion Systems    –    Germantown     MD             Troubleshoot network software and hardware issues Remote corrective actions supporting Monitored all functions around the voice and data network  Responsibly monitorered network and Tier 23 support  Interfacework with repairrestoration of remote site equipment Assisting field technicians in maintenance of remote site equipment Responsibly cross trained other members of the Network Engineering team to broaden the knowledge base within the team  Managed emergency change needs of the business  Proven ability to learn new systems as required to effectively support customer needs  Troubleshoot wireless problems using different RF analysis tools  Handle and prioritize high call volumes and customer inquiries  Other duties as assigned by the Director of Telecommunications           Network Engineer       102009   to   112011     MORGAN STANLEY    –    City     STATE             Involved in Network Redesign for branch for data environment  Convert Branch primary WAN circuit T1 to MPLS and branch router security migration  Performing BGP Changes on branch router and headend router  Conversions to BGP WAN routing  Which will be to convert WAN routing from OSPF to BGP OSPF is used for local routing only which involves new WAN links  Replace network hardware with new 7200 routers and 3825 switches in all branch locations  Design and implementation of GRE for multicast and unicast communication on an existing IP VPN Managed and engineered 58 JuniperCheckpoint firewalls  Experience on designing and troubleshooting of complex BGP and OSPF routing problems  Involved in designing and implementing QOS and policy map to 3800 series routers for all the branches Worked closely with network monitoring staff and will do network design testingcertification prior to production implementation  Implements configurations and implementation instructions into change management system and insures that all approvals and processes are adhered to compliant with Audit  Worked on Layer 2 protocols such as VTP STP RSTP PVST MST and other VLAN troubleshooting issues and configuring switches from scratch and deployment Experience in branch relocation connect workstation servers etc  Rack and stack preconfigured new hardware and connect the circuits  Worked with carrier to test and turnup circuits  Worked with carriers like ATT Verizon Wind stream and Level3 for deploying WAN circuits and implementation of MPLS cloud Performs system level documentation on platforms and assists in project tracking and documentation  Experience with developing network design documentation and presentations using VISIO  Troubleshoots with problems regarding the network changes and migrations           Network Engineer       112006   to   092009     PITNEY BOWES    –    City     STATE             Responsible for Design integration configuration maintenance performance monitoring and security of network infrastructure including local area networks LAN wide area networks WAN  firewalls DHCP DNS Installing the Network devices in datacenter environment and clearly articulate complex network designs and drawings through documentation Visio as well as verbal training sessions  Experience in Configuring SitetoSite and Remote Site VPNs NATPAT policies  Managing Cisco Secure ACS for TACACS  RADIUS authentications  Monitoring customer data networks and providing fault isolation and remote troubleshooting  Experience on designing and troubleshooting of EIGRP routing issues  Responsible for the management of network at the client environment  Supporting and performing projects for the client WAN environment at a global level  Implementation of network system upgrades and modifications including planning testing scheduling and coordination  Ensures that change management and defined security procedures for all network systems are executed in accordance with customer policies and procedures  Interacting with Carriers for installation of new WAN circuits at Customer premises and makes sure circuit installed with no issues and ready to use before users move in to the branch  Providing Teir3 technical support for LANWAN issues and oncall for technical escalation on a rotational basis Remedy Ticketing system  Well experienced in troubleshooting bug related issues with help of Cisco TAC service  Providing networking services coordinate tasks and ensure their execution and documentation in accordance with established corporate standards           Systems  Network Engineer       052005   to   092006     WESTERN UNION    –    City     STATE              Resolved customer complaints and concerns with strong verbal and negotiation skills  Responsible for clients new branches turn up and managing the network environment  Installation of Operating Systems application softwares and Troubleshooting hardware issues Management of WAN connected over Frame relay and DSL Management of Pix Firewall  Cisco Routers and switches infrastructure Configuration of routers and switches for OSPF EIGRP VLANs STP Trunks Ether Channel Load Balancing Configuration of Routers and Firewalls for sitetosite IPSEC VPN tunnels Implemented Secured Wireless Network based on WPA and MAC Authentication  technologies Integration of AVAYA IPPhones with Switches in VLAN environment  Policy configuration and management of firewalls  DNS changes as per client requests  Planning about new product requirements Contacting Vendors for product purchases  Contacting Service providers to troubleshoot issues on WAN connectivity  Involved in planning and designing team for network upgradeschanges  Configuring NAT Policies Global VPN Client Policies Establishing SiteSite VPN Connections Maintenance of DHCP Server  Enabling highavailability and highcapacity features such as Spanning Tree and link aggregation on Switches Responsible for service request tickets generated by the helpdesk in all phases such as troubleshooting maintenance upgrades patches fixes and all around technical support Basic Configurations and Maintenance of various Switches Routers Firewalls and Wireless Access Points at different client locations Responsible for interaction with third party technicians on site Performed network support involving daily wiring maintenance of cabling switch maintenance network port reenabling and cable room Documentation of all new software installation procedures troubleshooting procedures Responsible for implementation of new network infrastructure includes Cabling Switching Routing Establishing MAN Connectivity between  their different braches Involved in Loop back tests and troubleshooting issues during establishment of T1 Line Dynamic VLAN implementation using IEEE 8021x protocol and RADIUS Server Integration of Active Directory Services ADS with RADIUS Server and creation of remote access polices on RADIUS Implementation of Access Control ListsACLs  QoS Implementation of Portfast on all access switches and setting bridge priorities on L3 Switches Environment Cisco 2900 3560 1800 3700 3800 7200 2900 3500          Education       Bachelor of Technology          Expected in   2003     Goa Institute of Technology                GPA               Certifications      CCNP Cisco Certified Network Professional  CCNA Cisco Certified Network Associate        Skills     Active Directory ADS articulate AVAYA Backup Basic BGP budget cable Cabling call center change management Cisco router Cisco Cisco Routers hardware network systems computer telephony integration Client excellent customer service DOH designing DHCP Documentation DNS DSL EIGRP engineer fast features FirewallsFrameRelay gateways Gateway HP Openview Hubs IP local area networks LAN layout leasedline MAC Director Managing Messaging Access Exchange Outlook 2000 Windows2000 Win98 Migration Network Engineering network design network hardware network support Network networking networks Operating Systems OSPF PBX phone system Policies presentations processes project plans Protocols Express RIP router Routers Routing sales sales support scheduling servers Service Level Agreements SLA SNMP software installation SS7 Store manager Switches switch Cisco Switches T1 TCPIP TDM technical support telecommunications Telephony Phones Troubleshoot Troubleshooting upgrades view VPN VISIO voice and data Voice Mail VOIP WAN wiring,\n",
       " JC     Jessica    Claire                      Montgomery Street       San Francisco     CA    94105             555 4321000                 resumesampleexamplecom                         Summary      Senior Software Engineer with 26 years of experience as an enterpriselevel database web applications developer technical lead and project manager  Expert Microsoft SQL database administrator with SQL server integration services SSIS and SharePoint experience  ​  Proven leader and strategic thinker able to architect cuttingedge software solutions and lead development teams through the entire software development life cycle SDLC  Recipient of NASAs Space Flight Awareness Honoree award for significant contributions in the preservation and management of Lunar sample data         Skills           Databases Microsoft SQL Server 20002014 MongoDB MySQL  Languages SQL Microsoft NET C and VB ColdFusion 11 Java JavaScript PowerShell Python CC  Development ToolsMethodologies SDLC Agile  Waterfall Methodologies Object Oriented Programming OOP Application Programming Interfaces API MVC Visual Studio Eclipse Git Subversion UML SSIS SSRS HTML5 CSS SASSLESS web services REST jQuery Bootstrap Accessibility508 Compliance Website Security UX Design  Graphic DesignMultimedia  Adobe Creative Suite CC Photoshop Illustrator InDesign Dreamweaver Premiere Pro Lightroom Inkscape  Software  Adobe Acrobat Pro Microsoft SharePoint Visio and Project R                         Experience        012007   to   Present   Senior Software EngineerData Manager    Ssi Schaefer Systems International North America         Columbus     OH            Designed and developed web database applications to showcase NASAcurated astromaterials sample collections including comprehensive searchable databases with sample processing and availability information scientific analyses references and multimedia photos 3D models videos for use by space and planetary scientists  Technologies used included Adobe ColdFusion Microsoft NET C JavaScriptJQuery SVG REST various APIs and Microsoft SQL among others  Architected managed and developed internal Enterpriselevel databases and applications using both traditional waterfall and agile methodologies  Led teams of 25 developers and interns both internal and in distributed teams and provided technical mentorship  Significant expertise as database architect and administrator with experience creating SQL server integration services SSIS and reporting service SSRS solutions and optimizing query performance  Regularly employed scripting technologies such as PowerShell and Python to implement work automation and provide data visualization  As webmaster for the directorate public websites was a recognized expert in all aspects of website management including the administration of IIS and Apache web servers ColdFusion and Java application servers and SQL servers  Maintained adherence to NASA and government standards and regulations accessibility508 compliance information privacy websiteapplication security  Developed and maintained relationships and collaborations within NASA and global research and technology communities that leveraged crossfunctional expertise to improve the quality and accessibility and transfer of scientific data and support NASAs Open Data initiatives            012001   to   012007   IT Consultant    Splunk         Aldie     VA            Windows 10 Windows Server 2003  2012 R2 Linux IIS 758 Apache ColdFusion Server Designed and developed custom ecommerce and informational websites for small to mediumsized clients using various technologies including Adobe ColdFusion and Flash Microsoft Visual Basic and ASP Java JavaScript MySQL and Microsoft SQL on ApacheLinux and IISWindows systems  Provided website management and system administration services to consumers and small businesses  Coordinated full range of project development from initial proposal to final delivery            011998   to   012001   IT Program Manager    Polar Tank         Houston     TX            Managed enterprise software projects with budgets in excess of 3M which were consistently completed within budgetary and time constraints  Prepared proposals managed budgets and developed business system requirements and functional specifications for proposed projects  Supervised 10 business analysts project managers application developers and contractors during entire software development lifecycle  Designed and implemented relational and OLAP databases for integration with web applications and developed middletier components using Microsoft Visual Basic ASP ADO and COMCOM technologies using the Microsoft Visual Studio IDE and SQL Server 2000 with Analysis Server  Experienced using ERWin Data Modeler and UML for database design  Successfully completed global implementation of wide area networks and computer installations in 20 international locations by directing internal resources and local and international external vendors            011994   to   011998   DSP Marketing Programs Manager    TEXAS INSTRUMENTS         City     STATE            Designed and implemented intranetextranet web applications for the sales organization customers and product distributors that greatly reduced marketing support and training costs for the division  Web applications were implemented in C and Perl on a UNIX platform for the NCSA Mosaic browser and for Netscape Navigator  Managed team of 34 developers            011993   to   011994   Technology Transfer Team Leader    SEMATECH         City     STATE            Managed an average of 30 projects a month for the Lithography division to fulfill technology transfer requirements of consortium            011991   to   011993   Design Engineer    IBM CORPORATION         City     STATE            Designed 486based computer motherboards and peripheral interfaces for IBMs PC Value Line          Education and Training        Expected in   1991   MS       Electrical Engineering    Solid State Devices  Circuits  University of Michigan     Ann Arbor     MI      GPA       Electrical Engineering        Awards              Skills     Microsoft NET 3D ADO Adobe Creative Suite Adobe Acrobat Adobe Dreamweaver Photoshop Premiere Agile Apache API ASP automation budgets C ColdFusion COM COM CSS clients data visualization database applications Databases database architect database design delivery directing ecommerce Eclipse ERWin extranet Flash functional government Graphic Design UX HTML5 IBM IDE IIS IIS 75 Illustrator InDesign Java JavaScript JQuery Linux marketing C Microsoft SharePoint Microsoft SQL SQL Server 2000 Windows 2000 MongoDB motherboards Multimedia MVC MySQL Enterprise Netscape Navigator networks Object Oriented Programming OOP OLAP Perl Programming project development proposals proposal Python quality reporting research sales scientific SDLC servers scripting software development Microsoft SQL Server SQL SQL server system administration UML UNIX Visio Microsoft Visual Basic VB Microsoft Visual Studio Visual Studio Web applications web servers Web Development Website websites website management webmaster Windows Server 486       Additional Information       AWARDS JETS Superior Performance Team Award 2014  Apollo Sample Curation Team NASA Group Achievement Awards 2014  Apollo Sample Curation Team  2013  Hayabusa Curation Team  Stardust Interstellar Curation Team JSC Directors Innovation Group Achievement Award 2013  Antarctic Meteorite Curation Team NASA Space Flight Awareness Awards 2009  Honoree  GRANTS 2016 NASA PDART CoPI Creating and Serving Novel Data Products of Astromaterials Combining ImageBased 3D Reconstructions and XRay CT Data of Astromaterials 2015 NASA PDART CoPI MoonDB Restoration and Synthesis of Lunar Petrological Data         Websites Portfolios Profiles,\n",
       " Jessica  Claire                             resumesampleexamplecom                      555 4321000                       Montgomery Street     San Francisco     CA      94105                                                                                                                                                                                                             Summary     Highly motivated Sales Associate with extensive customer service and sales experience Outgoing sales professional with track record of driving increased sales improving buying experience and elevating company profile with target market           Skills         Machine LearningData Mining  NLP  Linear Regression neural networksdeep learning Naive Bayes SVM Logistic Regression  decision trees Kmean KNN N Grams edit distance gradient descent  Statistical Programming  Packages  R Python NumPy Matplotlib scikitlearn pandas ggplot2 Shiny dplyr caret e1071keras  Business Intelligence  Visualization  Tableau Qlik View Qlik Sense Excel OBIEE  Hadoop Ecosystem Components  Spark Hive Sqoop Flume Kafka Impala  Databases  Oracle MySql PostgreSql  Oracle ERP  Fusion Middleware  Oracle EBusiness Suite 11i  R12 Oracle SOA Oracle Service Bus  Other Languages  Tools  SQL PLSQL core java Scala RStudio Jupyter SqlDeveloper Toad Atom  Certifications  Tableau SQL  PLSQL                       Education and Training       University of Utah David Eccles School of Business    Salt Lake City     Utah      Expected in   August 2017     –      –       Master of Science        Information Systems          GPA           Information Systems Data Science and Analytics specialization   Recipient of 15000 Graduate Fellowship from David Eccles School of Business Academic Capstone Project  Big Data  Building statistical regression and classification models cleaning exploring data and developing interactive web interface using R Shiny which helps the company to classify clients loan type and predicting the amount of loan they will take in future Kaggle  House Prices Predictions  Applied different machine learning simple and advanced models on housing predictors for predicting the sales prices of houses used imputation methods for filling missing and null values in the data set Independent Study  Research  Apache Spark using Scala and Python Rajeev Gandhi Memorial College of Engineering and Technology          India                        Expected in   May 2012     –      –       Bachelor of Science        Computer Science and Engineering          GPA           Computer Science and Engineering Designed Hand Draw Shape Recognition interface which helps the user to invoke desired application just by drawing the shape linked to the application          Experience       Envestnet      Data Science  Data Engineer Intern   Secaucus     NJ                   012017      Present     Working on Big Data Ingestion using Sqoop for transferring data from multiple MySql database servers to transient storage in amazon EMR Hcatalog and using Hive to transfer data to persistent storage in amazon S3 bucket  Developing Sqoop and Hive scripts for data ingestion  Using R and spark in amazon EMR for filtering exploring analyzing providing insights on data and developing reports           First American Corporation      Oracle Technical Consultant  Data Analyst   City          India              022013      072016     Created SQL scripts for daily extracts adhoc requests  reporting and for analyzing large data sets  Designed ER diagrams conceptual models logical and physical models created database objects  Tables Indexes Sequences and Views  Developed Oracle Business Intelligence reports created and modified Oracle database objects  Tables Views and Indexes which increased the performance of Oracle Business Intelligence reports by 60 in production environment  Prepared SQL  Loader scripts for loading data from other systems into oracle ERP system worked with onsite business team in performing data fixes  Created PLSQL interfaces for doing business validation transferring data between ERP modules and loading data to base tables           CMC Limited      Data Analyst Intern   City          India              112012      012013     gt Developed SQL scripts worked on oracle 11i database and oracle reports          Skills     Academic ad Apache Big Data Business Intelligence Draw clients Data Mining Databases database EBusiness edit ERP filling drawing java Machine Learning Excel Middleware MySql NLP networks neural Oracle Oracle database PLSQL PostgreSql Programming Python reporting Research sales servers scripts SQL SQLLoader Tableau Tables Toad type validation View,\n",
       " Jessica    Claire                   Montgomery Street     San Francisco     CA  94105    609 Johnson Ave       49204     Tulsa     OK       Home   555 4321000    Cell       resumesampleexamplecom              Profile     Detailedoriented Senior Software Developerprogrammer with 9  years experience devising innovative and tailored solutions to achieve onschedule and high client satisfaction Provide cradletograve oversight of software project management and rollout of Enterprise applications       Relevant Professional Experience       Data Scientist Intern       062016   to   082016     Ascend Learning    –    San Antonio     TX             Created a predictive model for effective field goal percentage EFG used to understand the effect of player actions both offensively and defensively on shot quality  Analysis summary and visualization of shot qualitycontestedness  Created web application to display expected field goal and shot contentedness resultTechnologies used R RShiny RStudio Postgres           Additional Professional Experience       Senior Net Developer       012016   to   Current     CHICKASAW NATION INDUSTRIES    –    Norman     Oklahoma             Develop solutions in alignment with the Enterprise architecture while contributing and advocating the use of Enterprise frameworks  Defines applications and websites objectives by analyzing user requirements envisioning system features and functionality  Researching and understanding new web technologies to provide technical leadership in developing service applications and analyzing business requirements  Designs and develops user interfaces to Internetintranet applications by setting expectations and features priorities throughout development life cycle  Technologies used C ASPNet HTML CSS SQL Server SVN JQuery JavaScript CSS AngularJS Bootstrap Entity framework TFS WEBAPI2 Waterfall Methodology           Software Developer II       2015   to   092015     CHESAPEAKE ENERGY    –    Oklahoma City     Oklahoma             Reduced department cost 10 by reducing amount of time spent working of previous released projects by ensuring new code integrated with existing productReduced server load by 26 by converting numerous serverside components to clientside  Leveraged advanced knowledge of ASPNET and AngularJS to optimize Sharepoint created pages eliminating 13 of code while enhancing overall functionality and speed  Technologies used C MVC NET Test unit SQL Server AngularJS Bootstrap HMTL CSS PowerShell TFS SSIS REST SQLite Agile Methodology         ​          Senior Software Developer       012013   to   112014     NIC LLC    –    Oklahoma City     Oklahoma             Led programming tasks including enhancements maintenance and support for clients applications and interfaces  Developed new procedures for requirements gathering needs analysis testing scripting and documentation to strengthen quality and functionality of businesscritical applications  Managed 6member developer team  Technologies used WAMP stack HTML CSS Oracle SVN JQuery JavaScript Java Agile  Waterfall Methodology           Senior Software Developer       102007   to   112012     PAYCOM PAYROLL LLC    –    Oklahoma City     Oklahoma             Design and implementation of applications collaborating with project managers and quality assurance team to ensure ontime completion and quality of projects  Provided technical leadership to junior developers  Focused teams on business objectives and tracked progress to ensure project milestones were completed on time on budget and with the desired results  Reduced client cost by 32 by Improving client experience with the ability of managing multiple client products and employees from a single location  Created module that allows clients ability to send and receive synchronous feedback on employment eligibility and verification by connecting to the Department of Homeland Security EVerify  Created an Executive dashboard that displays client toplevel metrics helping executives run their companies efficiently This increased new business sales 270K in 2011  Technologies used LAMP stack HTML CSS MYSQL Subversion JQuery JavaScript SOAP XML C Visual Agile  Waterfall Methodology          Other Skills     JAVA CC   Python AMPL Matlab WEKA MongoDB data analysis optimization Git HIVE HIVEQL Tableau       Education       Master of Science     DATA SCIENCE  ANALYTICS     Expected in   2017     University of Oklahoma      Norman     Oklahoma     GPA                Bachelor of Science     Computer Engineering     Expected in   2007     University Of Oklahoma      Norman     Oklahoma     GPA               Affiliations       Engineering Student Life  member 2005 Date   National Society of Black Engineers  member 2005 Date   Gallogly College Of Engineering Graduate Student Community  member 2015  Date   Graduate Student Life  member 2015  Date        Certifications       R Programming  John Hopkins UniversityCoursera   Introduction to Big Data  University of California San DiegoCoursera   Hadoop Platform and Application Framework  University of California San DiegoCoursera   Getting and Cleaning Data  University of California San DiegoCoursera   Machine Learning Foundations  University of WashingtonCoursera,\n",
       " Jessica    Claire                   Montgomery Street     San Francisco     CA  94105    609 Johnson Ave       49204     Tulsa     OK       H   555 4321000    C       resumesampleexamplecom    Date of Birth         India                      single                    Summary       7 years of IT Industry experience in in designing and developing data mininganalytics solutions data centric integration developing and maintaining Business analytics   Adept in data query data migration data analysis predictive modeling machine learning data mining and data visualization implementations with extensive use of SQL Python R Java and Unix Shell scripting with platform of Toad Oracle developer Jupyter Notebook Pycharm RStudio Tableau Hadoop with Spark  Experience in predictive analytic procedures used in supervised learning Classification Regression Decision trees Random Forest SVM Neural Networks unsupervised learning ClusteringkMeans and PCA and reinforcement learning  Solid theory background for machine learning data mining text mining graph mining statistics modeling NLP and deep learning  Expert in Natural Language Processing like POS Tagging Parsing Named Entity Recognition Relationship extraction Information       Retrieval Sentimental Classification Machine Translation etc  Solid knowledge of deep learning algorithms like CNN RNN LSTM GRU etc for text mining and image processing  Professional in writing complex SQL queries on Oracle MS SQL server Teradata and MySQL using a lot of subqueries joins aggregate functions analytical functions and temporary tables etcWorked on Big Data Analytics Hadoop ecosystems Hadoop Sqoop Hive Pig Mapreduce and Spark for big data migration cleaning transformation processing query and analysis  Familiar with software lifecycle includes requirement collectingdocumentation development and testing for Unit Smoke  integration system nonfunctional testing regarding performance scalability usability enduration load and volume testing and regression testing multivariate testing AB testing and system maintenance  Work with business domain experts and application developers to identify data relevant analysis  mining and develop new predictive  analytical modeling methods andor tools in Financial like loan and foreign exchange Product Customer Sales domains etc  Experience in data aggregation and reduction techniques of large data sets with high performance and parallel computing for high performance analytical projects  Involved in diagnosing and resolving predictive  analytical model performance issues monitoring analytical system performance  ·       and implementing efficiency improvements  Conversant with MS SQL Oracle PLSQL and RDBMS Contributed in data definitions for new database filetable development andor changes to existing ones as needed for analysis and mining purpose  Experienced Oracle PLSQL Developer for designing developing debugging  maintaining and administrating database in Oracle RDBMS Solid experience in PLSQL and SQL programming and performance tuning   Familiarity with Oracle data warehousing features such as star  snowflake data modeling schemas materialized views bitmap indexes Index Organized Tables external tables etc and OLTP system using Btree index Hash Join etc  Experienced in frontend developing using Java Javascript C and backend developing using C  Professional in integrating and maintaining code using version control tools PVCS SVN CVS  Solid experience and knowledge in ETL and Data warehousing conceptsData Processing experience in designing implementing transformation processes using ETL tool   Involved in all aspects of ETL requirement gathering with standard interfaces to be used by operational sources data cleaning data loading strategies ETL mappings designing documentation and ETL jobs performance testing                    Using Unix bashcorn shell scripting to do backend process operation system resources  checking job scheduling batch data loading performance tuning and reporting     Conversant with Project Management deliverables and SDLC phases – Waterfall and Agile   A selfstarter team player excellent communicator prolific researcher  Expert technical documentation skills Strong interpersonal and communication skills both written and oral ability to communicate with people in a wide variety of areas and at various levels from technical specialists to senior management          Skills                        Roles  Data Scientist Data Analyst Business System Analyst Oracle PLSQL developer   Data Visualization  D3js Tableau R visualization packages Microsoft Excel    Data Analytics ToolsProgramming                 Python numpy scipy pandas scikitlearn gensim keras Rcaret weka ggplot  MATLAB Microsoft SQL Server Oracle PLSQL     Machine Learning Algorithms  classification regression clustering feature engineering    Big Data Tools  Hadoop MapReduce SQOOP Pig Hive NOSQL Cassandra Spark    Others Deep Learning NLP Topic Modeling Sklearn Graph Mining Text Mining C C  Java Javascript ASP Shell Scripting  \t\t\t\t\t \t\t\t\t \t\t\t \t\t        Experience       Data Scientist       082011      092016     Lockheed Martin Corporation    –    Yuma     AZ                              Actively develop predictive models and strategies for effective fraud detection for credit and  customer banking activities using Kmeans clustering using Python    Assisted senior data scientist to do text mining on customer reviewcomment data using topic modeling  and sentimental classification using deep learning algorithms like CNN RNN LSTM GRU to  remediate according financial products using Python    Assisted senior quantitative analyst in assessing risk management of financial derivative products like foreign exchange products bonds funds etc using machine learning techniques for providing appropriate investment recommendations using Collaborative filtering recommender system using Python    Mentored sophisticated organizations on large scale customer data and analytics using advanced  machine learning and statistical models relying for issuing loan using Random Forest using R    Performed kMeans clustering in order to understand customer backgrounds and segment the  customers based on the customer transaction behavior information for customized product  offering customized and priority service to improve existing profitable relationships and to avoid customer churn etc using R    Worked on Interactive Dashboards for building story and presenting to business using Tableau     Implementing Hadoop to provision big data analytics platforms for customer data Used  MapReduce Sqoop Hive and Spark to migrate and analyze large callqualitydata datasets from  multiple Data sources like integrated funds transfer system like FedWire CHIPS SWIFT for  securities treasury or derivatives and webbased cash management systems eGifts GiftsWEB GiftsWEB EDD for fraud detection and risk management for accounts based on positive pay and Automated Cash Handling balance reporting etc    Installed and configured Hadoop cluster in Test and Production environments Moving data from Oracle 9i database to HDFS and viceversa using SQOOP Collecting and aggregating large amounts of log data using Apache Flume and staging data in HDFS for further analysis Developed multiple MapReduce jobs in java for data cleaning and preprocessing Writing Pig scripts to transform raw data from several data sources into forming baseline data  Solved performance issues in Hive and Pig scripts with understanding of Joins Group and aggregation and how does it translate to MapReduce jobs Developed Oozie workflow for scheduling and coordinating the ETL process Using Spark for further data analysismining     Experience in using Sequence files RCFile AVRO and HAR file formats  Work with Data Analytics team to develop time series and optimization    Involved in development and maintenance of Oracle database using PLSQL and backend  development using CC for intranet management system for Employee Management System  EMS and Agent Payout System APS              Business System Analyst       042009      082011     Accenture    –    Overland Park     KS            Project Summary   This project is in Application service group for Mercury system in Canon USA Inc  which mainly in charge of the new item request item disclosure between companies item data import from other Canon Americas companies to Canon USA Canon Americas Master inquiry Model tree maintenance model configurations and cameravideo merchandise Maintenance for Canon Americas systems includes S21 for Canon USA merchandise master S98 for Panama CCI21 for Canada S85 for Mexico Chili Brazil and Argentina Ideal for Latin Americas countries       HardwareSoftware       Windows VistaNTXP7 Linux Oracle 11g10g9i8i SQLPLUS  Oracle SQL developer Toad  Microsoft SQL Server management studio 2008Microsoft Visual Studio 60ODBCJDBC  Microsoft IIS 511 Putty Cygwin Winmerge VPN ITG project management system PQedit IIS AutosysPCXware 510 MS Word Excel Access Project Visio      Responsibilities     Operational support for Canon Americas Mercury system includes data adjustmentresearch batch data loading system migration Technical and functional specification documentation reports business process alignment workflow stuck and reconciliation etc      BreakFix any issues or bugs collected from client and development regarding setup performance functionality and workflow stuck etc   System Enhancement regarding functionality and performance etc  Reproduce and review existing oracle 9i schema objects includes tables temporary tables views materialized views indexes triggers procedures functions packages based on customer requirement and system upgrade using Toad and Oracle SQL developer tools        Review and analyze ASP code for UMC Mercury application web development for data research and system feature fix and enhancement using Visual Interdev 60        Query realtime data regarding Canon Americas new item request item status inquiry item data disclosure and import model configuration and maintenance warranty maintenance and model configuration inquiry  etc  using complex SQL queries on Oracle 9i Canon mercury database      Using Unix bashcorn shell scripting to do backend process operation system resources checking job scheduling batch data loading performance tuning and reporting  Maintain scheduled day and night batch jobs for mercury system using AutosysPCXware and Unix box and check the MQ series using PQ edit      Implement client session action module service instance level endtoend application tracing using SQL trace with TKPROF and Explain plan to check execution plans for highload and Top SQL statement  Using Cygwin FTP Putty with Unix Bash shell to make a tunnel for Oracle database connection       Using Tortoise SVN for code checkout update and release–comparison etc       Tracking and documenting tickets for development and reproduction Using ITG ticket tracking system                        Assisted QA and build team to be involved in unit smoke integration system UAT nonfunctional testing regarding performance scalability usability  enduration load and volume testing and  regression testing and maintenance using SOUP UI and Seapine QA Wizard Pro for product release          Data loading using Impexp data pump and external tables from Americas Mercury system to S21CUSA merchandise master to RossCUSA retails system and Global Mercury system                Oracle PLSQL Developer       2008      042009     Cognizant Technology Solutions    –    Novi     MI            Project Summary   NYU Langone Medical Center a worldclass patientcentered integrated  academic medical center is one of the nation’s premier centers for excellence in healthcare biomedical research and medical education The project is to develop new oracle database objects on online Health Information Managment system on FindWdev instanceserver for 29 NYU medical school departments using in clinical education research and foundational areas etc to be used as Oracle staging area to store the loaded data from NYU Medical Dash DWH from different source systems to provide further data to be loaded into DWH for historical record Decision support and Datamart for reports  and Cube for UI display      HardwareSoftware     Unix Oracle 11g Oracle developer 11g Oracle EBS 11 ERP R12 IBM DataStage 80 Designer Director Manager Parallel Extender Oracle Enterprise Manager MS SQL server management studio 2008 Toad for Oracle 90 TSQL  PLSQL XML Erwin Microsoft Visio Autosys IBM Data stage 8 Oracle reports 11g   Responsibilities                      Independently develop Oracle database objects includes tables views materialized views indexes triggers functions procedures packages etc     Cooperated with BA SME to collect and document database design requirements and do data modeling with DB architect using Erwin and Microsoft Visio     Assisted DBA for job scheduling data loading and performance tuning using OEM SQL tuningaccess advisor hints  explain plan  SQL trace and V performance views under Unix     Write complicated queries using a lot of aggregate functions joins analytical functions subqueries  etc to provide realtime data from Oracle DB  for client and UI development supporting  Checking execution plan using explain plan together with SQL trace with TKPROF using trcsess under unix to realized endtoend application tracing      Add optimization hints into high–load and top SQL statements to change the optimization goal access method join method join order and parallelization etc    Designed and developed ETL processes using DataStage designer to load data from Oracle to staging database and from staging to the target Data Warehouse    Worked with Datastage Manager for importing metadata from repository new job Categories and creating new data elements  Used DataStage stages namely Hash file Sequential file Transformer Aggregate Sort Datasets Join Lookup Change Capture Funnel Peek Row Generator stages in accomplishing the ETL Coding  Job scheduling using Autosys  Coorporated with QA team for debugging unit system functional UI regression testing for new ISO release production    Working on Linux system for batch data loading job scheduling and system resource checking etc    Assisted backend developer for reviewing and debugging C program for Health information management systems                  Involved in web development of online Health information management systems using JAVA  Reviewed and reproduced online JAVA reports of Health information management system checked DB references in it for intelligent Decision Support System            Education       Master of Science       Computer Science       Expected in   2016                University of California      Los Angeles     CA     GPA        Status          GPA378   Courses                Statistics Programming Databases and Knowledge Bases Graphs and Network Flows  Language and Thought Current Topics in Computer TheoryMachine Learning Algorithm Computer Science ClassicsBasic Data Science Data Mining and Big Data Analytics System Security            Master of Science       Electrical Engineering       Expected in   2010                University of Bridgeport      Bridgeport     CT     GPA        Status          GPA362   Courses Computer Networks Database Management Systems Data and Computer Communications Data Structures          Bachelor of Science       Telecommunications Engineering       Expected in   2007                Jilin University      Changchun     Jilin     GPA        Status         GPA 350,\n",
       " Jessica    Claire                   Montgomery Street     San Francisco     CA  94105    609 Johnson Ave       49204     Tulsa     OK       H   555 4321000    C       resumesampleexamplecom    Date of Birth         India                      single                    Experience       Graduate Assistant Data Scientist       011      011     Pace University    –                     Information System IS Analyze data using SPSS for faculty development  Part of the research team on conference proceedings like AMCIS ICIS and ECIS on geographic information system GIS spatial analysis and location analysis  Assist undergraduate students understanding SQL MYSQL etc  Data Visualization using tableau pivot tables D3js etc           Business Analyst  eCARGO       011      011     Information System    –                     The project involves responsibility for the product planning and execution throughout the Product Lifecycle including gathering and prioritizing product and customer requirements defining the product vision and working closely with operations sales client delivery technology and other stakeholders to implement new products ensure revenue and customer satisfaction goals are met  The Product Managers job also includes ensuring that the product supports the companys overall strategy and goals  Responsibilities Reviewed  gathered business requirements with the business and created business analysis process  Created detailed Functional Requirement Specification FRS and NonFunctional Requirements for Individual Market Portal Project based on the approved scope document  Facilitated JAD sessions and workshops required to understand workflows business needs and storyboards  Conducted Scrum meetings on regular basis  Kept the Product Owner  Project Manager informed about project status and issues that may impact client relations  Attended client meetings and assist with determination of project requirements  Organized meetings team celebrations between team members and clients  Recorded minutes at meetings  kept detailed project notes and records  Worked with cross functional team like UX design development QA marketing and different Line of Businesses  Generated Use Case diagrams Activity diagrams Business Object to depict process flows and PowerPoint presentations  Performed User Acceptance Testing UAT for various web based and database related applications  Work on defining the sprint scope and oversee the BA schedule and deliverables  Work with IT to design and develop data collection and management tools to manage the information  Certifications and Training PH1252x Data Science Visualization Certificate ID          June XXX8 ExiLearn Business Analyst          Aug XXX8 Communicated with the client to elicit analyze and validate the requirements  Created System Requirements Specification SRS Business Requirements Specification and Document  Created Wireframes using Mockup Plus and InVision  Created Use case activity and sequence diagrams using drawio Prepared Gantt Chart Requirement Traceability Metrix using Microsoft Excel           Academic Projects       011      011     1Store One Stop Shop    –                     Objected at creating an application to integrate all utilities like electricity internet travel and mobile recharge Scraped data from all utility websites and REST APIs provided by them The framework used is Ionic 20 with Angular 2 Worked with users and stakeholders to analyze and validate requirements Managed project through status meetings weekly reports identifying risks and tracking issues  Refreshable Braille Display for Mathematical Equations          Feb15May16  Developed a hardware tool that could help visually impaired to read and understand mathematical equation using braille pins and  tactile displays  Identified the solutions that could help visually impaired to read and understand mathematical equation Responsible for specifications implementations and analytics Prepared business models flowcharts and diagrams          Education       Masters       Computer Science       Expected in                   Pace University Seidenberg School of CSIS                GPA        Status         Computer Science GPA 384         Algorithms and computing theory Mobile Web Content and Development Web Development and Content Management system Human Factors and Usability Metrics              Expected in                                   GPA        Status                  Bachelors       Computer Engineering       Expected in                   University of Mumbai                GPA        Status         Computer Engineering GPA 321         Analysis of algorithm Software Engineering Computer graphics Artificial Intelligence Distributed databases Data Warehouse and mining Cryptography and system security              Expected in                                   GPA        Status                 Summary     To leverage my knowledge and expertise to growth of organization and self Master of Science in Computer Science with graduate assistantship and GPA of 384 Strong communication skills Expert in Algorithms and Computing Theory Master in Artificial Intelligence Demonstrated efficiency in team projects as well as handled projects independently Highly organized with the ability to manage multiple projects and meet deadlines        Highlights           Mac Windows Linux Ubuntu  Programming Languages SQL Python MySQL Relational databases HTML5 CSS3 JavaScript XML XHTML jQuery JSON D3 ThreeJS  WebGL SVG images HTML Canvas Ionic 20 AngularJS React  Applications Jira InVision Axure Blueprint Mockup Plus Agile Scrum Microsoft Excel Pivot Tables VSLOOKUP macros  VBA Tableau Visual Studio Android Studio Photoshop Gimp Quincy Eclipse NetBeans GitHub                         Skills     Photoshop Agile API Artificial Intelligence BA Blueprint Business Analyst business analysis Canvas hardware draw Cryptography CSS3 client clients client relations customer satisfaction data collection Data Visualization Data Warehouse Databases database delivery Eclipse XML Functional Gimp GIS Computer graphics UX HTML HTML5 JavaScript jQuery JSON Linux notes Mac macros marketing Market meetings Microsoft Excel PowerPoint presentations Windows MYSQL Operating Systems Pivot Tables product planning Product Manager Programming Python QA read Relational databases Requirement research sales Scrum Software Engineering Specification SPSS SQL strategy Tableau utilities vision VBA Visual Studio Web Development and Content websites Web Content and Development workshops XHTML       Additional Information       Extracurricular Activities Event Organizer for colleges cultural and technical festival Participant in the CodeZilla Competition held by my Undergraduate School in XXX4 Honors and Awards Pace University Scholarship worth 6000,\n",
       " Jessica    Claire                      San Francisco     CA  94105    609 Johnson Ave       49204     Tulsa     OK      Home   555 4321000        Cell           resumesampleexamplecom                  Professional Summary     Data scientist with 1 years of experience in deClairevering datadriven insights in large data management enterprise fastpaced hedge fund and media entertainment conglomerate passionate and skilled at solving business problems with machine learning models and data analytics       Skills           Regression GLM Ridge Lasso KNN  Classification Logistic Regression Decision Trees Random Forest XGB SVM NaiveBayes  Clustering KMeans Hierarchical DBSCAN  Statistics  AB Testing Hypothesis Testing Bayesian Inference ProbabiClairety  Programming  Python SQL R Hive Spark Git Scala Java      Ad  Automate  Clustering  Credit  CRM  ETL  Java  Marketing  ModeClaireng  Predict  Programming  Promotion  Python  QuaClairety  Sales  SQL  Statistics  VaClairedation                       Work History      092019   to   Current     Data Scientist Consultant      Deloitte    –    San Juan     PR             Implemented and deployed marketing propensity model using XGBoost for customer acquisition on upcoming movies identified top 70 firsttime purchasers with highest product interest scores  Constructed adhoc SQL queries and performed AB test for quantifying retention and churn campaign promotion upClairefts collaborated with CRM teams to identify key metrics and evaluate testing results  Designed and developed ETL process using SQL and R to automate data vaClairedation process for identifying and tracking data quaClairety issues  Created user defined function using Kmeans in Snowflake warehouse to segment customer by user behavior and demographic information  Developed and pubClaireshed several interactive and scalable Rshiny visuaClairezation dashboards to increase visibiClairety on various KPIs          062019   to   082019     Data Scientist Intern      Ascend Learning    –    Nashua     NH             Identified and analyzed problems of cascade effect and data misrepresentation when using credit card transaction to predict companies’ sales provided solutions that reduced outofsample MAE error by 75  Partnered with investment team from different sectors to increase size of modeClaireng data using clustering sampClaireng and rule based method effectively improved data reClaireabiClairety and reduced geobias from various alternative data sources          052018   to   092018     Data Scientist Intern          –    Orlando     FL             Designed developed and deployed automated streamClairened procedure in Python for parsing test performance data and building visuaClairezation platform using Pyplot and Tableau for multiple drive performance comparison improving tasks efficiency by 30  UtiClairezed Hive platform to develop an automated pipeClairene for data query cleaning and transformation          Education      Expected in   052019     Master of Science     Statistical Science     Duke University      Durham     NC     GPA       GPA 37        Expected in   082016     Bachelor of Arts          University Of CaClairefornia Berkeley      Berkeley     CA     GPA       GPA 392        Work History      092019   to   Current     Data Scientist Consultant       Warner Bros Entertainment Inc Insight Global and Horkus Solutions   –   Burbank     CA      Implemented and deployed marketing propensity model using XGBoost for customer acquisition on upcoming movies identified top 70 firsttime purchasers with highest product interest scores  Constructed adhoc SQL queries and performed AB test for quantifying retention and churn campaign promotion upClairefts collaborated with CRM teams to identify key metrics and evaluate testing results  Designed and developed ETL process using SQL and R to automate data vaClairedation process for identifying and tracking data quaClairety issues  Created user defined function using Kmeans in Snowflake warehouse to segment customer by user behavior and demographic information  Developed and pubClaireshed several interactive and scalable Rshiny visuaClairezation dashboards to increase visibiClairety on various KPIs          062019   to   082019     Data Scientist Intern       Point72 Asset Management LP   –   New York     NY      Identified and analyzed problems of cascade effect and data misrepresentation when using credit card transaction to predict companies’ sales provided solutions that reduced outofsample MAE error by 75  Partnered with investment team from different sectors to increase size of modeClaireng data using clustering sampClaireng and rule based method effectively improved data reClaireabiClairety and reduced geobias from various alternative data sources          052018   to   092018     Data Scientist Intern          –   Sunnyvale     CA      Designed developed and deployed automated streamClairened procedure in Python for parsing test performance data and building visuaClairezation platform using Pyplot and Tableau for multiple drive performance comparison improving tasks efficiency by 30  UtiClairezed Hive platform to develop an automated pipeClairene for data query cleaning and transformation          Skills      Regression GLM Ridge Lasso KNN  Classification Logistic Regression Decision Trees Random Forest XGB SVM NaiveBayes  Clustering KMeans Hierarchical DBSCAN  Statistics  AB Testing Hypothesis Testing Bayesian Inference ProbabiClairety  Programming  Python SQL R Hive Spark Git Scala Java  Ad automate Clustering credit CRM ETL Java marketing modeClaireng predict Programming promotion Python quaClairety sales SQL Statistics vaClairedation,\n",
       " JC     Jessica    Claire                      Montgomery Street       San Francisco     CA    94105             555 4321000                 resumesampleexamplecom                                   Summary     Qualitydriven AIML Product Manager with 4year background in Data Science enterprise BI and building machine Learning product with a proven track record of ontime delivery Excellent customer interaction skills technical knowledge and presentation skills Good understanding of product management and firm grasp of Data Science principles 17 years of combined experience in Application Engineering presale activities product management and business development of Engineering and simulation technology softwares       Skills           People skills  Customer service  Business development  Requirements gathering  Scope development  Communication  Critical thinking  Agile methodology  Story oversight  Product planning  JIRAConfluence  Balsamiq software  AutoML framework  Keras LSTM  Statistical Modelling Regression Classification clustering Multivariate Forecasting      MLOps  Explainable AI  PDP ICE LIME SHAP  Hypothesis Testing DOE  Exploratory Data Analysis  Feature Engineering  Python R Language SQL SAS  Spyder RStudio MySQL Workbench VirtualBox  SAS Enterprise Miner  Ubuntu                       Experience        052019   to   Current   Data Scientist Product Manager    Snapchat         AZ     State            Designed implemented and released 3 versions of AIML desktop product Altair Knowledge Studio in 2021 in an Agile framework  Sphereheaded opensource integration features of AIML product  Increased the customer base from 19 to 35 an increase of 84  Wrote detailed specification for 4 explainable AI algorithms PDP ICE LIME SHAP for native implementation in Knowledge Studio  Wrote production grade Python code for integrating 5 key features Keras LSTM ARIMA scikitlearn libraries GLM and XGBOOST  Followed industry innovations and emerging trends through scientific articles conference papers or selfdirected research  Worked alongside PM leadership to identify product requirements and updated on product release status monthly  Translated business goals and customer needs into prioritized product requirements and use cases  Created epics and wrote user stories for different user personas  Communicated feature requirements to the developers worked closely with the developers reviewed developed features provided feedback to dev make sure the features meet MVP criteria  Recommended product changes to enhance customer interest and maximize sales  Outlined new feature plans created epics wrote detailed specifications produced wireframes of UI and made user facing decisions  Collaborated with design team to enhance the user experience and modernize the product UI  Collaborated with Data Scientists to review new feature specifications and gathered feedback on released features  Collaborated with legal team to understand the licensing and various other aspects of opensource libraries and code  Communicated changes in feature scope and timelines empathetically to the relevant stake holders            052018   to   052019   Applied Data Scientist    Atrium Health         Fort Mill     SC            Worked with presales sales and marketing teams to promote the new features and gathered feedback  Modernized products based on consumer feedback and market analysis to increase sales and expand product offering  Demonstrated selfreliance and leadership by meeting and exceeding workflow needs  Provided consultation to Altair Customers to help drive software usage Developed AutoML algorithm as a turnkey solution to do Machine Learning such as forecasting classification and regression using R on SaaS platform – Altair’s cloudnative enterprise level business analytics solution  Operationalized AutoML on the SaaS platform by working closely with DevOps team  Operationalized anomaly detection models on SaaS platform to understand remaining useful life RUL of a bearing  Tested validated and reformulated models to foster accurate prediction of outcomes  Built and deployed predictive models to understand the reliability of aircraft engines  Demonstrated Altairs Data Science suite of products to customers and helped them evaluate success criteria  Presented the results of AutoML to business stakeholders            062016   to   052018   Senior Application Specialist    Atrium Health         Belmont     NC            Worked with client database engines like Hadoop and HIVE to update custom dashboards on SaaS based BI application in almost realtime to meet customers’ business needs  Increased customer engagement by inperson troubleshooting sessions  Evaluated and led rootcause analysis for production issues and empathetically managed user concerns  Wrote user manuals and other documentation for rollout in customer training sessions  Performed advanced usability testing to improve software robustness  Documented decisions to allow for broader company learning and iteration opportunities            062007   to   062016   Senior Application Specialist    Altair Engineering Inc         City     STATE            Worked closely with account managers and helped them cross technical side of sales cycle  Analyzed user needs and software requirements by involving in product design life cycle of key customers to drive software usage  Resolved customer issues by establishing workarounds and solutions to debug and report defects to product manager which minimized software down time  Coached SMEs across Altair offices globally to meet prescribed business goals and to improve customer retention  Published paper on optimizing design process by coupling simulation software and design exploration at an international conference  Travelled to clients places internationally to better understand the process and client requirements  Established and maintained key relationships with business stakeholders to promote future opportunities          Education and Training        Expected in   122018   Master of Science       Predictive    Northwestern University Analytics  University of Mysore     Evanston     IL      GPA                 Expected in      Bachelor of Engineering       Mechanical                    GPA,\n",
       " Jessica  Claire                             resumesampleexamplecom                      555 4321000                       Montgomery Street     San Francisco     CA      94105                                                                                                                                                                                                             Career Overview     Data Science professional with 5 years of cross functional experience working on advanced analytics projects with marketing finance and strategy teams within retail and healthcare expertise in predictive modeling           Qualifications       R   Python   Apache Spark   Hive   SQL   Advanced Excel   Tableau Machine Learning Skills Linear Regression Logistic Regression Clustering Ensemble methods Deep Learning Naïve Bayes Random Forest Decision tree Text mining Time Series modeling NLP                     Education and Training       University of Cincinnati Carl H Lindner College of Business    Cincinnati     Ohio      Expected in   June 2016     –      –       Master of Science        Business Analytics          GPA           Business Analytics 3940         Indian Institute of Technology Delhi    New Delhi           Expected in   August 2010     –      –       Bachelor of Science        Mechanical Engineering          GPA           Mechanical Engineering          Accomplishments              Work Experience       Cox Communications Inc      Associate Data Scientist                           011      Present     Working on big data solutions for Sams club marketing and merchandising team           Maximus Inc      Novartis AG          Analyst                                      Marketing Science          21st October13  7th July15           Analytics advisory to global business strategy team and brand directors on forecasting and strategy projects for contact lens and lens care solutions portfolio with Alcon Vision Care  Capacity planning Developed model for entire contact lens portfolio with utilization estimated using MonteCarlo     simulation method leading to approval of 6 additional production lines costing 300MM to meet future demand   Product crosssell strategy Utilized transactional data from customers to determine most common pairs of contact lens    and lens solution to help crossselling strategy for Alcon model based on apriori algorithm developed in R   Forecast and valuation Built forecasts and valuation models for portfolio of existing and inline products Nielsen MSci          Business Analyst          30th January13  3rd October13           Redesigned standard operating procedures for universe estimation improving productivity by 60 transferred most of the procedures from excel to SAS  Automated VBA based tool to detect outliers in data           WNS Global Services      Senior Associate                                      24th March11  24th January13             Portfolio valuation and risk estimation Incorporated risk adjusted valuation in sales forecast models to estimate risk associated with each product development this helped accelerate the ideation process for products    Time series forecast Automated tool built for established drugs which was replicated for 6 other countries   Customer segmentation and retention analysis Built a model using clustering algorithm in R to segment physicians Model to predict churn rate for certain segments based on Rx data   Project management Trained and led 2 associates for projects in GSK emerging market team          Skills     Apache big data Business Analyst business strategy Capacity planning Clustering costing forecasting Machine Learning marketing market merchandising Excel modeling NLP predict product development Project management Python selling sales SAS simulation SQL strategy Tableau valuation Vision VBA,\n",
       " Jessica    Claire                   Montgomery Street     San Francisco     CA  94105    609 Johnson Ave       49204     Tulsa     OK       Home   555 4321000    Cell       resumesampleexamplecom              Professional Summary      Highly driven Data scientist with 5 years of experience who brings formidable solutions to diverse complex business problems using machine learning data mining and statistical analysis  Familiar with gathering cleaning and organizing data for use by technical and nontechnical personnel Advanced understanding of statistical algebraic and other analytical techniques  Organized motivated and diligent with significant background in PythonMachine LearningDeep learning Experienced working with vast data sets to break down information gather relevant points and solve advanced business problems Skilled in predictive modeling data mining and hypothetical testing        Skills           Machine learningStatistical AnalysisData Mining  · Python R SQL  · Keras NumPy Pandas Scikitlearn NLTK Spacy TensorFlow  Development Tools Anaconda PyCharm Spyder Visual Studio RStudio      Theoretical Competencies AGILE Scrum Algorithms Data Structures Databases SDLC  Version Control Git Bitbucket Perforce  Web TechnologiesAWS GCP Azure                       Work History       Data Scientist       062019   to   122020     Lockheed Martin Corporation    –    Durham     NC             1MedConnect   Jul 20  Dec 20    Developed and implemented a Forecasting algorithm to predict sales trx total count and nrx individual count of medicine purchasedCreated data visualization graphics translating complex data sets into comprehensive visual representations  Forecasted sales and improved accuracy – MAPE and RMSE by 30 by implementing advanced forecasting algorithms that were effective in detecting seasonality and trends in the patterns  Increased accuracy helped business plan better with respect to budgeting and sales and operations planning Tuned model parameters p d q for ARIMA using walk forward validation techniques for optimal model performance    2Imperial Bank  Nov 19  Jul 20    Clustered the customers owning the credit cards to optimize the targeting and offerings to increase the customer satisfaction and which in turn enhances revenue  Provided Comprehensive analysis and recommended solutions by applying advanced analytical methods to assess factors impacting growth and profitability across product and service offering by running the model against unstructured dataChat Conversations and identified the topic of chat  Generated word frequency for 1gram 2gram and 3gram words and used regex to identify the frequency of the main topicsissues Performed clustering on the TFIDF to segment the data    3Market Place Intelligence  Jun 19  Nov 19    Collaborated with senior personnel to define and meet data modeling standards for deep dive projects  Translated benefits of machine learning technology for nontechnical audiences including costbenefit analyses  Evaluated processes and data identifying productivity gains and sales growth within digitization segment           Data Scientist       112015   to   062019     Lockheed Martin Corporation    –    El Segundo     CA             1Client Samsung  Apr 17  Jun 19    Developed voice enabled features for Samsung Health Internet and Gallery applications Performed NLP tasks and techniques such as parsing text pre processing named entity recognition Modelling and Testing Train set preparation model building for CNN based Intent classifier and Slot tagger  Applied statistical and algebraic techniques to interpret key points from gathered data Best epoch selection by plotting cost functions  Coached developed and motivated team members providing coaching and mentoring to junior data scientists on SAS and data mining techniques           Software Engineer       112015   to   042017     Cgi Group Inc    –    Norfolk     VA             Adjusted design parameters to boost performance and incorporate new features  Checked client code for bugs and weaknesses and fixed the issues accordingly  Collaborated with business unit team members to design new applications system to enhance client requirements for mobile computing capabilities          Education       Master of Science     Computer Science     Expected in   012021     University Of Alabama At Birmingham      Birmingham     AL     GPA                Bachelor of Science     Electronics And Communication Engineering     Expected in   072015     SVPCET      Anantapur          GPA         Graduated with 324 GPA           Board of Intermediate Education     Mathematics Physics And Chemistry     Expected in   062011     Board Of Intermediate      Tirupathi          GPA         Graduated with 926100 percentage           High School Diploma          Expected in   052009     Infant Jesus English Medium School      Chittoor          GPA         Completed with 888100 percentage          Accomplishments       Received Best Employee of the month Award from Deloitte for Documenting and Resolving issues which led to a optimal solution to client  Received APPRECIATION Award from client SAMSUNG for colloborating with team in the development of Bixby Project  Received PAT on the BACK Award from Tech Mahindra for on time quality delivery work         Certifications       Completed the certification of “Neural Networks and Deep Learning” “Improving Deep Neural Networks” Hyperparameter tuning Regularization and Optimization “Convolutional Neural Networks” in Coursera by Andrew NG  Completed the certification of “Machine Learning” in Coursera by Carlos and Emily  Completed the certification of Google Cloud Platform Big Data and Machine Learning Fundamentals in coursera,\n",
       " Jessica  Claire                             resumesampleexamplecom                      555 4321000                                         100 Montgomery St 10th Floor                                                                                                                                                                                                           Professional Summary      Data Scientist with over 4 years of successful experience in Machine Learning NLP and Predictive Modeling Recognized consistently for performance excellence and contributions to success in business industry Strengths in math and programming skill backed by training in data science            Skills         Database MySQL Postgres SQL MongoDB  Programming Language Python and R  Machine Learning  Data Mining  Natural Language Processing  Statistical analysis      AB Testing  Project Management  Agile framework understanding  BigData HBase Hadoop  Hiveand Spark  Operating Systems LINUX WINDOW  Environment AWS AZURE Databricks                     Education       Colorado State University    Fort Collins     CO      Expected in   052019     –      –       Master of Science        Applied Statistics Specialization Data Science          GPA            GPA 343 400   Professional development completed in Data Science           Addis Ababa University    Addis Ababa           Expected in   062011     –      –       Master of Science        Biochemistry  Biophysics          GPA            GPA 350 400          Addis Ababa University    Addis     Ababa      Expected in   082003     –      –       Bachelor of Science        Medical Laboratory Technology          GPA                   Certifications       Introduction of TensorFlow for AIMachine Learning and Deep Learning Training  Nov 2019           Work History       Yahoo      Data Scientist   New York     NY                   062019      Current     Transformed raw data into MySQL with custommade ETL application to prepare unruly data for machine learning  Performed data cleaning features scaling featurization features engineering used Pandas NumPy SciPy Matplotlib Seaborn Scikitlearn in Python at various stages for developing machine learning model and AB Testing multivariate to measure impact on new initiatives  Used spark’s machine learning library to build and evaluate different models  Developed endtoend machine learning prototypes and scaled them to run in Aws sagemaker notebooks  Collaborated with internal stakeholders identifying and gathering analytical requirements for customer product and projects needs  Provided comprehensive analysis and recommend solutions to address complex business problems and issues using data from internal and external sources and applied advanced analytical methods to assess factors impacting growth and profitability across product and service offerings           Epic Games      Capstone Project    Colorado Springs     CO                   092017      062019     Built Recommendation system using cosine similarity to choose similar songs added to given playlist  Customer Churn Prediction Projects  Pick up top model based on recall score Evaluated models using Cross validation recall used to measure performance and used ROC curves and AUC for feature selection  Predict product categories for ibotta datasets Built machine learning classifier for many datasets and applied data mining to improve text quality by autocorrecting grammatical issues  Analysis on NBA Real PlusMinus for 20142015 Regular Seasons Applied multiple regression to examine relationship between players’ performances and numerical variables  Potato Virus Y detection using machine learning algorithms Pick up top model for detection of potato Y virus in potato’s seed from Xgboost Random Forest SVM Decision Tree kNN and Logitboost on chemical fingerprinting datasets           Houston Methodist      Research Scientist   Jacksonville     FL                   112015      052019     Use data visualization tools to help tell story about findings from data to people who are not necessarily dataliterate  Performed data collection data cleaning and analysis and recoding of existing vendor laboratory computer software  Ability to collaborate effectively with mentor and others in lab on new research projects  Excellent interpersonal skills crossgroup and crossculture collaboration  Lead Quality Assurance Data Management in different instruments evaluation and analysis of QAQC data identifying trends and shift and taking corrective actions           Swedish Medical Center      Medical Laboratory Scientist   City     STATE                   112011      102015     Collect store retrieve analyze and present data  Issues and regularly interfaces with hospital staff and administrators regarding their finding and collaborate with teams to integrate systems  Help clinicians and other staff troubleshoot technology issues and regularly interface with hospital staff and administrators regarding their findings and collaborate with teams to integrate systems  Led quality control diagnostic testing documenting all variances in results and blood product performance,\n",
       " Jessica    Claire                                   609 Johnson Ave       49204     Tulsa     OK   100 Montgomery St 10th Floor    Home   555 4321000    Cell       resumesampleexamplecom              Summary       Data Scientist in 4 years of broadbased experience in building data processing data mining algorithms business need analysis and informative reporting solutions Good understanding of data visualizations using R Python and creating dashboards also working with AWS cloud Dedicated and hardworking with passion for Big Data         Skills           Operating system    Windows  MacOS    Database Server     MySQL SQL server    Languages     R Python SQL    ML Algorithm      Linear Regression  Logistic Regression  Decision Trees  Supervised Learning and Unsupervised Learning Classification SVM Random Forests Naive Bayes KNN K Means CNN    Other Software  Tools     AWS services Git Docker hub Hadoop Spark scikitlearn NumPy Pandas Matplotlib SciPy                       Experience       Data Scientist       082021   to   Current     Hanes Brands    –    Gaithersburg     MD             Wrote and executed various MySQL database queries from Pychram and MySQL Db package  Hands on experience with Docker and Git for version control and code sharing with team members  Conducted business analysis to understand business needs and requirements to translate into conceptual designs Proficient in performing data analysis on various IDEs like VSC and PyCharm  Building predictive models using various machine learning tools to predict the possibility of equipment failure  Developing algorithms using Natural Language Processing  Creating charts and graphs for company’s outcome reporting purpose  Knowledge of Hadoop ecosystem and different frameworks inside it – HDFS YARN MapReduce Apache Pig and realtime processing Framework Apache Spark  Involved in understanding the applications using all AWS services like EC2 S3 bucket           Data Scientist       062018   to   122020     Hanes Brands    –         MD             Designing of Queries compiling of data and generating reports in MS Excel and MS Access  Data collection and entry as needed and problem solving  Created various types of data visualizations using Rggplot2 Python Matplotlib and Power BI  Writing and executing SQL queries  Data collection and entry as needed and problem solving  For getting company insights created dashboard with Tableau           Entry Level Data Scientist       052017   to   052018     200ok Solutions    –         STATE             Implemented ML algorithms to evaluate and solve diverse company problems  Developing and automating the data manipulation process for above using store proceduresviews in SQL Server Also Creating data visualization and reports for requested projects  Using various packages like NumPy SciPy Pandas Natural Language Processing Toolkit matplotlib to build the model          Education and Training       Master of Science     Data Science      Expected in   122022     New Jersey Institute of Technology      Newark     NJ     GPA                Bachelors of Engineering      Information Communication Technology     Expected in   052018     LJ Institute of Engineering and Technology      Ahmedabad Gujarat           GPA               Activities and Honors              Skills       Operating system    Windows  MacOS    Database Server     MySQL SQL server    Languages     R Python SQL    ML Algorithm    Linear Regression  Logistic Regression  Decision Trees  Supervised Learning and Unsupervised Learning Classification SVM Random Forests Naive Bayes KNN K Means CNN    Other Software  Tools     AWS services Git Docker hub Hadoop Spark scikitlearn NumPy Pandas Matplotlib SciPy         Work History       Data Scientist     082021   to   Current     Thinksoft Technologies   –   Tampa     FL      Wrote and executed various MySQL database queries from Pychram and MySQL Db package  Hands on experience with Docker and Git for version control and code sharing with team members  Conducted business analysis to understand business needs and requirements to translate into conceptual designs Proficient in performing data analysis on various IDEs like VSC and PyCharm  Building predictive models using various machine learning tools to predict the possibility of equipment failure  Developing algorithms using Natural Language Processing  Creating charts and graphs for company’s outcome reporting purpose  Knowledge of Hadoop ecosystem and different frameworks inside it – HDFS YARN MapReduce Apache Pig and realtime processing Framework Apache Spark  Involved in understanding the applications using all AWS services like EC2 S3 bucket           Data Scientist     062018   to   122020     Teleysia Networks PvtLtd   –        India      Designing of Queries compiling of data and generating reports in MS Excel and MS Access  Data collection and entry as needed and problem solving  Created various types of data visualizations using Rggplot2 Python Matplotlib and Power BI  Writing and executing SQL queries  Data collection and entry as needed and problem solving  For getting company insights created dashboard with Tableau           Entry Level Data Scientist     052017   to   052018     200ok Solutions   –        India      Implemented ML algorithms to evaluate and solve diverse company problems  Developing and automating the data manipulation process for above using store proceduresviews in SQL Server Also Creating data visualization and reports for requested projects  Using various packages like NumPy SciPy Pandas Natural Language Processing Toolkit matplotlib to build the model,\n",
       " Jessica    Claire               Montgomery Street       San Francisco     CA  94105    609 Johnson Ave       49204     Tulsa     OK      Home   555 4321000        Cell           resumesampleexamplecom                  Career Overview     Ten years work experience under LinuxUnix environment Latex and MS Excel    · Five years work experience of buildingmaintaining production MySQL databases and Apache Solr debugging      and optimizing ETL work flows based on scholarly big data    · Five years work experience of search engine architecture and infrastructure deploying and implementing web      application features    · Five years work experience of designing coding and testing LAMP website powered by MySQL databases      and Apache Solr using frameworks such as Django and Spring           1          Update on February 10 2017   · Five years programming experience with Python familiar with load balancing virtual environment firewall     eg iptables and file systems   · Three years work experience of managing software projects on open source software platforms eg GitHub   · Two years experience of analyzing logs using MapReduce Deep Learning architectures of RNN and CNN     on video data experience with Amazon AWS Microsoft Azure Cloud Google Cloud and Google Analytics     Experience with NLP tools Bash Java R Ruby on Rails RESTful API   · Backgrounds in Physics Math and Statistics Familiar with ML NLP ANN IR and genetic algorithms       Qualifications           Guest services  Inventory control procedures  Merchandising expertise      Loss prevention  Cash register operations  Product promotions                       Technical Skills                Accomplishments              Work Experience      062013   to   Present     Data Scientist Tech Director  DBA of CiteSeerX      State Of Louisiana    –    Ville Platte     LA     USA        I started with the web crawling module of CiteSeerX in 2011 then expanded to the full architecture around 2013  My job duties include administrating the MySQL database and Apache Solr index servers hacking the source    code PythonJavaPerl to fix security vulnerabilities developing new web application features managing 100    terabytes production and research data maintaining 30 physical and virtual servers to facilitate production    and research and developing software to improve web crawling information classification and extraction  By    the end of 2014 I was able to run the entire search engine single handed  In 2015 I proposed infrastructure    and software solutions to overcome scalability bottlenecks and blueprinted the next generation of CiteSeerX  By    the end of 2016 I had scaled the data collection from 3 million to over 10 million documents  Currently the    system can keep running for several months without major issues  The 200 page system document wrote by    me significantly flattens learning curve for new admins  I used to assist 3 professors to build private cloud and    GPU infrastructure  I also have experience of working on a Hadoop cluster and programming with MapReduce  Postdoctoral Scholar          June 2011  present          062006   to   052011     Research Assistant      Decatur Public Schools    –    Decatur     IL     USA        Utilize astronomical big data compiled from archives of space and groundbased telescopes such as the Hub    ble Space Telescope and the Sloan Digital Sky Survey to investigate important correlations between physical    parameters of Active Galactic Nuclei and quasars  Publish 7 peer reviewed journal articles          082004   to   052006     Teaching Assistant      Astronomy  Astrophysics Pennsylvania State University    –    City     STATE     USA        Lecture nonscience college students on astronomical fundamentals          Education and Training      Expected in   August 2011     PhD     Astronomy and Astrophysics     Pennsylvania State University      University Park     PA     GPA       Astronomy and Astrophysics        Expected in        PhD     Computational Science                     GPA       Computational Science        Expected in   July 2004     BS     Physics and Astronomy     University of Science and Technology of China          Hefei                GPA       Physics and Astronomy        Interests     Entity Recognition in Scientific Document          Ongoing   Leader          Research · Recognize and extract semantic domain knowledge entities from scientific documents   Video Compression with ANN          Ongoing   Coleader          Research · Perform nearlossless video compression using artificial neural network models   Migrating CiteSeerX to a Private Cloud          Published in 2014   Leader          System · Migrate CiteSeerX production servers to a private cloud with virtualization techniques   Document Classification in Digital Libraries          Published in 2014 and 2016   Coleader          Research · Automatically and accurately classify PDF documents with ML and structural features PUBLICATIONS   · See httpfanchynawixsitecomJessicaClairepubs for all publications OTHER INFORMATION   · PC members of 5 conferencesworkshops   · Reviewers for 14 toptier conferencesjournalstransactions including WWW SIGIR and TKDE   · Collaborated with people from UNT Microsoft AllenAI and Internet Archive           2          Update on February 10 2017       Skills     Apache AI big data conferences content data collection Database features Hub Java managing MySQL NLP next search engines page PDF Perl programming proposals publications Python research scientific servers developing software teaching typing articles       Additional Information       HONORS AND AWARDS   Best paper nomination in the 8th International Conference on Knowledge Capture          2015   Best application paper in the 26th Annual Conference on Innovative Applications of Artificial Intelligence 2014   Best paper nomination in the IEEE International Conference on Cloud Engineering          2014   Zaccheus Daniel Fund          2009   Zaccheus Daniel Fund          2007   Stephen B Brumbach Fellowship          2006   USTC Excellent Graduate Student Award          2004 SELECTED PROJECTS   Entity Recognition in Scientific Document          Ongoing   Leader          Research · Recognize and extract semantic domain knowledge entities from scientific documents   Video Compression with ANN          Ongoing   Coleader          Research · Perform nearlossless video compression using artificial neural network models   Migrating CiteSeerX to a Private Cloud          Published in 2014   Leader          System · Migrate CiteSeerX production servers to a private cloud with virtualization techniques   Document Classification in Digital Libraries          Published in 2014 and 2016   Coleader          Research · Automatically and accurately classify PDF documents with ML and structural features PUBLICATIONS   · See httpfanchynawixsitecomJessicaClairepubs for all publications OTHER INFORMATION   · PC members of 5 conferencesworkshops   · Reviewers for 14 toptier conferencesjournalstransactions including WWW SIGIR and TKDE   · Collaborated with people from UNT Microsoft AllenAI and Internet Archive           2          Update on February 10 2017,\n",
       " Jessica    Claire                   Montgomery Street     San Francisco     CA  94105    609 Johnson Ave       49204     Tulsa     OK       Home   555 4321000    Cell       resumesampleexamplecom              Professional Summary     To help an organization improve upon and create a truly transformational Customer Experience with endtoend design analytics and operational excellence       Core Qualifications         Advanced Microsoft Excel and Access JavaScript and Jscript skills Highly proficient in statistical analysis using applications Minitab and R Studio Github Other Technical Skills Familiarity with Java Visual Basic C SQL XML HTML                       Experience       Principal Data Scientist       082017   to   Current     Lumeris    –    Arkansas     KY             Primary analyst tasked with yielding strategic insights to drive key corporate initiatives based through customer feedback tools such as NPS product based surveys and operational data  Common predictive analytical techniques such as multivariate data models hypothesis testing using chisquares ANOVA ttests and ztests cluster and conjoint analyses are used to conclude necessary actions  Corporate NPS analysis has driven corporate initiatives to improve strategic partner relationships product quality and usability implementation services technical support and contracting licensing programs  Performed financial linkage analysis with customer satisfaction data to highlight the importance of customer satisfaction to bottom line top line figures through OLS and logistical regression  Revenue and new sales growth models were also developed to show projections of enhanced financials by focusing on improved customer experience  Developed predictive analytics models using Bayesian probability theory that helped to anticipate future customer escalations using many disparate data sources  Performed analysis on linkages between employee satisfaction sentiments and customer satisfaction scores to understand if areas of high employee satisfaction correlate to high customer satisfaction  Helped product teams conclude top areas to enhance improve or maintain to maximize customer adoption rates and likelihood for recommendation  Project managed a data science initiative of evaluating all Customer Experience metrics to understand biggest drivers of customer renewals and retentions  Led a series of recorded RProgramming training sessions for business intelligence analysts across all divisions within the Global Business Operations division           Survey Service Bureau Manager       042017   to   072017     Stilt    –    San Francisco     CA             Helped to establish the framework of a new Voice of Customer department by creating all processes guidelines and training documentation for Survey Service Bureau within CA Technologies Inc  These documents outlined the protocols for the design creation distribution and reporting of all corporate surveys sent through CA Technologies Inc  Managed the rollout of more than 50 survey projects including the Customer Relationship NPS Technical Support Satisfaction Services Satisfaction Partner Relationship Satisfaction Student Education Evaluation CA Communities and CA World Symposium Feedback managed through Confirmit  Outlined the guidelines for consulting with various departments throughout CA Technologies to help them formulate their key business problems and objectives to help design the survey structure determine appropriate conditional skip logic assign appropriate scalesmeasurements to help them get the right data to solve their problems  Reviewed sample selection strategies to reduce bias concerns  Managed data collections process from extraction through all cleansing steps  Trained and managed a team of analysts through handson sessions and documented processes on areas such as consulting best practices survey design project management survey programming data management statistical data analysis  Developed several project management tools used to outline all survey bureau tasks and timelines to efficiently and effectively complete survey projects  Facilitated relationship between survey software vendors and CA Technologies  Built survey programs and action oriented alert mechanisms using jScript coding           Senior Operations Specialist       082017   to   042017     Sanmina Sci    –    Manchester     NH             Customer satisfaction ambassador delegated to representing the voice of the customer through market research projects  Supervised a team of three responsible for disseminating a weekly executive management report based on data mining Web 20 consumer generated media  Developed data mining process that dissects consumer discussions to track sentiments towards Canon and competitor models including features purchase drivers brand perceptions safety and quality assurance issues and potential legal liabilities  Analyzed data to discover trends in customer sentiment towards Canon products using Microsoft Excel and Access  Summarized data into a weekly consumer insight report that has lead to changes in Canon strategies such as implementation of instant rebate programs a recall of the EOS 1D Mark III the detection of four separate class action movements and several product service announcements  Consulted executive management with a detailed study outlining advantages of Web 20 platforms in yielding customer insights with recommendations for potential future Canon projects such as a private online community and ideagoras for product innovation and a wiki knowledgebase to enhance online support  Analyzed survey data regarding customer experiences with the Canon websiteas well as repair and phone services to track customer satisfaction through multivariate statistical and commentary analysis  Developed Six Sigma control charts designed to identify a decline in service performance  Created key driver quadrant charts to prioritize primary customer satisfaction drivers  Helped improve customer satisfaction by 5 by changing focus from turnaround time to repair quality and communication  Presented PowerPoint presentations to summarize market research data to management upon requests           Business Administration Associate       082017   to   082017     Canon USA Inc    –    City     STATE             Extranet administrator responsible for the management of Consumer Imaging Group CIG marketing content user access management and ordering functionality  Organized and outlayed thousands of marketing product announcements images notices price lists and promotions for dealer display  Administered and assigned user privileges based upon contractual agreements to enhance security and maintain site integrity  Ecommerce Project Coordinator responsible for overseeing development and completion of EDI projects by ensuring that all trading partners are in accordance with Canons technical logistical and legal policies  Worked extensively with logistics and IT departments to ensure Supply Chain Vendor Compliance with issues such as EDI technical mappings logistical routing procedures RFID implementation and standard business practices  Analyzed current processes to help facilitate changes necessary for initiatives such as the systematic restructuring of the CIG sales force customer orders impacted by business unit consolidation and contract administration for all CIG customers  Generated daily sales reports which help to track sales volume of all CIG business units and the sales quota percentage as dictated by CIG sales management           ProgrammerAnalyst       011   to   082017     Datacor Inc    –    City     STATE             Developed and maintained an ERP application responsible for enabling customer order entry invoice tracking AR and AP payment processing and inventory control management  Provided customer support to meet daytoday operations in areas such as sales reporting resolving unbalanced general ledger postings troubleshooting inventory discrepancies  Trained customers extensively with onsite demonstrations that combined PowerPoint presentations with practical handson instruction  Performed analysis for all stages of the Systems Development Life Cycle such as inquiring customers of their needs and desires fielding customer specifications for systems enhancements detailing desired features in documentation making necessary coding adjustments testing and debugging enhancements installation of enhancements user training and support          Education       Bachelors of Science     Management Information Systems     Expected in   2000     Seton Hall University                GPA       Management Information Systems         Masters of Business Administration     Market Research     Expected in   2008     Stony Brook University                GPA       Market Research        Professional Affiliations              Skills     analyst AP business intelligence Business Operations C charts chi CA consulting content contract administration Customer satisfaction customer support data analysis data management data mining debugging documentation drivers Ecommerce EDI ERP executive management XML Extranet features financials financial focus general ledger HTML Imaging innovation instruction inventory inventory control Java JavaScript Jscript legal logic logistics Mark III market research marketing Access Microsoft Excel PowerPoint presentations Minitab order entry payment processing policies processes marketing product coding Programming project management protocols quality quality assurance reporting routing safety sales sales management sales reports sales reporting Six Sigma SQL statistical analysis strategic Supply Chain survey design surveys Symposium Systems Development technical support user training phone troubleshooting Visual Basic website,\n",
       " Jessica    Claire                   Montgomery Street     San Francisco     CA  94105    609 Johnson Ave       49204     Tulsa     OK       H   555 4321000    C       resumesampleexamplecom    Date of Birth         India                      single                    Professional Overview     Highly motivated Sales Associate with extensive customer service and sales experience Outgoing sales professional with track record of driving increased sales improving buying experience and elevating company profile with target market       Summary of Skills           Cell Culture  Culturing of cancer cells MDAMB231 T47D U251 BCWM1 Raji  Colony forming assay Clonogenic Assay  Culturing of Tumor initiating stem cells  Isolation of PBMCs buffy coat from whole blood samples  Molecular  Cellular Biology  Immunological Techniques  Sanger Sequencing using Big Dye Terminator v31 method  Plasmid DNA preparation Mini through Giga scale  Rolling Circle Amplification using TempliPhi Amplification  PCR Product purification using ExoSAPIT  Western Blotting  Electrophoresis Agarose SDSPAGE  MTT Assay  Single and Multicolor FACS  Transfection Plasmid siRNA  ELISA  Protein Nucleic Acid Quantification  Genotyping PCR Jessica Claire Proficient in Graphpad Prism Microsoft Office Exposure to bioinformatics software such as Rasmol Swiss pdb Ligand Scout Marvinsketch DS Visualizer and Argus Lab                         Education       Master of Science       Molecular Microbiology  Immunology       Expected in   May 2013                University of Southern California USC Keck School of Medicine      Los Angeles     CA     GPA        Status         Molecular Microbiology  Immunology         Bachelor of Technology       Biotechnology       Expected in   June 2011                Dr D Y Patil University      Mumbai          GPA        Status         Biotechnology         Molecular Biology of Cancer Infection  Host Responses Introduction to histology Pathology Cell Biology Biochemistry Biostatistics Structure and Management of Clinical Trials              Expected in                                   GPA        Status                  Immunology Microbiology Molecular Biology Pharmacology Animal  Plant Cell Culture Genetic Engineering IPR Biosafety Bioethics and Entrepreneurship              Expected in                                   GPA        Status                 ThesisDissertation              Professional Experience       Associate Scientist I       052014      Present     Planet Pharma    –    Oceanside     CA            Perform bench procedures in the process of isolating plasmid DNA  Midi Maxi Mega and Giga scale Work with both CLIMS program and Excel to track orders Provide troubleshooting help and quality customer service for customers both through email and over the phone Perform molecular biology techniques such as colony isolation culture inoculation and running sequencing reactions Process sequencing template including Preparation amplification and PCR purification Manage inventory and replenish consumable sequencing supplies to perform routine maintenance of DNA sequencers           Product Surveillance Coordinator       102013      012014     St Jude Medical    –    City     STATE            Retrospectively analysed medical device complaints  reclassified them as per new complaint guidelines from FDA Ensuring all adverse event medical device reports MDRseMDRs are submitted to FDA per 21 CFR 803  Gained knowledge of medical device GCP Used SAP to get product details and follow product life cycle also used Microsoft Sharepoint for collaborative work Evaluate files for inconsistencies and missing information          Fellowships and Awards              Publications     Chen TC Cho HY Wang W Claire M Sharma N Hofman FM Schönthal AH 2014 A novel temozolomide perillyl alcohol conjugate exhibits superior activity against breast cancer cells in vitro and intracranial triplenegative tumor growth in vivo Mol Cancer Ther 20141311811193 I coauthored two abstracts on Genetic basis of Rhabdomyosarcoma M Claire 2011 and on Chromosomal abnormalities in follicular thyroid carcinoma A V Kanugovi 2011which were selected for publication in the European Society of Human Genetics Conference 2011 Cocurricular  Extracurricular Highlights Completed short term certification course in Responsible Conduct of Research conducted at USC  2013 Presented a poster of research findings in the annual Microbiology and Immunology meet at USC The event was host to all department researchers and students 2012        Papers and Lectures              Memberships and Affiliations              Accomplishments       Inventory management for lab supplies  Research Experience Dr  AxelH Schönthals laboratory at Keck School of Medicine of USC  Masters Thesis          Jan 2012 ­ June 2013 The project involved preclinical trials of a novel anticancer drug candidate on breast cancer cell lines  The research focused on discovering the mechanism of action potency and mechanism of uptake and other characteristics of the compound  The longterm aim is treating breast cancers in the breast as well as those that have metastasized to the brain  This project helped me grow as a researcher and think outside the box  It got me accustomed to working individually while also taught me the value of a team  Cytogenetic Analysis of Acute Lymphoblastic Leukemia ALL at MGM hospital India  Undergraduate Thesis Jan 2011 ­ June 2011 The project was under the guidance of Dr  Bani  B  Ganguly towards the partial fulfilment of Bachelors degree  The project involved karyotyping of bone marrow samples of ALL patients followed by additional cytological analysis of the sample  Karyotyping was done following Gbanding of chromosomes in order to determine chromosomal aberrations         Skills     Acid Biochemistry Biology Biostatistics Cancer Cell Culture Clinical Trials customer service DNA ELISA email GCP Immunology inventory MB Excel Microsoft Office Microsoft Sharepoint 31 Midi Molecular Biology PAGE Pathology PCR Pharmacology Prism quality safety SAP phone troubleshooting Visualizer Western Blotting,\n",
       " Jessica    Claire                   Montgomery Street     San Francisco     CA  94105    609 Johnson Ave       49204     Tulsa     OK       H   555 4321000    C       resumesampleexamplecom    Date of Birth         India                      single                    Summary     12 years of machine learningdata science experience with a proven track record of developing and        implementing large scale algorithms that have significantly impacted business revenues and user experience        10 years of experience applying R Python SAS and SQL for algorithm development data modeling statistical        learnings and data visualization        Ranked a top 1 competitor on Kaggle worlds largest community of data scientist with over 300k members        Handson experience applying several MLStatistical algorithms to realworld problems Neural Networks        Gradient Boosted Trees Random Forest Clustering Generalized Linear Models Simulation models and        Gaussian Mixture Models        Strong experience building endtoend machine learning platform using Java and big data technologies        Cassandra Spark and Hive        Excellent skills at programming in JavaOOP       Highlights           R          Neural Networks  Java          Gradient Boosted Trees  Python          Random Forest  NoSQL Cassandra          Generalized Linear Models  Spark Hive Pig          Optimization  SQL CQL          Gaussian Mixture Models                         Experience       Senior Data Scientist       042017      Current     Factset Research Systems Inc    –    Reston     VA          Conceptualized architected and implemented a deep learning model to accurately predict demand for Nvidias products Algorithm applies Deep neural networks along with several real time social feeds econometric indicators product momentum to forecast demand         Data Science Lead       062014      042016     Bristol Myers Squibb    –    Minneapolis     MN            Developed and owned the core machine learning feature of the product a patentpending behavioral analytics engine for predicting crosscloud application security threats  Architected and implemented the machine learning platform from the ground up in Java Cassandra Hive and Spark              Analytic platform monitors multiple cloud applications AWS Salesforce Box etc and predicts security threats and breaches  Implemented the endtoend platform for performing user behavior analytics using unsupervised machine         learning  Designed and implemented algorithms for realtime decisioning         Implemented process to capture 500 behavioral profile features         Implemented several high IV features for ML algorithm consumption Maximum Geodistance between users         loginday Fast Geolocation Hopping etc         Owned the feature endtoend and worked directly with cofounderCTO to drive product enhancements           Principal Data Scientist       122012      052014     Lumeris    –    Saint Louis     MO            Lead several big data machine learning initiatives involving the design development and deployment of advanced machine learning algorithms that impacted PayPals core products allowing business to grow and scale to over 150 million customers and process over 3 billion online transactions annually  The developed solutions have directly helped PayPal lower losses improve user experience and increase revenue simultaneously  Few key PayPal core products worked on are included below  PayPal ATO Models         Designed and developed Neural Network models to prevent account takeover activity at the time of user         authentication  Performed feature selection from over 2000 features and applied best practices in Neural Network         model development  Model accurately captured 81 of incoming fraud activity and resulted in 48bps of reduction         of losses for PayPal in 2013 freeing up capital to grow and expand margins  PayPal Here Mobile Card Reader         Architected the very first antifraud ML algorithm that enabled PayPal here product to expand and scale to over       million merchants  Designed many new geolocation specific features that showed high IV contribution to the       implemented model  PayPal Wallet       Spearheaded the development of ensemble models for predicting stolen financial usage at the time of transaction       completion  Developed Gradient Boosted Trees using GBM package in R  Implemented new features using IP       IPGEO Velocity etc  to improve algorithm performance  Designed several tools in R to visualize GBT model and       developed process to extract model parameters for deployment  Partnered with business and product teams to       execute and influence business decision around the solution implementation           Lead Analytic Scientist       052007      112012     Cushman  Wakefield Inc    –    Stockton     CA            Managed the design development and deployment of several predictive modeling solutions that underlie ISO Risk Analyzer portfolio of products which have contributed to significant revenues for the company  Few highlights are listed below  Lead the development of an expert system to accurately predict a consumers likelihood of committing a traffic violationDeveloped Logistic models for predicting violation probability and Poisson models for predict violation frequencyIncorporated intelligence from 1500 features from 7 different data sources Claritas Crime Traffic Patterns Business Info Weather etc TweedieCompound Poisson Distribution Model Developed and implemented several Tweedie distribution models to examine environmental factor for predicting personal auto risks for calculating insurance premiumsDeveloped separate frequency and severity models to improve model accuracyCaptured interaction effects between various environment variables such as traffic generator traffic pattens population density weather etcRisk Analyzer Credit Scoring Module Designed and developed first generation credit scoring algorithms to predict a consumers accident likelihood using credit payment behaviorPerformed feature reduction on close to 800 credit attributes and applied Multivariate Adaptive Regression Splines MARS to detect 2nd and 3rd order interactions effectsCaptured nonlinearity using splines and piecewise regressionWorked as the analytic manager for the movie advertisement testing product a high revenue growth initiative for the company           Senior Research Analyst       092004      042007     Nbc Universal    –    Boston     MA            Managed 5 statisticians to build predictive models for rating movie trailerTV spots content on their effectiveness to generate interest   Provided analytic insights and advice to maximize the impact and reach of clients resources  The product served 4 of the top hollywood movie studios and generated over 13M in annualized revenues for the company  Movie TrailerTV Spots Advertisement Testing Product Predictive models for rating movie trailers TV spots print ads etc  Team worked on over 100 movies for most of the motion picture studiosmajors and assisted in building         customized statistical models for several minimajors  Provided strategic insights and advice to Hollywood         Studios to maximize the impact and reach of clients marketing resources  Box Office Forecasting Models         Developed forecasting models to predict weekend box office revenues to help studios estimate accurately a films         potential at the day of the release  Model used several audience tracking data to accurately predict weekend box         office receipts  Fox Movie Sequel Study Client  20th Century Fox          Developed a series of ordinal logistic regression models to compare characteristics and attributes describing         several Fox movies  Based on the study results 20th Century Fox decided to produce a sequel to Die Hard in         2007 which was one of the biggest box office hits of that year           Researcher       012002      012004     University Of Missouri    –    City     STATE            Managed home healthcare initiative for Missouris Sinclair School that involved developing a AI system based GPS to optimize hospital resources for saving cost  The GPS system incorporated new algorithms for solving multipletraveling salesman problem in a dynamic setting  Researched and applied spatial clustering algorithms in the context of constraint optimization problem          Education       Master of Science       Industrial EngineeringOperations Research       Expected in   2004                University of Missouri      Columbia     MO     GPA        Status         Industrial EngineeringOperations Research Thesis  Dynamic Stochastic Vehicle Routing Model in Home Healthcare Scheduling                Metallurgical Engineering       Expected in   2002                Indian Institute of Technology                GPA        Status         Metallurgical Engineering BHU          Varanasi UP IN Thesis  Monte Carlo Simulation Modeling of NonUniform Stress in Structured Materials Secured All India IITJEE rank in the top 06  ranked among 250000 applicants        Skills     ads AI big data clustering content Credit Client clients expert system Fast features financial Forecasting GPS Home Healthcare insurance IP ISO Java machine learning machine         learning marketing MARS Materials Office 2000 Modeling monitors Network Networks Neural NoSQL Optimization predict Testing Product Python realtime Routing Scheduling Simulation SQL strategic Structured TV]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = db.from_disk(\"./IT1-train-data.spacy\")\n",
    "print(len(data))\n",
    "docs = list(data.get_docs(nlp.vocab))\n",
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    John Doe\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " has proficient in Python programming for data analysis and visualization living in \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Brussels\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Belgium\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " on \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    25/12/2023\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       "</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "str_data= \"John Doe has proficient in Python programming for data analysis and visualization living in Brussels Belgium on 25/12/2023\"\n",
    "doc2 = nlp(str_data)\n",
    "displacy.render(doc2, style=\"ent\", jupyter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is 'would' an English word: True\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "words = set(nlp.vocab.strings)\n",
    "word = 'would'\n",
    "print(f\"Is '{word}' an English word: {word in words}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('CARDINAL',\n",
       " 'DATE',\n",
       " 'EVENT',\n",
       " 'FAC',\n",
       " 'GPE',\n",
       " 'LANGUAGE',\n",
       " 'LAW',\n",
       " 'LOC',\n",
       " 'MONEY',\n",
       " 'NORP',\n",
       " 'ORDINAL',\n",
       " 'ORG',\n",
       " 'PERCENT',\n",
       " 'PERSON',\n",
       " 'PRODUCT',\n",
       " 'QUANTITY',\n",
       " 'TIME',\n",
       " 'WORK_OF_ART')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.get_pipe('ner').labels"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
