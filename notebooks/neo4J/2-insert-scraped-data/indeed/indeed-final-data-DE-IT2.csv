Id|profile|titles|companies|links|data|date_listed|skills
11|Data Engineer|Data Engineer|Imagine One Technology & Management, Ltd.Lexington Park, MD|http://www.indeed.com/rc/clk?jk=5bddec5615f1184d&bb=HKH-ysDsRD4PV8MpMJn7w-ElJ7whwJS_70qbDnHEjwF7sJkOc6QuhKJUwvIaHrGRjAPY4XJ-RylRmKLqo-SABaW1Hc0GaVzeppB9JW4GZc-XTqPC1WJd2w%3D%3D&xkcb=SoBV67M3CNjvTlWbHp0FbzkdCdPP&fccid=67827b2d5b3e6ebe&vjs=3|Profile insightsFind out how your skills align with the job descriptionLicensesDo you have a valid Secret Clearance licenseYesNoSkillsDo you have experience in ISO 27001YesNoEducationDo you have a Bachelors degreeYesNo LocationLexington Park MD BenefitsPulled from the full job description401kDental insuranceHealth insuranceOpportunities for advancementProfit sharingTuition reimbursementVision insurance Full job description Job Location Lexington Park Maryland   Job Code 16424193   Imagine One Technology  Management is currently seeking a Data Engineer “contingent” on award of the associated work to the Imagine One Team This position supports the US Navy in Lexington Park Maryland  The Data Engineer discovers opportunities for data acquisition and sensor integration performs systems engineering for databases and data processing systems develops data systems architectures and models leverages highperformance computing infrastructures into systems architecture and recommends best architectures tools and technologies to address organizational needs  Security Requirements   Candidates must have US Citizenship  Candidates must have an ACTIVE DoD Secret Clearance or higher    Experience Requirements   Minimum of ten 10 years of experience carrying out duties similar to the functions above     Educational Requirements   Bachelor’s degree from an accredited fouryear college or university  Candidates who do not possess a bachelors degree can still qualify with one of the following   Six 6 years of additional experience for a total of 16 years of experience OR Associate’s degree plus four 4 years of additional experience for a total of 14 years of experience      Imagine One offers a full package of benefits and competitive salary excellent group medical vision and dental programs 401K savings plan 4K annual tuition reimbursement 5K if pursuing Master’s degree employee training development and education programs profit sharing advancement opportunities and much more   Imagine One is an EmployeeOwned Business  ISO 90012015 ISO 2000012018 ISO 270012013  CMMI Development Level 3   Imagine One Technology  Management Ltd is an Equal OpportunityAffirmative Action Employer Protected veterans and individuals with disabilities encouraged to apply    Imagine One “Contingent” offers for employment may stipulate that one or more requirements be satisfied before final commitment between candidate and Imagine One is established namely award of contract to the Imagine One Team Contingent requirements vary and may also include but not be limited to additional factors ie the position still being available after negotiations with the Government final approval of your qualifications by the Government or ability to successfully acquire andor transfer a DoD security clearance        Get job alerts by email Sign up now Join Our Talent Network      Job Snapshot  Employee Type Contractor      Location Lexington Park MD Onsite      Job Type Engineering      Experience Not Specified      Date Posted 03192024      Job ID 16424193      ||['Data Engineer', 'Data Engineer', 'data acquisition', 'sensor integration', 'systems engineering', 'data processing']
12|Data Engineer|Data Center Engineer (Infrastructure/Cloud)|Abile Group, Inc.Annapolis Junction, MD|http://www.indeed.com/rc/clk?jk=a1b3553c1d019b53&bb=HKH-ysDsRD4PV8MpMJn7w5lgy9lyYzgLpPSEyoxK96qk-UY3bk7EcEqRU9jftHW-eH25MSLgEZvRbWj29SVyAxfatds1jYi08N4zcp2XfI9U6zyL3HeL0Q%3D%3D&xkcb=SoDh67M3CNjvTlWbHp0EbzkdCdPP&fccid=aba787904aa14d6f&vjs=3|Profile insightsFind out how your skills align with the job descriptionLicensesDo you have a valid TSSCI licenseYesNoCertificationsDo you have a valid ITIL Certification certificationYesNoSkillsDo you have experience in VirtualizationYesNoEducationDo you have a Masters degreeYesNo Job detailsHere’s how the job details align with your profileJob typeFulltime LocationAnnapolis Junction MD Full job description  Overview       Abile Group has an exciting and challenging opportunity for a Data Center Engineer InfrastructureCloud supporting a DoD Customers Classified Network Services The mission will include Operations Compliance Cyber Security Customer Service and Engineering The right Desktop Systems Administrator candidate will possess the below skills and qualifications and be ready to handle all responsibilities independently and professionally   Responsibilities    Designs delivers and optimizes Virtual Infrastructure Services to improve security availability performance and resource utilization  Reviews current virtual infrastructures architectures designs and operations to identify potential improvements  Analyzes refines and documents the requirements for transition from legacy architectures into modern virtualized infrastructure environment  Designs virtual Infrastructure services to maximize available capacity of physical compute storage and network hardware resources  Documents security configuration and performance benchmarks of Virtual Infrastructure Services  Qualifications     Clearance Required TSSCI      Degree and Years of Experience 5 to 8 years with BSBA or 3 to 5 years with MSMA or 0 to 2 years with PhD      Required Certifications    DoD 85701M IAT Level II certification ie Security    Desired Certifications    ITIL Foundations certification  Professional level VMware certification    Required Skills    Proven expertise in the VMware suite of cloud computing and virtualization technology  About Abile Group Inc       Abile Group Inc was formed in July 2004 to partner with the Intelligence Community and their Contractors in the areas of Enterprise Analytics  Performance Management IT  Systems Engineering and Program  Project Management We have significant experience with the Federal Government and are an EDWOSB dedicated to our employees and clients We are looking for high performing employees who enjoy providing advice and guidance along with solutions development and implementation support crafted by combining industry best practices with the clients’ subject matter experience and Abile’s breadth of expertise   EEO Statement       Abile Group Inc is an Equal Opportunity Employer All qualified applicants will receive consideration for employment without regard to race color religion sex sexual orientation gender identity national origin or protected veteran status and will not be discriminated against on the basis of disability Anyone requiring reasonable accommodations should email careersabilegroupcom with requested details A member of the HR team will respond to your request within 2 business days      Please review our current job openings and apply for the positions you believe may be a fit If you are not an immediate fit we will also keep your resume in our database for future opportunities    ||['Cyber Security', 'Customer Service', 'Virtual Infrastructure Services', 'storage', 'VMware', 'VMware', 'cloud computing', 'Project Management']
13|Data Engineer|Salesforce/ServiceNow Data Engineer|ManTechRemote in San Antonio, TX 78201|http://www.indeed.com/rc/clk?jk=0e4a3df056005be3&bb=HKH-ysDsRD4PV8MpMJn7w20bFxJz9c-vTbw1i8c4rvHd-95zSL3ThX9PaFpkID_f-DT7ZP6R92yc5Zd3f6MFDRYLBBOhlJ0PKGPD_8JcNKYvMXQEy7Mi9Q%3D%3D&xkcb=SoDG67M3CNjvTlWbHp0bbzkdCdPP&fccid=578fa8376f4eec04&vjs=3|Profile insightsFind out how your skills align with the job descriptionLicensesDo you have a valid Secret Clearance licenseYesNoSkillsDo you have experience in ServiceNowYesNoEducationDo you have a Bachelors degreeYesNo Job detailsHere’s how the job details align with your profileJob typeFulltime LocationSan Antonio TX 78201 BenefitsPulled from the full job descriptionOpportunities for advancement Full job description Secure our Nation Ignite your Future   Become an integral part of a diverse team while working at an Industry Leading Organization where our employees come first At ManTech International Corporation you’ll help protect our national security while working on innovative projects that offer opportunities for advancement   Currently ManTech is seeking a motivated career and customeroriented SalesforceServiceNow Data Engineer to join our team This is hybrid role splitting time working remote and on client site   Responsibilities include but are not limited to   Researches and integrates design strategies product specifications  development schedules and user expectations into product capabilities  Develops technical designs and specifications for complex document file data  pipelinesdata flows and data migrations with ServiceNow or Salesforce  Applications  Uses ETL tools or languages to build test and maintain product modules  components and subsystems for data  Performs data integrations between systems using industry standard tools and  connectivity protocols  Identifies data gaps and potential remediation or integration activity for  consideration by PM andor customer  Leads and influences team on project deliverables  Drives quality assurance program for project deliverables  Creates quality deliverables for customers  Drives full life cycle of servicessolution delivery for projects  Provides technical leadership to lowerlevel engineers    Basic Qualifications   Bachelor’s degree in computer science Business Engineering Math or related field OR10 years of comparable work experience  The successful candidate must be able to work remotely and be able to travel  occasionally as needed  5 years of experience as a Data Engineer or similar role with a strong track  record of architecting and implementing complex solutions using data migration  and data integration tools  Must have experience with migrating managing connecting and sustaining  document management databases  Experienced in processing and building automated ETL pipelines for  documentation files such as PDFs Excels between source and target systems    Security Clearance Requirements   US citizenship requiring a background check  Ability to obtain a SECRET Clearance    For all positions requiring access to technologysoftware source code that is subject to export control laws employment with the company is contingent on either verifying USperson status or obtaining any necessary license The applicant will be required to answer certain questions for export control purposes and that information will be reviewed by compliance personnel to ensure compliance with federal law ManTech may choose not to apply for a license for such individuals whose access to exportcontrolled technology or software source code may require authorization and may decline to proceed with an applicant on that basis alone   ManTech International Corporation as well as its subsidiaries proactively fulfills its role as an equal opportunity employer We do not discriminate against any employee or applicant for employment because of race color sex religion age sexual orientation gender identity and expression national origin marital status physical or mental disability status as a Disabled Veteran Recently Separated Veteran Active Duty Wartime or Campaign Badge Veteran Armed Forces Services Medal or any other characteristic protected by law   If you require a reasonable accommodation to apply for a position with ManTech through its online applicant system please contact ManTechs Corporate EEO Department at 703 2186000 ManTech is an affirmative actionequal opportunity employer  minorities females disabled and protected veterans are urged to apply ManTechs utilization of any external recruitment or job placement agency is predicated upon its full compliance with our equal opportunityaffirmative action policies ManTech does not accept resumes from unsolicited recruiting firms We pay no fees for unsolicited services   If you are a qualified individual with a disability or a disabled veteran you have the right to request an accommodation if you are unable or limited in your ability to use or access httpwwwmantechcomcareersPagescareersaspx as a result of your disability To request an accommodation please click careersmantechcom and provide your name and contact information  ||['Data Engineer', 'user expectations', 'technical designs', 'ServiceNow', 'Salesforce', 'ETL', 'data integrations', 'connectivity protocols', 'data gaps', 'quality assurance', 'Data Engineer', 'data integration', 'processing', 'ETL', 'pipelines']
14|Data Engineer|Data and Cloud Engineer|BRSSan Antonio, TX|http://www.indeed.com/rc/clk?jk=77139425a9ee8408&bb=HKH-ysDsRD4PV8MpMJn7w1vYq7-sZMKKj4nmQVzFTlPRYhbvNYi9R_JzlRF7HjryZad9gaXJMF77mIsq7mrzmCQT0yrQnjZcHT5E3bMr6C2b3DBshAiHxg%3D%3D&xkcb=SoBy67M3CNjvTlWbHp0abzkdCdPP&fccid=e2c1d9254247b2b7&vjs=3|Profile insightsFind out how your skills align with the job descriptionLicensesDo you have a valid TSSCI licenseYesNoCertificationsDo you have a valid CompTIA Security certificationYesNo Job detailsHere’s how the job details align with your profileJob typeFulltime LocationSan Antonio TX Full job descriptionTekPro Support Services LLC TSS is seeking a Data and Cloud Engineer    Datacloud engineer supportsintegrates enterprise database systems using sound database management practices to organize and store data Interacts with development and enduser personnel to determine application data access requirements transaction rates volume analysis and other pertinent data required to develop and maintain integrated databases Provides support and reviews webbased applications including online and internal applications to support client operations Support the implementation of interfaces to applications review both client side and serverside code to allow webbased applications to deliver the correct content Be able to translate applications requirements into the design of complex web sites including integrating web pages and applications Must be able to apply new and emerging technologies to the site development process  Qualifications   CompTIA Security CE required Active TSSCI required  ||['database management', 'store data', 'data access', 'transaction rates', 'volume analysis', 'translate applications requirements', 'integrating web pages']
0|Data Engineer|Data Engineer (L5) - Privacy|NetflixRemote|http://www.indeed.com/rc/clk?jk=598d9eae2a89ab8b&bb=UkWqgXROFXK6Hr5wr58UhXxZ7PuS9roaHE59gxhnPO32ilsSBGIjtsz1_RFMyx4W3IAAAGyz9udzbnFVRGGvYtvEMct7px1qqNV07YS3e2I%3D&xkcb=SoC467M3CNjr8KwiIp0LbzkdCdPP&fccid=66403b30a2c0d89c&vjs=3|Profile insightsFind out how your skills align with the job descriptionSkillsDo you have experience in System designYesNo Job detailsHere’s how the job details align with your profileJob typeFulltime LocationRemote BenefitsPulled from the full job description401k401k matchingFlexible spending accountHealth insurancePaid time offStock options Full job description             Remote United States                      Data Science and Engineering                     Netflix is enjoyed by more than 230 million members globally entertaining new audiences every day We are in the midst of major transformative developments for the Netflix product with the launch of an Advertisingsupported plan Games and Live content These new products alongside our streaming service have resulted in significant increases in the complexity and breadth of our internal data ecosystem We manage one of the largest paid subscription businesses and are committed to handling our members’ data with a high degree of care towards appropriate use as well as compliance with local privacy laws and regulations in the 190 countries where we operate        The Privacy and Legal Data Engineering pod builds scalable data management and extraction frameworks which are at the core of our ability to hold ourselves to the highest data privacy and hygiene standards in the industry        We are looking for a Data Engineer to help augment our ability to build these robust scalable privacycentric data frameworks As part of this team you will work on diverse data technologies such as Spark Presto Flink Kafka and others to build insightful scalable and robust data pipelines write ETL jobs to collect and aggregate data and build highquality data frameworks that enable appropriate handling of customer personal data        The ideal candidate will bring a strong track record of having built data systems and frameworks to strengthen the privacy posture at large consumer businesses They will have a deep background in distributed data processing and share our passion for continuously improving the ways we handle data to make Netflixs data privacy posture better        Who you are   Passionate about consumercentric data privacy and risk mitigation for the business  Highly proficient in at least one of Java Python or Scala with at least 10 years of softwaredata engineering experience  Proficient in advanced SQL and effective in a complex data environment  Highly experienced in engineering data pipelines using big data technologies Hive Presto Spark Flink on medium to large scale data sets  Comfortable working crossfunctionally with multiple types of stakeholder groups  Able to successfully lead large complex systems design and implementation challenges independently     What you will do   Design and implement elegant frameworks to scalably meet various internal and consumerfacing data privacy and legal needs  Engineer efficient adaptable and scalable data pipelines to process structured and unstructured data  Develop a deep understanding of the data ecosystem at Netflix from a privacy lens  Partner with the privacy engineering teams to understand product goals and provide data that enables us to respond to customer and regulatory data requests  Mentor and inspire teammates while elevating the impact of the team  Enable Netflix to effectively manage legal and regulatory risk and compliance while maintaining a high standard of consumer data privacy expectations         A few more things to know           Our culture is unique and we live by our values so its worth learning more about Netflix at jobsnetflixcomculture We regularly share examples of our work on our tech blog You will need to be comfortable working in the most agile of environments Requirements will be vague Iterations will be rapid You will need to be nimble and take smart risks        Our compensation structure consists solely of an annual salary we do not have bonuses You choose each year how much of your compensation you want in salary versus stock options To determine your personal topofmarket compensation we rely on market indicators and consider your specific job family background skills and experience to determine your compensation in the market range The range for this role is 170000  720000        Netflix provides comprehensive benefits including Health Plans Mental Health support a 401k Retirement Plan with employer match Stock Option Program Disability Programs Health Savings and Flexible Spending Accounts Familyforming benefits and Life and Serious Injury Benefits We also offer paid leave of absence programs Fulltime hourly employees accrue 35 days annually for paid time off to be used for vacation holidays and sick paid time off Fulltime salaried employees are immediately entitled to flexible time off See more details about our Benefits here        Netflix is a unique culture and environment Learn more here        We are an equal opportunity employer and celebrate diversity recognizing that diversity of thought and background builds stronger teams We approach diversity and inclusion seriously and thoughtfully We do not discriminate on the basis of race religion color ancestry national origin caste sex sexual orientation gender gender identity or expression age disability medical condition pregnancy genetic makeup marital status or military service         ||['Data Science', 'Legal Data', 'data privacy', 'Spark', 'Presto', 'Flink', 'Kafka', 'data pipelines', 'ETL', 'aggregate data', 'data frameworks', 'personal data', 'distributed data', 'processing', 'data privacy', 'data privacy', 'Java', 'Python', 'Scala', 'SQL', 'data pipelines', 'big data', 'Hive', 'Presto', 'Spark', 'Flink', 'data sets', 'design', 'data privacy', 'data pipelines', 'unstructured data', 'data privacy', 'agile']
1|Data Engineer|Senior Data Engineer|Fiserv, Inc.Berkeley Heights, NJ 07922|http://www.indeed.com/rc/clk?jk=8113001dad7c7efc&bb=UkWqgXROFXK6Hr5wr58UhZQXTF4woyLPcmnoj5YTf3mmYLYjULKWK6RSAl9e24raReVRr3Qp0F7nn7E5Ol-BL7pEYnQtybTDBpyK3l7QCaE%3D&xkcb=SoAM67M3CNjr8KwiIp0KbzkdCdPP&fccid=1ea0475711674f3b&vjs=3|Profile insightsFind out how your skills align with the job descriptionSkillsDo you have experience in SparkYesNoEducationDo you have a Bachelors degreeYesNo Job detailsHere’s how the job details align with your profileJob typeFulltime Location100 Connell Drive Berkeley Heights NJ 07922 Full job description Calling all innovators – find your future at Fiserv   We’re Fiserv a global leader in Fintech and payments and we move money and information in a way that moves the world We connect financial institutions corporations merchants and consumers to one another millions of times a day – quickly reliably and securely Any time you swipe your credit card pay through a mobile app or withdraw money from the bank we’re involved If you want to make an impact on a global scale come make a difference at Fiserv   Job Title Senior Data Engineer    What does a successful Senior Data Engineer do at Fiserv   As a member of our Data Commerce Solutions group you will build and take ownership of the design and development of data engineering projects within Fiserv’s Enterprise Data Commerce Solutions division You will be responsible for building and taking ownership over largescale data engineering integration and warehousing projects build custom integrations between cloudbased systems using APIs and write complex and efficient queries to transform raw data sources into easily accessible models by using the Data integration tool with coding across several languages such as Java Python and SQL Additional responsibilities include but are not limited to architect build and launch new data models that provide intuitive analytics to the team and Build data expertise and own data quality for the pipelines you create   What you will do   Collaborate with crossfunctional teams to design scalable data architecture and create robust data processing pipelines  Design and implement data models that align with business requirements enabling seamless data access and analytics  Identify opportunities to enhance data processing efficiency and implement performance optimizations for our data pipelines  Implement data quality checks and validation processes to ensure the accuracy and integrity of our data  Work closely with data scientists analysts and software engineers to understand data needs provide technical support and troubleshoot datarelated issues  Stay up to date with the latest data engineering technologies and tools and recommend improvements to our existing systems  Maintain comprehensive documentation of data engineering processes data flows and system configurations   What you will need to have   610 years of overall industry experience with at least 6 years experience in building largescale big data applications development and a bachelor’s degree in computer science or a related field  Possess strong technical leadership skills demonstrating expertise in developing data solutions building frameworks and designing solutions for processing large volumes of data using data processing tools and Big Data platforms    Handson experience building Data Lake EDW and data applications on Azure cloud Proficiency in major programmingscripting languages like Java andor Python  Strong understanding of cluster and parallel architecture experience with highscale databases and SQL and exposure to NoSQL databases like Cassandra HBase DynamoDB and Elastic Search  Conduct code reviews and strive for improvement in software engineering quality  Experience in realtime data processing and streaming technologies like Kafka and Apache Beam as well as a successful track record in delivering big data projects using Kafka and Spark    What would be great to have   Experience in Banking Financial domain  Advanced certifications in data engineering or related fields  Familiarity with machine learning frameworks and data science workflows  Knowledge of containerization technologies like Docker and orchestration tools like Kubernetes  Experience working with PCI Data and collaborating with data scientists Knowledge of data governance security and privacy principle    This role is not eligible to be performed in Colorado California Hawaii New York or Washington   Please note that salary ranges provided for this role on external job boards are salary estimates made by outside parties and may not be accurate   Thank you for considering employment with Fiserv Please    Apply using your legal name  Complete the stepbystep profile and attach your resume either is acceptable both are preferable    What you should know about us   Fiserv is a global fintech leader with 40000plus and growing associates proudly serving clients in more than 100 countries As a FORTUNE™ 500 company one of Fast Company’s Most Innovative Companies and a top scorer on Bloomberg’s GenderEquality Index we are committed to excellence and purposeful innovation   Our commitment to Diversity and Inclusion   Fiserv is an Equal Opportunity Employer and we welcome and encourage diversity in our workforce that reflects our world All qualified applicants will receive consideration for employment without regard to race color religion sexual orientation gender identity national origin disability protected veteran status or any other category protected by law   We will ensure that individuals with disabilities are provided reasonable accommodation to participate in the job application or interview process to perform essential job functions and to receive other benefits and privileges of employment Please contact us to request accommodation   Warning about fake job posts   Please be aware of fraudulent job postings that are not affiliated with Fiserv Fraudulent job postings may be used by cyber criminals to target your personally identifiable information andor to steal money or financial information   Any communications from a Fiserv representative will come from a legitimate business email address We will not hire through text message social media or email alone and any interviews will be conducted in person or through a secure video call We won’t ask you for sensitive information nor will we ask you to pay anything during the hiring process We also won’t send you a check to cash on Fiserv’s behalf   If you see suspicious activity or believe that you have been the victim of a job posting scam you should report it to your local FBI field office or to the FBI’s Internet Crime Complaint Center  ||['transform', 'data sources', 'accessible', 'Data integration', 'Java', 'Python', 'SQL', 'data models', 'data quality', 'pipelines', 'data processing', 'pipelines', 'Design', 'data models', 'business requirements', 'Identify opportunities', 'data processing', 'data pipelines', 'data quality', 'big data', 'developing', 'data solutions', 'designing', 'processing', 'data processing', 'Big Data', 'Handson', 'Data Lake', 'Azure cloud', 'Java', 'Python', 'SQL', 'NoSQL', 'Cassandra', 'HBase', 'DynamoDB', 'code reviews', 'realtime data', 'processing', 'streaming', 'Kafka', 'Apache Beam', 'big data', 'Kafka', 'Spark', 'machine learning', 'data science', 'Docker', 'Kubernetes', 'data governance', 'interviews', 'office']
2|Data Engineer|Principal Data Engineer (Remote)|Collins AerospaceRemote in Texas|http://www.indeed.com/rc/clk?jk=d94a7763ac4ec289&bb=UkWqgXROFXK6Hr5wr58UhdPjWsPtgFSnh83meCL14_iW_4J3JqvxJNXf61IBcx4JZTjGpqlkfUw-tBs73qy4ErWRtNF6p9ds3_sS3TvbNwg%3D&xkcb=SoCR67M3CNjr8KwiIp0JbzkdCdPP&fccid=3d30677097704d8f&vjs=3|Profile insightsFind out how your skills align with the job descriptionCertificationsDo you have a valid AWS Certification certificationYesNoSkillsDo you have experience in TerraformYesNo Job detailsHere’s how the job details align with your profileJob typeFulltime LocationTexas BenefitsPulled from the full job description401k401k matchingAdoption assistanceDental insuranceDisability insuranceEmployee assistance programFlexible scheduleShow morechevron down Full job description Date Posted 20231120   Country United States of America   Location HTX99 Field Office  TX Remote Location Remote City TX 73301 USA   Position Role Type Remote     Do you want to be part of the team that builds the Data Platform at the center of Transforming the Aviation Industry   As a Principal Data Engineer you will be on a mission to ensure that our Data Platform can leverage data from various sources to help transform the passenger journey as well as help our customers leverage data to improve their operations This role is responsible for the design development and maintenance of data processes and pipelines supporting critical Strategic Business Unit SBU Data initiatives in support of the Digital Transformation The scope of the role encompasses many facets of the aviation industry You will work with Data Scientists and Application Developers to build databased products that benefit commercial airlines airports and passengers Your work will influence the next generation of connected aviation products   You will work with a team where you will be able to share your ideas and vulnerabilities and will be treated with care and empathy You will work with a team that shows courage in doing the right thing not because it is easy This is a great opportunity with room to grow and learn about new and interesting technology solutions   Our business unit Connected Aviation Solutions CAS is leading the Connected Ecosystem strategic pillar for Collins Aerospace The Data Management  Data Science DMDS team has endtoend responsibility to ensure that CAS data assets are managed with integrity and quality prior to consumption by our critical customer facing applications  whether via API’s analytics andor data visualizations   What YOU will do   YOU will contribute to establishing Data Engineering best practices building the DataOps model and enabling the ML and AI roadmap of the future  YOU will develop automation and monitoring processes that support the data pipelines  YOU will work closely with the architecture team to implement modern data repositories that support the CAS use cases Pipelines API’s Data Science Applications and Visualizations  YOU will work with internal business customers and software development teams to gather and document requirements for data publishing and data consumption  YOU will work with the CAS and DT Enterprise Data Architects to automate cloud deployments as well as build CICD pipeline to support cloudbased workloads This includes developing views materialized views and SQL scripts  YOU may travel domestically and internationally up to 15  YOU will work on a distributed and diverse team that collaborates and communicates well    What YOU will learn   YOU will learn all about the datasets that are produced in the aerospace ecosystem such as how the various components in an aircraft interact with each other  YOU will learn how to enable Data Scientists to perform ML and AI experiments  YOU will gain exposure to large scale data processing leveraging modern technology stacks including Databricks and AWS native services  YOU can take flight to becoming a subject matter expert and leader in Data Engineering with exposure to the variety of business and products in an everevolving aerospace industry CAS is growing and so can you    Education  Experience   Typically requires a degree in Science Technology Engineering or Mathematics STEM unless prohibited by local lawsregulations and minimum 8 years prior relevant experience or an Advanced Degree in a related field and minimum 5 years of experience or in absence of a degree 12 years of relevant experience    Qualifications You Must Have   Must be authorized to work in the US without sponsorship now or in the future RTX will not offer sponsorship for this position  Demonstrated engineering experience in system integration and design data pipeline development or softwareservice development and deployment  Experience building data pipelines leveraging tools like Spark Python PySpark  SQL as well as working with AWSAzure Cloud platforms and related services and Terraform Gitlab and similar CICD tools  Experience with Databricks Platform and leveraging that platform to build out a Data Lake    Skills We Value   Professional background developing complex SQL queries and programming in Python with ability to transform raw data into valuable insights  Experience designing cloudbased data platforms that ensure cost optimization scalability performance and ease of use for end users of the platform  Experience with Micro Services Architectures  AWSAzure certifications    Collins Aerospace an RTX company is a leader in technologically advanced and intelligent solutions for the global aerospace and defense industry Collins Aerospace has the capabilities comprehensive portfolio and expertise to solve customers’ toughest challenges and to meet the demands of a rapidly evolving global market   reempowerprogram  This role is also eligible for the ReEmpower Program The ReEmpower Program helps support talented and committed professionals as they rebuild their capabilities enhance leadership skills and continue their professional journey Over the course of the 14week program experienced professionals will gain paid onthejob experience have an opportunity to participate in sessions with leadership develop personalized plans for success and receive coaching to guide their returntowork experience Upon completion of the program based on performance and contributions participants will be eligible for a career at RTX   Minimum Program Qualifications   Be on a career break of one or more year at time of application  Have prior experience in functional area of interest  Have interest in returning in either a fulltime or parttime position    Connected Aviation Solutions  Our Connected Aviation Solutions team provides advanced information management systems products and services that enable the connected ecosystem by bringing together Collins’ unique breadth of aviation products with our smart digital solutions to help us enhance every aspect of the endtoend travel experience We help airlines airports and business aircraft turn data into value to streamline operations increase efficiency and reduce cost enhance the passenger experience and contribute to sustainable flight By combining the best networks connectivity and dataanalytics solutions we’re solving big problems for our customers and the world while enhancing the security and connectivity of systems both on and off the aircraft to help operators and passengers stay more connected and informed and create a more sustainable efficient reliable and enjoyable travel experience Aviation connects the world Our Connected Aviation Solutions team connects aviation Sustainably Seamlessly Securely   Diversity drives innovation inclusion drives success We believe a multitude of approaches and ideas enable us to deliver the best results for our workforce workplace and customers We are committed to fostering a culture where all employees can share their passions and ideas so we can tackle the toughest challenges in our industry and pave new paths to limitless possibility  WE ARE REDEFINING AEROSPACE    Please ensure the role type defined below is appropriate for your needs before applying to this role    Remote Employees who are working in Remote roles will work primarily offsite from home An employee may be expected to travel to the site location as needed   Position is remote however if you live within a reasonable commute of a Collins site with other colleagues you interact with your manager will discuss whether there is a degree of onsite presence associated with this role     Some of our competitive benefits package includes   Medical dental and vision insurance  Three weeks of vacation for newly hired employees  Generous 401k plan that includes employer matching funds and separate employer retirement contribution including a Lifetime Income Strategy option  Tuition reimbursement program  Student Loan Repayment Program  Life insurance and disability coverage  Optional coverages you can buy pet insurance home and auto insurance additional life and accident insurance critical illness insurance group legal ID theft protection  Birth adoption parental leave benefits  Ovia Health fertility and family planning  Adoption Assistance  Autism Benefit  Employee Assistance Plan including up to 10 free counseling sessions  Healthy You Incentives wellness rewards program  Doctor on Demand virtual doctor visits  Bright Horizons child and elder care services  Teladoc Medical Experts second opinion program  And more    At Collins the paths we pave together lead to limitless possibility And the bonds we form – with our customers and with each other  propel us all higher again and again   Apply now and be part of the team that’s redefining aerospace every day   The salary range for this role is 96000 USD  200000 USD The salary range provided is a good faith estimate representative of all experience levels RTX considers several factors when extending an offer including but not limited to the role function and associated responsibilities a candidate’s work experience location educationtraining and key skills   Hired applicants may be eligible for benefits including but not limited to medical dental vision life insurance shortterm disability longterm disability 401k match flexible spending accounts flexible work schedules employee assistance program Employee Scholar Program parental leave paid time off and holidays Specific benefits are dependent upon the specific business unit as well as whether or not the position is covered by a collectivebargaining agreement   Hired applicants may be eligible for annual shortterm andor longterm incentive compensation programs depending on the level of the position and whether or not it is covered by a collectivebargaining agreement Payments under these annual programs are not guaranteed and are dependent upon a variety of factors including but not limited to individual performance business unit performance andor the company’s performance   This role is a USbased role If the successful candidate resides in a US territory the appropriate pay structure and benefits will apply   RTX anticipates the application window closing approximately 40 days from the date the notice was posted However factors such as candidate flow and business necessity may require RTX to shorten or extend the application window    RTX is An Equal OpportunityAffirmative Action Employer All qualified applicants will receive consideration for employment without regard to race color religion sex sexual orientation gender identity national origin disability or veteran status age or any other federally protected class   Privacy Policy and Terms  Click on this link to read the Policy and Terms  ||['AWS', 'Data Platform', 'Data Engineer', 'Data Platform', 'design', 'data processes', 'pipelines', 'Digital Transformation', 'Data Science', 'data visualizations', 'AI', 'develop', 'automation', 'monitoring', 'data pipelines', 'use cases', 'Pipelines', 'Data Science', 'Visualizations', 'cloud', 'CICD', 'SQL', 'datasets', 'AI', 'data processing', 'Databricks', 'AWS', 'subject matter expert', 'Mathematics', 'pipeline development', 'data pipelines', 'Spark', 'Python', 'PySpark', 'SQL', 'Cloud', 'Gitlab', 'CICD', 'Databricks', 'Data Lake', 'SQL', 'Python', 'transform raw data', 'optimization', 'Micro Services']
3|Data Engineer|Software Engineer II - Data Engineering|UberSunnyvale, CA|http://www.indeed.com/rc/clk?jk=e425cb2bbab68927&bb=UkWqgXROFXK6Hr5wr58UhfUgKJJAX3HpR3aJ0UIATp1q341ctfv2Mz1xHm4EWr3xAf6cMZYYY7b89MPE6kwK2305EjJRK94u2Nv9ojqs5qj-tBpw4cOCTg%3D%3D&xkcb=SoAl67M3CNjr8KwiIp0IbzkdCdPP&fccid=f766f8bfbc3effb7&vjs=3|Profile insightsFind out how your skills align with the job descriptionSkillsDo you have experience in System designYesNoEducationDo you have a Masters degreeYesNo Job detailsHere’s how the job details align with your profilePay158000 a yearJob typeFulltime LocationSunnyvale CA Full job description About the Team   The Global Intelligence Team focuses on making Uber take meaningful marketplace decisions with better data and algorithms The ambitious problems include modeling sophisticated marketlevel dynamics rider and driver choices crossservice decisions across rideseats and finetuning Ubers pricing with dataalgorithms from this team The software engineers on the team use meaningful amounts of data to address these challenges building scalable engineering solutions    We are looking for people who are passionate about solving ambitious businessproduct issues with welltrained data engineering expertise with prior experience or interest in science models and methodologies and who are also passionate about seeking the truth via deepdiving into the complicated structured and unstructured data    About the Role    What the Candidate Will Do    Work on creating a platform that powers data driven decision making for Uber Rides and Eats line of business  Design and develop new systems to empower fast datadriven decisions  Build distributed backend systems serving realtime analytics and machine learning features at Uber scale  Work with the product and science team to build and drive technical roadmap and vision for the team   Basic Qualifications    3 years of fulltime engineering experience  Experience working with multiple multifunctional teams product scienceproduct ops etc  Understanding of Big data architecture ETL frameworks and platforms  Expertise in one or more objectoriented programming languages eg Python Go Java C and the eagerness to learn more  Experience with datadriven architecture and systems design  Proven experience in largescale distributed storage and database systems SQL or NoSQL eg MySQL Cassandra and data warehousing architecture and data modeling   Preferred Qualifications    Experience or interest in learning science models and methodologies  Experience building complex systems and knowledge of Hadoop related technologies such as HDFS Kafka Hive and Presto  BSMSPhd in Computer Science or related field required   For San Francisco CAbased roles The base salary range for this role is USD158000 per year  USD175500 per year For Sunnyvale CAbased roles The base salary range for this role is USD158000 per year  USD175500 per year For all US locations you will be eligible to participate in Ubers bonus program and may be offered an equity award  other types of comp You will also be eligible for various benefits More details can be found at the following link httpswwwubercomcareersbenefits  ||['algorithms', 'modeling', 'unstructured data', 'data driven', 'decision making', 'datadriven decisions', 'machine learning', 'teams', 'Big data', 'ETL', 'programming', 'Python', 'Go', 'Java', 'C', 'design', 'storage', 'SQL', 'NoSQL', 'MySQL', 'Cassandra', 'data warehousing', 'data modeling', 'Hadoop', 'HDFS', 'Kafka', 'Hive', 'Presto']
4|Data Engineer|Sr. Engineer - Data|TDECUHybrid remote in Sugar Land, TX|http://www.indeed.com/rc/clk?jk=7359cb27d82b1399&bb=UkWqgXROFXK6Hr5wr58UhVyN2uYldS5Wfk99rxDhk2cv9rTyt5aCteSTzdZwzyvUoTALQHQfb5iulkv4Eojt94VNVBrbrmQnEIeYFQ0KquRbdP3AWx33dw%3D%3D&xkcb=SoCr67M3CNjr8KwiIp0PbzkdCdPP&fccid=ccbb60cd599a87fc&vjs=3|Profile insightsFind out how your skills align with the job descriptionSkillsDo you have experience in SparkYesNoEducationDo you have a Bachelors degreeYesNo Job detailsHere’s how the job details align with your profileJob typeFulltime LocationSugar Land TX Full job descriptionPosition Title Senior Data Engineer    Position Summary  The Senior Data Engineer is responsible for designing building and maintaining the enterprise data warehouse ensuring data quality and supporting data lake and surrounding technology ecosystem including Master Data Management Extract Load Transform Data Security and Data Catalog Domain Financial Services – Banking    Essential Duties and Responsibilities  Designs builds and maintains data architectures pipelines and Extract Load Transform processes to ensure efficient and reliable data ingestion processing and storage Develops and maintains data models schema and metadata to enable effective data analysis Collaborate with data analysts data scientists and other stakeholders to understand data requirements and ensure data quality Implements data validation and cleansing processes to ensure data accuracy and consistency as required Monitors and troubleshoots data pipelines to ensure that they are running smoothly and efficiently Stays current with the latest data engineering trends and technologies and applies them as appropriate and in alignment with data strategy    Minimum Qualifications  Education  Bachelors degree in Computer Science Information Systems or a related field or an equivalent combination of education and work experience is required    Certification  Azure DP203 Data Engineering required  Snowflake DEAC01 SnowPro Advanced Data Engineer preferred    Experience  Seven plus years relevant experience in data modeling data integration or data management  Experience in dimensional modeling at large enterprise  Experience on Git Azure DevOps  Experience with distributed computing frameworks such as Hadoop and Spark  Strong experience with SQL and database management systems  Experience with cloud data technologies eg GCP Dataproc Big query Airflow Snowflake Data Factory preferred    Knowledge Skills and Abilities  Strong programming skills in languages such as Python Java or Scala  Proven ability to build data pipelines and framework for a scalable solution to support the dynamic cloud environment  Ability to write complex queries and stored procedures  Ability to manage multiple priorities simultaneously  Excellent written and oral communication skills  Ability to identify research and resolve technical problems  Ability to work both independently and as part of a team    Physical Demands and Work Environment  The physical demands and work environment characteristics described herein are representative of those that must be met by an employee to successfully perform essential functions of this position andor may be encountered while performing essential functions Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions    While performing the essential duties of this position an employee would frequently be required to stand walk and sit  Specific vision abilities required by this position include close vision distance vision and the ability to adjust focus  The noise level in the work environment is usually moderate  Our company offers a dynamic hybrid work arrangement which requires three days onsite in the Sugar Land TX office Our retail roles are required to be onsite at the branch locations    Disclaimer  The above statements are intended to describe the general nature and level of work being performed by people assigned to this job They are not intended to be an exhaustive list of all responsibilities duties and skills required of personnel so classified    Texas Dow Employees Credit Union is an equal opportunity employer dedicated to a policy of nondiscrimination in employment on any basis including race color age protected veteran status sex religion disability genetic information national origin or other status protected by federal state or local law Consistent with the American Disabilities Act applicants may request accommodations needed to participate in the application process ||['designing', 'maintaining', 'data warehouse', 'data quality', 'data lake', 'Load', 'Transform', 'Data Security', 'Data Catalog', 'pipelines', 'Load', 'Transform', 'processing', 'storage', 'data models', 'data analysis', 'data requirements', 'data quality', 'data validation', 'data accuracy', 'consistency', 'data pipelines', 'trends', 'data strategy', 'Azure', 'Snowflake', 'Data Engineer', 'data modeling', 'data integration', 'dimensional modeling', 'Git', 'Azure', 'DevOps', 'Hadoop', 'Spark', 'SQL', 'database management', 'cloud data', 'GCP', 'Dataproc', 'Big query', 'Airflow', 'Snowflake', 'Data Factory', 'programming', 'Python', 'Java', 'Scala', 'data pipelines', 'cloud', 'stored procedures', 'research']
5|Data Engineer|Data Center Technical Operations Engineer I|Advantis GlobalRemote in Dublin, OH|http://www.indeed.com/rc/clk?jk=e8a9e3e75cef1843&bb=UkWqgXROFXK6Hr5wr58UhVyN2uYldS5WUFAXeGchZvbbnhIe3kQaq6SJ-4aCUvKNQ2nKqrdTB4DLpwiqhMVXBMiABssqyZe_42NTzh0pnw_vwHkqgFIEaQ%3D%3D&xkcb=SoAf67M3CNjr8KwiIp0ObzkdCdPP&fccid=808a3c26240b15ba&vjs=3|Profile insightsFind out how your skills align with the job descriptionSkillsDo you have experience in Electrical experienceYesNoEducationDo you have a Trade schoolYesNo Job detailsHere’s how the job details align with your profilePay31 an hourJob typeContractShift and schedule8 hour shiftDay shiftMonday to Friday LocationDublin OH BenefitsPulled from the full job descriptionDental insuranceVision insurance Full job description        Dublin                      Ohio           Data Center             Remote Work Option             Yes                 Job ID           348196             Employment Type           Contract             Pay Rate           Base Salary                      3100           hr           The Data Center Technical Operations Engineer will be responsible for risk management and mitigation corrective and preventative maintenance of critical infrastructure vendor management and metric reporting    MF 8Hr days Day shift    THE OPPORTUNITY FOR YOU    Ensure that all work performed is in accordance with established practices and procedures Establish performance benchmarks conduct analyses and prepare reports on all aspects of the critical facility operations and maintenance Work with IT managers and other business leaders to coordinate projects manage capacity and optimize plant safety performance reliability and efficiency Operate and manage both routine and emergency services on a variety of critical systems such as switchgear generators UPS systems power distribution equipment chillers cooling towers computer room air handlers building monitoring systems etc May assist in the design and build out of new facilities May assist in projects to increase current facility efficiency Responsible for asset and inventory management Assist in recruiting efforts Deliver quality service and ensure all customer demands are met   KEY SUCCESS FACTORS    Degree in Electrical Engineering Mechanical Engineering or relevant discipline or trade schoolmilitary experience 1 years of Mechanical andor Electrical Operations experience 1 years of experience with Mechanical andor electrical troubleshooting Experience with utilizing building management systems Strong verbal and written communication skills Strong leadership and organizational skills Strong attention to detail Ability to prioritize in complex fastpaced environment Experience with emergency response to facility related issues Experience with critical electrical and cooling systems Experience with computer systems excel word etc   PREFERRED QUALIFICATIONS    12 years of Data Center Engineering Experience 12 years of Data Center Management Experience Related technical certifications   BENEFITS    Companysponsored Health Dental and Vision insurance plans    EQUAL OPPORTUNITY STATEMENT  Advantis Global is an equal opportunity employer and makes employment decisions on the basis of merit qualifications and abilities Company policy prohibits unlawful discrimination based on race color religion sex including gender gender identity gender expression pregnancy childbirth or medical condition related to pregnancy or childbirth sexual orientation national origin ancestry age physical or mental disability genetic information political affiliation union membership marital or registered domestic partnership status military or veteran status or any other characteristic protected by law “Protected Characteristic” Additionally Advantis Global is committed to promoting pay equity and prohibits harassment of any employee on the basis of any Protected Characteristic  Advantis Global is a progressive and openminded collective If you’re smart optimistic and care about being awesome at what you do come as you are We welcome you with open arms  This policy applies to all terms and conditions of employment including recruiting hiring placement promotion termination layoff recall transfer leaves of absence compensation and training   LIMW1  ||['risk management', 'preventative maintenance', 'metric reporting', 'optimize', 'reliability', 'monitoring', 'design', 'communication skills', 'organizational skills', 'attention to detail', 'emergency response', 'excel', 'word']
7|Data Engineer|Data Warehouse Engineer|BRSRemote|http://www.indeed.com/rc/clk?jk=46b1845d965e80c7&bb=UkWqgXROFXK6Hr5wr58UhSAcmIPBOZdMxvXY2qTsM4nkbUGL_Up7uqFKakEbIGXYBkQjsXaIGULy5AEvyAB8JqzuOAkjAKZ6RNYMdQGzL_4DzmnnFlIq3g%3D%3D&xkcb=SoA267M3CNjr8KwiIp0MbzkdCdPP&fccid=e2c1d9254247b2b7&vjs=3|Profile insightsFind out how your skills align with the job descriptionLicensesDo you have a valid Secret Clearance licenseYesNoSkillsDo you have experience in SQLYesNoEducationDo you have a Bachelors degreeYesNo Job detailsHere’s how the job details align with your profileJob typeFulltime LocationRemote Full job descriptionVista Innovative Services LLC is seeking a Data Warehouse Manager to add to our Enterprise Analytics and Systems Support Services EASSS team in support of Human Resources Command HRC Enterprise Modernization Directorate EMoD    Responsibilities Include   This role will partner crossfunctionally with all areas of the business to create a single source from where teams can pull data and insights Defines an overarching data strategy to ensure the right people have the right data at the right time while overseeing data design and the creation of database architecture and data repositories Responsible for the design implementation maintenance and support of the data warehouse systems and projects Ensures that reporting modeling and ETL projects and initiatives are supported fully and run smoothly Installs processes for auditing data warehouses and ensuring data quality Establishes connections between data warehousedata models and BI visualization tools Ensures stability of data warehouses including security uptime and troubleshooting of database errors Maintains data warehouses including rollout of upgrades and constant evaluation of emergent technologies Work in a multiprotocol multiplatform environment Providing a managerial role while providing daytoday support of the data warehouse and troubleshooting existing procedures and processes Guides the project in identifying any new data needs and deliver mechanisms for acquiring and reporting such information as well as addressing the actual needs Designs and develops systems for maintenance of the data warehouse ETL processes and business intelligence Highly collaborative with other team members and data consumers within the business to gather and populate data warehouse table structure Establishes the documentation of reports develops and maintains technical specification documentation for all reports and processes  Qualifications   Bachelor’s degree in management information systems Computer Science or a related field Education may be substituted for years of experience 59 years of experience in database administration database architecture or a related field Mastery of SQL and experience standing up cloud data warehouses Extensive knowledge of Data Warehouse design concepts and tools Secret Clearance  ||['Data Warehouse', 'data design', 'data warehouse', 'reporting', 'modeling', 'ETL', 'data warehouses', 'data quality', 'BI', 'visualization', 'data warehouses', 'data warehouses', 'evaluation', 'data warehouse', 'reporting', 'data warehouse', 'ETL', 'business intelligence', 'data warehouse', 'SQL', 'cloud', 'data warehouses', 'Data Warehouse design']
11|Data Engineer|Senior Data Engineer|Renown HealthRemote in Reno, NV 89502|http://www.indeed.com/rc/clk?jk=5aa36a1e7a8daca1&bb=UkWqgXROFXK6Hr5wr58UhccMGObYIx1dRax496VeGfn4ldvBG9xVDSiAl5BmFb81WhiVstMC8jH898jVeI3k5_Cr81XyddHixMYVBRHTqNY%3D&xkcb=SoBC67M3CNjr8KwiIp0AbzkdCdPP&fccid=994a93a3bf96eb2c&vjs=3|Profile insightsFind out how your skills align with the job descriptionSkillsDo you have experience in XMLYesNoEducationDo you have a Masters degreeYesNo Job detailsHere’s how the job details align with your profileJob typeFulltime Location1155 Mill Street Reno NV 89502 Full job description        Position Purpose               Renown Health is looking for a Senior Data Engineer familiar with the Microsoft Azure Cloudbased platform This position will develop design implement and maintain a Microsoft Azure Data Warehousing environment and help architect the Enterprise Data Warehouse for all corporate entities of Renown Health The role will include setting up and automating data pipelines via ETL  ELT processes with internal departments and external third parties verifying data accuracy and optimizing the data environments to enable the work of data scientists and analysts The engineer will be expected to know SQL and be comfortable discussing complex computer science or statistical concepts with data scientists and analysts Innovation is critical to this role as an ideal candidate will possess the ability to lead the development of a cloudbased enterprise data warehouse along with engineering solutions to support the development of new reporting systems analytic engines and machine learning algorithms                      Nature and Scope               This role can be either remote or hybrid   Primary Responsibilities  In collaboration with data scientists build full technology stack of services for commercialization purposes including PaaS Platform asaservice IaaS Infrastructure asaservice SaaS software asaservice operations and management   Manage and optimize the movement and validation of data from an Epic EMR system to Renown Health’s Enterprise Data Warehouse EDW   Accountable for data engineering lifecycle including research proof of concepts architecture design development test deployment and maintenance   Oversee the development of novel data pipelines that integrate and normalize large data from a variety of sources eg electronic health record claims wearable device publicly available data etc to enable learning health machine learning model development and deployment   Design direct and implement ETL processes including data capture data quality testing and validation methods   Knowledge of interface engines and protocols Experience with HL7 X12 andor XML and OPENLink   Provide guidance on synchronizing the Epic EMR data architecture with customized data models that facilitate reporting and analytics   Layer in instrumentation in the development process so that data pipelines can be monitored Measurements are used to detect internal problems before they result into user visible outages or data quality issues   Build processes and diagnostic tools to troubleshoot maintain and optimize engineering environments and respond to production issues   Provide subject matter expertise and hands on delivery of data capture curation and consumption pipelines for Microsoft Azure   Ability to build Azure data solutions and provide technical perspective on storage big data platform services serverless architectures Hadoop ecosystem vendor products RDBMS DWDM NoSQL databases and security   Participate in deep architectural discussions to build confidence and ensure customer success when building new solutions and migrating existing data applications on the Azure platform   Develop documentation such as data dictionaries guides or data flow diagrams that assists staff in identifying locating and using the organization’s data    Incumbent Must Possess   Minimum of 3 years of SQL programming experience and associated SQL tools SSIS SSMS SSRS etc   Experience with Visual Studio is preferred   At least 3 years of experience in developing data ingestion data processing and analytical pipelines for big data relational databases NoSQL and data warehouse solutions   Minimum of 3 years of RDBMS experience   Extensive handson experience implementing data migration and data processing using Azure services ADLS Azure Data Factory Azure Functions SynapseDW Azure SQL DB Event Hub IOT Hub Azure Stream Analytics Azure Analysis Service HDInsight Databricks Azure Data Catalog Cosmo Db ML Studio AIML etc   Familiarity of the environments needed to facilitate the work of data scientists and analysts in healthcare   Knowledge of medical terminology especially ICD10 codes CPT codes DRG codes and an understanding of adjudicated claims data   Excellent verbal and written communication An applicant may be asked to provide examples of written work to demonstrate technical writing proficiency    This position does not provide patient care                      Disclaimer           The foregoing description is not intended and should not be construed to be an exhaustive list of all responsibilities skills and efforts or work conditions associated with the job It is intended to be an accurate reflection of the general nature and level of the job                      Minimum Qualifications Requirements  Required andor Preferred               Name    Description       Education    Must have workinglevel knowledge of the English language including reading writing and speaking English Master’s degree with 10 years’ experience preferred bachelor’s degree with 13 years of equivalent experience will be considered in place of master’s degree requirement       Experience    Requires a minimum of 10 years’ experience with at least five 5 years working in data management data engineering or data architecture Enterprise Data Warehouse development preferred Requires at least five 5 years working with healthcare data more is preferred SQL proficiency is required       Licenses    None       Certifications    Ability to obtain Epic System’s Caboodle and Clarity Development Certificates and relevant data model badges required within 12 months of hire Must stay current on new version certification as applicable       Computer  Typing    Must be proficient with Microsoft Office Suite including Outlook PowerPoint Excel and Word and can use the computer to complete online learning requirements for jobspecific competencies access online forms and policies complete online benefits enrollment etc                     Location Renown Health · 100612 Enterprise Data Analytics   Schedule Full Time  Eligible for Benefits Day 40  ||['Data Engineer', 'Azure', 'Azure', 'Data Warehousing', 'Data Warehouse', 'data pipelines', 'ETL', 'data accuracy', 'SQL', 'data warehouse', 'reporting', 'machine learning', 'algorithms', 'optimize', 'EMR', 'Data Warehouse', 'data pipelines', 'machine learning', 'ETL', 'data quality', 'testing', 'XML', 'EMR', 'data models', 'data pipelines', 'data quality', 'pipelines', 'Azure', 'Azure', 'data solutions', 'storage', 'big data', 'Hadoop', 'RDBMS', 'NoSQL', 'existing data', 'Azure', 'Develop', 'data dictionaries', 'data flow diagrams', 'SQL', 'programming', 'SQL', 'SSIS', 'SSMS', 'SSRS', 'Visual Studio', 'developing', 'data processing', 'pipelines', 'big data', 'relational databases', 'NoSQL', 'data warehouse', 'RDBMS', 'handson', 'data processing', 'Azure', 'ADLS', 'Azure', 'Data Factory', 'Azure', 'SynapseDW', 'Azure', 'SQL', 'IOT', 'Azure', 'Stream Analytics', 'Azure', 'Analysis', 'Databricks', 'Azure', 'Data Catalog', 'Data Warehouse', 'SQL', 'Microsoft Office', 'Outlook', 'PowerPoint', 'Excel', 'Word', 'Data Analytics']
0|Data Engineer|Senior Data Engineer|Schneider ElectricHybrid remote in Franklin, TN 37067|http://www.indeed.com/rc/clk?jk=9da902ba5f721bfa&bb=9kdXdebxtoL5LCu5AWPBVR6ENYgklyLasKKaLrlqG3fU-lR3rwrBG6xFmKHCtMJxvJxM-jnKboDUX7ifjxPKEXHDDPqxAbiw6sQ_x2Ry6DeDTAVdYpz1qg%3D%3D&xkcb=SoDQ67M3CNjobgRSRx0LbzkdCdPP&fccid=8dc4399ddb463d4a&vjs=3|Profile insightsFind out how your skills align with the job descriptionSkillsDo you have experience in SparkYesNoEducationDo you have a Masters degreeYesNo Job detailsHere’s how the job details align with your profileJob typeFulltime Location6700 Tower Circle Franklin TN 37067 BenefitsPulled from the full job descriptionOpportunities for advancement Full job description  Job Description    Schneider Electric USA Inc seeks a Senior Data Engineer in Franklin TN   Job Description Ensure data warehouse and other data sources are structured documented and updated Use API integration skills SQL coding and leadingedge data housing skills Optimize data systems Make raw data easier to access and more useful for a global team of Data Scientists Machine Learning Engineers and Data Analysts to consume Eligible for up to 3 days remote work per week Qualifications    Requirements Position requires a Master’s or Bachelor’s degree or foreign equivalent in Computer Science or related field and experience 1 year with Master’s or 3 years with Bachelor’s in data engineering or related occupation which must include at least some education in or experience with the following skills Programming using SQL Python Spark Scala and Java Advanced data mining methods and automation using ETL and scripting Creating and supporting optimal data pipeline architectures for scalability Cloud technologies with APIs or AWS cloud services Redshift Athena RDS DynamoDB Batch Glue Deploying applications using Docker Rancher or Kubernetes Ingesting analyzing and summarizing large datasets Performing complex data modeling and ETL design and using large databases in a business environment and Indexes partitions and distributed storage and access   EOE    To Apply Visit httpcareerssecom and search Req68692   About Our Company     Why us      Schneider Electric is leading the digital transformation of energy management and automation Our technologies enable the world to use energy in a safe efficient and sustainable manner We strive to promote a global economy that is both ecologically viable and highly productive      €257bn global revenue       137 000 employees in 100 countries       45 of revenue from IoT       5 of revenue devoted for RD      You must submit an online application to be considered for any position with us This position will be posted until filled      It is the policy of Schneider Electric to provide equal employment and advancement opportunities in the areas of recruiting hiring training transferring and promoting all qualified individuals regardless of race religion color gender disability national origin ancestry age military status sexual orientation marital status or any other legally protected characteristic or conduct Concerning agencies Schneider Electric does not accept unsolicited resumes and will not be responsible for fees related to such    ||['data warehouse', 'data sources', 'SQL', 'Optimize', 'raw data', 'Machine Learning', 'Programming', 'SQL', 'Python', 'Spark', 'Scala', 'Java', 'data mining', 'automation', 'ETL', 'pipeline architectures', 'Cloud technologies', 'AWS cloud', 'Redshift', 'Athena', 'RDS', 'DynamoDB', 'Batch', 'Glue', 'Docker', 'Kubernetes', 'Ingesting', 'datasets', 'data modeling', 'ETL', 'design', 'distributed storage', 'digital transformation', 'IoT']
1|Data Engineer|Sr. Data Engineer|UMB Financial CorporationRemote in Kansas City, MO|http://www.indeed.com/rc/clk?jk=7013afacedbce8e8&bb=9kdXdebxtoL5LCu5AWPBVaopXf_Z3XgR0-kk35vuXvopJlMO13s51c5NwWx76qgRqZnfKiwlfwVbkqiTi0XlwmHYkVaEg40c6DPsVro7VoA%3D&xkcb=SoBk67M3CNjobgRSRx0KbzkdCdPP&fccid=13f5bb3a3abd1e37&vjs=3|Profile insightsFind out how your skills align with the job descriptionSkillsDo you have experience in SparkYesNoEducationDo you have a Bachelors degreeYesNo LocationKansas City MO BenefitsPulled from the full job description401k matchingAdoption assistanceDental insuranceEmployee assistance programFlexible spending accountGym membershipHealth insuranceShow morechevron down Full job description    UMB Bank NA seeks two Sr Data Engineers for Kansas City MO with option to telecommute work from anywhere within US        The Enterprise Data Warehouse  Analytics team provides support of our data warehouse environment and analytics tools This allows our business leaders access to business intelligence data in order to develop strategies for our organization to grow        As a Sr Data Engineer you will be a part of UMB’s data team during an exciting time of growth and modernization As part of this job you will be working to implement cloud strategies modernizing legacy systems and coding for the future of data processing at UMB As you grow in technical expertise in one or more areas of specialization as well as leadership capabilities your position and role within the team would advance and reflect this growth accordingly If you have a passion for new technology love to solve complex problems aren’t afraid to learn technology and love change we want to talk to you        The Enterprise Data Warehouse  Analytics team is a closeknit group of data engineers coming from diverse backgrounds and experiences We share a strong commitment of providing high quality enterprise data solutions and we believe in fully supporting each other to achieve this goal Trust and open communication are the cornerstones of how we roll and we have plenty of fun while doing it Selfeducation peer consultation mentor guidance and formal trainingseminars are some of the methods that we share information and knowledge      How you’ll spend your time      The Sr Data Engineer will be responsible for building and maintaining optimal data pipelines architectures and data sets required for extraction transformation and loading of data from a wide variety of data sources using SQL and integration technologies Leverage existing data infrastructure to fulfill all datarelated requests perform necessary data housekeeping data cleansing normalization hashing and implementation of required data model changes Build and utilize appropriate data platform structures to organize and store data in a particular manner Work with big data technologies onprem cloud and hybrid Implement data lifecycle management strategies around the flow of data within the organization implementing policy and automated approaches Implement BI business intelligence platforms such as Power BI both onpremises and cloud Establish governance and strategies around visualization of creating reports and dashboards to help improve upon operational and analytical reporting Examine assess translate and classify data recognize collect and analyze data to encourage the advancement execution and application of data platform systems Analyze data to spot anomalies trends and correlate similar data sets Design develop and implement natural language processing software modules Create models and standards to govern which data is collected and how it is stored arranged integrated and use in data systems and in organizations Perform major tasks deliverables and formal application delivery methodologies deliver new or enhanced applications Perform additional database administrator duties as assigned      We’re excited to talk if you have      Bachelor’s degree in Computer Science or a closely related field       Five years’ progressive experience in job offered or related which must include experience in the following concurrently     5 years in a technical role supporting or designing application technologies  5 years in data development or engineering  Experience serving as technical lead or project management formal or informal  5 years with Data Pipeline Development or Business Intelligence Implementation and subject matter expertise in Modem Data Platform Implementation  Experience in the following  Analyzing rearchitecting and replatforming onpremise data warehouses to data platforms on AWS cloud or similar using AWS or similar or 3rd party services  Designing and building production data pipelines from ingestion to consumption within a big data architecture using Java Python and Scala or similar technologies  Designing and implementing data engineering ingestion and curation functions on AWS cloud or similar using AWS native or similar or custom programming  3 years of experience designing and developing solutions using AWS or similar services such as Lamdba Glue SQS SNS Redshift or similar  Architecting and implementing very largescale data intelligence solutions around Snowflake Data Warehouse or similar technologies  Developing ETL pipelines in and out of data warehouse using combination of Python and Snowflakes Snow SQL  Writing SQL queries against Snowflake or similar technologies       Demonstrated ability to design build and operationalize large scale enterprise data solutions and applications using one or more of AWS or similar data and analytics services in combination with 3rd parties  Spark EMR DynamoDB RedShift Kinesis Lambda Glue Snowflake or similar Up to 10 local travel required        Applicants must have legal authority to work in the United States Work Visa sponsorship not available for this position   xaxa       UMB offers competitive and varied benefits to eligible associates such as Paid Time Off a 401k matching program annual incentive pay paid holidays a comprehensive company sponsored benefit plan including medical dental vision and other insurance coverage health savings flexible spending and dependent care accounts adoption assistance an employee assistance program fitness reimbursement tuition reimbursement an associate wellbeing program an associate emergency fund and various associate banking benefits Benefit offerings and eligibility requirements vary        Are you ready to be part of something more    Youre more than a means to an end—a way to help us meet the bottom line UMB isnt comprised of workers but of people who care about their work one another and their community Expect more than the status quo At UMB you can expect more heart Youll be valued for exactly who you are and encouraged to support causes you care about Expect more trust We want you to do the right thing no matter what And expect more opportunities UMBers are known for having multiple careers here and having their voices heard      UMB and its affiliates are committed to inclusion and diversity and provide employment opportunities to all employees and applicants for employment without regard to race color religion sex including gender pregnancy sexual orientation and gender identity national origin age disability military service veteran status genetic information or any other status protected by applicable federal state or local law If you need accommodation for any part of the employment process because of a disability please send an email to   talentacquisitionumbcom  to let us know the nature of your request     If you are a California resident please visit our      Privacy Notice for California Job Candidates    to understand how we collect and use your personal information when you apply for employment with UMB   ||['Data Warehouse', 'data warehouse', 'business intelligence', 'develop', 'Data Engineer', 'cloud strategies', 'data processing', 'technical expertise', 'Data Warehouse', 'data solutions', 'Data Engineer', 'maintaining', 'data pipelines', 'data sets', 'transformation', 'loading', 'data sources', 'SQL', 'existing data', 'data housekeeping', 'data cleansing', 'normalization', 'hashing', 'data platform', 'big data', 'cloud', 'Implement', 'lifecycle management', 'Implement', 'BI', 'business intelligence', 'Power BI', 'cloud', 'visualization', 'dashboards', 'reporting', 'analyze data', 'data platform', 'Analyze data', 'anomalies', 'trends', 'data sets', 'Design', 'develop', 'implement', 'natural language processing', 'Create models', 'designing', 'project management', 'Pipeline Development', 'Business Intelligence', 'Data Platform', 'data warehouses', 'AWS cloud', 'AWS', 'Designing', 'data pipelines', 'big data', 'Java', 'Python', 'Scala', 'Designing', 'AWS cloud', 'AWS', 'programming', 'designing', 'developing', 'AWS', 'Lamdba', 'Glue', 'SQS', 'SNS', 'Redshift', 'Snowflake', 'Data Warehouse', 'Developing', 'ETL', 'pipelines', 'data warehouse', 'Python', 'SQL', 'SQL', 'Snowflake', 'design', 'data solutions', 'AWS', 'Spark', 'EMR', 'DynamoDB', 'RedShift', 'Kinesis', 'Lambda', 'Glue', 'Snowflake']
2|Data Engineer|Data Engineer|GTI EnergyDes Plaines, IL 60018|http://www.indeed.com/rc/clk?jk=070847f493a6c894&bb=9kdXdebxtoL5LCu5AWPBVRgEh-JXr5tXANM7EtsfX2ipacFIehBuN3dYVDpJ1HApmFxqMcWunHCLcMlpWapf74DfFuBHuwgvluOlNIkgPc7UWB9ttnAXmg%3D%3D&xkcb=SoD567M3CNjobgRSRx0JbzkdCdPP&fccid=64b757511be5394c&vjs=3|Profile insightsFind out how your skills align with the job descriptionSkillsDo you have experience in Power BIYesNoEducationDo you have a Masters degreeYesNo Job detailsHere’s how the job details align with your profileJob typeFulltime LocationDes Plaines IL 60018 Full job description   General Summary   GTI Energy the nation’s leading research development deployment and training organization serving energy markets has an opportunity for a Data EngineerAnalyst in our Research  Engineering group The Data Engineer will collaborate with a team of engineers and scientists to deliver technological solutions for energy projects This role involves applying engineering practices to develop and deploy instrumentation controls and connected systems The engineer will contribute to development documentation and commissioning of data visualization of instrumentation systems     Why GTI Energy   GTI Energy offers generous benefits competitive salaries career advancement and the opportunity to work in a professional RD environment Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions  We are proud of what we do because our work matters GTI Energy is working toward solving global energy challenges in transitioning to a lowcarbon economy We have a proven track record in producing innovative ideas and commercializing solutions to deliver clean and reliable energy At GTI Energy we deliver innovative technology solutions for safe efficient and responsible energy  So what does that mean for you You will work in a positive and respectful work culture that fosters growth collaboration and opportunity You will be supported by competitive compensation incentives and benefits while enjoying purposeful work that drives improvement of delivering clean energy to the world     Work Location   The position will be based in the Chicagoland area at the GTI Energy Headquarters We offer a hybridcore work week where employees may be remote Mondays and Fridays and required to be onsite Tuesday through Thursday     Primary Responsibilities   This position is within a group of engineers and scientists that bring technological solutions to a broad range of energy project developers utility companies and endusers The candidate must be able to apply standard practices to the development and deployment of data visualizationsdashboards for instrumentation systems The candidate must be able to work within the structure of an overall project team while being able to work independently on subtasks Position responsibilities include but are not limited to  Participate in developing data requirements from work proposals Research and identify components and software that match requirements Document work in written graphical and presentation form Assist in the handson commissioning data acquisition systems Perform other duties as assigned      Required Knowledge Skills Abilities and Other Characteristics    Specific knowledge of the MS Azure and PowerBI stack General knowledge of data visualization methodologies Data storage and management tools such as SQL Server OPC and Cosmos DB Data historian tools such as PARCview or PI Industrial protocols such as MODBUS MQTT or Ethernet Wireless IoT protocols such as LoRaWAN LTE or Monnit Preferred candidate will have prior experience with live sensor data      Education and Experience   BSc or MSc degree in an engineering discipline 5 years of relevant professionallevel experience after a BS 3 years of relevant professionallevel experience after an MS      EEO Statement   GTI Energy is committed to developing a barrierfree recruitment process and work environment If you require any accommodation please email us at HumanResourcesgtienergy and we’ll work with you to meet your accessibility needs You must have legal authorization to work for GTI Energy on your date of hire with no further action required by GTI Energy We are an Equal Employment Opportunity employer and consider qualified applicants without regard to race color age religion sexual orientation gender identity national origin disability veteran status pregnancy or genetic information   Equal Opportunity EmployerProtected VeteransIndividuals with Disabilities  The contractor will not discharge or in any other manner discriminate against employees or applicants because they have inquired about discussed or disclosed their own pay or the pay of another employee or applicant However employees who have access to the compensation information of other employees or applicants as a part of their essential job functions cannot disclose the pay of other employees or applicants to individuals who do not otherwise have access to compensation information unless the disclosure is a in response to a formal complaint or charge b in furtherance of an investigation proceeding hearing or action including an investigation conducted by the employer or c consistent with the contractor’s legal duty to furnish information 41 CFR 60135c  ||['data visualization', 'data requirements', 'match requirements', 'handson', 'data acquisition', 'Azure', 'PowerBI', 'data visualization', 'Data storage', 'SQL Server', 'Cosmos DB', 'IoT']
3|Data Engineer|Data Engineer|Capital OneMcLean, VA|http://www.indeed.com/rc/clk?jk=e4551550092579f0&bb=9kdXdebxtoL5LCu5AWPBVTPqW0IaWKoD75j2k-6qS9J9lCQQ-zVoiOhG4Q1KU5qggLpL9OmzxZwUIbfKL49tec9tha5HnrXHtHCppDV9XSY%3D&xkcb=SoBN67M3CNjobgRSRx0IbzkdCdPP&fccid=b85c5070c3d3d8c8&vjs=3|Profile insightsFind out how your skills align with the job descriptionSkillsDo you have experience in SparkYesNoEducationDo you have a Bachelors degreeYesNo Job detailsHere’s how the job details align with your profileJob typeFulltime LocationMcLean VA BenefitsPulled from the full job descriptionHealth insurance Full job description  Locations VA  McLean United States of America McLean Virginia   Data Engineer    Do you love building and pioneering in the technology space Do you enjoy solving complex business problems in a fastpaced collaborative inclusive and iterative delivery environment At Capital One youll be part of a big group of makers breakers doers and disruptors who solve real problems and meet real customer needs We are seeking Data Engineers who are passionate about marrying data with emerging technologies As a Capital One Data Engineer you’ll have the opportunity to be on the forefront of driving a major transformation within Capital One  What You’ll Do   Support the design and development of scalable data architectures and systems that extract store and process large amounts of data  Build and optimize data pipelines for efficient data ingestion transformation and loading from various sources while ensuring data quality and integrity  Collaborate with Data Scientists Machine Learning Engineers Business Analysts andor Product Owners to understand their requirements and provide efficient solutions for data exploration analysis and modeling  Implement testing validation and pipeline observability to ensure data pipelines are meeting customer SLAs  Use cutting edge technologies to develop modern data pipelines supporting Machine Learning and Artificial Intelligence    Basic Qualifications   Bachelor’s Degree  At least 2 years of experience in application development Internship experience does not apply  At least 1 year of experience in big data technologies    Preferred Qualifications   3 years of experience in application development including Python Scala or Java  1 years of experience using Spark  1 years of experience working on data stream systems Kafka or Kinesis  1 years of data warehousing experience Redshift or Snowflake  1 years of experience with Agile engineering practices  1 years of experience working with a public cloud AWS Microsoft Azure Google Cloud    At this time Capital One will not sponsor a new applicant for employment authorization for this position   Capital One offers a comprehensive competitive and inclusive set of health financial and other benefits that support your total wellbeing Learn more at the Capital One Careers website Eligibility varies based on full or parttime status exempt or nonexempt status and management level  This role is expected to accept applications for a minimum of 5 business days   No agencies please Capital One is an equal opportunity employer committed to diversity and inclusion in the workplace All qualified applicants will receive consideration for employment without regard to sex including pregnancy childbirth or related medical conditions race color age national origin religion disability genetic information marital status sexual orientation gender identity gender reassignment citizenship immigration status protected veteran status or any other basis prohibited under applicable federal state or local law Capital One promotes a drugfree workplace Capital One will consider for employment qualified applicants with a criminal history in a manner consistent with the requirements of applicable laws regarding criminal background inquiries including to the extent applicable Article 23A of the New York Correction Law San Francisco California Police Code Article 49 Sections 49014920 New York City’s Fair Chance Act Philadelphia’s Fair Criminal Records Screening Act and other applicable federal state and local laws and regulations regarding criminal background inquiries    If you have visited our website in search of information on employment opportunities or to apply for a position and you require an accommodation please contact Capital One Recruiting at 18003049102 or via email at RecruitingAccommodationcapitalonecom All information you provide will be kept confidential and will be used only to the extent required to provide needed reasonable accommodations   For technical support or questions about Capital Ones recruiting process please send an email to Careerscapitalonecom   Capital One does not provide endorse nor guarantee and is not liable for thirdparty products services educational tools or other information available through this site   Capital One Financial is made up of several different entities Please note that any position posted in Canada is for Capital One Canada any position posted in the United Kingdom is for Capital One Europe and any position posted in the Philippines is for Capital One Philippines Service Corp COPSSC  ||['customer needs', 'transformation', 'design', 'optimize', 'data pipelines', 'data ingestion', 'transformation', 'loading', 'data quality', 'Machine Learning', 'data exploration', 'analysis', 'modeling', 'Implement', 'testing', 'validation', 'data pipelines', 'develop', 'data pipelines', 'Machine Learning', 'Artificial Intelligence', 'big data', 'Python', 'Scala', 'Java', 'Spark', 'Kafka', 'Kinesis', 'data warehousing', 'Redshift', 'Snowflake', 'Agile', 'cloud', 'AWS', 'Azure', 'Google Cloud']
4|Data Engineer|Data Engineer|Axos BankSan Diego, CA 92122 (University City area)|http://www.indeed.com/rc/clk?jk=e60c74293b10ec2b&bb=9kdXdebxtoL5LCu5AWPBVaUq_bQ1tC8NBjCndQDTVXXvEe4GTgUSqyCsZC-5X28oNwDK-fxLvUXJGxmpecwK3fkb7Yd_-D5MOeucaAkcfPfCcFOlLcsPSQ%3D%3D&xkcb=SoDD67M3CNjobgRSRx0PbzkdCdPP&fccid=0c746cab37cd5dd5&vjs=3|Profile insightsFind out how your skills align with the job descriptionSkillsDo you have experience in Unit testingYesNoEducationDo you have a Bachelors degreeYesNo Job detailsHere’s how the job details align with your profilePay105000 a yearJob typeFulltime Location4350 La Jolla Village Drive Suite 140 San Diego CA 92122 BenefitsPulled from the full job description401k401k matchingDental insuranceFlexible spending accountHealth insuranceHealth savings accountLife insuranceShow morechevron down Full job description  Axos Bank       Target Range   8500000 Yr  10500000 Yr      Actual starting pay will vary based on factors including but not limited to geographic location experience skills specialty and education    Eligible for an Annual Discretionary Cash Bonus Target 10   Eligible for an Annual Discretionary Restricted Stock Units Bonus Target 10     These discretionary target bonuses may be awarded semiannually based upon your achievement of performance goals and targets       About This Job   As our Data Engineer you will work within the Enterprise Data Management group using SQL SSIS MS SQL Server python etc to create revenue generating enterprise data solutions       Responsibilities     Work with Technical and business team to understand the business requirements functional and technical specifications  Design code and maintain new and existing complex SQL stored procedures and functions  Performance tune existing stored procedures tables and indexes  Work with other engineers to troubleshoot repair and performance tune databases  Review SQL code written by other developers to ensure compliance to coding standards and best practices as well as maximum performance  Create SSIS packages for data transformation cleansing caching aggregation staging and transfer  Troubleshoot problems that may come up with database environments performance issues replication issues or operational issues  Perform data analysis and data profiling tasks to provide support and recommendations for development and design decisions  Analyze and define data flow requirements and prepares applicable system documentation and operation manuals as needed  Support production data loads and ongoing refreshes of the database systems  Define prepare execute and implement data validation and unit testing methods to ensure data quality  Maintain reusable development standards that help implement each solution andor enhancements to existing systems to meet current and future needs  Perform enhancements and bug fixes as required  Perform any additional duties as assigned       Requirements     Bachelors degree in a related field or relevant experience may be used in lieu of a degree  3 years with relational DBs in a production environment  3 years with Microsoft SQL Server versions  3 years of SSIS packages  2 years in an AgileSCRUM environment required  Experience in Performance Tuning  Deliver high quality high traffic scalable database objects  Deep understanding of data warehousing concepts including complex data structures data transformations and data analytics  Experience with multiplatform distributed application implementations across SQL Server Cloud based data warehouses such as AWS       Axos Employee Benefits May Include             Medical Dental Vision and Life Insurance              Paid Sick Leave 3 weeks’ Vacation and Holidays about 11 a year              HSA or FSA account and other voluntary benefits              401k Retirement Saving Plan with Employer Match Program and 529 Savings Plan              Employee Mortgage Loan Program and free access to an Axos Bank Account with SelfDirected Trading             About Axos        Born digitalfirst Axos delivers financial tools and services that allow individuals small businesses and companies to access and manage their money how when and where they want We’re a diverse team of dynamic insightful and independent innovators who are excited to provide technologydriven solutions that offer unbeatable value to our customers        Axos Financial is our holding company and is publicly traded on the New York Stock Exchange under the symbol AX NYSE AX          Learn more about working at Axos          PreEmployment Background Check and Drug Test        All offers are contingent upon the candidate successfully passing a credit check criminal background check and preemployment drug screening which includes screening for marijuana Axos Bank is a federally regulated banking institution At the federal level marijuana is an illegal schedule 1 drug therefore we will not employ any person who tests positive for marijuana regardless of state legalization        Equal Employment Opportunity        Axos is an Equal Opportunity employer We are committed to providing equal employment opportunities to all employees and applicants without regard to race religious creed color sex including pregnancy breast feeding and related medical conditions gender gender identity gender expression sexual orientation national origin ancestry citizenship status military and veteran status marital status age protected medical condition genetic information physical disability mental disability or any other protected status in accordance with all applicable federal state and local laws        Job Functions and Work Environment        While performing the duties of this position the employee is required to sit for extended periods of time Manual dexterity and coordination are required while operating standard office equipment such as computer keyboard and mouse calculator telephone copiers etc        The work environment characteristics described here are representative of those an employee may encounter while performing the essential functions of this position Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions of this position    ||['SQL', 'SSIS', 'MS SQL Server', 'python', 'data solutions', 'business requirements', 'technical specifications', 'Design code', 'SQL', 'stored procedures', 'stored procedures', 'SQL', 'maximum', 'SSIS', 'data transformation', 'cleansing', 'caching', 'aggregation', 'staging', 'data analysis', 'data profiling', 'design decisions', 'data flow requirements', 'implement', 'data validation', 'unit testing', 'data quality', 'implement', 'SQL Server', 'SSIS', 'Performance Tuning', 'data warehousing', 'data structures', 'data transformations', 'data analytics', 'distributed application', 'SQL Server', 'Cloud', 'data warehouses', 'AWS', 'office']
5|Data Engineer|Staff Data Engineer|VisaHybrid remote in Austin, TX|http://www.indeed.com/rc/clk?jk=1e58a20a21a2ea06&bb=9kdXdebxtoL5LCu5AWPBVaUq_bQ1tC8NaWT88S2RI2zqisSjfkCe4_e4GhoUb1Zb9yRLnuX2Ctfs67e_PoH1oHyyZdzvGrjZauLRO4-xJJM%3D&xkcb=SoB367M3CNjobgRSRx0ObzkdCdPP&fccid=a3f737e511d9fc8c&vjs=3|Profile insightsFind out how your skills align with the job descriptionSkillsDo you have experience in Testdriven developmentYesNoEducationDo you have a Masters degreeYesNo Job detailsHere’s how the job details align with your profilePay130100  188750 a year LocationAustin TX BenefitsPulled from the full job description401kDental insuranceFlexible spending accountHealth insuranceHealth savings accountLife insurancePaid time offShow morechevron down Full job description Company Description  Visa is a world leader in payments and technology with over 259 billion payments transactions flowing safely between consumers merchants financial institutions and government entities in more than 200 countries and territories each year Our mission is to connect the world through the most innovative convenient reliable and secure payments network enabling individuals businesses and economies to thrive while driven by a common purpose – to uplift everyone everywhere by being the best way to pay and be paid  Make an impact with a purposedriven industry leader Join us today and experience Life at Visa Job Description  Payments are a very exciting and fastdeveloping area with a lot of new and innovative ideas coming to market With strong demand for new solutions in this space it promises to be an exciting area of innovation VISA is a strong leader in the payment industry and is rapidly transitioning into a technology company with significant investments in this area  If you want to be in the exciting payment space learn fast and make big impacts Ecosystem  Operational Risk technology which is part of Visa’s ValueAdded Services business unit is an ideal place for you  In Ecosystem  Operational Risk group Payment Fraud Disruption team is responsible for building critical risk and fraud detection and prevention applications and services at Visa This includes idea generation architecture design development and testing of products applications and services that provide Visa clients with solutions to detect prevent and mitigate fraud for Visa and Visa client payment systems  This position is ideal for an experienced data engineer who is passionate about collaborating with business and technology partners in solving challenging fraud prevention problems You will be a key driver in the effort to define the shared strategic vision for the Payment Fraud Disruption platform and defining tools and services that safeguard Visa’s payment systems  The right candidate will possess strong ML and Data Science background with demonstrated experience in building training implementing and optimized advanced AI models for payments risk or fraud prevention products that created business value and delivered impact within the payments or payments risk domain or have experience building AIML solutions for similar industries  As a Data Engineer you will be responsible to establish processes automations structures and big data systems based on business and technical requirements to channel multiple requirements route appropriately and plan proper big data technology using combination of open source and vendor supported big data technologies databases and other applicable big data technologies as required  A successful candidate should have the ability to engage in high bandwidth conversations with business and technology partners and be able to think broadly about Visa’s business and drive solutions that will enhance the safety and integrity of Visa’s payment ecosystem The candidate will help deliver innovative insights to Visas strategic products and business This role represents an exciting opportunity to make key contributions to strategic offering for Visa This candidate needs to have strong academic track record and be able to demonstrate excellent software engineering skills The candidate will be a selfstarter comfortable with ambiguity with strong attention to detail and excellent collaboration skills  The ideal candidate will bring the excitement and passion to leverage Generative AI to advance existing fraud detection mechanisms and to innovate and solve new fraud use cases This engineer will use code generation capabilities like GitHub copilot to drive efficiencies in software development  Essential Functions  As a Data Engineer you will help design enhance and build next generation fraud detection solutions in an agile development environment Formulate business problems as technical data problems while ensuring key business drivers are captured in collaboration with product stakeholders Drive development effort endtoend for ontime delivery of highquality solutions that conform to requirements conform to the architectural vision and comply with all applicable standards Responsibilities span all phases of solution development Collaborate with project team members Product Managers Architects Analysts Developers Project Managers etc to ensure development and implementation of new data driven business solutions Work with architects where applicable or work as architect with senior technologists to develop architecture and design Deliver on all code commitments and ensure a complete endtoend solution that meets and exceeds business expectations Identify proper service metrics and measurements for ensuring performance against Service Level Agreement Assist in scoping and designing analytic data assets implementing modelled attributes and contributing to brainstorming sessions Build and maintain a robust data engineering process to develop and implement selfserve data and tools for Visa’s data scientists Perform other tasks on RD data governance system infrastructure analytics tool evaluation and other cross team functions on an asneeded basis Find opportunities to create automate and scale repeatable analyses or build selfservice tools for business users Execute data engineering projects ranging from small to large either individually or as part of a project team Ensure project delivery within timelines and budget requirements Mentor and train other juniors on the team on key solutions Able to work on multiple projects and initiatives with differentcompeting timelines and demands Present technical solutions capabilities considerations and features in business terms Effectively communicate status issues and risks in a precise and timely manner   This is a hybrid position Hybrid employees can alternate time between both remote and office Employees in hybrid roles are expected to work from the office 23 set days a week determined by leadershipsite with a general guidepost of being in the office 50 or more of the time based on business needs Qualifications   Basic Qualifications     5 years of relevant work experience with a Bachelor’s Degree or at least 2  years of work experience with an Advanced degree eg Masters MBA JD    MD or 0 years of work experience with a PhD OR 8 years of relevant work    experience     Preferred Qualifications     6 or more years of work experience with a Bachelors Degree or 4 or more  years of relevant experience with an Advanced Degree eg Masters MBA JD    MD or up to 3 years of relevant experience with a PhD     Experience with creating data driven business solutions and solving data  problems using a wide variety of technologies such as Hadoop MapReduce    Hive Spark Scala MongoDB NoSQL as well as traditional data technologies    like MySQL RDBMS     Experience building ETLELT data pipelines data quality checks and data  anomaly detection and notification systems     Experience with successful design architecture and development using  Hadoop Spark and Scala for large data processing and transaction systems     Experience in applications and services development using Java Experience in developing and architecting large scale enterprise class  distributed systems of high availability low latency  strong data consistency     Experience with agile development incorporating Continuous Integration and  Continuous Delivery utilizing technologies such as GITStash Maven Jenkins    Selenium and Chef     Experience in full stack technology in one or more of the following  technologies Java Spring MVC Spring Boot Angular JavaScript MySQL    Maven Design Patterns Test Automation framework     Expertise in web applications and webservices technology standards and  frameworks     Experienced in testdriven development and test automation Experience in card industry or fintech delivering solutions in fraud risk or  payments space     Strong facilitation and analytical skills with excellent problemsolving ability Strong interpersonal and leadership skills Ability to present complex ideas in a clear concise way Passionate about delivering zero defect code that meet or exceed the  proposed defect SLA and have high sense of accountability for quality and    timeliness of one’s own deliverables and team deliverables     Be systematic and be able to do deep research wanting to uncover the details Have good work ethics and be a team player to bring the best results as a  team     You have the passion to understand people and always strive to improve our  products     Highly driven resourceful and results oriented Demonstrated ability to lead and navigate through ambiguity While youll have the skill to see and understand the big picture youre able to  stay focused on the task at hand to achieve immediate goals   Additional Information  Work Hours Varies upon the needs of the department  Travel Requirements This position requires travel 510 of the time  MentalPhysical Requirements This position will be performed in an office setting The position will require the incumbent to sit and stand at a desk communicate in person and by telephone frequently operate standard office equipment such as telephones and computers  Visa is an EEO Employer Qualified applicants will receive consideration for employment without regard to race color religion sex national origin sexual orientation gender identity disability or protected veteran status Visa will also consider for employment qualified applicants with criminal histories in a manner consistent with EEOC guidelines and applicable local law  Visa will consider for employment qualified applicants with criminal histories in a manner consistent with applicable local law including the requirements of Article 49 of the San Francisco Police Code  US APPLICANTS ONLY The estimated salary range for a new hire into this position is 13010000 to 18875000 USD per year which may include potential sales incentive payments if applicable Salary may vary depending on jobrelated factors which may include knowledge skills experience and location In addition this position may be eligible for bonus and equity Visa has a comprehensive benefits package for which this position may be eligible that includes Medical Dental Vision 401 k FSAHSA Life Insurance Paid Time Off and Wellness Program  ||['design', 'testing', 'Data Science', 'AI', 'establish processes', 'big data', 'technical requirements', 'big data', 'big data', 'big data', 'drive solutions', 'insights', 'Generative AI', 'use cases', 'GitHub', 'copilot', 'Data Engineer', 'design', 'agile', 'data driven', 'designing analytic data', 'data governance', 'evaluation', 'business needs', 'data driven', 'Hadoop', 'MapReduce', 'Hive', 'Spark', 'Scala', 'MongoDB', 'NoSQL', 'MySQL', 'RDBMS', 'data pipelines', 'data quality', 'anomaly detection', 'design architecture', 'Hadoop', 'Spark', 'Scala', 'data processing', 'Java', 'data consistency', 'agile', 'Maven', 'Jenkins', 'Selenium', 'Java', 'Spring MVC', 'Spring Boot', 'Angular', 'JavaScript', 'MySQL', 'Maven', 'Design Patterns', 'Test Automation', 'web applications', 'test automation', 'analytical skills', 'research']
6|Data Engineer|Engineer III, Data Engineering (mult.)|Samsung ElectronicsRidgefield Park, NJ 07660|http://www.indeed.com/rc/clk?jk=44f9fad47fc734ae&bb=9kdXdebxtoL5LCu5AWPBVQcX_XoxABY2xn-rc75kJBuivaKOBfLlBqPeKzUNQMkke72xodzt_nnx-AqT0HBG_roHKQCAT0iXfxWWcNm11Ug%3D&xkcb=SoDq67M3CNjobgRSRx0NbzkdCdPP&fccid=da3c7fed78dd1607&vjs=3|Profile insightsFind out how your skills align with the job descriptionSkillsDo you have experience in SparkYesNoEducationDo you have a Bachelors degreeYesNo Location55 Challenger Road Ridgefield Park NJ 07660 Full job description    Position Summary    Implement complex big data projects with a focus on collecting parsing managing analyzing and visualizing large sets of data to turn information into actionable deliverables across customerfacing platforms       Role and Responsibilities        Implement complex big data projects with a focus on collecting parsing managing analyzing and visualizing large sets of data to turn information into actionable deliverables across customerfacing platforms Translate complex functional and technical requirements into detailed design Perform Hadoop technical development and implementation Load from disparate data sets by leveraging various big data technology including AWS EMR S3 Hadoop hive and pyspark Preprocess and support queries using Hive Impala Spark Presto and Pig Design and implement data modeling using hivepresto Hue and Erwin Data Modeler Maintain security and data privacy in an environment secured using Kerberos and LDAP Perform highspeed queries using inmemory technologies including Spark Follow and contribute best engineering practice for source control release management and deployment Provide production support job scheduling and monitoring ETL data quality and generate data freshness reporting        Requirements Bachelor’s degree in Computer Science Electronic Engineering Electrical Engineering Information Systems Technology or a related field and 5 years of progressive post baccalaureate experience as Engineer III Data Engineering or related occupation in the Big Data software development engineering Of the 5 years of experience must have included       Experience in writing complex SQL queries and highperformance reliable and maintainable code Experience with Python development for data analysis and data modeling Experience with Hadoop including Hive Spark Impala Pig and Oozie and Experience with AWSCloud components including EC2 S3 and EMR        LIDNI        Skills and Qualifications      At Samsung we believe that innovation and growth are driven by an inclusive culture and a diverse workforce We aim to create a global team where everyone belongs and has equal opportunities inspiring our talent to be their true selves Together we are building a better tomorrow for our customers partners and communities     Samsung Electronics America Inc and its subsidiaries are committed to employing a diverse workforce and provide Equal Employment Opportunity for all individuals regardless of race color religion gender age national origin marital status sexual orientation gender identity status as a protected veteran genetic information status as a qualified individual with a disability or any other characteristic protected by law       Reasonable Accommodations for Qualified Individuals with Disabilities During the Application Process       Samsung Electronics America is committed to providing reasonable accommodations for qualified individuals with disabilities in our job application process If you have a disability and require a reasonable accommodation in order to participate in the application process please contact our Reasonable Accommodation Team 8555573247 or SEAAccommodationsExtseasamsungcom for assistance This number is for accommodation requests only and is not intended for general employment inquiries    ||['big data', 'big data', 'collecting', 'parsing', 'technical requirements', 'design', 'Hadoop', 'Load', 'data sets', 'big data', 'AWS', 'EMR', 'S3', 'Hadoop', 'hive', 'pyspark', 'Preprocess', 'Hive', 'Spark', 'Presto', 'data modeling', 'Erwin', 'Data Modeler', 'data privacy', 'Spark', 'monitoring', 'ETL', 'data quality', 'reporting', 'Big Data', 'SQL', 'Python', 'data analysis', 'data modeling', 'Hadoop', 'Hive', 'Spark', 'EC2', 'S3', 'EMR', 'LIDNI']
7|Data Engineer|Senior Data Engineer|PluralsightRemote|http://www.indeed.com/rc/clk?jk=8be09d8eec212ba3&bb=9kdXdebxtoL5LCu5AWPBVTgBsVhrRxqQ4LpRud1ubHaC-k5q7O8ziNR8LJNqGnnq-abN1nEbG4bIVwxBmZEHzR2iN05a-FGZnfd3im94BpRDCyvMj04EmQ%3D%3D&xkcb=SoBe67M3CNjobgRSRx0MbzkdCdPP&fccid=51dc2e5aecda9e29&vjs=3|Profile insightsFind out how your skills align with the job descriptionSkillsDo you have experience in SparkYesNo Job detailsHere’s how the job details align with your profileJob typeFulltime LocationRemote Full job description    Job Description       The Opportunity        Our Data Engineering team within our Data Services Organization builds and maintains the infrastructure essential to delivering highvolume businesscritical data to the organization to enable datadriven decisions       We are focused on expanding our curated and modeled data that unify sources of truth across our multiple products and domains You’ll have the opportunity and empowerment to guide the team on best practices using modern distributed data tools like Snowflake Spark Kafka and dbt       This is an ideal opportunity for someone that has strong opinions on how things should be done and loves figuring out what the right solution is for the scenario at hand Your voice will be heard and will be given the opportunity to make an impact with the direction and delivery of our data platform to internal stakeholders        Who you are           5 years of experience designing and delivering data warehouses and marts to support business analytics            Hands on experience with dbt certification preferred            Solid foundation in SQL development on RDBMS Snowflake and Postgres preferred            Experience with dimensional data modelingdata workflow diagrams using Kimball methodology conceptual logical and physical            Experience with source control and deployment workflows for ETL dbt airflow preferred            Hands on experience with scripting languages Python BASH etc            Experience with metadata management and data quality            Knowledge of software engineering standard processes with experience with implementing CICD Gitlab Github Actions Teamcity etc monitoring  alerting for production systems           What you’ll own           Data Warehousing and modeling delivery            Support and evolution of data environment to deliver highquality data speed and availability            Curation of sourcesystem data to deliver trusted data sets            Involvement on data cataloging and data management efforts            Production ETL performance tuning and environmentlevel resource consumption and management            Migration of POC pipelines to production data processes           Experience you’ll need           Strong capability to manipulate and analyze complex highvolume data from a variety of sources            Good experience crafting and building endtoend data models and pipelines as well as alerting            Knowledge of data management fundamentals and data storage principles            Experience in data modeling for batch processing and streaming data feeds structured and unstructured data           Experience that’s a bonus           Expertise in streaming  realtime data processing using a technology like Spark Kafka ksqlDB or Databricks etc and best practices on production deployment of these platforms            Experience working with AWS services such as DynamoDB Glue Lambda Step Functions S3 CloudFormation           Bring yourself Pluralsight is an equal opportunity employer All qualified applicants will receive consideration for employment without regard to race color religion sex national origin sexual orientation gender identity disability age or protected veteran status Pluralsight will also consider for employment qualified applicants with criminal histories in a manner consistent with EEOC guidelines and applicable local law       We will ensure that individuals with disabilities are provided reasonable accommodation to participate in the job application or interview process to perform essential job functions and to receive other benefits and privileges of employment Please visit the        bottom of our website    to learn how to request an accommodation       For more information on Pluralsight’s commitment to building a more diverse and inclusive workforce please review our most recent Diversity Equity Inclusion and Belonging report        here           LISW1    ||['datadriven decisions', 'distributed data', 'Snowflake', 'Spark', 'Kafka', 'dbt', 'data platform', 'designing', 'data warehouses', 'dbt', 'SQL', 'RDBMS', 'Snowflake', 'Postgres', 'workflow diagrams', 'Kimball', 'ETL', 'dbt', 'airflow', 'Python', 'BASH', 'data quality', 'CICD', 'Gitlab', 'Github', 'monitoring', 'Data Warehousing', 'modeling', 'data sets', 'ETL', 'performance tuning', 'POC', 'pipelines', 'data models', 'pipelines', 'storage', 'data modeling', 'processing', 'streaming data', 'unstructured data', 'streaming', 'realtime data', 'processing', 'Spark', 'Kafka', 'Databricks', 'AWS', 'DynamoDB', 'Glue', 'Lambda', 'S3']
8|Data Engineer|Big Data Engineer|CEDENTAlpharetta, GA|http://www.indeed.com/rc/clk?jk=0b75f6bbaaafb80b&bb=9kdXdebxtoL5LCu5AWPBVTJk9L_scjWSq6oe0XrEzHVptQDsf4gcABPIfIrEpc0AKfpxUcqXr_FXJ-8ll6J7JZjmf3D51WWr3GDKRAVZzgbliMziD7Zv5g%3D%3D&xkcb=SoC367M3CNjobgRSRx0DbzkdCdPP&fccid=2ecf4575019bf07a&vjs=3|Profile insightsFind out how your skills align with the job descriptionSkillsDo you have experience in WindowsYesNoEducationDo you have a Bachelors degreeYesNo Job detailsHere’s how the job details align with your profileJob typeFulltime LocationAlpharetta GA BenefitsPulled from the full job descriptionOnthejob training Full job description Title Big Data Engineer  Alpharetta GA   Terms of Hire Full Time  Salary  Open  yr  Benefits   Job description   Develops moderately complex code using both front andor back end programming languages within multiple platforms as needed in collaboration with business and technology teams for internal and external client software solutions Designs creates and delivers moderately complex program specifications for code development and support on multiple projectsissues with a wide understanding of the application  database to better align interactions and technologies   Provides broad and indepth knowledge of analysis modification and development of complex codeunit testing in order to develop concise application documentation Performs and advises on testing validation requirements and corrective measures for complex code deficiencies and provides systemic proposals   Participates in client facing meetings joint venture discussions vendor partnership teams to determine solution approaches   Provides advise to leadership on the design development and enforcement of business  infrastructure application standards to include associated controls procedures and monitoring to ensure compliance and accuracy of data Applies a full understanding and indepth knowledge of procedures methodology and application standards to include Payment Card Industry PCI security compliance   Develops administers and recommends billable hours and resource estimates on complex initiatives projects and issues   Assists with onthejob training and provides indepth expertise and advice to software engineers  What Are We Looking For in This Role  Minimum Qualifications     BS in Computer Science Information Technology Business  Management Information Systems or related field   Typically minimum of 6 years  Professional Experience In Coding Designing Developing And Analyzing Data Typically has an advanced knowledge and use of two or more opposing front  back end languages  technologies from the following but not limited to two or more modern programming languages used in the enterprise experience working with various APIs external Services experience with both relational and NoSQL Databases Preferred Qualifications     BS in Computer Science Information Technology Business  Management Information Systems or related field   8 years professional Experience In Coding Designing Developing And Analyzing Data and experience with IBM Rational Tools  What Are Our Desired Skills and Capabilities   Skills  Knowledge  Having wideranging experience uses professional concepts and company objectives to resolve complex issues in creative and effective ways Some barriers to entry exist at this level eg deptpeer review  Job Complexity  Works on complex issues where analysis of situations or data requires an indepth evaluation of variable factors Exercises judgment in selecting methods techniques and evaluation criteria for obtaining results Networks with key contacts outside own area of expertise  Supervision  Determines methods and procedures on new assignments and may coordinate activities of other personnel Team Lead Operating Systems     Linux distributions including one or more for the following Ubuntu CentOSRHEL Amazon Linux   Microsoft Windows   zOS   TandemHPNonstop  What are the 34 nonnegotiable requirements of this position   What are the 34 nonnegotiable requirements of this position   Oracle  PLSQL    must be strong in this area Senior level or Lead level ONLY   You Will Enjoy     An opportunity to be a part of a great culture an awesome team a challenging work environment and some fun along the way   Apply today to learn more and be part of our Growth story  All applications will be kept strictly confidential and once shortlisted our team will be in touch with you for further discussions  ||['Big Data', 'code development', 'analysis', 'testing', 'monitoring', 'Coding', 'Designing', 'Developing', 'Analyzing Data', 'NoSQL', 'Coding', 'Designing', 'Developing', 'Analyzing Data', 'analysis', 'evaluation', 'evaluation', 'Linux', 'Linux', 'Windows', 'Oracle', 'PLSQL']
9|Data Engineer|Data Engineer Snaplogic|VeoliaTrevose, PA 19053|http://www.indeed.com/rc/clk?jk=309eef7c680fc212&bb=9kdXdebxtoL5LCu5AWPBVfWK_VNM_rH8XfyRisvaKkvrU2TVzQSQ-O5H24xP0YuRlxEMnvThze3JQqrderLaHfvPzwqaXB4haHJNl7OKAtUli44fxNtjRA%3D%3D&xkcb=SoAD67M3CNjobgRSRx0CbzkdCdPP&fccid=28ee277926be0542&vjs=3|Profile insightsFind out how your skills align with the job descriptionSkillsDo you have experience in S3YesNo LocationTrevose PA 19053 Full job description Veolia Water Technologies  Solutions VWTS is a worldwide leader in water recovery treatment and reuse We design and supply a range of water systems from food and beverage applications to municipal water to microelectronics ultrapure water and heavy industrial wastewater treatment We serve more than 50000 customers worldwide and treat more than 11 million cubic meters of water every day We simply aim to be the benchmark company for ecological transformation across the world   At WTS we realize diverse teams make smarter decisions deliver better results and build stronger communities We are an organization that champions diversity and inclusion at every rung of the ladder and are proud to be an equal opportunity workplace We offer challenging and meaningful careers with competitive benefits and flexible work arrangements   Summary of the Job The data engineer snaplogic architect will play a crucial role in designing implementing and optimizing integration solutions using the Snaplogic platform The role would require collaboration with cross functional teams to understand business requirements and translate them into efficient and scalable snaplogic solutions   Key Characteristics  Create endtoend integration solutions using Snaplogic that align with business goals requirements and technical requirements  Implement and configure Snaplogic pipelines to integrate diverse systems and data sources  Continuously improve and optimize existing Snaplogic workflows to enhance performance scalability and maintainability    Duties  Responsibilities  Diagnose and resolve issues related to Snaplogic integrations ensuring smooth and reliable operation  Implement data quality checks and monitoring processes to ensure data accuracy and consistency  Define maintain integration workbooks with supporting documentation around design end point connectivity and security  Define and implement improvements to increase system reliability security and performance  Monitor the health and performance of the HR Integrations    Hard Skills  Indepth knowledge and handson experience with Snaplogic platform features components and best practices  Strong working knowledge of modern programming languages ETLData Integration tools preferably SnapLogic and understanding of Cloud Concepts  Experience in leading integration solutions between Successfactors and other downstream platforms using snaplogic as the middleware    Soft Skills  Communication Strong communication and interpersonal skills to collaborate effectively with crossfunctional teams and stakeholders  Problem Solving Ability to identify opportunities and designing solutions which are sustainable  Achievement Ability to come up with new ideas based on experience and competencies to develop or implement new procedures or systems to improve the business and the client experience  Inclusive Passionate for working in different cultures and environments in a matrixed organization with a more universal and a diversity team  Team Player Ability to work with others toward a shared goal participating actively accountable and committed to the entire team respecting peers leadership stakeholders and clients    Education  Experience Required  8 years of SnapLogic ETL Services experience  5 years of related experience including MySQL NoSQL ETL and Data Integration  AWS Technologies RDS SQS S3 EC2 etc  RedShift data warehouse    Preferred  Preferred global experience    Working Conditions  Annual Travel at 5 of time    ||['business requirements', 'technical requirements', 'Implement', 'pipelines', 'data sources', 'optimize', 'Implement', 'data quality', 'monitoring', 'data accuracy', 'consistency', 'implement', 'reliability', 'Monitor', 'programming', 'Cloud Concepts', 'Problem Solving', 'identify opportunities', 'designing', 'ETL', 'MySQL', 'NoSQL', 'ETL', 'Data Integration', 'AWS', 'RDS', 'SQS', 'S3', 'EC2', 'RedShift', 'data warehouse']
10|Data Engineer|Sr. ETL Data Engineer III|Aflac, IncorporatedRemote|http://www.indeed.com/rc/clk?jk=a7a5fa4d1987ae78&bb=9kdXdebxtoL5LCu5AWPBVVx1GUCu7P8XhoH_HZgn6tZ4czQTWWujFLLddBpaALTWumBkOKBFUk0-47PV6OIoSS1cj2MzLh8tdYkTRyh-bu0%3D&xkcb=SoCe67M3CNjobgRSRx0BbzkdCdPP&fccid=8e5dab8caa064d1b&vjs=3|Profile insightsFind out how your skills align with the job descriptionSkillsDo you have experience in TableauYesNoEducationDo you have a Bachelors degreeYesNo LocationRemote BenefitsPulled from the full job description401kDental insuranceFlexible spending accountHealth insurancePaid time offParental leavePrescription drug insuranceShow morechevron down Full job description Salary Range 55000  140000   We’ve Got You Under Our Wing  We are the duck We develop and empower our people cultivate relationships give back to our community and celebrate every success along the way We do it all…The Aflac Way   Aflac a Fortune 500 company is an industry leader in voluntary insurance products that pay cash directly to policyholders and one of Americas bestknown brands Aflac has been recognized as Fortune’s 50 Best Workplaces for Diversity and as one of World’s Most Ethical Companies by Ethispherecom   Our business is about being there for people in need So ask yourself are you the duck If so there’s a home and a flourishing career for you at Aflac   Work Designation Depending on your location within the continental US this role may be hybrid or remote   If you live within 50 miles of the Aflac offices located in Columbus GA this role will be hybrid This means you will be expected to work in the office for at least 60 of the work week You will work from your home within the continental US for the remaining portion of the work week Details of this schedule will be discussed with your leadership  If you live more than 50 miles from the Aflac offices located in Columbus GA this role will be remote This means you will be expected to work from your home within the continental US If the role is remote there may be occasions that you are requested to come to the office based on business need Any requests to come to the office would be communicated with you in advance    What does it take to be successful at Aflac   Acting with Integrity  Communicating Effectively  Pursuing SelfDevelopment  Serving Customers  Supporting Change  Supporting Organizational Goals  Working with Diverse Populations    What does it take to be successful in this role   Advanced working SQL knowledge and experience working with relational databases query authoring SQL as well as working familiarity with a variety of databases  Advanced knowledge of SSIS SSRS and Business Objects  Experience building and optimizing ‘big data’ data pipelines architectures and data sets  Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement  Strong analytic skills related to working with unstructured datasets  Build processes supporting data transformation data structures metadata dependency and workload management  A successful history of manipulating processing and extracting value from large disconnected datasets  Working knowledge of message queuing stream processing and highly scalable ‘big data’ data stores  Strong project management and organizational skills  Experience supporting and working with crossfunctional teams in a dynamic environment    Education  Experience Required   Bachelor’s Degree in Computer Science Information Systems Analytics or related field  Four or more years of experience in data analytics or other related experience   Or an equivalent combination of education and experience   Experience Preferred   Experience in Tableau Infoworks  Devx and Github is preferred    Principal Duties  Responsibilities   Create and maintain optimal data pipeline architecture  Assemble large complex data sets that meet functional  nonfunctional business requirements  Identify design and implement internal process improvements automating manual processes optimizing data delivery redesigning infrastructure for greater scalability etc  Build the infrastructure required for optimal extraction transformation and loading of data from a wide variety of data sources using SQL and AWS ‘big data’ technologies  Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition operational efficiency and other key business performance metrics  Work with stakeholders to assist with datarelated technical issues and support their data infrastructure needs  Create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader  Work with data and analytics experts to strive for greater functionality in our data systems  Performs other duties as required    Total Rewards  This compensation range is specific to the job level and takes into account the wide range of factors that are considered in making compensation decisions including but not limited to education experience licensure certifications geographic location and internal equity The range has been created in good faith based on information known to Aflac at the time of the posting Compensation decisions are dependent on the circumstances of each case This salary range does not include any potential incentive pay or benefits however such information will be provided separately when appropriate The salary range for this position is 55000  140000   In addition to the base salary we offer an array of benefits to meet your needs including medical dental and vision coverage prescription drug coverage health care flexible spending dependent care flexible spending Aflac supplemental policies Accident Cancer Critical Illness and Hospital Indemnity offered at no costs to employee 401k plans annual bonuses and an opportunity to purchase company stock On an annual basis you’ll also be offered 11 paid holidays up to 20 days PTO to be used for any reason and if eligible state mandated sick leave Washington employees accrue 1 hour sick leave for every 40 hours worked and other leaves of absence if eligible when needed to support your physical financial and emotional wellbeing Aflac complies with all applicable leave laws including but not limited to sick and safe leave and adoption and parental leave in all states and localities  ||['SQL', 'relational databases', 'SQL', 'SSIS', 'SSRS', 'Business Objects', 'data pipelines', 'data sets', 'analysis', 'identify opportunities', 'datasets', 'data transformation', 'data structures', 'manipulating', 'processing', 'extracting', 'large disconnected datasets', 'message queuing', 'stream processing', 'data stores', 'project management', 'data analytics', 'Tableau', 'Infoworks', 'Devx', 'Github', 'data sets', 'business requirements', 'design', 'automating manual processes', 'optimizing data', 'redesigning infrastructure', 'extraction', 'transformation', 'loading', 'data sources', 'SQL', 'AWS', 'data infrastructure']
11|Data Engineer|Director, Data Engineer|PrudentialNewark, NJ 07102 (Central Business District area)|http://www.indeed.com/rc/clk?jk=64653758a2053a9b&bb=9kdXdebxtoL5LCu5AWPBVWH76GIAstAtue0XatjB_83dImP8HdciNepDdkf1R4aF1K2aYaR2RWNnsNElUmv8Y3wvm5fwJVNl37zfFuKcHcg%3D&xkcb=SoAq67M3CNjobgRSRx0AbzkdCdPP&fccid=9f38ffb6fcd14039&vjs=3|Profile insightsFind out how your skills align with the job descriptionSkillsDo you have experience in TableauYesNoEducationDo you have a Bachelors degreeYesNo Job detailsHere’s how the job details align with your profilePay173500  234700 a yearJob typeFulltime Location25 Lafayette St Newark NJ 07102 BenefitsPulled from the full job description401k matchingDental insuranceDisability insuranceEmployee stock purchase planHealth insuranceLife insuranceMilitary leaveShow morechevron down Full job description    Job Classification   Technology  Engineering  Cloud       Are you interested in building capabilities that enable the organization with innovation speed agility scalability and efficiency The Global Technology team is a purpose driven organization that takes great pride in our culture where digital transformation is built into our DNA When you join our organization at Prudential you’ll unlock an exciting and impactful career – all while growing your skills and advancing your profession at one of the world’s leading financial services institutions     Your Team  Role     As a Director Data Engineer you will partner with talented architects infrastructure engineers machine learning engineers data scientists and data analysts to improve many different products and services You will analyze design develop test and perform ongoing maintenance to build high quality data pipelines that drive platform delivery You will implement capabilities to solve sophisticated business problems deploy innovative products services and experiences to delight our customers In addition to deep technical expertise and experience you will bring excellent problem solving communication and teamwork skills along with agile ways of working strong business insight an inclusive leadership attitude and a continuous learning focus to all that you do     Here is What You Can Expect on a Typical Day     Build and optimize data pipelines logic and storage systems with latest coding practices and industry standards and modern design patterns and architectural principles remove complex technical impediments Develop high quality well documented and efficient code adhering to all applicable Prudential standards Conduct complex data analysis and report on results prepare data for prescriptive and predictive modeling combine raw information from different sources Collaborate with data analysts scientists and architects on data projects to enhance data acquisition transformation organization processes data reliability efficiency and quality Write unit integration tests and functional automation researching problems discovered by quality assurance or product support developing solutions to address the problems Bring a deep understanding of relevant and emerging technologies give technical direction to team members and embed learning and innovation in the daytoday Work on significant and unique issues where analysis of situations or data requires an evaluation of intangible variables and may impact future concepts products or technologies If people leader please add Use programming languages including but not limited to Python R SQL Java Scala PysparkApache Spark Shell scripting   The Skills  Expertise You Bring      Bachelor of Computer Science or Engineering or experience in related fields Experience in working with DevOps automation tools  practices Knowledge of full software development life cycle SDLC Ability to lead independently with minimal guidance and effectively leverage diverse ideas experiences thoughts and perspectives to the benefit of the organization Knowledge of business concepts tools and processes that are needed for making sound decisions in the context of the companys business Ability to learn new skills and knowledge on an ongoing basis through selfinitiative and tackling challenges Excellent problem solving communication and collaboration skills enjoy learning new skills Significant experience andor deep expertise with several of the following  o Programming Language Python R SQL Java Scala PysparkApache Spark Shell scripting    o Data Ingestion Integration  Transformation Moving data from multiple sources formats and volumes to analytics platforms through various tools Preparing data for further analysis transforming and mapping raw data to generate insights and wrangling data through tools    o Database Management System Storing organizing managing and delivering data using relational DBs NoSQL DBs Graph DBs and data warehouse technologies including AWS Redshift and Snowflake    o Database tools Data architecture to store organize and manage data Experience with SQL and NoSQL based databases for storage and processing of structured semistructured  unstructured data    RealTime Analytics Spark Kinesis Data Streams    Data Buffering Kinesis Kafka    Workflow Orchesration Airflow AppFlow Austosys Cloudwatch Splunk    Data Visualization Tableau Power BI MS Excel    o Data Lakes  Warehousing Building Data Models Data Lakes and Data Warehousing    o Data Protection and Security Knowledge of data protection security principles and services data loss prevention role based access controls data encryption data access capture and core security services    o Common Infrastructure as Code IaC Frameworks Ansible CloudFormation    o Cloud Computing Knowledge of fundamentals of AWS architectural principles and services Strong ability on cloud formation and to write code Knowledge of AWS core services    o TestingQuality Unit interface and end user testing concepts and tooling inclusive of nonfunctional requirements performance usability reliability securityvulnerability scanning etc including how testing integrated into Dev Ops accessibility awareness     Preferred qualifications  o Serverless data pipeline development using AWS Glue Lambda and Step functions    o Other Certifications        What we offer you     Market competitive base salaries with a yearly bonus potential at every level  Medical dental vision life insurance disability insurance Paid Time Off PTO and leave of absences such as parental and military leave  Retirement plans  401k plan with company match up to 4  Companyfunded pension plan  Wellness Programs to help you achieve your wellbeing goals including up to 1600 a year for reimbursement of items purchased to support personal wellbeing needs  WorkLife Resources to help support topics such as parenting housing senior care finances pets legal matters education emotional and mental health and career development  Tuition Assistance to help finance traditional college enrollment toward obtaining an approved degree many accredited certificate programs and industry designations  Employee Stock Purchase Plan Shares can be purchased at 85 of the lower of two prices Beginning or End of the purchase period after one year of service       To find out more about our Total Reward package visit        Work Life Balance  Prudential Careers    Some of the above benefits may not apply to parttime employees scheduled to work less than 20 hours per week     You’ll Love Working Here Because You Can    Join a team and culture where your voice matters where every day your work transforms our experiences to make lives better As you put your skills to use we’ll help you make an even bigger impact with learning experiences that can grow your technical AND leadership capabilities You’ll be surprised by what this rocksolid organization has in store for you    Note Prudential is required by state specific laws to include the salary range for this role when hiring a resident in applicable locations The salary range for this role is from 17350000 to 23470000 Specific pricing for the role may vary within the above range based on many factors including geographic location candidate experience and skills Roles may also be eligible for additional compensation andor benefits Eligibility to participate in a discretionary annual incentive program is subject to the rules governing the program whereby an award if any depends on various factors including without limitation individual and organizational performance In addition employees are eligible for standard benefits package including paid time off medical dental and retirement                                                                      Prudential Financial Inc of the United States is not affiliated with Prudential plc which is headquartered in the United Kingdom                                                                 Prudential is a multinational financial services leader with operations in the United States Asia Europe and Latin America Leveraging its heritage of life insurance and asset management expertise Prudential is focused on helping individual and institutional customers grow and protect their wealth The companys wellknown Rock symbol is an icon of strength stability expertise and innovation that has stood the test of time Prudentials businesses offer a variety of products and services including life insurance annuities retirementrelated services mutual funds asset management and real estate services                                                                 We recognize that our strength and success are directly linked to the quality and skills of our diverse associates We are proud to be a place where talented people who want to make a difference can grow as professionals leaders and as individuals Visit                                                               wwwprudentialcom                                to learn more about our values our history and our brand                                                                 Prudential is an equal opportunity employer All qualified applicants will receive consideration for employment without regard to race color religion national origin ancestry sex sexual orientation gender identity national origin genetics disability marital status age veteran status domestic partner status  medical condition or any other characteristic protected by law                                                                 The Prudential Insurance Company of America Newark NJ and its affiliates                                                                 Note that this posting is intended for individual applicants Search firms or agencies should email Staffing at                                                               staffingagenciesprudentialcom                                for more information about doing business with Prudential                                                                 PEOPLE WITH DISABILITIES                                If you need an accommodation to complete the application process which may include an assessment please email                                                               accommodationshwprudentialcom                                                                                                Please note that the above email is solely for individuals with disabilities requesting an accommodation If you are experiencing a technical issue with your application or an assessment please email                                                               careerstechnicalsupportprudentialcom                                to request assistance                                                                    ||['Classification', 'Cloud', 'digital transformation', 'machine learning', 'data pipelines', 'implement', 'technical expertise', 'problem solving', 'agile', 'optimize', 'data pipelines', 'storage', 'design patterns', 'Develop', 'data analysis', 'predictive modeling', 'transformation', 'data reliability', 'automation', 'quality assurance', 'analysis', 'evaluation', 'Python', 'R', 'SQL', 'Java', 'Scala', 'Spark', 'Shell', 'DevOps', 'automation', 'software development life cycle', 'SDLC', 'problem solving', 'Programming', 'Python', 'R', 'SQL', 'Java', 'Scala', 'Spark', 'Shell', 'Transformation', 'analysis', 'transforming', 'raw data', 'generate insights', 'Database Management System', 'NoSQL', 'data warehouse', 'AWS', 'Redshift', 'Snowflake', 'SQL', 'NoSQL', 'storage', 'processing', 'unstructured data', 'Spark', 'Kinesis', 'Data Streams', 'Kinesis', 'Kafka', 'Airflow', 'Splunk', 'Data Visualization', 'Tableau', 'Power BI', 'MS Excel', 'Data Lakes', 'Data Models', 'Data Lakes', 'Data Warehousing', 'Data Protection', 'data protection', 'security principles', 'data loss prevention', 'role based access', 'data encryption', 'data access', 'Ansible', 'Cloud Computing', 'AWS', 'AWS', 'end user testing', 'reliability', 'pipeline development', 'AWS', 'Glue', 'Lambda']
12|Data Engineer|Senior Data Engineer|GantriSan Francisco, CA|http://www.indeed.com/rc/clk?jk=cfe5b2f2b0a996ea&bb=9kdXdebxtoL5LCu5AWPBVeLJaaN-StCUkdnYlAhsfOVrBFRmzZFJxN4PeeQWSJUQJHIRAXrGsc9YX-5f3VEKw-e3G0pwmWCYXeau6FPsU7GQQxj3selDAg%3D%3D&xkcb=SoCk67M3CNjobgRSRx0HbzkdCdPP&fccid=0ae5fffdc0fd2f94&vjs=3|Profile insightsFind out how your skills align with the job descriptionSkillsDo you have experience in TableauYesNoEducationDo you have a Bachelors degreeYesNo Job detailsHere’s how the job details align with your profilePay165000  185000 a yearJob typeFulltime LocationSan Francisco CA BenefitsPulled from the full job description401kDental insuranceHealth insurancePaid time offVision insurance Full job description   Company     Gantri is the world’s first digital manufacturer for creative lighting We help independent designers studios and influencers to develop original sustainably made lighting designs and sell directly to consumers We manufacture and fulfill all orders ondemand using 3D printing from innovative plantbased materials       Since launching in 2017 we’ve collaborated with the world’s best designers and studios including Ammunition Beats by Dre Smart Design OXO and Karim Rashid We’re the most awarded lighting brand in the US winning Time’s Best Inventions Fast Company’s Most Innovative in Design and many other awards       Role       Join Gantri as our first ever Data Engineer       Gantri is a highly collaborative vertically integrated organization that operates across manufacturing hardware software product design and marketing We believe that data is the key to helping us prioritize the right problems to solve and deliver even better products for our customers       As our founding Data Engineer you’ll have the opportunity to shape our data strategy and architecture You’ll get to design and implement scalable data pipelines build robust data warehousing solutions and enable advanced analytics capabilities This role offers immense growth potential as you establish data engineering best practices across the company and mentor other team members You’ll sit within our software organization and collaborate closely with all teams across the company       Responsibilities    Design build and maintain scalable and efficient data pipelines to collect process and store data from various sources including our inhouse manufacturing software and ecommerce platforms  Develop and maintain data warehouse architecture to ensure reliability accuracy performance and accessibility of data for analytics and reporting purposes  Collaborate with software engineers to integrate data collection and instrumentation into existing and new systems ensuring data quality and consistency  Create data models and schema designs to support reporting analytics and visualization needs of different teams within the organization  Implement data governance and security best practices to protect sensitive information and ensure compliance with regulations  Choose design and develop data visualization dashboards and tools to enable stakeholders to monitor key performance metrics and make datadriven decisions  Conduct exploratory data analysis and provide insights to support strategic decisionmaking and identify opportunities for business improvement  Stay current with industry trends tools and technologies related to data engineering analytics and visualization and recommend and implement improvements to our data infrastructure and processes       Requirements    Bachelors degree or higher in Computer Science Engineering or a related field  Proven experience 5 years as a data engineer or similar role with a strong track record of building and maintaining data infrastructure and pipelines  Proficiency in SQL and experience working with relational databases eg PostgreSQL MySQL and data warehousing solutions eg Redshift BigQuery  Experience with cloud platforms such as AWS Azure or Google Cloud and familiarity with services like S3 EC2 EMR or equivalent  Strong programming skills in languages such as Python Java or Scala and experience with data processing frameworks like Apache Spark or Apache Flink  Experience with data visualization tools such as Tableau Looker or Power BI and proficiency in data manipulation and visualization techniques  Excellent communication and collaboration skills with the ability to work effectively in crossfunctional teams and translate business requirements into technical solutions  Strong problemsolving skills and attention to detail with a passion for continuous learning and improvement  Bonus Experience working in a directtoconsumer or manufacturing industry with knowledge of manufacturing processes and systems  Bonus Experience with machine learning predictive analytics or data science techniques       Benefits    Competitive salary and equity  Medical dental and vision insurance  401k  Paid vacation days and paid holidays  Work from X benefits  Access to 3D printers for your personal projects  Monthly team lunches  And much more          165000  185000 a year      ||['product design', 'design', 'implement', 'data pipelines', 'data warehousing', 'analytics capabilities', 'data pipelines', 'data warehouse', 'reliability', 'reporting', 'data collection', 'data quality', 'consistency', 'data models', 'reporting', 'visualization', 'teams', 'Implement', 'data governance', 'develop', 'data visualization', 'dashboards', 'monitor', 'datadriven decisions', 'exploratory data analysis', 'provide insights', 'identify opportunities', 'trends', 'visualization', 'data infrastructure', 'data engineer', 'maintaining', 'data infrastructure', 'pipelines', 'SQL', 'relational databases', 'PostgreSQL', 'MySQL', 'data warehousing', 'Redshift', 'BigQuery', 'cloud', 'AWS', 'Azure', 'Google Cloud', 'S3', 'EC2', 'EMR', 'Python', 'Java', 'Scala', 'data processing', 'Apache', 'Spark', 'Apache Flink', 'data visualization', 'Tableau', 'Looker', 'Power BI', 'data manipulation', 'visualization', 'business requirements', 'problemsolving skills', 'machine learning', 'predictive analytics', 'data science']
