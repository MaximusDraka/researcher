profile|url|id|data|resume_html
Data Engineer|https://www.livecareer.com/resume-search/r/data-engineer-2803c6ab603a4a0681e372b5316189e3|280519406331163022609303386259277165013|Jessica    Claire                   Montgomery Street     San Francisco     CA  94105    609 Johnson Ave       49204     Tulsa     OK       Home   555 4321000    Cell       resumesampleexamplecom              Professional Summary      Energetic Data Engineer in developing robust code for highvolume businesses Strong decisionmaker with 6 years of experience in Data engineering and help firms in designing and executing solutions for complex business problems involving large scale data warehousing realtime analytics and reporting solutions Ability to translate business questions and concerns into specific quantitative questions that can be answered with available data using sound methodologies        Skills           Python 3x R SQL  Hadoop Apache Spark  Hive Pig Kafka Sqoop Oozie  Teradata Snowflake      Amazon S3EMRLambda  Git Jenkins Splunk  MS Office  Microsoft Visual CNET                       Work History       Data Engineer       042020   to   Current     Avanade    –    Bangor     ME             Combining data from multiple source systems Profile Systematics etc and multiple platforms Snowflake OneLake Hubs and computing canonical goldstar metrics “once and for all” to cut operational costs  Develop Spark jobs to transform data and apply business transformation rules to loadprocess data across enterprise and application specific layers  Experience in buildingoperatingmaintaining fault tolerant and scalable data processing integrations using AWS  Configured S3 buckets with various life cycle policies to archive the infrequently accessed data based on requirement  Good working experience on submitting the Spark jobs which shows the metrics of the data which is used for Data Quality Checking  Working on building efficient data pipelines that transform high volume data into a format used for analytical fraud prevention and ML use cases  Extensively used Splunk Search Processing Language SPL queries Reports Alerts and Dashboards  Excellent knowledge of source control management concepts such as Branching Merging LabelingTagging and Integration with tool like Git  Performing Data Quality checks like row count schema validation Hash key validation for all data movement between applications           Data Engineer       082019   to   042020     Avanade    –    Burlington     NC             Responsible for designing and developing various analytical solutions for gaining analytical insights into large data sets by ingesting and transforming these datasets in the Big Data environment using technologies like Spark Sqoop Oozie HIVE  Scheduling jobs to automate the process for regular executing jobs worked on using Oozie  Developed Oozie workflow schedulers to run multiple Hive and Pig jobs that run independently with time and data availability  Familiar with data architecture including data ingestion pipeline design Hadoop information architecture data modeling and data mining  machine learning and advanced data processing  All the projects which I have worked for are Open Source Projects and has been tracked using JIRA  Parallel copying of files between various clusters using Distcp Kafka in Hadoop           Data Scientist Intern       092018   to   122018     Ascend Learning    –    Memphis     TN             Acquire clean integrate analyze and interpret disparate datasets using a variety of statistical data analysis and data visualization methodologies reporting and authoring findings where appropriate  Developed Linear Mixed Effects Models for Boston Edfi dataset to estimate the teacher contribution to the student test scores  Random intercept model which utilized a preposttest design and included fixed effects for student demographics and a growth model where students were nested by time random slope and intercept and teacher was tested  Generated various Clustering models for entire West Virginia department of education and evaluated cluster’s performance           Big Data Engineer       012014   to   072017     Verizon    –                      Identify customers digital analytical needs and engage with customer and principal architects daily understand the business requirements for big data analytical solutions and break down large scale requirements into detailed system specifications  Moving data to HDFS framework using SQOOP from Teradata SQL Server  Good working experience on Hadoop tools related to Data warehousing like Hive Pig and also involved in extracting the data from these tools on to the cluster using Sqoop  Solved performance issues in Hive with understanding of joins groups bucketing partitions and working on them using HiveQL  Deployed programs written in PySpark to run Spark MLlib for analytics and reduced customers churn rate by 25          Education       Master of Science     Business Analytics     Expected in   4 2020     The University Of Texas At Dallas      Richardson     TX     GPA               Websites Portfolios Profiles        httpswwwlinkedincominJessicaClaire    httpwwwgithubcomJessicaClaire                  Skills       Python 3x R SQL  Hadoop Apache Spark  Hive Pig Kafka Sqoop Oozie  Teradata Snowflake    Amazon S3EMRLambda  Git Jenkins Splunk  MS Office  Microsoft Visual CNET         Work History       Data Engineer     042020   to   Current     Capital One Financial Corp   –   Wilmington     DE      Combining data from multiple source systems Profile Systematics etc and multiple platforms Snowflake OneLake Hubs and computing canonical goldstar metrics “once and for all” to cut operational costs  Develop Spark jobs to transform data and apply business transformation rules to loadprocess data across enterprise and application specific layers  Experience in buildingoperatingmaintaining fault tolerant and scalable data processing integrations using AWS  Configured S3 buckets with various life cycle policies to archive the infrequently accessed data based on requirement  Good working experience on submitting the Spark jobs which shows the metrics of the data which is used for Data Quality Checking  Working on building efficient data pipelines that transform high volume data into a format used for analytical fraud prevention and ML use cases  Extensively used Splunk Search Processing Language SPL queries Reports Alerts and Dashboards  Excellent knowledge of source control management concepts such as Branching Merging LabelingTagging and Integration with tool like Git  Performing Data Quality checks like row count schema validation Hash key validation for all data movement between applications           Data Engineer     082019   to   042020     Verizon Wireless   –   Tampa     FL      Responsible for designing and developing various analytical solutions for gaining analytical insights into large data sets by ingesting and transforming these datasets in the Big Data environment using technologies like Spark Sqoop Oozie HIVE  Scheduling jobs to automate the process for regular executing jobs worked on using Oozie  Developed Oozie workflow schedulers to run multiple Hive and Pig jobs that run independently with time and data availability  Familiar with data architecture including data ingestion pipeline design Hadoop information architecture data modeling and data mining  machine learning and advanced data processing  All the projects which I have worked for are Open Source Projects and has been tracked using JIRA  Parallel copying of files between various clusters using Distcp Kafka in Hadoop           Data Scientist Intern     092018   to   122018     Hoonuit   –   Minneapolis     MN      Acquire clean integrate analyze and interpret disparate datasets using a variety of statistical data analysis and data visualization methodologies reporting and authoring findings where appropriate  Developed Linear Mixed Effects Models for Boston Edfi dataset to estimate the teacher contribution to the student test scores  Random intercept model which utilized a preposttest design and included fixed effects for student demographics and a growth model where students were nested by time random slope and intercept and teacher was tested  Generated various Clustering models for entire West Virginia department of education and evaluated cluster’s performance           Big Data Engineer     012014   to   072017     Tata Consultancy Services   –              Identify customers digital analytical needs and engage with customer and principal architects daily understand the business requirements for big data analytical solutions and break down large scale requirements into detailed system specifications  Moving data to HDFS framework using SQOOP from Teradata SQL Server  Good working experience on Hadoop tools related to Data warehousing like Hive Pig and also involved in extracting the data from these tools on to the cluster using Sqoop  Solved performance issues in Hive with understanding of joins groups bucketing partitions and working on them using HiveQL  Deployed programs written in PySpark to run Spark MLlib for analytics and reduced customers churn rate by 25|none
Data Engineer|https://www.livecareer.com/resume-search/r/data-engineer-3fb6a76ff6b44876ada5d6b8ca0e51f7|101004532999732917696975093886375431500|Jessica    Claire                   Montgomery Street     San Francisco     CA  94105    609 Johnson Ave       49204     Tulsa     OK       H   555 4321000    C       resumesampleexamplecom    Date of Birth         India                      single                    Summary     Involving in various projects related to Data Modeling Data Analysis Design and Development for Data warehousing environments Practical understanding of the Data modeling Dimensional  Relational concepts like StarSchema Modeling Snowflake Schema Modeling Fact and Dimension tables Comprehensive knowledge and experience in process improvement normalizationdenormalization data extraction data cleansing data manipulation Exceptional troubleshooting skills with ETL Technologies        Highlights         Hadoop Hive Avro Kafka MapReduce Looker Programming Languages SQL Java Scala PHP Shell Script HTML Database Tools Aster Database PostgreSQL MySQL Operating Systems Linux Unix Microsoft Windows                       Accomplishments              Experience       Data Engineer       082012      Current     Avanade    –    Greenville     NC            Experience with full development cycle of a Data Warehouse including requirements gathering design implementation and maintenance  Data modeling based on Kimball methodology developed and architected ETL processes for different projects RMA inventory purchase order etc Reengineer some of the current ETL processes to streamline the data acquisition and integration process using our homegrown ETL tools  Built eventdriven data pipeline that comprises multiple steps to gather high volume and velocity data from both push based and pull based sources which includes design and implement web service to collect data JSON object over http request convert data in JSON format into Avro then feed into Kafka land data in Kafka on Hadoop and Aster  Designed and built Looker API using Scala which makes other teams access the data in data warehouse more easily and gracefully  Establish and maintain SQL queries and routines  Write adhoc queries based upon the schema understanding for diverse needs of our business users           Java Intern       022012      032012     Dominion Enterprises    –    Fredericksburg     VA            Implemented code for small features  bugfixes in Java           PHP Developer       062011      092011     Meetoncruise    –    City     STATE            Implemented the backend logic using PHP  Utilized JQuery and AJAX to provide dynamic and interactive user interface  Designed and implemented data model in MySQL database to support the website          Education       Master of Science       Electrical and Computer Engineering       Expected in   2012                Polytechnic Institute of New York University      Brooklyn     NY     GPA        Status         Electrical and Computer Engineering         Bachelor of Science       Automation Engineering       Expected in   2010                Nanjing University of Aeronautics and Astronautics      Nanjing     Jiangsu     GPA        Status         Automation Engineering        Skills     streamline ad AJAX API data acquisition Data modeling data warehouse Database engineer ETL features HTML http PHP inventory Java JQuery JSON Linux logic access Microsoft Windows MySQL Operating Systems PostgreSQL processes Programming requirements gathering Shell Script SQL Unix user interface website|none
Data Engineer|https://www.livecareer.com/resume-search/r/data-engineer-71257baffbce48d4a96368645e3008da|26624075482424204881256882949061507743|Jessica    Claire                   Montgomery Street     San Francisco     CA  94105    609 Johnson Ave       49204     Tulsa     OK       Home   555 4321000    Cell       resumesampleexamplecom              Summary      Over 5 years of engineering and finance experience as a Data Developer with cross platform integration experience using Hadoop and Spark architecture Handson experience configuring as well as installing Hadoop Ecosystem  HDFS MapReduce Pig Hive Oozie Flume HBase Spark Sqoop Flume and Oozie Strong understanding of various Hadoop services MapReduce and YARN architecture Vast knowledge in importing as well as exporting data in HDFS using SQOOP Automated transfer of data from Hbase by developing Map Reduce jobs Expertise in analysis using PIG HIVE and MapReduce Experience in HDFS data storage and support for running mapreduce jobs Involved in Infrastructure set up and installation of HDP stack on Amazon Cloud Experienced with ingesting data from RDBMS such as SQL Teradata into HDFS using Sqoop and Oracle Expertise in Hadoop architecture HDFS Mapreduce Oozie Sqoop Spark Hive Zookeeper and NoSQL databases Deployed and configured clusters in Cloudera Manager Set up backups and disaster recovery for Data Node and Name Node metadata as well as sensitive data on clusters Expertise in implementing and designing HDFS access controls directory and file permissions user authorization that facilitates stable secure access for multiple users in a large multitenant cluster Knowledge on exporting as well as importing stream data into HDFS using Flume Spark and Kafka messaging systems Utilized various schedulers on the Job tracker to share resources within clusters for Map Reduce jobs such as FIFO scheduler Fair Scheduler and Capacity Scheduler Monitored jobs with YARN and provisioned configured and installed HBase Kafka Hive Oozie Sqoop Ranger Storm Flume Spark as well as maintained total architecture AWS services for cloud migration such as S3 Redshift EMR Glue Athena and DynamoDB Expertise in Vertica DB architecture High Availability and column orientation Great knowledge of Agile and Scrum methodologies Behavior Driven Development Domain Driven DesignTest Driven Development and continuous integration as well as delivery Skilled in defining functional and gathering user interface requirements for applications and websites Expertise in real time analysis by utilizing RDD Datasets Data Frames and Streaming API in Apache Spark Expertise in using Spark Resilient distributed datasets and dataframe APIs over the Cloudera platform to perform analytics on Hive data by integrating Hadoop with Kafka Expertise in uploading Click stream data from Kafka to HDFS Expert in utilizing Kafka for messaging and publishing subscriber based messaging systems  Worked with NoSQL databases such as Cassandra HBASE PostgreSQL MongoDB Redis DynamoDB        Skills           SQL transactional replications  SAN technologies  Reverse engineering skills  Warehouse models  Security Protocols  Enterprise information architecture      Quality analysis  Deep learning  Data mining  Data analytics  Critical thinking                       Experience       Data Engineer       072021   to   Current     Principal Financial Group    –    Pittsburgh     PA            Analyze design and build Modern data solutions using Azure PaaS service to support visualization of data  Understand current Production state of application and determine the impact of new implementation on existing business processes  Extract Transform and Load data from Sources Systems to Azure Data Storage services using a combination of Azure Data Factory TSQL Spark SQL and USQL Azure Data Lake Analytics Data Ingestion to one or more Azure Services  Azure Data Lake Azure Storage Azure SQL Azure DW and processing the data in In Azure Databricks  Created Pipelines in ADF using Linked  ServicesDatasetsPipeline to Extract Transform and load data from different sources like Azure SQL Blob storage Azure SQL Data warehouse writeback tool and backwards  Developed Spark applications using Pyspark and  SparkSQL for data extraction transformation and  aggregation from multiple file formats for analyzing  transforming the data to uncover insights into the  customer usage patterns  Responsible for estimating the cluster size monitoring  and troubleshooting of the Spark databricks cluster  Experienced in performance tuning of Spark  Applications for setting right Batch Interval time  correct level of Parallelism and memory tuning   Adept in troubleshooting and identifying current issues and providing effective solutions  Managed performance monitoring and tuning while identifying and repairing issues within database realm  Contributed to maintaining  Type  databases in conjunction with data development and software engineering teams  Assisted solution providers with definition and implementation of technical and business strategies  Collaborated with solution architects to define database and analytics engagement strategies for operational territories and key accounts           Data Engineer       072020   to   062022     Principal Financial Group    –    Portland     OR             Worked on MongoDB by using CRUD Create Read Update and Delete Indexing Replication and Sharding features  Involved in designing the row key in HBase to store Text and JSON as key values in the HBase table and designed row key in such a way to getscan it in sorted order  Oozie was integrated with the Hadoop stack which consists of MapReduce Hive Sqoop and Pig and Unix shell scripts  While working on Hive tables used Hive QL designed and Implemented PartitioningStatic Dynamic Buckets on Hive  Performed Cache and Persist as well as Checkpointing when utilizing Spark Streaming APIs to build common learning data models to get near realtime data from Kafka and persisted into Cassandra  Conducted cluster coordination services with Zookeeper and monitored the workload capacity planning and job performance through Cloudera Manager  Built applications by utilizing Maven and integrated with Continuous Integration servers such as Jenkins to build jobs  Deployed maintained and configured Test and multinode Dev Kafka Clusters as well as handled clusters and implemented data ingestion for real time processing in Kafka  Created cubes in Talend for various aggregation types of data from PostgreSQL and MS SQL server to visualize data  Monitored Name Node health status in Hadoop as well as the number of Data Nodes and Task trackers running along with automating jobs to pull data from various MySQL data sources to push result set data to HDFS  Created story telling dashboards through Tableau Desktop to publish on Tableau Server and integrated GitHub for version control tools to maintain the versions in projects  Deployed Spark applications in python and utilized Datasets and DataFrames in Spark SQL for processing data faster  Loaded transactional data with Sqoop from Teradata created managed and external tables in Hive and worked with semistructured and structured data of 5 Petabytes in size  Constructed MapReduce jobs to validate clean and access data and worked with Sqoop jobs with incremental load to populate and load into Hive External tables  Designed strategies to optimize distribution of weblog data over clusters in addition to exporting and importing stored web log data into Hive and HDFS through Sqoop  Responsibilities of building scalable data solutions that are distributed through Hadoop and Cloudera as well as developed and designed automated test scripts in Python  Integrated Apache Storm with Kafka to perform web analytics and to perform clickstream data from Kafka to HDFS  Developed SQL scripts and designed solutions to implement Spark with Hive Generic UDFs for incorporating business logic within Hive queries  Developed data pipelines in AWS using S3 EMR Redshift to extract data from weblogs to store into HDFS  Transmitted streaming data from Kafka to HBase Hive and HDFS by integrating Apache Storm and wrote Pig scripts for transforming raw data from various data sources to form baseline data  Participated in Agile meetings Ford Credit Customer Data domain conducted daily scrum meetings and spring planning  Expanded and optimized data pipelines and architecture as well as optimized data flow and collection  Created pipelines from scratch using PySpark and scheduled jobs using Airflow  Stream processed data in Kafka streaming wrote Producer Consumer Connector and Streams API to handle stream of records subscription of topics consume input and build reusable producers and consumers  Worked with unstructured datasets such as IoT sources sensor data XML and JSON document sources  Worked with on prem clusters as well as clusters on the cloud and used GCP Big Query Data Fusion and DataFlow  Scaled up architecture with Google Kubernetes and set up load balancing  Worked on various optimization techniques in Spark such as cache and persist using accumulators  bucketing and partitioning garbage collection tuning data serialization windowing functions and broadcast variables  Used numerous Spark transformations such as groupByKeyreduceByKey flatMap filter sample union etc  Utilized Dataproc to spin up clusters Dataprep for data analysis and Dataflow for streaming data using Apache Beam  Dealt with VPC controls on Google Cloud Platform and CMEK encryption for data security  Environment Hadoop HDFS HBase SparkPython and Scala Azure Databricks Scala Hive Kafka MapReduce Sqoop ETL Java Python PostgreSQL SQL Server Teradata UnixLinux           Big Data Developer       052017   to   052020     Cognizant Technology Solutions    –    Mount Laurel     NJ             Performed query tuning in HiveQL as well as performance tuning transformations in Pyspark using Spark RDDs and Python  Used lambda functions to create a Serverless Data intake pipeline on AWS  Using python constructed a Spark Streaming pipeline to receive realtime data from Apache Kafka and store it in DynamoDB  Implemented Apache Spark data processing module to handle data from multiple RDBMS and Streaming sources then compiled Apache Spark applications using Scala and Python  Extensive experience designing and scheduling multiple Spark Streaming  batch Jobs in Python pyspark and Scala  Achieved highthroughput scalable faulttolerant stream processing of live data streams using Apache Spark Streaming  Involved with the use for creating and saving data frames using various Python modules with pyspark  Sqooped data and performed Hive queries for data ingestion from relational databases to analyze historical data  Experienced with Elastic MapReduce EMR as well as setting up environments on amazon AWS EC2 instances for pipelines in AWS  Expertise in handling Hive queries using Spark SQL such as window functions and aggregations  Ran Spark applications on Docker using EMR and used AWS Glue data catalog as the metastore in Spark SQL  Configured different File Formats like Avro parquet for HIVE querying and processing based on business logic  Utilized Sequence files RC files Map side joins bucketing partitioning for Hive performance enhancement and storage improvement  Implemented Hive UDF to implement business logic and performed extensive data validation using Hive  Involved in loading the structured and semi structured data into spark clusters using Spark SQL and Data Frames API  Utilized AWS CloudWatch to monitor the performance environment instances for operational and performance metrics during load testing  Scripting Hadoop package installation and configuration to support fully automated deployments  Involved in chefinfra maintenance including backupsecurity fix on Chef Server  Deployed application updates using Jenkins  Installed configured and managed Jenkins  Triggering the SIT environment build of the client remotely through Jenkins  Deployed and configured Git repositories with branching forks tagging and notifications  Worked on MongoDB database concepts such as locking transactions indexes Shading replication schema design  Viewing the selected issues of web interface using SonarQube  Developed a fully functional login page for the companys user facing website with complete UI and validations  Installed Configured and utilized AppDynamics Tremendous Performance Management Tool in the whole JBoss Environment Prod and NonProd  Installed and installed Hive in a Hadoop cluster and assisted business usersapplication teams in finetuning their HIVE QL for optimal performance and efficient use of cluster resources  Utilized Oozie workflow for ETL Process for critical data feeds across the platform  Configured Ethernet bonding for all Nodes to double the network bandwidth  Configured Kerberos Security Authentication protocol for existing clusters  Constructed the use of Zookeeper failover controller ZKFC and Quorum Journal nodes for high availability for significant production clusters and automatic failover controller created  Installation and deployment of many Apache Hadoop nodes on an AWS EC2 system as well as development of Pig Latin scripts to replace the old traditional process with Hadoop and data feeding to AWS S3  Experience with AWS CloudFront including the creation and management of distributions that provide access to an S3 bucket or an HTTP server running on EC2 instances  Developed Python scripts UDFs using both Data framesSQL and RDDMapReduce in Spark 16 for Data Aggregation queries and writing data back into OLTP system through Sqoop And Developed enterprise application using Python  Constructed Spark application performance optimization including determining the appropriate Batch Interval time Parallelism Level and Memory Tuning  Experience and handson knowledge in Akka and LIFT Framework  Used PostgreSQL and NoSQL database and integrated with Hadoop to develop datasets on HDFS  Environment HDFS Map Reduce Hive 110 Kafka Hue 390 Pig Flume Oozie Sqoop Apache Hadoop 26 Spark SOLR Storm Cloudera Manager Red Hat MySQL Prometheus Docker Puppet YARN SparkSQL Python Amazon AWS Elastic Search Tableau Linux  Key Skills SQL Apache hive Apache SparkDatabricks Jupyter Notebook Anaconda Python Django Pandas Flask Keras NumPy Scikitlearn MatPlotLib Tensorflow  Time Series Forecasting AB testing Bayesian methods PowerBI MicrosoftWord Excel Powerpoint Java Data Visualization Analytical Skills Cost Accounting Corporate Finance Knowledge Statistical AnalysisRStudio          Education and Training       Bachelor’s     Computer Science     Expected in        Uttara Institute of Business and Technology                GPA|none
Data Engineer|https://www.livecareer.com/resume-search/r/data-engineer-b9cc3bb45c274243bede854fa43fe37c|272474282630622662458174313553127824080|Jessica    Claire                                   609 Johnson Ave       49204     Tulsa     OK   100 Montgomery St 10th Floor    H   555 4321000    C       resumesampleexamplecom    Date of Birth         India                      single                    Summary      I am an Automation Developer with a love for troubleshooting and electronics This passion for automation started at Micro Center in 2017 where I began finding ways to simplify my reports to upper management These reports took several hours to compile and took the time I could have spent guiding my agents Eventually I started finding ways to gather that data through an API After discovering I could collect this information and use APIs to simplify tasks I started programming software to do these things This new skill helped change how I approached my teams problems  complaints and eventually led to me creating tools to improve our efficiency and productivity Since then my passion has grown into a career that keeps me wanting to learn more        Skills           Systems Engineering  Lab Test Technician  Cybersecurity  Data Engineering      API Design  Deployment  Software Developer Python NodeJS PHP Bash Git Etc  Automation  Disaster Recovery                       Experience       Data Engineer       062021      112023     Bank Of America Corporation    –    Aurora     IL            Deployed Linux cloud servers and applications to meet the needs of the company PostgreSQL Metabase Apache Spark TableAU  Secured servers and applications using ACLsﬁrewallsIDSIPS and following standard security practices  Built several ETLs in PythonPHPJavaScript for several ticketing platforms  Designed disaster recovery plans for our systems  Constructed complex SQL queries to aid in reporting and automation  Tested data regularly to ensure accurate reporting  Managed several PostgreSQL databases  Automated reports and redundant tasks through the use of APIs and databases  Created and implemented complex business intelligence solutions  Created conceptual logical and physical data models for use in different business areas  Adept in troubleshooting and identifying current issues and providing effective solutions  Managed performance monitoring and tuning while identifying and repairing issues within database realm  Identified protected and leveraged existing data  Planned and installed database management system software upgrades to enhance systemic performance           Test Engineering Technician       082020      062021     General Atomics    –    Houlka     MS            Traveled daily to integrators to provide quality assurance for PowerSpec systems and review the build process  Compiled reports for integrators to log and classify defects  Answered product questions for PowerSpec systems  Regularly assisted neighboring departments on build projects and quality controlled parts for buyers  Worked directly with vendors for BIOS updates and patches on PowerSpec systems  Created and deployed system images for PowerSpec products  Built extensive QC reports through rigorous testing methodologies including benchmarking components and testing for compatibility  Performed problem solving and resolution for technical quality inspection and customer quality issues  Developed and maintained solutions for integration and testing phases  Tested functionality performance and compliance of each product against design specifications to maintain strong development standards and high customer satisfaction  Completed unit and regression tests on software and individual modules  Created and optimized automated testing tools for repetitive tasks  Created and maintained database of common and known testing defects  Worked with offsite teams to complete timely tests and facilitate smooth product releases  Promoted high customer satisfaction by resolving problems with knowledgeable and friendly service           Call Center Lead       012019      082020     Metlife    –    Omaha     NE            Encouraged team members to improve productivity and service levels by modeling correct behaviors and coaching employees  Resolved team support issues with efficient approach to keep call center operating smoothly and customers satisfied with services  Routinely updated guides to reduce questions on the ﬂoor  Provided accurate and detailed reports for management  Handled customer escalations and ensured they went to the appropriate team  Maintained Zendesk and the ticketing procedures to ensure both a smooth and efficient experience for my agents  Worked with management to update legacy procedures and remove redundant processes through automation  Managed customer concerns with calm demeanor and knowledgeable service  Created an efficient workflow in order to provide a better experience for consumers  Kept records of customer interactions or transactions thoroughly recording details of inquiries  Worked directly with stores and customer relations team to improve customer retention  Built and maintained call center server to house reports and automations           Technical Consultant       092017      012019     Applied Systems Inc    –    University Park     IL            Troubleshot and resolved problems with programs and systems  Utilized knowledge of applications programming and systems functionality to assist employees with technical needs  Assisted customers with various types of technical issues via email live chat and telephone  Handled customer service issues by providing guidance or escalating for advanced support  Served as first point of contact for escalated technical service calls emails and live chat  Troubleshot hardware issues and worked with service providers to facilitate repairs for end users  Developed and maintained strong relations with customers to meet quality expectations  Documented customer complaints and inquiries for use in technical documentation and bug tracking  Reviewed support cases for technical and troubleshooting accuracy and identified needed process improvements  Maintained uptodate case documentation for future reference  Demonstrated advanced product knowledge to solve customer issues  Delivered remote assistance for technical issues using screen sharing mouse and keyboard control and other tools          Education and Training       High School Diploma       Electronic Classroom       Expected in   062012                Electronic Classroom of Tomorrow      Columbus OH          GPA        Status   |none
Data Engineer|https://www.livecareer.com/resume-search/r/data-engineer-2c2f724ef72e40e2b35028b711268d0e|60738515287105690973581748617742576500|Jessica    Claire                                   609 Johnson Ave       49204     Tulsa     OK   100 Montgomery St 10th Floor    H   555 4321000    C       resumesampleexamplecom    Date of Birth         India                      single                    Summary       Data Engineering  with experience in Design Development Implementation and support of  Data Warehousing  for over  8 years  Experienced in complete  Software Development Life Cycle SDLC   software Testing Life Cycle STLC   SDLC methodologies  Extensively worked on  Informatica Designer Tools  Source Analyze Warehouse Designer Mapping Designer Mapplet Designer and Transformation Developer and Workflow Manager Tools Task Developer Worklet and Workflow Designer Workflow Monitor and informatica Power exchange Experience in working with using Informatica in  SAP HANA   Oracle   MS SQL   Teradata  and  DB2 environments  Hands on experience in migrating on premise ETL to  Google Cloud PlatformGCP  using cloud native tools such as  BIG Query   Cloud Data Proc   Google Cloud Storage   Composer   Practical understanding of the Data modeling concepts like  Star  Schema Modeling snowflake Schema Modeling Fact and Dimension tables  Also experience in Optimizing Database querying data manipulation using SQL and  PLSQL  in Oracle flat files and SQL server database Experienced in implementing  Change Data Capture CDC  using informatica Power Center for Oracle and SAP Systems Experienced in debugging mapping by analyzing the data flow and evaluating transformations Experienced in performance tuning of data flow through source target sessions and mappings  identifying and resolving performance bottlenecks at various stages  using techniques like Database tuning and Session Partitioning Experienced in test strategy developing test plan details test cases and writing test scripts by decomposing business requirements and developing test scenarios to support quality deliverables Involved in test planning and execution for various Test Phases  Unit Test   System and User Acceptance Testing  Expert in  analyzing designing developing installing configuring  and  deploying  MS SQL Server suite of products with Business Intelligence in SQL Server Reporting Services SQL Server Analysis Services and SQL Server Integration Services Performed data profiling data cleansing data conversion exception handling and data matching using  informatica IDQ   Excellent communication skills good organizational skills selfmotivated hardworking ability to grasp quickly and learn fast and open to new technologies         Skills  Tools           ETL Tools Informatica Power Center 1051 Power Exchange 961901 Informatica Data Quality 961 Power connect for SAP BW power connect for JMS power connect for IBM MQ series power connect for Mainframes DTS MDM ERWIN  Scheduling TIDAL UC4 CONTROLM AUTOSYS OpCon  Oracle SAP HANA MS SQL Server Snowflake MongoDB Teradata DB2 AWS  Python Java SQL UNIX Unix Shell Scripts HTML XML JSON Microsoft Office Apache Spark Kafka Kubernetes Hive Scala  Data analysis Data management Data warehouse Big Data PLSQL RDBMS NoSQL Vertica Spark Kafka Oozie Maven      Debugging Coding Designing Quality analysis ETL SAP BW  AWS Cloud Tools EC2 Elastic Loadbalancers Elastic Container Service Docker Containers S3 Elastic Beanstalk Cloud Front Elastic Files System RDS Dynamo DB DMS VPC Direct Connect Route53 Cloud Watch Cloud Trail Cloud Formation IAM EMR ELB Lambda functions REST API Airflow Data Pipeline RedShift  Google Cloud Platform GCP Cloud Storage Big Query Composer Cloud Dataproc Cloud SQL Cloud Functions Cloud PubSub Dataflow AI Building Blocks Looker Cloud Data Fusion Dataprep Firestone  Azure Azure Storage Database Azure Data Factory Azure Analysis Services                       Experience       Data Engineer       082019      Current     Lockheed Martin    –    Eagan     MN            Responsible in Identifying all the Legacy systems analyze their  data models  mathematical and  Scientific models and all the business components to be migrated to Arkansas Integrated Eligibility system ARIES  NexGen solution   Business and Data Mapping Analyst worked with Client to gather business and functional requirements  Experience in building largescale data pipelines and datacentric applications using Big Data tooling like Hadoop Spark Hive and Airflow in a production setting  Experience in working with Rest APIs for data extraction  Designing and coordinating with  Informatica Power center  admin to set up services users Groups database components like tables indexes procedures and synonyms Unix groups and User access for ARIES system  Designing all the components of ARIES system and step by step conversion approach using the  Ralph Kimball  and  Bill Inmom  data warehouse design methodologies to determine the feasibility of the design within the time and cost constraints  Development of  ETL  Extract Transform and Load code components like mappings Workflows Sessions and database objects like stored procedures functions and  Unix shell scripts  from business requirements and design plan  Designing and developing the mathematical models and analytical reports in  Cognos  analyze  Developing integrations using  Informatica Cloud  Data Integration  IICS  –  CDI  Service  For Google Analytics  Responsible Identifying the performance bottleneck in the ARIES systems during Integrated  Testing  IT and  System Testing  ST and PT  Performance Testing  phases and implement Performance tuning techniques  Confer with the scrum master client partners Business Managers and adhere to the  agile   Experience in multiple database technologies such as traditional RDBMS MS SQL Server Oracle MySQL PostgreSQL MPP AWS Redshift Snowflake Teradata Distributed Processing Spark Hadoop EMR NoSQL MongoDB DynamoDB Cassandra Neo4J Titan  Conduct code review sessions with peer developers to ensure code quality  Wrote scripts and processes for  data integration  and bug fixes  Utilized  Python  to handle debugging and automation scripting tasks  Created and implemented complex business intelligence solutions  Create  Managing buckets on  S3  and store DB and log backup upload images for CND server  Setup databases on  Amazon RDS  or  EC2 Instances  as per requirements  Handson experience with snowflake utilities SnowSQL SnowPipe Big data model techniques using python  Expert in migrating data from various systems into Salesforce CRM using ETL tools   Informatica   Hands on Experience in  Data Management Data Security Data Modeling Data Quality Workflow Automation Formulas  Validations   Collaborated with Legacy team to define data extraction methodologies and data source tracking protocols  Used  SparkSQ L to read parquet data and create tables in  Hive  using  Scala API   Hands on experience with data ingestion tools like  Sqoop Kafka Flume   Used various  spark transformations  and  Actions  for cleansing the input data  Installed and configured  Apace Airflow  for workflow management and created workflow in python  Worked on Tableau Desktop versions 782 Tableau Reader and Server  Build data pipelines in Airflow in GCP for ETL related jobs using different airflow operators  Experience in GCP Dataproc GCS Cloud functions BigQuery           BIETL Developer       112018      072019     Wells Fargo    –    Loveland     CO            Analyzing the source data coming from Mainframe sources and working with business users and developers to develop the Model  Created xsd and used it in  xml generator Transformation   Also called  WSDL  files using web consumer transformation in  Informatica   Effectively and efficiently communicated systems solutions to business problems to team members business unit representatives management and other impacted project teams  Analyze and modify existing stored procedures functions and queries in order to integrate them into previously built reporting application utilizing  SSIS  and  SQL Server Management Studio   Change ETL process from  importing flat files  and  COBOL  as source for previously built application utilizing informatica Power center 96 to read data from existing Reporting Server SQL Server databases  Interface with report users to determine requirements for new and existing reports  Develop test and deploy  ETL  jobs with reliable errorexception handling and rollback framework Manage automation of file processing as well as all ETL processes within a job  workflow   Worked as a Data Analysts to match the current data mappings with old mainframe mappings  Created Design Documents Context Diagrams on every Projects and did code review  Created Reusable lookup to send emails Notification to Users  This Lookup was used by multiple developer in multiple Projects  STOP and START the  Netezza  appliances in case of issues  Prepared best practices documentation for teams in writing  NOSQL   Conducted sessions to help explain teams about the  Netezza  architecture and design  As a part of Informatica decommission objects Project Used  SVN  to archive the ETL Code and delete the unwanted mappings and workflows  Extracted data from  flat file  and staged into a single place and applied business logic to load them in the  Teradata database   Lead in few complex Projects and Performed Unit testing and created  QA documents   Participated in solution brainstorming and provided technical instruction and coaching to others within organization  Developed technical project deliverables  Created spreadsheets using  Power BI  and  Power Pivot  by importing data from the sources directly  Created visually impactful dashboards in Excel and  Tableau  for data reporting using  PivotTables  and  VLOOKUP   Involved in migrating ETL code lower environments to like dev testLoad to production environment  Used  Debugger  for debugging Mappings  Created  Tidal  Jobs and  Runbooks  to schedule jobs in Tidal  Scheduling ETL Jobs using  UC4 scheduler   Migrated ETL code using Deployment Groups from Dev to Prod environments  Created SSIS package for loading the data coming from various interfaces like OMS Orders Adjustments and Objectives and also used multiple transformation in SSIS to collect data from various sources  Worked on SSIS Package DTS ImportExport for transferring data from Database Oracle and Text format data to SQL Server  Created  SSIS  packages for File Transfer from one location to the other using FTP task  Manage and document our platform infrastructure This can go from installing a new Consul server to resolving performance issues in a MongoDB cluster through setting up a continuous integration pipeline           Informatica Developer       122017      102018     Cognizant Technology Solutions    –    Horsham     PA            Involved in all the phases of the development like Analysis Design Coding  Unit Testing  System Testing and UAT  Extracted data from  heterogenous sources  and performed complex transformations to load data into the target systems  Resolved various performance issues by examining the logs current design and  removing the bottlenecks   Created reusable ETL components which need to be run at the mapping session and workflow levels  Wrote complex SQL queries and performed extensive data analysis in  Oracle 11g   Peer reviewed developers code and ensured they fall into the enterprise guidelines  Worked extensively with session parameters Mapping Parameters Mapping Variables and Parameter files for Incremental Loading  Created Informatica mappings to load Payment flow BT cash data Currency conversion data from  SAP HANA DSL layer  to  SAP HANA DPL layerDLL SAP BA layer  Implemented SAP BW and  BOBJ  with different SAP data source  Used  Qlik  and Informatica for  ETL   reporting  Worked closely with  SAP ABAP  team to create logical systems RFC destinations and to create tRFC port for RFC destinations  Followed best practices that were defined at the enterprise level and also peer reviewed the code for the same  Created and reviewed scripts to create new tables queries for new enhancements and bug fixes in the existing  data warehouse   Used Debugger and various other techniques like tracing to fix the defects errors and data issues  Extensively worked with various Lookup caches like  Static cache Dynamic cache and Persistent cache   Involved in developing the Deployment groups for deploying the code between various environment Dev QA  Worked in the Data Integration Team to perform data and application integration with a goal of moving more data more effectively efficiently and with high performance to assist in businesscritical projects coming up with huge data extraction  Migrated data from SQL Server to  Netezza using NZMigrate utility   Experience in integration of various data sources like  Oracle DB2 SQL server csv XML and Flat Files  into staging area  Developed code to extract transform and load ETL data from inbound flat files and various databases into outbound  flat files  and  XML  files using complex business logic  Involved in deploying objects from DEV to UATPROD during monthlyquarterly releases  Developed Slowly Changing Dimension Mappings for  Type 1  SCD  and  Type 2 SCD  Monitored and improved query performance by creating views indexes and sub queries Extensively involved in enhancing and managing Unix Shell Scripts  Developed workflow dependency in  Informatica  using Event Wait Task Command Wait  Involved in  L3 Support  by fixing load failures and defects during peak and offPeak hours  Working with Informatica and  SAP ECC   We are extracting data in Informatica from  SAP ECC  via  Business Content Data sources  Design the ETL architecture for the conversion of source from legacy to new  ERP SAP   Built Sqoop scripts to extract data from the SAP  Responsible for data integration  Epicor and SAP  and data management  Validated DW data with standard  SAP reports            ETL Informatica Developer       082013      122015     ObjectOne Information Systems    –    City     STATE           · Responsible for developing ETL mappings for the reporting requirement  for data feeds  · Created mapplets and many other reusable components reduce redundancy  · Provided the best solution for their requirement Help the Clients in designing of the system and process to make it more robust and meaningful  · Created the ETL component and test scripts Involved in client meetings for their inconsistent requirements  · Sourced data from  SAP HANA  using  SAP Adapter  in Informatica Target Tables  · End to end processing from the source to target Load the data from various File systems to the  DWH  and  DM  Maintain the Versioning for the objects by using  VSS   · Successfully conducted Load Testing and Performance Testing  · Resolve the issues coming from the end to end processing Perform the enhancements if required by the business users requirement  for data feeds  · Involved in preparing Source to Target mappings and Application Design Document Worked closely with all upstream and downstream application owners to make sure interface agreement documents are clear  · Successfully conducted Load Testing and Performance Testing Automated regression test suite for actuate reporting and true portal  · Used  ALM  to track and report system defects and bugs writing modification request for the bugs in the application and helped developers to track the problem and resolve the technical issues         Education and Training       Master of Science       Computer And Information Systems       Expected in   122017                New England College      Henniker     NH     GPA        Status   |none
Data Engineer|https://www.livecareer.com/resume-search/r/data-engineer-e1345820d6384278b986c6b6dfd4e897|150574715265165963952823813869633129863|Jessica    Claire                   Montgomery Street     San Francisco     CA  94105    609 Johnson Ave       49204     Tulsa     OK       H   555 4321000    C       resumesampleexamplecom    Date of Birth         India                      single                    Summary       Over 3 years of professional IT experience in  Data Engineering  and  Data Analytics  using various languages and tools like  SQL Python BigHadoop   Extensive experience on Data Engineering field including Ingestion Datalake Datawarehouse Reporting and Analytics  Strong knowledge and experience on Data Analysis Data Lineage Big Data pipelines Data quality Data Reconciliation Data transformation rules Data flow diagram including Data replication Data integration and Data orchestration tools  Knowledge and experience on AWS services like RedshiftRedshift spectrumS3GlueAthena Lambdacloudwatch and EMRs like HIVE Presto  Extensively used ETL methodology for performing Data Migration Extraction Transformation and loading using  Talend  and designed data conversions from wide variety of source systems  Experienced in Data Ingestion projects to inject data into  Data lake  using multiple sources systems using Talend Bigdata  Good technical Skills in  SQL Server   ETL  Development using  Informatica tool   Expertise in writing  SQL   PLSQL  to integrate of complex OLTP and OLAP database models and data marts worked extensively on  Oracle SQL SERVER   Experience in all the life cycle phases of the projects on  large data sets  and experience with performance  tuning  and  troubleshooting   Ability to work effectively with associates at all levels within the organization  Strong background in mathematics and have very good analytical and problemsolving skills         Skills           Big Data Ecosystems  HDFS MapReduce Spark Kafka Hive Airflow Stream Sets HBase Flume Zookeeper Nifi Sentry Ranger  Scripting Language  Python PowerShell Scripting Pig Latin HiveQL  Cloud Environment  Amazon Web Services AWS Microsoft Azure  NoSQL Database  Database  MySQL Oracle Teradata MS SQL SERVER PostgreSQL DB2  Version Control  Git SVN Bitbucket  ETL Tools  Tableau Microsoft Excel Informatica Power BI R Google Data Studio                        Experience       Data Engineer       012022      Current     Honeywell    –    Michigan     ND            Worked on Architecture Design for Multistate implementation or deployment  Implement One time Data Migration of Multistate level data from SQL server to Snowflake by using Python and SnowSQL  Day today responsibility includes developing ETL Pipelines in and out of data warehouse develop major regulatory and financial reports using advanced SQL queries in snowflake  Stage the API or Kafka Datain JSON file format into Snowflake DB by FLATTENing the same for different functional services  Build Docker Images to run airflow on local environment to test the Ingestion as well as ETL pipelines  BuildingMaintaining Docker container clusters managed by Kubernetes Utilization of Kubernetes and Docker for the runtime environment of the CICD system to build test and deploy  Created Airflow DAGs to schedule the Ingestions ETL jobs and various business reports  Created  Airflow  Scheduling scripts in Pythonx  Cluster capacity planning along with operations team and management team and Cluster maintenance as well as creation and removal of nodes  HDFS  support and maintenance  Strong knowledge of  Rack awareness  topology in the  Hadoop cluster   Involved in Loading data from  LINUX file system  to  Hadoop Distributed File System   Responsible for building scalable distributed data solutions using  Hadoop   Experience in managing and reviewing  Hadoop log files   Data migration from  RDMS  to  Hadoop  using  Sqoop  for analysis and implemented  Oozie  jobs for automatic data imports from source  Created  HBase  tables to store various data formats of  PII  data coming from different portfolios  Strong in Exporting the analyzed and processed data to the  Relational databases  using  Sqoop  for visualization and for generation of reports for the team           Data Engineer       012021      122021     Honeywell    –    Nashville     TN            Prepared ETL design document which consists of the database structure change data capture Error handling restart and refresh strategies  Worked with different feeds data like JSON CSV XMLDAT and implemented Data Lake concept  Developed Informatica design mappings using various transformations  Designing and building multiterabyte full endtoend Data Warehouse infrastructure from the ground up on Confidential  Redshift  for large scale data handling Millions of records every day  Optimizing and tuning the  Redshift  environment enabling queries to perform up to 100x faster for Tableau and SAS Visual Analytics  Wrote various data normalization jobs for new data ingested into  Redshift   Advanced knowledge on Confidential  Redshift  and MPP database concepts  Migrated on premise database structure to Confidential  Redshift  data warehouse  Developed UDF in Scala to implement the business logic  Developed spark applications in Scala on distributed environment to load huge number of JSON files with different schema in to Hive tables  Most of the infrastructure is on AWS used   AWS EMR  Distribution for Hadoop   AWS S3  for raw file storage   AWS EC2  for Kafka  Used  AWS Lambda  to perform data validation filtering sorting or other transformations for every data change in a DynamoDB table and load the transformed data to another data store  Created  Airflow  Scheduling scripts in Python  Programmed  ETL functions  between Oracle and Amazon Redshift           SQL Developer       062019      122023     Ihs Markit    –    Southfield     MI            Gathered business requirements and converted them into new TSQL stored procedures in visual studio for database project  Performed unit tests on all code and packages  Analyzed requirement and impact by participating in Joint Application Development sessions with business client online  Performed and automated SQL Server version upgrades patch installs and maintained relational databases  Performed front line code reviews for other development teams  Modified and maintained SQL Server stored procedures views adhoc queries and SSIS packages used in the search engine optimization process  Updated existing and created new reports using Microsoft SQL Server Reporting Services Team consisted of 2 developers  Created files views tables and data sets to support Sales Operations and Analytics teams  Monitored and tuned database resources and activities for SQL Server databases          Education       Master of Science       Data Analytics Engineering       Expected in   122022                George Mason University      Fairfax     VA     GPA        Status           38 GPA           Bachelor of Science       Electronics  Communication Engineering       Expected in   062019                KL University      Guntur          GPA        Status   |none
Data Engineer|https://www.livecareer.com/resume-search/r/data-science-data-engineer-intern-bd32a7569cbb4dd2a9f164b4801eef35|266612002933194965787459684177947415296|Jessica  Claire                             resumesampleexamplecom                      555 4321000                       Montgomery Street     San Francisco     CA      94105                                                                                                                                                                                                             Summary     Highly motivated Sales Associate with extensive customer service and sales experience Outgoing sales professional with track record of driving increased sales improving buying experience and elevating company profile with target market           Skills         Machine LearningData Mining  NLP  Linear Regression neural networksdeep learning Naive Bayes SVM Logistic Regression  decision trees Kmean KNN N Grams edit distance gradient descent  Statistical Programming  Packages  R Python NumPy Matplotlib scikitlearn pandas ggplot2 Shiny dplyr caret e1071keras  Business Intelligence  Visualization  Tableau Qlik View Qlik Sense Excel OBIEE  Hadoop Ecosystem Components  Spark Hive Sqoop Flume Kafka Impala  Databases  Oracle MySql PostgreSql  Oracle ERP  Fusion Middleware  Oracle EBusiness Suite 11i  R12 Oracle SOA Oracle Service Bus  Other Languages  Tools  SQL PLSQL core java Scala RStudio Jupyter SqlDeveloper Toad Atom  Certifications  Tableau SQL  PLSQL                       Education and Training       University of Utah David Eccles School of Business    Salt Lake City     Utah      Expected in   August 2017     –      –       Master of Science        Information Systems          GPA           Information Systems Data Science and Analytics specialization   Recipient of 15000 Graduate Fellowship from David Eccles School of Business Academic Capstone Project  Big Data  Building statistical regression and classification models cleaning exploring data and developing interactive web interface using R Shiny which helps the company to classify clients loan type and predicting the amount of loan they will take in future Kaggle  House Prices Predictions  Applied different machine learning simple and advanced models on housing predictors for predicting the sales prices of houses used imputation methods for filling missing and null values in the data set Independent Study  Research  Apache Spark using Scala and Python Rajeev Gandhi Memorial College of Engineering and Technology          India                        Expected in   May 2012     –      –       Bachelor of Science        Computer Science and Engineering          GPA           Computer Science and Engineering Designed Hand Draw Shape Recognition interface which helps the user to invoke desired application just by drawing the shape linked to the application          Experience       Envestnet      Data Science  Data Engineer Intern   Secaucus     NJ                   012017      Present     Working on Big Data Ingestion using Sqoop for transferring data from multiple MySql database servers to transient storage in amazon EMR Hcatalog and using Hive to transfer data to persistent storage in amazon S3 bucket  Developing Sqoop and Hive scripts for data ingestion  Using R and spark in amazon EMR for filtering exploring analyzing providing insights on data and developing reports           First American Corporation      Oracle Technical Consultant  Data Analyst   City          India              022013      072016     Created SQL scripts for daily extracts adhoc requests  reporting and for analyzing large data sets  Designed ER diagrams conceptual models logical and physical models created database objects  Tables Indexes Sequences and Views  Developed Oracle Business Intelligence reports created and modified Oracle database objects  Tables Views and Indexes which increased the performance of Oracle Business Intelligence reports by 60 in production environment  Prepared SQL  Loader scripts for loading data from other systems into oracle ERP system worked with onsite business team in performing data fixes  Created PLSQL interfaces for doing business validation transferring data between ERP modules and loading data to base tables           CMC Limited      Data Analyst Intern   City          India              112012      012013     gt Developed SQL scripts worked on oracle 11i database and oracle reports          Skills     Academic ad Apache Big Data Business Intelligence Draw clients Data Mining Databases database EBusiness edit ERP filling drawing java Machine Learning Excel Middleware MySql NLP networks neural Oracle Oracle database PLSQL PostgreSql Programming Python reporting Research sales servers scripts SQL SQLLoader Tableau Tables Toad type validation View|none
Data Engineer|https://www.livecareer.com/resume-search/r/senior-data-engineer-ffd843d6febb4217800488911db2a3f8|137893745859917600174161396390961745079|Jessica    Claire               Montgomery Street       San Francisco     CA  94105    609 Johnson Ave       49204     Tulsa     OK      Home   555 4321000        Cell           resumesampleexamplecom                  Professional Summary      Business Intelligence Consultant with a 10year career in data warehousing business intelligence reporting and data management architecture Progressive developer and technical team lead with a strength in design  development as well as driving performance reducing inefficiencies and cutting costs Possess comprehensive knowledge and hands on experience in both ETL and Reporting tools Knowledge of Credit Card account life cycle management in Finance domain Functional knowledge of Collections and Recovery operations Expertise in planning executing and spearheading various SDLC and Agile Scrum projects in compliance to quality standards Known for effective communication with excellent relationship building  interpersonal skills strong analytical problem solving  organizational abilities Proven track record of taking ownership and diving deeper into issues to identify the root cause and troubleshoot towards resolution        Skills           ETL Tools  Ab Initio  Scripting Languages  Unix shell scripting Python SparkScala  Cloud Services Microsoft Azure Cloud Services Data Lake  DataBricks and Data Pipelines Azure Data Factory  BI Reporting Skills  Tableau Desktop Tableau Server Power BI Reporting  SAP Business Objects SAP BOUniverse Designer Tool SAP BO XI WEBI ReportingSAP BO XI Deski Reporting  Database  Oracle  Teradata Hive      Scheduler tools  Autosys ControlM  Relational Database Management  Business Intelligence Reporting  Project Management  Data Analysis and Visualization                       Work History      062017   to   Current     Senior Data Engineer      Thoughtworks    –    Memphis     TN            A multitenure loyalty program across all Williams Sonoma brands – the first time that customers can earn points by purchasing across the multiple brands WSI Pottery Barn West Elm etc I work in the customer data warehouse CDW which is Teradata and work with their 3rd party marketing systems vendor There are various data points and integrations with the data warehouse which holds all customer information points transactions loyalty IDs etc   Worked with Requirements Analysts and PDMs to identify understand and document business needs for data flow Analyze requirementsUser stories at business meetings and strategize impact of requirements on different platformsapplications Worked with Project Management in creation of project estimates for each Agile story  Engaged in projects that uses Scala and Azure DatabricksDatafactoryDatalake to extract process and load Adobe Clickstream data received for Williams Sonoma ECOM website Deployed custom codes in Scala to read JSON extract CSV files from Adobe add column headers handle badmalformed records handle invalid records before finally writing cleansed data into ParquetDelta file format partitioned by date and hour  Build and review design deliverables Perform dependency analysis between new objects created in Ab Initio graphs Conduct IT and UAT testing of each of these graphs Record errors reported during Unit and Integrated testing  Prepare production Implementation Plan to deploy codes successfully to production environment  Coordinate daily standups short meetings where teammates talk through whats being worked on yesterday what was done today and if blocked Involved in variety of other scrum meetings such as planning meetings where team pulls in stories requirements grooming meeting to look at backloglist of stories and flush out timeline and work expected demo show work that was completed in sprint etc  Reporting  Visualization in Tableau and Power BI  Design and deploy rich Graphic visualizations with Drill Down and Drop down menu option Prepare Dashboards using calculations parameters Apply various reporting objects like Filters prompts Calculated fields Groups Parameters Work on the development of Dashboard reports for the Key Performance Indicators for the top management          032010   to   062017     Senior DeveloperTechnical Team Lead      Tech Mahindra Synchrony Financial Services    –    City     STATE            Synchrony Financial is a consumer financial services company offering consumer financing products including credit promotional financing and loyalty programs and installment lending through Synchrony Bank its wholly owned subsidiary Synchrony is the largest provider of private label credit cards in the US The company provides private label credit cards for such brands as Amazon JC Penney CheapOAir OneTravel Sams Walmart Lowe’s Guitar Center Gap BP We as Data warehouse solution providers store this credit card holder information from the instance a credit card is applied till the account is closedcharged off   Understanding the full scope of requirements from business Estimating time and effort involved from gathering project requirements till project implementation  Answering technical queries driving product initiatives and metric collection and analysis  CoOrdinating between project stake holders – Business Client and offshore teams during all phases of project  Preparing design documentation design reviews development performing code reviews to ensure coding standards are followed testing and deployment of application enhancements  Experience in Ab Initio toolsets including the following  o Parallel and serial flow batch graphs conditional components other components like reformat normalize and join lookup and graphs processing ASCII and EBCDIC layouts  o Knowledge on Abinitio architecture including the GDE Cooperating system EME and other related items  o Fine tuning of Abinitio graphs based on performance enhancement by proper usage of memory in the components  o Well versed with various Ab Initio components such as Join Rollup Partition Departition Dedup sorted Scan Normalize DeNormalize  o Expertise knowledge improving Performance and Troubleshooting of the AbInitio graphs and monitoring ABInitio run time statistics  o Experience with advanced Abinitio metaprogramming air commands and other admin related tasks including the creation of save and performing migration from one server to the other  Establish support such as acquiring conditioned test data support from third partyteam etc for Integration Testing to simulate production environment and to ensure correctness and quality of buildparameter set up  Getting sign off from IT managers for deploying parameterset up onto production environment  Documenting implementation plan and Hour by Hour plan listing down the tasks in sequence of their execution on the date of implementation  Coordinate release activities across multiple teams          Education      Expected in   4 2008     Bachelors     Information Technology     College of Engineering Bhubaneswar      India          GPA               Accomplishments      • Tableau Desktop Specialist Certified No expiration  These are Open Badges that I have been awarded and that attest to my skills  httpswwwyouracclaimcombadges556948fdd8114f8097d245ab6c530d9clinkedinprofile   o Tableau Desktop Specialist title use their foundational knowledge of Tableau Desktop and data analytics to solve problemsDesktop Specialists can connect to prepare explore and analyze data and share their insights        Skills       ETL Tools  Ab Initio  Scripting Languages  Unix shell scripting Python SparkScala  Cloud Services Microsoft Azure Cloud Services Data Lake  DataBricks and Data Pipelines Azure Data Factory  BI Reporting Skills  Tableau Desktop Tableau Server Power BI Reporting  SAP Business Objects SAP BOUniverse Designer Tool SAP BO XI WEBI ReportingSAP BO XI Deski Reporting  Database  Oracle  Teradata Hive    Scheduler tools  Autosys ControlM  Relational Database Management  Business Intelligence Reporting  Project Management  Data Analysis and Visualization         Work History      062017   to   Current     Senior Data Engineer       Kforce Inc Williams Sonoma Inc   –   San Francisco     CA     A multitenure loyalty program across all Williams Sonoma brands – the first time that customers can earn points by purchasing across the multiple brands WSI Pottery Barn West Elm etc I work in the customer data warehouse CDW which is Teradata and work with their 3rd party marketing systems vendor There are various data points and integrations with the data warehouse which holds all customer information points transactions loyalty IDs etc   Worked with Requirements Analysts and PDMs to identify understand and document business needs for data flow Analyze requirementsUser stories at business meetings and strategize impact of requirements on different platformsapplications Worked with Project Management in creation of project estimates for each Agile story  Engaged in projects that uses Scala and Azure DatabricksDatafactoryDatalake to extract process and load Adobe Clickstream data received for Williams Sonoma ECOM website Deployed custom codes in Scala to read JSON extract CSV files from Adobe add column headers handle badmalformed records handle invalid records before finally writing cleansed data into ParquetDelta file format partitioned by date and hour  Build and review design deliverables Perform dependency analysis between new objects created in Ab Initio graphs Conduct IT and UAT testing of each of these graphs Record errors reported during Unit and Integrated testing  Prepare production Implementation Plan to deploy codes successfully to production environment  Coordinate daily standups short meetings where teammates talk through whats being worked on yesterday what was done today and if blocked Involved in variety of other scrum meetings such as planning meetings where team pulls in stories requirements grooming meeting to look at backloglist of stories and flush out timeline and work expected demo show work that was completed in sprint etc  Reporting  Visualization in Tableau and Power BI  Design and deploy rich Graphic visualizations with Drill Down and Drop down menu option Prepare Dashboards using calculations parameters Apply various reporting objects like Filters prompts Calculated fields Groups Parameters Work on the development of Dashboard reports for the Key Performance Indicators for the top management          032010   to   062017     Senior DeveloperTechnical Team Lead       Tech Mahindra Synchrony Financial Services   –   Chicago     IL     Synchrony Financial is a consumer financial services company offering consumer financing products including credit promotional financing and loyalty programs and installment lending through Synchrony Bank its wholly owned subsidiary Synchrony is the largest provider of private label credit cards in the US The company provides private label credit cards for such brands as Amazon JC Penney CheapOAir OneTravel Sams Walmart Lowe’s Guitar Center Gap BP We as Data warehouse solution providers store this credit card holder information from the instance a credit card is applied till the account is closedcharged off   Understanding the full scope of requirements from business Estimating time and effort involved from gathering project requirements till project implementation  Answering technical queries driving product initiatives and metric collection and analysis  CoOrdinating between project stake holders – Business Client and offshore teams during all phases of project  Preparing design documentation design reviews development performing code reviews to ensure coding standards are followed testing and deployment of application enhancements  Experience in Ab Initio toolsets including the following  o Parallel and serial flow batch graphs conditional components other components like reformat normalize and join lookup and graphs processing ASCII and EBCDIC layouts  o Knowledge on Abinitio architecture including the GDE Cooperating system EME and other related items  o Fine tuning of Abinitio graphs based on performance enhancement by proper usage of memory in the components  o Well versed with various Ab Initio components such as Join Rollup Partition Departition Dedup sorted Scan Normalize DeNormalize  o Expertise knowledge improving Performance and Troubleshooting of the AbInitio graphs and monitoring ABInitio run time statistics  o Experience with advanced Abinitio metaprogramming air commands and other admin related tasks including the creation of save and performing migration from one server to the other  Establish support such as acquiring conditioned test data support from third partyteam etc for Integration Testing to simulate production environment and to ensure correctness and quality of buildparameter set up  Getting sign off from IT managers for deploying parameterset up onto production environment  Documenting implementation plan and Hour by Hour plan listing down the tasks in sequence of their execution on the date of implementation  Coordinate release activities across multiple teams|none
Data Engineer|https://www.livecareer.com/resume-search/r/data-support-services-engineer-fd6014dbd6d04903b67269cf3fc6cd59|12880653418622435105799992611550629230|Jessica    Claire                   Montgomery Street     San Francisco     CA  94105    609 Johnson Ave       49204     Tulsa     OK       H   555 4321000    C       resumesampleexamplecom    Date of Birth         India                      single                    Summary     Desktop and Server Support Application Server Technician Offer my Windows Server 20122008 R22003 Windows XP78 Mac OS X Linux Application Server Microsoft Office 2010 and Office Mac 2011 Active Directory and Network LANWAN switches and routers experience Desktop and server hardware and software technical support experience Strong analytical troubleshooting communication and customer service skills  Skilled Windows System Administrator offering 10 years of experience building and maintaining multiplatform technology services with a solid understanding of current Windows Mac and UNIX application systems       Highlights           Systems	Windows XP78 Desktop	Max OS X 108 109 1010	iO78 mobile and tablet  Windows 20032008 Server	Android mobile		Red Hat Enterprise Linux  Unix web applications	LANWAN  Mobile Phone	iPhoneiPad Apple	Blackberry		Android  Applications	Microsoft Office 20072010	Office Mac 2010		Final Cut 7 and 10  Microsoft Office 365	Pages OS X		Numbers OS X  Adobe Creative Suite cloud	Adobe Acrobat XXI	Adobe Lighthouse 45  Parallels	WebEx  Utilities	Symantec Antivirus	Voltage Email Encryption	Barracuda Backup Cloud  PGP DesktopServer	Symantec Ghost  Server Applications	Active Directory	PowerShell Scripting	WINS	DFS  DHCP	FilePrint Services	LDAP	Group Policy GP  Exchange 2010	NTFS security		HyperV	DNS                         Accomplishments       Requirements Analysis    Completed business requirements analysis including the evaluation of systems specifications for the Soundview Throgs Neck Community Health Center     Strategy and Planning    Developed and communicated Electronic Health Record security policies and standards to all users  Established policies and procedures for medical record documentation     IT Training    Successfully trained all employees to use Electronic Health Record and Billing systems     Network Support    Acted as first point of contact for all major technical issues including power outages system failures and disaster recovery  Oversaw infrastructure of three offices and acted as support for helpdesk technicians of Yeshiva University          Experience       Data Support Services Engineer       072013      092013     Montefiore Medical Center formally SVTNCMHC Health Care Services    –    City     STATE            Managed the daytoday IT operations for the Montefiore Medical Center  Assisted in the migration of technology services from Yeshiva Universitys servers to Montefiores servers including computers user logins data files printer settings software applications and email archives  Provided QA testing in the migration of the centers Electronic Health Record Mindlinc and Billing IMA system  Trained all staff in the use of Montefiores technical services including clerical registration billing electronic health record and emailprintingdata file usage           Technical System Support Engineer       072003      072013     Yeshiva University Health Care Services Soundview Throgs Neck Community Health Center SVTNCMHC    –    City     STATE            Desktops Mobile Phones Printers and Application Servers Provided all levels of enduser desktop server mobile phonetablet and printer technical support for 2 healthcare center locations in the Bronx  Backend technical support for all server and network services  Responsible for managing 15 application servers including 4 domain controllers  Deployed and maintained a Windows 2008R2 and 2003 Active Directory environment  Managed all aspects of server and application security using Active Directory LDAP and Linux  Planned and implemented the physical deployment and migration of Windows 7 desktops from Windows XP  Consulted daily with the executive clinical and administrative staff concerning the overall quality and possible improvement of technology systems for the medical center  Trained all staff in the use of SVTNYeshiva Universitys technical services including clerical registration billing electronic health record and emailprintingdata file usage  Provided QA support and testing of our internal and external billing system IMA  Work closely with outside vendors to design and maintain the EHR Billing and Backup applications  Implemented and maintained the centers data backup system using Barracuda Cloud Backup  Identified designed and implemented the requirements for the centers disaster recovery system  Responsible for managing and maintaining the centers audiovideo conference room system          Education       Graduate Certificate       Digital Media and Project Management       Expected in                   The New School      New York     NY     GPA        Status                  BBA       Computer Information Systems       Expected in                   Baruch College City University of New York      New York     NY     GPA        Status                  Skills      Active Directory administrative Adobe Adobe Acrobat Antivirus Apple audio Backup Billing billing system clerical Encryption Desktops DHCP disaster recovery DNS Email Ghost LAN LDAP Linux Mac managing Max Exchange Microsoft Office Office Windows 7 Windows Windows XP migration Enterprise network OS printer Printers quality QA Red Hat Servers Scripting Symantec technical support Phones Phone Unix Utilities video WAN web applications|none
Data Engineer|https://www.livecareer.com/resume-search/r/aws-data-engineer-fcef99cc1f1c4bdeb25cbb8d5b3ac32c|339690346324715490168338998099130748299|Jessica    Claire                                   609 Johnson Ave       49204     Tulsa     OK   100 Montgomery St 10th Floor    H   555 4321000    C       resumesampleexamplecom    Date of Birth         India                      single                    Summary       Dynamic and motivated IT professional with around 7 years of experience as a Big Data Engineer with expertise in designing data intensive applications using Hadoop Ecosystem  Big Data Analytical  Cloud Data engineering  Data Warehouse  Data Mart Data Visualization  Reporting  and Data Quality solutions   In  depth knowledge of Hadoop architecture and its components like YARN  HDFS Name Node Data Node Job Tracker Application Master Resource Manager  Task Tracker and Map Reduce programming paradigm  Extensive experience in Hadoop led development of enterprise level solutions utilizing Hadoop components such as Apache Spark MapReduce HDFS Sqoop PIG Hive HBase Oozie Flume NiFi Kafka Zookeeper and YARN  Profound experience in performing Data Ingestion Data Processing Transformations enrichment and aggregations  Strong Knowledge on Architecture of Distributed systems and Parallel processing Indepth understanding of MapReduce programming paradigm and Spark execution framework  Experienced with the Spark improving the performance and optimization of the existing algorithms in Hadoop using Spark Context  SparkSQL  Dataframe API  Spark Streaming MLlib  Pair RDD s and worked explicitly on PySpark and Scala   Handled ingestion of data from different data sources into HDFS using Sqoop Flume and perform transformations using Hive Map Reduce and then loading data into HDFS  Managed Sqoop jobs with incremental load to populate HIVE external tables Experience in importing streaming data into HDFS using Flume sources and Flume sinks and transforming the data using Flume interceptors  Experience in Oozie and workflow scheduler to manage Hadoop jobs by Direct Acyclic Graph  DAG  of actions with control flows  Implemented the security requirements for Hadoop and integrating with Kerberos authentication infrastructure KDC server setup creating realm domain managing  Experience of Partitions bucketing concepts in Hive and designed both Managed and External tables in Hive to optimize performance   Experience with different file formats like Avro  parquet  ORC  Json and XML   Expertise in Creating Debugging Scheduling and Monitoring jobs using Airflow and Oozie  Experienced with using most common Operators in Airflow  Python Operator Bash Operator Google Cloud Storage Download Operator Google Cloud Storage Object Sensor  Handson experience in handling database issues and connections with SQL and NoSQL databases such as MongoDB  HBase  Cassandra  SQL server  and PostgreSQL   Created Java apps to handle data in MongoDB and HBase Used Phoenix to create SQL layer on HBase  Experience in designing and creating RDBMS Tables Views User Created Data Types Indexes Stored Procedures Cursors Triggers and Transactions  Expert in designing ETL data flows using creating mappingsworkflows to extract data from SQL Server and Data Migration and Transformation from OracleAccessExcel Sheets using SQL Server SSIS   Expert in designing Parallel jobs using various stages like Join Merge Lookup remove duplicates Filter Dataset Lookup file set Complex flat file Modify Aggregator XML  Handson experience with Amazon EC2 Amazon S3 Amazon RDS VPC IAM Amazon Elastic Load Balancing Auto Scaling CloudWatch SNS SES SQS Lambda EMR and other services of the AWS family  Created and configured new batch job in Denodo scheduler with email notification capabilities and Implemented Cluster setting for multiple Denodo node and created load balance for improving performance activity  Instantiated created and maintained CICD continuous integration  deployment pipelines and apply automation to environments and applications  Worked on various automation tools like GIT Terraform Ansible Experienced in fact dimensional modeling  Star schema Snowflake schema  transactional modeling and SCD Slowly changing dimension  Experienced with JSON based RESTful web services and XMLQML based SOAP web services and also worked on various applications using python integrated IDEs like Sublime Text and PyCharm   Efficient Cloud Engineer with years of experience assembling cloud infrastructure Utilizes strong managerial skills by negotiating with vendors and coordinating tasks with other IT team members Implements best practices to create cloud functions applications and databases         Skills          ·  Big Data Technologies  Hadoop MapReduce HDFS Sqoop PIG Hive HBase Oozie Flume NiFi Kafka Zookeeper Yarn Apache Spark Mahout Sparklib  ·  Databases  Oracle MySQL SQL Server MongoDB Cassandra DynamoDB PostgreSQL Teradata Cosmos  ·  Programming  Python PySpark Scala Java C C Shell script Perl script SQL  ·  Cloud Technologies  AWS Microsoft Azure  ·  Frameworks  Django REST framework MVC Hortonworks  ·  Tools  PyCharm Eclipse Visual Studio SQLPlus SQL Developer TOAD SQL Navigator Query Analyzer SQL Server Management Studio SQL Assistance Eclipse Postman  ·  Versioning tools  SVN Git GitHub    ·  Operating Systems  Windows 78XP20082012 Ubuntu Linux MacOS  ·  Network Security  Kerberos  ·  Database Modelling  Dimension Modeling ER Modeling Star Schema Modeling Snowflake Modeling  ·  Monitoring Tool  Apache Airflow  ·  Visualization Reporting  Tableau ggplot2 matplotlib SSRS and Power BI  ·  Machine Learning Techniques  Linear  Logistic Regression Classification and Regression Trees Random Forest Associative rules NLP and Clustering                      Experience       AWS Data Engineer       012022      022022     Accenture Contractor Jobs    –    Rochester     NY            Designed and setup Enterprise Data Lake to provide support for various uses cases including Analytics processing storing and Reporting of voluminous rapidly changing data  Responsible for maintaining quality reference data in source by performing operations such as cleaning transformation and ensuring Integrity in a relational environment by working closely with the stakeholders  solution architect  Designed and developed Security Framework to provide fine grained access to objects in AWS S3 using AWS Lambda DynamoDB  Set up and worked on Kerberos authentication principals to establish secure network communication on cluster and testing of HDFS Hive Pig and MapReduce to access cluster for new users  Performed end toend Architecture  implementation assessment of various AWS services like Amazon EMR Redshift S3  Implemented the machine learning algorithms using python to predict the quantity a user might want to order for a specific item so we can automatically suggest using kinesis firehose and S3 data lake  Used AWS EMR to transform and move large amounts of data into and out of other AWS data stores and databases such as Amazon Simple Storage Service Amazon S3 and Amazon DynamoDB  Used Spark SQL for Scala  amp Python interface that automatically converts RDD case classes to schema RDD  Import the data from different sources like HDFSHBase into Spark RDD and perform computations using PySpark to generate the output response  Creating Lambda functions with Boto3 to deregister unused AMIs in all application regions to reduce the cost for EC2 resources  Importing  exporting database using SQL Server Integrations Services SSIS and Data Transformation Services DTS Packages  Coded Teradata BTEQ scripts to load transform data fix defects like SCD 2 date chaining cleaning up duplicates  Developed reusable framework to be leveraged for future migrations that automates ETL from RDBMS systems to the Data Lake utilizing Spark Data Sources and Hive data objects  Conducted Data blending Data preparation using Alteryx and SQL for Tableau consumption and publishing data sources to Tableau server  Developed Kibana Dashboards based on the Log stash data and Integrated different source and target systems into Elasticsearch for near real time log analysis of monitoring End to End transactions  Implemented AWS Step Functions to automate and orchestrate the Amazon SageMaker related tasks such as publishing data to S3 training ML model and deploying it for prediction  Integrated Apache Airflow with AWS to monitor multistage ML workflows with the tasks running on Amazon SageMaker  Environment AWS EMR S3 RDS Redshift Lambda Boto3 DynamoDB Amazon SageMaker Apache Spark HBase Apache Kafka HIVE SQOOP Map Reduce Snowflake Apache Pig Python SSRS Tableau  Assessed organization technology infrastructure and managed cloud migration process  Configured computing networking and security systems within cloud environment  Implemented cloud policies managed technology requests and maintained service availability           Data Engineer       012016      112019     Verizon    –    Beaverton     OR            Worked on Azure Data Factory to integrate data of both onprem MY SQL Cassandra and cloud Blob storage Azure SQL DB and applied transformations to load back to Azure Synapse  Managed Configured and scheduled resources across the cluster using Azure Kubernetes Service  Monitored Spark cluster using Log Analytics and Ambari Web UI  Transitioned log storage from Cassandra to Azure SQL Datawarehouse and improved the query performance  Involved in developing data ingestion pipelines on Azure HDInsight Spark cluster using Azure Data Factory and Spark SQL  Also Worked with Cosmos DB SQL API and Mongo API  Develop dashboards and visualizations to help business users analyze data as well as providing data insight to upper management with a focus on Microsoft products like SQL Server Reporting Services SSRS and Power BI  Performed the migration of large data sets to Databricks Spark create and administer cluster load data configure data pipelines loading data from ADLS Gen2 to Databricks using ADF pipelines  Created various pipelines to load the data from Azure data lake into Staging SQLDB and followed by to Azure SQL DB  Created Databrick notebooks to streamline and curate the data for various business use cases and also mounted blob storage on Databrick  Utilized Azure Logic Apps to build workflows to schedule and automate batch jobs by integrating apps ADF pipelines and other services like HTTP requests email triggers etc  Worked extensively on Azure data factory including data transformations Integration Runtimes Azure Key Vaults Triggers and migrating data factory pipelines to higher environments using ARM Templates  Ingested data in minibatches and performs RDD transformations on those minibatches of data by using Spark Streaming to perform streaming analytics in Data bricks  Environment Azure SQL DW Databrick Azure Synapse Cosmos DB ADF SSRS Power BI Azure Data lake ARM Azure HDInsight Blob storage Apache Spark  Adept in troubleshooting and identifying current issues and providing effective solutions  Managed performance monitoring and tuning while identifying and repairing issues within database realm  Identified key use cases and associated reference architectures for market segments and industry verticals  Designed surveys opinion polls and assessment tools to collect data  Tested validated and reformulated models to foster accurate prediction of outcomes  Created graphs and charts detailing data analysis results  Recommended data analysis tools to address business issues  Developed new functions and applications to conduct analyses  Cleaned and manipulated raw data  Collaborated with solution architects to define database and analytics engagement strategies for operational territories and key accounts           Big Data Engineer  Hadoop Developer       102013      122015     Two95 International Inc    –    Boca Raton     FL          AnsibleDenodoDenodoCloudWatchAvroPySparkPySparkPySparkMLlibDataframeNiFiNiFi  Interacted with business partners Business Analysts and product owner to understand requirements and build scalable distributed data solutions using Hadoop ecosystem  Developed Spark Streaming programs to process near real time data from Kafka and process data with both stateless and state full transformations  Worked with HIVE data warehouse infrastructurecreating tables data distribution by implementing partitioning and bucketing writing and optimizing the HQL queries  Built and implemented automated procedures to split large files into smaller batches of data to facilitate FTP transfer which reduced 60 of execution time  Worked on developing ETL processes Data Stage Open Studio to load data from multiple data sources to HDFS using FLUME and SQOOP and performed structural modifications using Map Reduce HIVE  D eveloping Spark scripts UDFS using both Spark DSL and Spark SQL query for data aggregation querying and writing data back into RDBMS through Sqoop  Written multiple MapReduce Jobs using Java API Pig and Hive for data extraction transformation and aggregationAvrom multiple file formats including Parquet Avro XML JSON CSV ORCFILE and other compressed file formats Codecs like gZip Snappy Lzo  Strong understanding of Partitioning bucketing concepts in Hive and designed both Managed and External tables in Hive to optimize performance  Developed PIG UDFs for manipulating the data according to Business Requirements and also worked on developing custom PIG Loaders  Developing ETL pipelines in and out of data warehouse using combination of Python and Snowflakes SnowSQL Writing SQL queries against Snowflake  Experience in report writing using SQL Server Reporting Services SSRS and creating various types of reports like drill down Parameterized Cascading Conditional Table Matrix Chart and Sub Reports  Used DataStax Spark connector which is used to store the data into Cassandra database or get the data from Cassandra database  Wrote oozie scripts and setting up workflow using Apache Oozie workflow engine for managing and scheduling Hadoop jobs  Worked on implementation of a log producer in Scala that watches for application logs transform incremental log and sends them to a Kafka and Zookeeper based log collection platform  Used Hive to analyze data ingested into HBase by using HiveHBase integration and compute various metrics for reporting on the dashboard  Transformed tPySpark using AWS Glue dynamic frames with PySpark cataloged the transformed the data using Crawlers and scheduled the job and crawler using workflow feature  Worked on installing cluster commissioning  decommissioning of data node name node recovery capacity planning and slots configuration  Developed data pipeline programs with Spark Scala APIs data aggregations with Hive and formatting data JSON for visualization and generatiPySpark     Environment AWS Cassandra PySpark Apache Spark HBase Apache Kafka HIVE SQOOP FLUME Apache oozie Zookeeper ETL UDF Map Reduce Snowflake Apache Pig Python Java SSRS  Onfidential  Developed and implemented Hadoop code while observing coding standards  Optimized and tuned Hadoop environments and modified hardware to meet prescribed performance thresholds  Developed new functions and applications to conduct analyses  Created graphs and charts detailing data analysis results  Tested validated and reformulated models to foster accurate prediction of outcomes           Python Developer        092012      102013     Fiserv    –    City     STATE            AWS S3 EC2 LAMBDA EBS IAM Datadog CloudTrail CLI Ansible MySQL Python Git Jenkins DynamoDB Cloud Watch Docker Kubernetes  Leveraged open communication collective decisionmaking and thorough reviews to create performant and scalable systems  Worked with serverside and frontend technologies and leveraged common design patterns to code dynamic and userfriendly systems  Implemented new API routes architected new ORM structures and refactored code to boost application performance  Harnessed version control tools to coordinate project development and individual code submissions  Introduced cloudbased technologies into Python development to expand onpremise deployment options  Wrote clear and clean code for use in projects  Resolved customer issues by establishing workarounds and solutions to debug and create defect fixes          Education and Training       Post Graduate        Data Engineering        Expected in   022022                Purdue University      West Lafayette     IN     GPA        Status                  Post Graduate        Data Science And Business Analytics        Expected in   092021                University of Texas At Austin      Austin     TX     GPA        Status                  Bachelor of Arts       Business Administration And Management       Expected in   122009                Califonia State University       Fullerton CA          GPA        Status   |none
Data Engineer|https://www.livecareer.com/resume-search/r/voice-data-network-engineer-22138788e64d42bdb03363162c2bd70a|285353067357438442010566533524756651993|Jessica    Claire                   Montgomery Street     San Francisco     CA  94105    609 Johnson Ave       49204     Tulsa     OK       Home   555 4321000    Cell       resumesampleexamplecom              Summary      Technical Customer Service Specialist with a vast knowledge of web applications software and framework seeking to assist clients in all troubleshooting endeavors Outstanding networking adept at developing customer relationships looking for an opportunity to bring exceptional team building skills to a management position in a vibrant customer service department          Highlights           RoutersHubsSwitches        Juniper Nexus Cisco 2600 2800 3600 3700 3800 7200 2900 3500  Authentication TACACS  RADIUS  Network Analyzers Ethereal Sniffer Pro  Network Technologies        STP RSTP HSRP VRRP IRB Port Channel Cisco ASA 5500 SA  Operating Systems Windows20002003 Win98ME2000 proxp  Routing Protocols TCPIP RIP EIGRP OSPF and BGP  WAN Technologies T1E1 DS3 FrameRelay DSL MPLS leasedline  LAN Technologies 8021q ISL Patching up BackupRestoration DNS Infoblox DHCP  VOIP SIPH323 MGCPTDMSS7 Avaya  Voice gateways                         Accomplishments       10 years of IT experience in design development implementation troubleshooting and maintenance of mediumto large scale Network infrastructure Experience in Static Routing and configuring dynamic Routing Protocols  RIP v1 and v2 IGRP EIGRP OSPF and BGP Expertise in network protocols Switching Routing and Security technologies Experience on Cisco Catalyst Series 6500 Switches and Virtual switching system  Deployed the switches in high availability configuration  Good knowledge of Spanning Tree Protocol  IEEE 8021d IEEE 8021w IEEE 8021s PVST Well experienced in VLAN implementation VTP domain settings Stacking Load balance and Redundancy technologiesXRRP VRRP HSRP PAGP LACP Configuration of Access Control Lists ACL Quality of  ServiceQoS VPN NATPAT policies Experience in implementation of  PPP ISDN HDLC Frame Relay  T1 DS3 MPLS Installation and maintenance of RADIUS TACACS    Cisco Secure ACS Good understanding of the OSI Reference Model and the TCPIP Model Network Management CiscoWorks LMS ProCurve Manager Plus PCM  SonicwallOpen View Network analysis and troubleshooting tools  Sniffer Pro Wireshark Agilent Network and analysis tools Experience working with Cisco Nexus 2148 Fabric Extender and Nexus 5000 series to provide a Flexible Access Solution for a datacenter access architecture  Experience configuring Virtual Device Context in Nexus 7010  Experience convert PIX rules over to the Cisco ASA solution  Worked on Extensively on Cisco Firewalls Cisco PIX 506E515E525  ASA     550055105540 Series  Proficient in the operation and administration of Juniper NetScreenISGSSGbased firewalls Juniper SRXseries services gateways Juniper JMMXseries routers Juniper SAseries SSL VPN appliances F5 loadbalancing products LTM GTM FirePass and various Cisco IOSbased platform  Assisted in converting PIX rules over to the Cisco ASA solution  Good knowledge on VOIP protocols like H323 SIP MGCP and SS7 and interfacing of TDM to VOIP system    Worked on Avaya  Voice gateways for VOIP implementation using Cisco Catalyst switches Experience in System Software installations Implementation of DNS TCPIP DHCP and IAS in Network environments Windows 2003 Windows 2000 and Windows 9598 Sound knowledge of networking methods techniques and processes Extensive knowledge of installing advanced configurations on Cisco Call Manager platforms Possess good working knowledge of TCPIP networks Comprehensive knowledge of Cisco network protocols and transport systems Indepth knowledge of Cisco Unified Communications like UCM UCCX MPE Unity NSTS and DRSN Well experienced in Planning Designing implementation and management of mediumtolarge scale of enterprise networks         Experience       Voice  Data Network Engineer       012015   to   Current     Criterion Systems    –    Washington     DC             Responsible for presales and postsales support for the design and implementation of call center and corporate voice solutions  Implemented call routing call management and computer telephony integration  Configured installed and supported Cisco Unified Communication Manager CallManager 8x Cisco Messaging Systems UnityUnity Connection 8x CER VoiceGateways Cisco routers and switches  Performed system upgrades and patches based on request schedule or events  Created dialplans route patterns route groups route lists calling search space partitions  Patched and upgraded Cisco Unified Communications applications  Created Voice Mail boxes call handlers create and reset passwords MWIs administered and maintained Active Directory on Unity  Used tools such as Advanced Settings Tool Message Store manager DOH PropTest Services Tools Depot  Checked Outlook accounts in Exchange servers to view warning and limits text messages associated w Unity Voice Mail created Subscriber services skill sets and prompts for UCCX deployment  Created Subscriber services skill sets prompts for UCCX deployment  Established and maintained collaborative relationships with customers recognized for consistently providing excellent customer service and retention  Instrumental in developing telecommunications departmental Service Level Agreements SLAs and standard processes which optimized daily operations           Network Engineer       072012   to   112014     Criterion Systems    –    Beltsville     MD             Performed responsibilities of assisting voice engineer in designing and installing Cisco network equipment  Handle first level of designing and installing Cisco Call Manager and associated Voice applications  Responsible for the administration configuration and implementation of IP Telephony systems  Handle the tasks of designing and maintaining documentation related to network layout  Perform responsibilities of maintaining security policies on Cisco firewall solutions  Monitor and ensure that the requirements of high availability are in place for Cisco environment  Manage team tasks against SLAs as well as work with project plans adhering to project timelines resource constraints and within budget  Primary support for Cisco Unity Unity Connection Unity Express AIM and NMCUE Call Manager VOIP Migration Project Involved in migrating Lehmans Branches to centralized VOIP platform that will replace the existing Standalone phone system  Cisco router 3745 series and switch series 3560 are used to support to add VLANs to all the routers and switches to support the VOIP phones  Worked on Avaya Gateway equipment is added to the network to support the ports from Cisco Switches across the network  Successfully performed installation and configuration for IPSEC VPN on Cisco routers PIX series VPN Concentrator 3000 and ASA 5500 security appliances  Worked extensively in Configuring Monitoring and Troubleshooting Ciscos ASA 5500PIX security appliance Failover DMZ zoning  configuring     VLANsroutingNATing with the firewalls as per the design  Assisted in migration of centralized voice mail system based on Cisco Unity connection and support interfacing of legacy TDM PBX of the sited in voice network system  Familiar with H323 IOS gateways and SRST telephony design and implementation and call manager deployment in the voice network  Hands on experience on implementation and troubleshooting of ACLs and QoS for the networks Involved in supporting voice infrastructure including call routing the voice gateways and its troubleshooting methods  Worked on updating CATOS for that switches and IOS for the routers to support the VOIP standalone system for 6500 Multilayer switch and 3500 switch series  HP Openview SNMP network node manager is used to monitor the network and in the times of green zones and DMZ zones           Sr Voice Data Analyst       2012   to   062012     Criterion Systems    –    Germantown     MD             Troubleshoot network software and hardware issues Remote corrective actions supporting Monitored all functions around the voice and data network  Responsibly monitorered network and Tier 23 support  Interfacework with repairrestoration of remote site equipment Assisting field technicians in maintenance of remote site equipment Responsibly cross trained other members of the Network Engineering team to broaden the knowledge base within the team  Managed emergency change needs of the business  Proven ability to learn new systems as required to effectively support customer needs  Troubleshoot wireless problems using different RF analysis tools  Handle and prioritize high call volumes and customer inquiries  Other duties as assigned by the Director of Telecommunications           Network Engineer       102009   to   112011     MORGAN STANLEY    –    City     STATE             Involved in Network Redesign for branch for data environment  Convert Branch primary WAN circuit T1 to MPLS and branch router security migration  Performing BGP Changes on branch router and headend router  Conversions to BGP WAN routing  Which will be to convert WAN routing from OSPF to BGP OSPF is used for local routing only which involves new WAN links  Replace network hardware with new 7200 routers and 3825 switches in all branch locations  Design and implementation of GRE for multicast and unicast communication on an existing IP VPN Managed and engineered 58 JuniperCheckpoint firewalls  Experience on designing and troubleshooting of complex BGP and OSPF routing problems  Involved in designing and implementing QOS and policy map to 3800 series routers for all the branches Worked closely with network monitoring staff and will do network design testingcertification prior to production implementation  Implements configurations and implementation instructions into change management system and insures that all approvals and processes are adhered to compliant with Audit  Worked on Layer 2 protocols such as VTP STP RSTP PVST MST and other VLAN troubleshooting issues and configuring switches from scratch and deployment Experience in branch relocation connect workstation servers etc  Rack and stack preconfigured new hardware and connect the circuits  Worked with carrier to test and turnup circuits  Worked with carriers like ATT Verizon Wind stream and Level3 for deploying WAN circuits and implementation of MPLS cloud Performs system level documentation on platforms and assists in project tracking and documentation  Experience with developing network design documentation and presentations using VISIO  Troubleshoots with problems regarding the network changes and migrations           Network Engineer       112006   to   092009     PITNEY BOWES    –    City     STATE             Responsible for Design integration configuration maintenance performance monitoring and security of network infrastructure including local area networks LAN wide area networks WAN  firewalls DHCP DNS Installing the Network devices in datacenter environment and clearly articulate complex network designs and drawings through documentation Visio as well as verbal training sessions  Experience in Configuring SitetoSite and Remote Site VPNs NATPAT policies  Managing Cisco Secure ACS for TACACS  RADIUS authentications  Monitoring customer data networks and providing fault isolation and remote troubleshooting  Experience on designing and troubleshooting of EIGRP routing issues  Responsible for the management of network at the client environment  Supporting and performing projects for the client WAN environment at a global level  Implementation of network system upgrades and modifications including planning testing scheduling and coordination  Ensures that change management and defined security procedures for all network systems are executed in accordance with customer policies and procedures  Interacting with Carriers for installation of new WAN circuits at Customer premises and makes sure circuit installed with no issues and ready to use before users move in to the branch  Providing Teir3 technical support for LANWAN issues and oncall for technical escalation on a rotational basis Remedy Ticketing system  Well experienced in troubleshooting bug related issues with help of Cisco TAC service  Providing networking services coordinate tasks and ensure their execution and documentation in accordance with established corporate standards           Systems  Network Engineer       052005   to   092006     WESTERN UNION    –    City     STATE              Resolved customer complaints and concerns with strong verbal and negotiation skills  Responsible for clients new branches turn up and managing the network environment  Installation of Operating Systems application softwares and Troubleshooting hardware issues Management of WAN connected over Frame relay and DSL Management of Pix Firewall  Cisco Routers and switches infrastructure Configuration of routers and switches for OSPF EIGRP VLANs STP Trunks Ether Channel Load Balancing Configuration of Routers and Firewalls for sitetosite IPSEC VPN tunnels Implemented Secured Wireless Network based on WPA and MAC Authentication  technologies Integration of AVAYA IPPhones with Switches in VLAN environment  Policy configuration and management of firewalls  DNS changes as per client requests  Planning about new product requirements Contacting Vendors for product purchases  Contacting Service providers to troubleshoot issues on WAN connectivity  Involved in planning and designing team for network upgradeschanges  Configuring NAT Policies Global VPN Client Policies Establishing SiteSite VPN Connections Maintenance of DHCP Server  Enabling highavailability and highcapacity features such as Spanning Tree and link aggregation on Switches Responsible for service request tickets generated by the helpdesk in all phases such as troubleshooting maintenance upgrades patches fixes and all around technical support Basic Configurations and Maintenance of various Switches Routers Firewalls and Wireless Access Points at different client locations Responsible for interaction with third party technicians on site Performed network support involving daily wiring maintenance of cabling switch maintenance network port reenabling and cable room Documentation of all new software installation procedures troubleshooting procedures Responsible for implementation of new network infrastructure includes Cabling Switching Routing Establishing MAN Connectivity between  their different braches Involved in Loop back tests and troubleshooting issues during establishment of T1 Line Dynamic VLAN implementation using IEEE 8021x protocol and RADIUS Server Integration of Active Directory Services ADS with RADIUS Server and creation of remote access polices on RADIUS Implementation of Access Control ListsACLs  QoS Implementation of Portfast on all access switches and setting bridge priorities on L3 Switches Environment Cisco 2900 3560 1800 3700 3800 7200 2900 3500          Education       Bachelor of Technology          Expected in   2003     Goa Institute of Technology                GPA               Certifications      CCNP Cisco Certified Network Professional  CCNA Cisco Certified Network Associate        Skills     Active Directory ADS articulate AVAYA Backup Basic BGP budget cable Cabling call center change management Cisco router Cisco Cisco Routers hardware network systems computer telephony integration Client excellent customer service DOH designing DHCP Documentation DNS DSL EIGRP engineer fast features FirewallsFrameRelay gateways Gateway HP Openview Hubs IP local area networks LAN layout leasedline MAC Director Managing Messaging Access Exchange Outlook 2000 Windows2000 Win98 Migration Network Engineering network design network hardware network support Network networking networks Operating Systems OSPF PBX phone system Policies presentations processes project plans Protocols Express RIP router Routers Routing sales sales support scheduling servers Service Level Agreements SLA SNMP software installation SS7 Store manager Switches switch Cisco Switches T1 TCPIP TDM technical support telecommunications Telephony Phones Troubleshoot Troubleshooting upgrades view VPN VISIO voice and data Voice Mail VOIP WAN wiring|none
Data Engineer|https://www.livecareer.com/resume-search/r/data-engineer-ii-30ba17cad1264ff7923637259cc2cb9f|148616979939238102062955431006346284182|Jessica    Claire                                   609 Johnson Ave       49204     Tulsa     OK   100 Montgomery St 10th Floor    H   555 4321000    C       resumesampleexamplecom    Date of Birth         India                      single                    Summary      Selfmotivated Data Engineer offering 5 years of leadership experience across various industries Methodical with significant experience in data mining and statistical analysis Excellent problemsolver with a history of automating processes and driving operational enhancements Effective at making important team decisions focused on moving products through planning preproduction and production phases        Skills           Data Integrity Validation and Analysis  Database Programming and SQL  Product Planning      Analytical Problem Solving  Strong Work Ethic  Application Support                       Experience       Data Engineer II        032021      Current     Usaa    –    Argyle     TX            Work with stakeholders to identify improvements to processes and data delivery using technical aptitude to deliver ad hoc tools reporting and analytics with a focus on the needs of the Residential Portfolio  Collaborated with solution architects to define database and analytics engagement strategies for operational territories and key accounts  Maintain JIRA projects and workflows to meet project metrics  Work with Residential Portfolio to reduce CIP Construction InProgress by 69 across Residential Cox Business and Network Transformation programs by developing clear processes to mitigate risk providing visibility through enhanced reporting and database aligning  Build and validate the hypothesis of product ideas and infrastructure improvements for Fiber Reinforcement New Build Rebuild and Expansion Projects  Provide for database management to support the integrity of data for enterprisesupported tools and applications  Work with software development team to design and customize applications SiteTracker applications and trackers to meet market exceptions  Utilized existing reporting to perform data blending as needed to serve business needs  Develop processes to improve workflow and department efficiency  Designed and developed data quality dashboards with visualization in Tableau Power BI and Salesforce  Work with the development team to define and implement customer change requests to enhance product functionality  Complete pilot testing implement best data practices and optimize workflow to enhance performance and drive efficiencies in the organization to meet or exceed customer and business expectations  Utilize WATTS and SiteTracker experience as a user andor report development  Identify strengths and weaknesses of existing reports suggests areas of improvement and help enhance existing data reports to meet evolving requirements  Interpret and analyze data using exploratory mathematic and statistical techniques based on scientific methods           ANALYTICS CONSULTANT       032019      042021     Syndigo    –    Boise     ID            Partnered with WBS developers to automate manual processes decreasing errors and saving time creating a 6 increase in margins 2021 fiscal year  Managed performance monitoring and tuning while identifying and repairing issues within database realm  Worked to create UI mockups and prototypes that illustrate how sites function and look like  Provided executives with analytics and decisionsupport tools used a basis for reorganization consolidation and relocation strategies  Executed tests collected and analyzed resulting data and identified trends and insights to achieve maximum ROI in paid search campaigns  Evaluated project requirements and content standards for each project to produce copy in line with a creative structure  Recommended changes to website architecture content and linking to improve SEO positions           DATA QUALITY ANALYST       052018      092020     Illumina    –    Virginia     MN            Worked mainly with wellknown engineering clients to provide customers with quality products  Dashboard development for project projection project closing and project profit  Responsible for estimating negotiating and agreeing on budgets and times lines while overseeing the production process  Responsible for drafted proposals per specifications and estimation skeleton with a focus on Data Centers  Developed RPAs that work alongside ERP to run cost analytics and tracked quality data metrics  Provide code compliance knowledge and enforcement for both owner and contractor  Drive and own backlog grooming and management prioritize iteration and drive acceptance testing and delivery of iterations  Defining road maps and prioritizing backlogs of work to meet with a vision of providing services that meet customers standards  Prioritized functionality backlog after golive to resteer team to achieve the desired ROI  Performed root cause analysis based on rework data to create corrective and preventive measures throughout the product development  Collaborated with Business Analysts and the software development team to identify and convert business goals into data requirements  Developed and streamlined productivity tracker to provide 34month predictions  Responsible for managing the progression of a project from RFP to  CO          Education and Training       Master of Science       Computer Science  Analytics        Expected in                   Georgia Tech Master of Science in Computer       Atlanta GA          GPA        Status                  Bachelor of Science       Civil Engineering   Industrial Microbiology       Expected in                   University of Georgia      Athens     GA     GPA        Status                 Activities and Honors       GatherUp  Nonprofit organization working with the community to provide recourses for further growth  NAMIC  Marketing  2021 2H Synergy Award|none
Data Engineer|https://www.livecareer.com/resume-search/r/data-center-cloud-engineer-architect-8eec0f1efb0947ffab14c9580532f9d1|326757138740783914221199641260286969063|Jessica    Claire               Montgomery Street       San Francisco     CA  94105    609 Johnson Ave       49204     Tulsa     OK      Home   555 4321000        Cell           resumesampleexamplecom                  Summary      Senior system engineer with 20 years of experience in software design development and architecture Full software development life cycle requirement gathering prototyping design implementation testing release and maintenance Has strong customer interfacing experience Has strong project lead and vendor management experience Capable of working with various teams to drive requirement gathering analysis and application design Polished communication and presentation skills able to demo products and solutions to both internal and external audience        Highlights          Performance and scalability optimization  Development environment software  Complex problem solver  Strong decision maker  Excellent communicator     Strong in C C  Microsoft Visual C  PHP MySQL   Linux Scripting   Cloudera Hadoop Certified  Ceph storage clustering  Apache Mesos   Docker and Linux Containers                       Accomplishments      Promoted to Lead Engineer after 18 months of employment at Dell  Promoted to strategist position at Dell after 5 years of employment  Holder of several US issued patents  US patent 20090100194  httpwwwfaqsorgpatentsapp20090100194   US patent 20130086262  httpwwwfaqsorgpatentsapp20130086262   US patent 20120198349  httpwwwfaqsorgpatentsapp20120198349         Experience      022013   to   072015     Data Center Cloud EngineerArchitect      Abbott Laboratories    –    Madison     MS             Solid experience with Mesosphere and the latest offering of DCOS Data Center Operating System Currently integrating DCOS on cloud hardware using Chef as a configuration management tool   Experience with Data Center Cloud Servers Responsible for designing and building a rack level softwarehardware solution for hyperscale cloud customers   Responsible for evaluating ARM 64 bit as a server solution in a data center   Evaluating CoreOS and Docker containers as a solution for Dell servers in a data center   Experience with Ceph as a cold storage server solution  Currently working as a solution architect to support the sales team by providing technical guidance on Dell cloud servers  Responsible for proposing solutions to customers and responding to customer RFI and RFP  Travel to customer site to present about Dell cloud servers          2007   to   022013     Principal Engineer      Johnson  Johnson    –    Athens     GA             Worked on competitive analysis to compare the Cisco UCS solution to Dells Active System solution  Worked on automating OS deployment using WSMAN and Dells life cycle controller The solution was intended to help services team in the field to have a quick tool to deploy the Active System solution  Worked on integrated solutions using PowerEdge servers PowerConnect switches and Compellent storage array The integrated solution is intended to build a business ready configuration called vStart  Was Responsible for the integration of Hadoop Big Data with HPC clustering stack  Was the lead technical engineer to lead an engineering group of 10 The team was responsible for developing custom solutions to address unique customer requirements  Was responsible to support the sales team in EMEA by providing technical insight into Dell products  Developed plugins for Microsoft SCOM System Center Operation Manager Most development was done using C Visual Basic scripting and XML  Traveled to Dell India to train group of engineers on Dell system management products  Interface and interlock between several teams to lock down requirements and drive to results  Worked with Dell marketing on new feature requirements  Developed a Windows and Linux solution to monitor Dell systems for storage and BMC alerts and send SNMP traps to a system management console          032000   to   2007     Senior Software Engineer      Transcore    –    Hayward     CA             Developed firmware using C and C to authenticate users via Active Directory using industry standard LDAP protocol  Have a good working knowledge of USB protocols Worked with CATC to debug several USB devices  Developed a USB Linux kernel mode mass storage stack to make a USB slave device appear as a USB disk  Was the lead engineer of a group that developed Voice over IP clientserver application that allowed chat over the network The technology used GSM610 Audio Codec and Win32 Wave API  Developed Internet Explorer plugin using ActiveX technology to be used with Dell Remote Access Cards remote media feature  Worked on defining a protocol to send SCSI commands over  TCPIP The protocol was used as the basis for the remote media feature on Dells Remote Management Card DRAC   Developed application software for remote KVM keyboard video and mouse to provide the console redirection feature for Dells Remote Management Card DRAC   Was responsible for the integration of a high performance serial device driver using Microsoft DDK for Windows NT as well as Windows 20002003 following the WDM architecture          041999   to   032000     Software Engineer      Transcore    –    Miramar     FL             Was responsible for the design implementation and integration of tools such as compiler linker and assembler in an integrated development environment IDE  The IDE is used by firmware programmers to develop on Zilogs family of microcontrollers  This project required intense use of C MFC and Multithreaded Programming          031997   to   031999     Software Engineer      Transcore    –    Peachtree Corners     GA             Was the primary engineer responsible for developing Windows 98 and Windows NT device driver using WDM Win32 Driver Model Microsofts SDK and Microsofts DDK Driver Development Kit to allow host to target communication between Kodaks digital camera and the PC  Successfully developed application and interface software using C and object oriented techniques that allowed interfacing a digital camera to the IEEE 1394 high performance serial bus  Was part of the team to develop firmware embedded software for Kodaks high end digital camera  Was part of the team to develop the camera SDK software development kit using multithreaded concepts and Visual C the SDK was used by outside developers to control and acquire images from the Kodak digital camera          111994   to   031997     Software Engineer      ULTRA SCANCALSPAN CORPORTATION    –    City     STATE             Was part of the team responsible for coding and maintaining fingerprint match software using C and C on a UNIX workstation  Developed Windows 95 driver using C to allow communication with an ultrasonic fingerprint scanner from a PC over the parallel port  Integrated fingerprint match software into several applications using Visual C MFC and the Win32 SDK Software Development Kit  Designed and implemented firmware using Assembly and C to interface the MOTOROLA DSP56166 to an ultrasonic fingerprint scanner  Successfully developed firmware to allow transfer of images from a scanner to the PC over the parallel and the serial port Assembly and C were used in this project          Education      Expected in        BS     Electrical and Computer Engineering     State University of New York      Buffalo     New York     GPA   with Cum Laude GPA 3640            Skills      Win32 API ActiveX Big Data IPMI WSMAN C  C Visual C Visual Basic Visual Source Safe ClearCase Linux gnu tools  storage clustering competitive analysis  Database Dell servers device drivers XML Windows Audio API  PHP ASP  JAVA LDAP Active Directory MySQL Microsoft SQL MFC API Windows 2000  Windows 2008 Windows 20012  networking object oriented  Programming Red Hat Linux Ubuntu Linux  technical sales  SCSI protocols  Storage technology  scripting SNMP   UNIX USB VB scripting Voice over IP|none
Data Engineer|https://www.livecareer.com/resume-search/r/data-protection-engineer-95cf566a964e41eaa5970c3e1d68ce54|88130048337986624128176699613407932497|JC     Jessica    Claire                      Montgomery Street       San Francisco     CA    94105             555 4321000                 resumesampleexamplecom                         Profile     Professional and dedicated worker committed to delivering high quality performance and superior customer service to insure team success Utilize strong ethics customer relations and training  Over 8 years of experience in Storage management including designing installing configuring  and administering TSM  Netbackup Experience in both UNIX and Windows environment       Core Qualifications           Extensive knowledge of TSM administration procedures    Adept at server software installation and maintenance      Familiar with UNIX and Perl scripting     Good problem solving skills                          Professional Experience        072015   to   Present   Data Protection Engineer    Bmo         Pleasant Prairie     WI            TSM Implementation and administration TSM 6X 5X Implementation and administration on AIX Linux Solaris Windows platforms Tivoli data Protection for Oracle SQL implementation Bare metal Recovery implementation IBM 3592 EO5 LTO2LTO3 and LTO4  DataDomain configuration Tivoli Storage Management Disaster Recovery Implementation Installing TSM client on Unix and Win 200x servers TSM tuning for faster backup and restore Server to server configuration Expertise in TSM DR implementation and recovery Lanfree configuration  on UnixAixLinuxHPUX TSM library manager and library client configuration and Implementation Managing 8 TSM server environment with 2000 clients different site with Data Doman and physical library TSM administration and node backup centralized scheduling and reporting Avamar Client registration and configuration Avamar Client backup and restore Participate in SRT Schedules Retention and Targets yearly review with customers            042012   to   052015   Data Protection Engineer    Bmo         Portage     WI            TSM 6X 5X Implementation and administration on AIX Linux Solaris WinTel platforms Tivoli data Protection for Oracle SQL implementation Bare metal Recovery implementation IBM 3592 EO5 LTO2LTO3 and LTO4  DataDomain configuration Tivoli Storage Management Disaster Recovery Implementation Installing TSM client on Unix and Win 200x servers TSM tuning for faster and backup and restore Server to server configuration Expertise in TSM DR implementation and recovery Lanfree configuration  on UnixAixLinuxHPUX TSM library manger and library client configuration and Implementation Managing 10 TSM servers environment with 3000 clients different site with Data Doman and physical library            042007   to   052012   IT Specialist    Autodesk Inc         Colorado     TX            Netbackup 5x 6x implementation and administration on Window and Unix Netbackup client installation and configuration Provided  247 oncall support rotation Responsible for troubleshooting and daily backup issues Monitored and maintained tape volumes Troubleshot ACSLStape library software  issues Wrote a Runbook for both TSM and Netbackup Netbackup to TSM migration Netbackup client implementation Backup and restore using TSM Tivoli data Protection for Oracle SQL implementation            122006   to   042007   System Administrator    Advantest America Corporation         Fremont     CA            Coordinated hardware and software installations and upgrades to insure work is performed in accordance with Agency policy  Coordinated and monitored troubleshooting to isolate and diagnose command system problems  Daily system checks of all TSM servers tape library devices and server backup operations  Improved processes by writing scripts to automate task that is done on regular base            042000   to   062005   Design Automation Engineer    Intel Corp         Multiple Cities     NJ            Extensive experience in gate level simulation  Evaluated and QA new simulation tools  Assisted Design Engineers with tool issues they encountered and solve the problem  Interfaced between Intel and tool vendors to resolve issues and new releases  Provided automation and made improvements to existing flows  Trained new users on Gate Level Simulation tools and any new methodology  Experience in test vector generation test bench writing and regression running  Supported GLS and RTL VTPSIM Vector Test Pattern Simulation for all CPD Components Platform Division and tool owner for VTPSIM  Supported Design Engineering Environment for all Chipset Engineering including Software and License installations  Responsible for Local DBA Database Administration for TIBETBug tracking tool  Developed utility to generate indicator data for managers  Created Auto clone feature for Design Group which enabled them to submit bugs in two different projects at the same time  Provided training for Design Product Design Automation and Marketing Engineers on bug tracking tool  Setup training class for Design Automation Group            051997   to   042000   Test Engineer    Drs Technologies         Johnstown     PA            Sole author of STIL2S9K tool that generated all S9K test mode patterns for Camino MCH MTH and Carmel MCH  This tool was the first tool that enabled PCG Platform Components  Group to generate scan transition fault vectors with multiple timing sets  Kafka tool owner and support  This tool converts VCD Variable Change Dump file to STIL Standard Test Interface Language format  It was the first tool that enabled PCG to convert VCD to STIL  Worked with Teradyne Engineers to develop a STIL2J973 vector generation tool for J973 testers  Ran tests and gave feedback to the vendor  Helped out Product Engineers in generating test mode and functional vectors and validated the pattern before silicon arrived  Site owner for software tools Fabio and Purify  These tools were required to be run on the products test tape for white paper process          Education        Expected in   1994   Bachelor of Science       Computer Engineering    California State University     Sacramento     CA      GPA       Computer Engineering        Skills     AIX Agency automate Automation Backup hardware Client clients Database Administration DBA Disaster Recovery functional HP UX IBM Intel Linux Managing 8 Marketing Win WinTel Windows Window 2000 migration Oracle processes QA reporting scheduling server configuration servers scripts Simulation Solaris SQL Tivoli troubleshooting TSM TSM 6X Unix upgrades Netbackup Netbackup 5x author|none
Data Engineer|https://www.livecareer.com/resume-search/r/senior-software-engineer-data-manager-92600f55fb9a4018a4a7688a4607e44f|191782290901319920686020512632969913854|JC     Jessica    Claire                      Montgomery Street       San Francisco     CA    94105             555 4321000                 resumesampleexamplecom                         Summary      Senior Software Engineer with 26 years of experience as an enterpriselevel database web applications developer technical lead and project manager  Expert Microsoft SQL database administrator with SQL server integration services SSIS and SharePoint experience  ​  Proven leader and strategic thinker able to architect cuttingedge software solutions and lead development teams through the entire software development life cycle SDLC  Recipient of NASAs Space Flight Awareness Honoree award for significant contributions in the preservation and management of Lunar sample data         Skills           Databases Microsoft SQL Server 20002014 MongoDB MySQL  Languages SQL Microsoft NET C and VB ColdFusion 11 Java JavaScript PowerShell Python CC  Development ToolsMethodologies SDLC Agile  Waterfall Methodologies Object Oriented Programming OOP Application Programming Interfaces API MVC Visual Studio Eclipse Git Subversion UML SSIS SSRS HTML5 CSS SASSLESS web services REST jQuery Bootstrap Accessibility508 Compliance Website Security UX Design  Graphic DesignMultimedia  Adobe Creative Suite CC Photoshop Illustrator InDesign Dreamweaver Premiere Pro Lightroom Inkscape  Software  Adobe Acrobat Pro Microsoft SharePoint Visio and Project R                         Experience        012007   to   Present   Senior Software EngineerData Manager    Ssi Schaefer Systems International North America         Columbus     OH            Designed and developed web database applications to showcase NASAcurated astromaterials sample collections including comprehensive searchable databases with sample processing and availability information scientific analyses references and multimedia photos 3D models videos for use by space and planetary scientists  Technologies used included Adobe ColdFusion Microsoft NET C JavaScriptJQuery SVG REST various APIs and Microsoft SQL among others  Architected managed and developed internal Enterpriselevel databases and applications using both traditional waterfall and agile methodologies  Led teams of 25 developers and interns both internal and in distributed teams and provided technical mentorship  Significant expertise as database architect and administrator with experience creating SQL server integration services SSIS and reporting service SSRS solutions and optimizing query performance  Regularly employed scripting technologies such as PowerShell and Python to implement work automation and provide data visualization  As webmaster for the directorate public websites was a recognized expert in all aspects of website management including the administration of IIS and Apache web servers ColdFusion and Java application servers and SQL servers  Maintained adherence to NASA and government standards and regulations accessibility508 compliance information privacy websiteapplication security  Developed and maintained relationships and collaborations within NASA and global research and technology communities that leveraged crossfunctional expertise to improve the quality and accessibility and transfer of scientific data and support NASAs Open Data initiatives            012001   to   012007   IT Consultant    Splunk         Aldie     VA            Windows 10 Windows Server 2003  2012 R2 Linux IIS 758 Apache ColdFusion Server Designed and developed custom ecommerce and informational websites for small to mediumsized clients using various technologies including Adobe ColdFusion and Flash Microsoft Visual Basic and ASP Java JavaScript MySQL and Microsoft SQL on ApacheLinux and IISWindows systems  Provided website management and system administration services to consumers and small businesses  Coordinated full range of project development from initial proposal to final delivery            011998   to   012001   IT Program Manager    Polar Tank         Houston     TX            Managed enterprise software projects with budgets in excess of 3M which were consistently completed within budgetary and time constraints  Prepared proposals managed budgets and developed business system requirements and functional specifications for proposed projects  Supervised 10 business analysts project managers application developers and contractors during entire software development lifecycle  Designed and implemented relational and OLAP databases for integration with web applications and developed middletier components using Microsoft Visual Basic ASP ADO and COMCOM technologies using the Microsoft Visual Studio IDE and SQL Server 2000 with Analysis Server  Experienced using ERWin Data Modeler and UML for database design  Successfully completed global implementation of wide area networks and computer installations in 20 international locations by directing internal resources and local and international external vendors            011994   to   011998   DSP Marketing Programs Manager    TEXAS INSTRUMENTS         City     STATE            Designed and implemented intranetextranet web applications for the sales organization customers and product distributors that greatly reduced marketing support and training costs for the division  Web applications were implemented in C and Perl on a UNIX platform for the NCSA Mosaic browser and for Netscape Navigator  Managed team of 34 developers            011993   to   011994   Technology Transfer Team Leader    SEMATECH         City     STATE            Managed an average of 30 projects a month for the Lithography division to fulfill technology transfer requirements of consortium            011991   to   011993   Design Engineer    IBM CORPORATION         City     STATE            Designed 486based computer motherboards and peripheral interfaces for IBMs PC Value Line          Education and Training        Expected in   1991   MS       Electrical Engineering    Solid State Devices  Circuits  University of Michigan     Ann Arbor     MI      GPA       Electrical Engineering        Awards              Skills     Microsoft NET 3D ADO Adobe Creative Suite Adobe Acrobat Adobe Dreamweaver Photoshop Premiere Agile Apache API ASP automation budgets C ColdFusion COM COM CSS clients data visualization database applications Databases database architect database design delivery directing ecommerce Eclipse ERWin extranet Flash functional government Graphic Design UX HTML5 IBM IDE IIS IIS 75 Illustrator InDesign Java JavaScript JQuery Linux marketing C Microsoft SharePoint Microsoft SQL SQL Server 2000 Windows 2000 MongoDB motherboards Multimedia MVC MySQL Enterprise Netscape Navigator networks Object Oriented Programming OOP OLAP Perl Programming project development proposals proposal Python quality reporting research sales scientific SDLC servers scripting software development Microsoft SQL Server SQL SQL server system administration UML UNIX Visio Microsoft Visual Basic VB Microsoft Visual Studio Visual Studio Web applications web servers Web Development Website websites website management webmaster Windows Server 486       Additional Information       AWARDS JETS Superior Performance Team Award 2014  Apollo Sample Curation Team NASA Group Achievement Awards 2014  Apollo Sample Curation Team  2013  Hayabusa Curation Team  Stardust Interstellar Curation Team JSC Directors Innovation Group Achievement Award 2013  Antarctic Meteorite Curation Team NASA Space Flight Awareness Awards 2009  Honoree  GRANTS 2016 NASA PDART CoPI Creating and Serving Novel Data Products of Astromaterials Combining ImageBased 3D Reconstructions and XRay CT Data of Astromaterials 2015 NASA PDART CoPI MoonDB Restoration and Synthesis of Lunar Petrological Data         Websites Portfolios Profiles|none
Data Engineer|https://www.livecareer.com/resume-search/r/sr-data-engineer-867553e4eb4548f0bdb1253aa98a392b|217835661821555841839767419203542304004|Jessica  Claire                             resumesampleexamplecom                      555 4321000                       Montgomery Street     San Francisco     CA      94105                                                                                                                                                                                                             Professional Summary       Over 8 years of progressive professional experience in analysis Design Development and Implementation as a Sr Data Engineer and Data ModelerData Analyst  Strong experience in Data Migration Data Cleansing Transformation Integration Data Import and Data Export  Good knowledge in Data Quality  Data Governance practices  processes  Highly Qualified with about 5 years of experience in building Big data applications creating data lakes to manage structured and unstructured data  Well versed with Agile with Scrum Waterfall Model and Testdriven Development TDD methodologies  Server Reporting Services SSRS and SQL Server Integration Services SSIS  Worked with Java based ETL tool Talend and Implemented Integration solutions for cloud platforms with Informatica Cloud  Extensive experience in setting up CI CD pipelines using tools such as Jenkins Github Nexus and Maven  Experience developing On  premise and Real Time processes  Experience on Migrating SQL database to Azure data lake Azure data lake analytics Azure SQL database Data Bricks and Azure SQL Data Warehouse and Controlling and granting database access and migrating on premise databases to Azure Data Lake Store using Azure Data Factory  Strong experience in Big Data technologies like Spark Spark SQL Pyspark Hadoop HDFS Hive Sqoop Flume Kafka Spark Streaming  Experience in job workflow scheduling and monitoring tools like Oozie M2  Experience in importing and exporting data using Sqoop from HDFS to Relational Database Systems and viceversa  Experience in designing dashboards reports performing adhoc analysis and visualizations using Tableau Power BI  Handson experience on NoSQL databases like Snowflake HBase Cassandra and Mongo DB  Experience in building and architecting multiple Data pipelines end to end ETL and ELT process for Data ingestion and transformation in GCP and coordinating tasks among the team  Expertise in DBMS concepts  Experience in GCP Dataproc GCS Cloud functions Big Table and Big Query  Experience in writing and executing unit system integration and UATscripts in data warehouse projects  Worked on different file formats like Parquet Avro ORC and Flat files  Designing star schema Snowflake schema for Data Warehouse ODS architecture  Experience with Apache Spark ecosystem using SparkCore SQL Data Frames and RDDs  Experienced in data manipulation using python  Handson experience working at Amazon Web Services AWS using Elastic Map Reduce Redshift and EC2 for data processing AWS glue RDS S3 Lambda  Proficient in installing configuring and using Apache Hadoop ecosystems such as MapReduce Hive Pig Flume Yarn HBase Sqoop Spark Storm Kafka Oozie and Zookeeper  Experience in integrating Kafka with Spark streaming for high speed data processing  Extensive experience in developing and driving strategic direction of SAP operating system SAP ECC and SAP business intelligence SAP BI system  Develop effective working relationships with client teams to understand and support requirements develop tactical and strategic plans to implement technology solutions and effectively manage client expectations  An excellent team member with an ability to perform individually good interpersonal relations strong communication skills hardworking and high level of motivation             Skills         Technical Skills  HadoopSpark Ecosystem  Hadoop MapReduce Hiveimpala YARN Kafka Flume Sqoop Oozie Zookeeper Spark  Databases Oracle My Sql SQL Server PostgreSQL HBase Snowflake Cassandra Mongo DB  Cloud computing  Amazon Web Services AWS Amazon Redshift MS Azure Azure blob storage Azure Data Factory Azure Synapse  Google cloud PlatformBig Query Big Table Dataproc      BI Tools Business Objects XI Tableau 91 Power BI  Query Languages SQL PLSQL TSQL  Scripting Languages Unix Python  Operating Systems Linux Windows Ubuntu Unix  SDLC Methodology Agile Scrum Waterfall UML                     Education       CBIT    Hyderabad           Expected in   2013     –      –       Bachelor’s        Computer Science          GPA                     Work History       Humana Inc      Sr Data Engineer   Riverton     WY                   102020      Current     Involved in requirements gathering analysis design development change management deployment  Involved in development of real time streaming applications using PySpark Apache Flink Kafka Hive on distributed Hadoop Cluster  Utilized Apache Spark with Python to develop and execute Big Data Analytics and Machine learning applications executed machine Learning use cases under Spark ML and Milib  Extracted data from heterogeneous sources and performed complex business logic on network data to normalize raw data which can be utilized by BI teams to detect anomalies  Designed and developed Flink pipelines to consume streaming data from Kafka and applied business logic to massage and transform and serialize raw data  Developed a common Flink module for serializing and deserializing AVRO data by applying schema  Developed Spark streaming pipeline to batch real time data detect anomalies by applying business logic and write anomalies to Hbase table  Implemented layered architecture for Hadoop to modularize design  Developed framework scripts to enable quick development  Designed reusable shell scripts for Hive Sqoop Flink and PIG jobs  Standardize error handling logging and metadata management processes  Indexed processed data and created dashboards and alerts in splunk to be utilized action by support teams  Responsible for operations and support of Big data Analytics platform Splunk and Tableau visualization  Managed developed and designed dashboard control panel for customers and Administrators using Tableau PostgresQL and REST API calls  Designed and Developed applications using Apache Spark Scala Python Nifi S3 AWS EMR on AWS cloud to format cleanse validate create schema and build data stores on S3  Developed CICD pipelines to automate build and deploy to Dev QA and production environments  Supported production jobs and developed several automated processes to handle errors and notifications  Also tuned performance of slow jobs by improving design and configuration changes of PySpark jobs  Created standard report Subscriptions and Data Driven Report Subscriptions  Tools Hadoop Map Reduce Spark Spark MLLib Tableau SQL Excel PIG Hive AWS PostgresQL Python PySpark Flink SQL Server 2012 TSQL CICD Git XML Tableau           Cognizant Technology Solutions      Sr GCP Data Engineer   Lake Forest     CA                   012018      092020     Developed multi cloud strategies in better using GCP for its PAAS and Azure for its SAAS  Involved in loading and transforming large sets of the structured semistructured dataset and analysing them by running Hive queries  Developed custom python program including CICD rules for Google cloud data catalog for metadata management  Design and develop spark job with Scala to implement end to end data pipeline for batch processing  Do fact dimensional modeling and proposed solution to load it  Processing data with Scala spark spark SQL and load in hive partition tables in parquet file format  Develop spark job with partitioned RDD like hash range custom for faster processing  Develop and deploy the outcome using spark and Scala code in Hadoop cluster running on GCP  Develop near real time data pipeline using flume Kafka and spark stream to ingest client data from their web log server and apply transformation  Performs data analysis and design and creates and maintains large complex logical and physical data models and metadata repositories using ERWIN and MB MDR  Assist service developers in finding relevant content in the existing reference models  Like Access Excel CV Oracle flat files using connectors tasks and transformations provided by AWS Data Pipeline  Utilized Spark SQL API in PySpark to extract and load data and perform SQL queries  Worked on developing Pyspark script to encrypting the raw data by using Hashing algorithms concepts on client specified columns  Responsible for Design Development and testing of the database and Developed Stored Procedures Views and Triggers  Developed Pythonbased API RESTful Web Service to track revenue and perform revenue analysis  Compiling and validating data from all departments and Presenting to Director Operation  Develop SQOOP script and SQOOP job to ingest data from client provided database in batch fashion on incremental basis  Use DISTCP to load files from S3 to HDFS and Processing cleansing and filtering data using Scala Spark Spark SQL HIVE Impala Query and Load in Hive tables for data scientists to apply their ML algorithms and generate recommendations as part of data lake processing layer  Build data pipelines in airflow in CP for ETL related jobs using different airflow operators both old and newer operators  Created Big Query authorized views for row level security or exposing the data to other teams  Good knowledge in using cloud shell for various tasks and deploying services           Honeywell      Big Data Engineer   Altamonte Springs     FL                   062016      122017     Implemented a generic ETL framework with high availability for bringing related data for Hadoop  Cassandra from various FRANCHI sources using spark  Experienced in using Platfora a data visualization tool specific for Hadoop and created various Lens and Viz boards for a realtime visualization from hive tables  Queried and analysed data from Cassandra for quick searching sorting and grouping through COL  Implemented various Data Modelling techniques for Cassandra  Joined various tables in Cassandra using spark and Scala and ran analytics on top of them  Participated in various upgrades and troubleshooting activities across enterprises  Knowledge in performance troubleshooting and tuning Hadoop clusters  Applied Spark advanced procedures like text analytics and processing using inmemory processing  Implemented Apache Drill on Hadoop to join data from SQL and No SQL databases and store it in Hadoop  Created architecture stack blueprint for data access with NoSQL Database Cassandra  Brought data from various sources into Hadoop and Cassandra using Kafka  Experienced in using Tidal enterprise scheduler and Ooze Operational Services for coordinating the cluster and scheduling workflows  Applied spark streaming for real time data transforming  Created multiple dashboards in tableau for multiple business needs  Installed and configured Hive and written Hive UDFs and used piggy bank a repository of UDFs for Pig Latin  Implemented Partitioning Dynamic Partitions and Buckets in HIVE for efficient data access  Exported the analysed data to the relational databases using Sqoop for visualization and to generate reports for the BI team Using Tableau  Implemented Composite server for the data virtualization needs and created multiple views for restricted data access using a REST API  Devised and led the implementation of next generation architecture for more efficient data ingestion and processing  Created and implemented various shell scripts for automating the jobs  Implemented Apache Sentry to restrict the access on the hive tables on a group level  Employed AVRO format for the entire data ingestion forecaster operation and less space utilization  Experienced in managing and reviewing Hadoop log files  Worked in an Agile environment and used rally tools to maintain the user stories and tasks  Worked with Enterprise data support teams to install Hadoop updates patches version upgrades as required and fixed problems which were raised after the upgrades  Implemented test scripts to support testdriven development and continuous integration  Used Spark for Parallel data processing and better performances  Tools Map Reduce HDFS Hive pig Impala Cassandra spark Scala solr Java SQL Tableau PIG Zookeeper Sqoop Teradata CentOS Pentaho           ITC InfoTech      Data Engineer   City          India              062014      112015     Worked on configuration and monitoring Hadoop cluster using Cloudera distribution  Involved in migrating data from on prem Cloudera cluster to AWS EC2 instances deployed on EMR cluster and developed ETL pipeline to extract logs and store in AWS S3 Data Lake and further processed it using PySpark  Moved files between HDFS and AWS S3 and worked with S3 bucket in AWS on a regular basis  Responsible for developing data pipelines using Flume Sqoop and Pig to extract the data from weblogs and store them in HDFS  Migrated data between various data sources like Teradata Oracle and MySQL to HDFS by using Sqoop  Used HCatalog to access Hive table metadata from MapReduce and Pig code  Developed a data pipeline using Kafka and Storm for streaming data and to store it into HDFS  Used Informatica Powercenter for cleaning managing and integrating data from different sources for ETL and loaded into a single warehouse repository  Used Impala to read write and query the Hadoop data in HDFS from HBase and constructed Impala scripts to reduce query response time  Analysed data stored in S3 buckets using SQL PySpark and stored the processes data in Redshift and validated data sets by implementing Spark components  Performed ETL operations using Python SQL on many data sets to obtain metrics  Prepared data according to analyst requirements on the extracted data using Pandas and NumPy modules in Python  Involved in designing and developing automation test scripts using Python  Involved in writing multiple python scripts to extract data from different API’s  Created HBase tables using Shell to load large sets of data from different databases  Involved in scheduling Time based Oozie workflow engine to run multiple Hive and Pig jobs  Developed flow XML files using Apache NiFi to process and ingest data into HDFS  Worked on performance tuning of Apache NiFi workflow to optimize the data ingestion speeds  Responsible for collecting and aggregating large amounts of log data using Flume and staging it into HDFS for further analysis  Worked on integration of Apache Storm with Kafka to perform web analytics and upload streaming data from Kafka to HBase and Hive  Responsible for developing data pipelines using Apache Kafka by implementing Kafka producers and consumers  Used Hive optimization techniques like partitioning and bucketing to provide better performance with HiveQL queries  Loaded large amounts of data to HBase using MapReduce jobs  Worked on developing UDFs to work with Hive and wrote our tests in Scala  Used zookeeper to maintain configurations across clusters and for better synchronization grouping and reliable distributed coordination  Worked with Kerberos and Apache sentry for security and authorization on Hadoop  Used Git for version control  Tools Cloudera CDH4 Hadoop 2x HDFS MapReduce Yarn Sqoop Hive AWS EC2 S3 Redshift Impala Spark Pig SQL HBase Kafka Zookeeper Flume Oozie HCatalog NiFi Storm Informatica Python MySQL Scala Teradata Oracle Git          Skills       Technical Skills  HadoopSpark Ecosystem  Hadoop MapReduce Hiveimpala YARN Kafka Flume Sqoop Oozie Zookeeper Spark  Databases Oracle My Sql SQL Server PostgreSQL HBase Snowflake Cassandra Mongo DB  Cloud computing  Amazon Web Services AWS Amazon Redshift MS Azure Azure blob storage Azure Data Factory Azure Synapse  Google cloud PlatformBig Query Big Table Dataproc    BI Tools Business Objects XI Tableau 91 Power BI  Query Languages SQL PLSQL TSQL  Scripting Languages Unix Python  Operating Systems Linux Windows Ubuntu Unix  SDLC Methodology Agile Scrum Waterfall UML         Work History       ALCON     Sr Data Engineer   Fort Worth     TX    102020      Current     Involved in requirements gathering analysis design development change management deployment  Involved in development of real time streaming applications using PySpark Apache Flink Kafka Hive on distributed Hadoop Cluster  Utilized Apache Spark with Python to develop and execute Big Data Analytics and Machine learning applications executed machine Learning use cases under Spark ML and Milib  Extracted data from heterogeneous sources and performed complex business logic on network data to normalize raw data which can be utilized by BI teams to detect anomalies  Designed and developed Flink pipelines to consume streaming data from Kafka and applied business logic to massage and transform and serialize raw data  Developed a common Flink module for serializing and deserializing AVRO data by applying schema  Developed Spark streaming pipeline to batch real time data detect anomalies by applying business logic and write anomalies to Hbase table  Implemented layered architecture for Hadoop to modularize design  Developed framework scripts to enable quick development  Designed reusable shell scripts for Hive Sqoop Flink and PIG jobs  Standardize error handling logging and metadata management processes  Indexed processed data and created dashboards and alerts in splunk to be utilized action by support teams  Responsible for operations and support of Big data Analytics platform Splunk and Tableau visualization  Managed developed and designed dashboard control panel for customers and Administrators using Tableau PostgresQL and REST API calls  Designed and Developed applications using Apache Spark Scala Python Nifi S3 AWS EMR on AWS cloud to format cleanse validate create schema and build data stores on S3  Developed CICD pipelines to automate build and deploy to Dev QA and production environments  Supported production jobs and developed several automated processes to handle errors and notifications  Also tuned performance of slow jobs by improving design and configuration changes of PySpark jobs  Created standard report Subscriptions and Data Driven Report Subscriptions  Tools Hadoop Map Reduce Spark Spark MLLib Tableau SQL Excel PIG Hive AWS PostgresQL Python PySpark Flink SQL Server 2012 TSQL CICD Git XML Tableau           USAA     Sr GCP Data Engineer   San Antonio     TX    012018      092020     Developed multi cloud strategies in better using GCP for its PAAS and Azure for its SAAS  Involved in loading and transforming large sets of the structured semistructured dataset and analysing them by running Hive queries  Developed custom python program including CICD rules for Google cloud data catalog for metadata management  Design and develop spark job with Scala to implement end to end data pipeline for batch processing  Do fact dimensional modeling and proposed solution to load it  Processing data with Scala spark spark SQL and load in hive partition tables in parquet file format  Develop spark job with partitioned RDD like hash range custom for faster processing  Develop and deploy the outcome using spark and Scala code in Hadoop cluster running on GCP  Develop near real time data pipeline using flume Kafka and spark stream to ingest client data from their web log server and apply transformation  Performs data analysis and design and creates and maintains large complex logical and physical data models and metadata repositories using ERWIN and MB MDR  Assist service developers in finding relevant content in the existing reference models  Like Access Excel CV Oracle flat files using connectors tasks and transformations provided by AWS Data Pipeline  Utilized Spark SQL API in PySpark to extract and load data and perform SQL queries  Worked on developing Pyspark script to encrypting the raw data by using Hashing algorithms concepts on client specified columns  Responsible for Design Development and testing of the database and Developed Stored Procedures Views and Triggers  Developed Pythonbased API RESTful Web Service to track revenue and perform revenue analysis  Compiling and validating data from all departments and Presenting to Director Operation  Develop SQOOP script and SQOOP job to ingest data from client provided database in batch fashion on incremental basis  Use DISTCP to load files from S3 to HDFS and Processing cleansing and filtering data using Scala Spark Spark SQL HIVE Impala Query and Load in Hive tables for data scientists to apply their ML algorithms and generate recommendations as part of data lake processing layer  Build data pipelines in airflow in CP for ETL related jobs using different airflow operators both old and newer operators  Created Big Query authorized views for row level security or exposing the data to other teams  Good knowledge in using cloud shell for various tasks and deploying services           T  Mobile     Big Data Engineer   Bellevue     WA    062016      122017     Implemented a generic ETL framework with high availability for bringing related data for Hadoop  Cassandra from various FRANCHI sources using spark  Experienced in using Platfora a data visualization tool specific for Hadoop and created various Lens and Viz boards for a realtime visualization from hive tables  Queried and analysed data from Cassandra for quick searching sorting and grouping through COL  Implemented various Data Modelling techniques for Cassandra  Joined various tables in Cassandra using spark and Scala and ran analytics on top of them  Participated in various upgrades and troubleshooting activities across enterprises  Knowledge in performance troubleshooting and tuning Hadoop clusters  Applied Spark advanced procedures like text analytics and processing using inmemory processing  Implemented Apache Drill on Hadoop to join data from SQL and No SQL databases and store it in Hadoop  Created architecture stack blueprint for data access with NoSQL Database Cassandra  Brought data from various sources into Hadoop and Cassandra using Kafka  Experienced in using Tidal enterprise scheduler and Ooze Operational Services for coordinating the cluster and scheduling workflows  Applied spark streaming for real time data transforming  Created multiple dashboards in tableau for multiple business needs  Installed and configured Hive and written Hive UDFs and used piggy bank a repository of UDFs for Pig Latin  Implemented Partitioning Dynamic Partitions and Buckets in HIVE for efficient data access  Exported the analysed data to the relational databases using Sqoop for visualization and to generate reports for the BI team Using Tableau  Implemented Composite server for the data virtualization needs and created multiple views for restricted data access using a REST API  Devised and led the implementation of next generation architecture for more efficient data ingestion and processing  Created and implemented various shell scripts for automating the jobs  Implemented Apache Sentry to restrict the access on the hive tables on a group level  Employed AVRO format for the entire data ingestion forecaster operation and less space utilization  Experienced in managing and reviewing Hadoop log files  Worked in an Agile environment and used rally tools to maintain the user stories and tasks  Worked with Enterprise data support teams to install Hadoop updates patches version upgrades as required and fixed problems which were raised after the upgrades  Implemented test scripts to support testdriven development and continuous integration  Used Spark for Parallel data processing and better performances  Tools Map Reduce HDFS Hive pig Impala Cassandra spark Scala solr Java SQL Tableau PIG Zookeeper Sqoop Teradata CentOS Pentaho           ITC InfoTech     Data Engineer   Pune         062014      112015     Worked on configuration and monitoring Hadoop cluster using Cloudera distribution  Involved in migrating data from on prem Cloudera cluster to AWS EC2 instances deployed on EMR cluster and developed ETL pipeline to extract logs and store in AWS S3 Data Lake and further processed it using PySpark  Moved files between HDFS and AWS S3 and worked with S3 bucket in AWS on a regular basis  Responsible for developing data pipelines using Flume Sqoop and Pig to extract the data from weblogs and store them in HDFS  Migrated data between various data sources like Teradata Oracle and MySQL to HDFS by using Sqoop  Used HCatalog to access Hive table metadata from MapReduce and Pig code  Developed a data pipeline using Kafka and Storm for streaming data and to store it into HDFS  Used Informatica Powercenter for cleaning managing and integrating data from different sources for ETL and loaded into a single warehouse repository  Used Impala to read write and query the Hadoop data in HDFS from HBase and constructed Impala scripts to reduce query response time  Analysed data stored in S3 buckets using SQL PySpark and stored the processes data in Redshift and validated data sets by implementing Spark components  Performed ETL operations using Python SQL on many data sets to obtain metrics  Prepared data according to analyst requirements on the extracted data using Pandas and NumPy modules in Python  Involved in designing and developing automation test scripts using Python  Involved in writing multiple python scripts to extract data from different API’s  Created HBase tables using Shell to load large sets of data from different databases  Involved in scheduling Time based Oozie workflow engine to run multiple Hive and Pig jobs  Developed flow XML files using Apache NiFi to process and ingest data into HDFS  Worked on performance tuning of Apache NiFi workflow to optimize the data ingestion speeds  Responsible for collecting and aggregating large amounts of log data using Flume and staging it into HDFS for further analysis  Worked on integration of Apache Storm with Kafka to perform web analytics and upload streaming data from Kafka to HBase and Hive  Responsible for developing data pipelines using Apache Kafka by implementing Kafka producers and consumers  Used Hive optimization techniques like partitioning and bucketing to provide better performance with HiveQL queries  Loaded large amounts of data to HBase using MapReduce jobs  Worked on developing UDFs to work with Hive and wrote our tests in Scala  Used zookeeper to maintain configurations across clusters and for better synchronization grouping and reliable distributed coordination  Worked with Kerberos and Apache sentry for security and authorization on Hadoop  Used Git for version control  Tools Cloudera CDH4 Hadoop 2x HDFS MapReduce Yarn Sqoop Hive AWS EC2 S3 Redshift Impala Spark Pig SQL HBase Kafka Zookeeper Flume Oozie HCatalog NiFi Storm Informatica Python MySQL Scala Teradata Oracle Git|none
Data Engineer|https://www.livecareer.com/resume-search/r/aws-data-engineer-7289f190da885bd0d8ec5349e6934932|239182503578527980007051234933087188268|Jessica    Claire                                   609 Johnson Ave       49204     Tulsa     OK   100 Montgomery St 10th Floor    Home   555 4321000    Cell       resumesampleexamplecom              Summary       Dynamic and motivated IT professional with around 7 years of experience as a Big Data Engineer with expertise in designing data intensive applications using Hadoop Ecosystem  Big Data Analytical  Cloud Data engineering  Data Warehouse  Data Mart Data Visualization  Reporting  and Data Quality solutions   In  depth knowledge of Hadoop architecture and its components like YARN  HDFS Name Node Data Node Job Tracker Application Master Resource Manager  Task Tracker and Map Reduce programming paradigm  Extensive experience in Hadoop led development of enterprise level solutions utilizing Hadoop components such as Apache Spark MapReduce HDFS Sqoop PIG Hive HBase Oozie Flume NiFi Kafka Zookeeper and YARN  Profound experience in performing Data Ingestion Data Processing Transformations enrichment and aggregations  Strong Knowledge on Architecture of Distributed systems and Parallel processing Indepth understanding of MapReduce programming paradigm and Spark execution framework  Experienced with the Spark improving the performance and optimization of the existing algorithms in Hadoop using Spark Context  SparkSQL  Dataframe API  Spark Streaming MLlib  Pair RDD s and worked explicitly on PySpark and Scala   Handled ingestion of data from different data sources into HDFS using Sqoop Flume and perform transformations using Hive Map Reduce and then loading data into HDFS  Managed Sqoop jobs with incremental load to populate HIVE external tables Experience in importing streaming data into HDFS using Flume sources and Flume sinks and transforming the data using Flume interceptors  Experience in Oozie and workflow scheduler to manage Hadoop jobs by Direct Acyclic Graph  DAG  of actions with control flows  Implemented the security requirements for Hadoop and integrating with Kerberos authentication infrastructure KDC server setup creating realm domain managing  Experience of Partitions bucketing concepts in Hive and designed both Managed and External tables in Hive to optimize performance   Experience with different file formats like Avro  parquet  ORC  Json and XML   Expertise in Creating Debugging Scheduling and Monitoring jobs using Airflow and Oozie  Experienced with using most common Operators in Airflow  Python Operator Bash Operator Google Cloud Storage Download Operator Google Cloud Storage Object Sensor  Handson experience in handling database issues and connections with SQL and NoSQL databases such as MongoDB  HBase  Cassandra  SQL server  and PostgreSQL   Created Java apps to handle data in MongoDB and HBase Used Phoenix to create SQL layer on HBase  Experience in designing and creating RDBMS Tables Views User Created Data Types Indexes Stored Procedures Cursors Triggers and Transactions  Expert in designing ETL data flows using creating mappingsworkflows to extract data from SQL Server and Data Migration and Transformation from OracleAccessExcel Sheets using SQL Server SSIS   Expert in designing Parallel jobs using various stages like Join Merge Lookup remove duplicates Filter Dataset Lookup file set Complex flat file Modify Aggregator XML  Handson experience with Amazon EC2 Amazon S3 Amazon RDS VPC IAM Amazon Elastic Load Balancing Auto Scaling CloudWatch SNS SES SQS Lambda EMR and other services of the AWS family  Created and configured new batch job in Denodo scheduler with email notification capabilities and Implemented Cluster setting for multiple Denodo node and created load balance for improving performance activity  Instantiated created and maintained CICD continuous integration  deployment pipelines and apply automation to environments and applications  Worked on various automation tools like GIT Terraform Ansible Experienced in fact dimensional modeling  Star schema Snowflake schema  transactional modeling and SCD Slowly changing dimension  Experienced with JSON based RESTful web services and XMLQML based SOAP web services and also worked on various applications using python integrated IDEs like Sublime Text and PyCharm   Efficient Cloud Engineer with years of experience assembling cloud infrastructure Utilizes strong managerial skills by negotiating with vendors and coordinating tasks with other IT team members Implements best practices to create cloud functions applications and databases         Skills          ·  Big Data Technologies  Hadoop MapReduce HDFS Sqoop PIG Hive HBase Oozie Flume NiFi Kafka Zookeeper Yarn Apache Spark Mahout Sparklib  ·  Databases  Oracle MySQL SQL Server MongoDB Cassandra DynamoDB PostgreSQL Teradata Cosmos  ·  Programming  Python PySpark Scala Java C C Shell script Perl script SQL  ·  Cloud Technologies  AWS Microsoft Azure  ·  Frameworks  Django REST framework MVC Hortonworks  ·  Tools  PyCharm Eclipse Visual Studio SQLPlus SQL Developer TOAD SQL Navigator Query Analyzer SQL Server Management Studio SQL Assistance Eclipse Postman  ·  Versioning tools  SVN Git GitHub    ·  Operating Systems  Windows 78XP20082012 Ubuntu Linux MacOS  ·  Network Security  Kerberos  ·  Database Modelling  Dimension Modeling ER Modeling Star Schema Modeling Snowflake Modeling  ·  Monitoring Tool  Apache Airflow  ·  Visualization Reporting  Tableau ggplot2 matplotlib SSRS and Power BI  ·  Machine Learning Techniques  Linear  Logistic Regression Classification and Regression Trees Random Forest Associative rules NLP and Clustering                      Experience       AWS Data Engineer       012022   to   022022     Deloitte    –    Gilbert     AZ             Designed and setup Enterprise Data Lake to provide support for various uses cases including Analytics processing storing and Reporting of voluminous rapidly changing data  Responsible for maintaining quality reference data in source by performing operations such as cleaning transformation and ensuring Integrity in a relational environment by working closely with the stakeholders  solution architect  Designed and developed Security Framework to provide fine grained access to objects in AWS S3 using AWS Lambda DynamoDB  Set up and worked on Kerberos authentication principals to establish secure network communication on cluster and testing of HDFS Hive Pig and MapReduce to access cluster for new users  Performed end toend Architecture  implementation assessment of various AWS services like Amazon EMR Redshift S3  Implemented the machine learning algorithms using python to predict the quantity a user might want to order for a specific item so we can automatically suggest using kinesis firehose and S3 data lake  Used AWS EMR to transform and move large amounts of data into and out of other AWS data stores and databases such as Amazon Simple Storage Service Amazon S3 and Amazon DynamoDB  Used Spark SQL for Scala  amp Python interface that automatically converts RDD case classes to schema RDD  Import the data from different sources like HDFSHBase into Spark RDD and perform computations using PySpark to generate the output response  Creating Lambda functions with Boto3 to deregister unused AMIs in all application regions to reduce the cost for EC2 resources  Importing  exporting database using SQL Server Integrations Services SSIS and Data Transformation Services DTS Packages  Coded Teradata BTEQ scripts to load transform data fix defects like SCD 2 date chaining cleaning up duplicates  Developed reusable framework to be leveraged for future migrations that automates ETL from RDBMS systems to the Data Lake utilizing Spark Data Sources and Hive data objects  Conducted Data blending Data preparation using Alteryx and SQL for Tableau consumption and publishing data sources to Tableau server  Developed Kibana Dashboards based on the Log stash data and Integrated different source and target systems into Elasticsearch for near real time log analysis of monitoring End to End transactions  Implemented AWS Step Functions to automate and orchestrate the Amazon SageMaker related tasks such as publishing data to S3 training ML model and deploying it for prediction  Integrated Apache Airflow with AWS to monitor multistage ML workflows with the tasks running on Amazon SageMaker  Environment AWS EMR S3 RDS Redshift Lambda Boto3 DynamoDB Amazon SageMaker Apache Spark HBase Apache Kafka HIVE SQOOP Map Reduce Snowflake Apache Pig Python SSRS Tableau  Assessed organization technology infrastructure and managed cloud migration process  Configured computing networking and security systems within cloud environment  Implemented cloud policies managed technology requests and maintained service availability           Data Engineer       012016   to   112019     Cognizant Technology Solutions    –    Hatboro     PA             Worked on Azure Data Factory to integrate data of both onprem MY SQL Cassandra and cloud Blob storage Azure SQL DB and applied transformations to load back to Azure Synapse  Managed Configured and scheduled resources across the cluster using Azure Kubernetes Service  Monitored Spark cluster using Log Analytics and Ambari Web UI  Transitioned log storage from Cassandra to Azure SQL Datawarehouse and improved the query performance  Involved in developing data ingestion pipelines on Azure HDInsight Spark cluster using Azure Data Factory and Spark SQL  Also Worked with Cosmos DB SQL API and Mongo API  Develop dashboards and visualizations to help business users analyze data as well as providing data insight to upper management with a focus on Microsoft products like SQL Server Reporting Services SSRS and Power BI  Performed the migration of large data sets to Databricks Spark create and administer cluster load data configure data pipelines loading data from ADLS Gen2 to Databricks using ADF pipelines  Created various pipelines to load the data from Azure data lake into Staging SQLDB and followed by to Azure SQL DB  Created Databrick notebooks to streamline and curate the data for various business use cases and also mounted blob storage on Databrick  Utilized Azure Logic Apps to build workflows to schedule and automate batch jobs by integrating apps ADF pipelines and other services like HTTP requests email triggers etc  Worked extensively on Azure data factory including data transformations Integration Runtimes Azure Key Vaults Triggers and migrating data factory pipelines to higher environments using ARM Templates  Ingested data in minibatches and performs RDD transformations on those minibatches of data by using Spark Streaming to perform streaming analytics in Data bricks  Environment Azure SQL DW Databrick Azure Synapse Cosmos DB ADF SSRS Power BI Azure Data lake ARM Azure HDInsight Blob storage Apache Spark  Adept in troubleshooting and identifying current issues and providing effective solutions  Managed performance monitoring and tuning while identifying and repairing issues within database realm  Identified key use cases and associated reference architectures for market segments and industry verticals  Designed surveys opinion polls and assessment tools to collect data  Tested validated and reformulated models to foster accurate prediction of outcomes  Created graphs and charts detailing data analysis results  Recommended data analysis tools to address business issues  Developed new functions and applications to conduct analyses  Cleaned and manipulated raw data  Collaborated with solution architects to define database and analytics engagement strategies for operational territories and key accounts           Big Data Engineer  Hadoop Developer       102013   to   122015     Novogradac  Co Llp    –    Long Beach     CA           AnsibleDenodoDenodoCloudWatchAvroPySparkPySparkPySparkMLlibDataframeNiFiNiFi  Interacted with business partners Business Analysts and product owner to understand requirements and build scalable distributed data solutions using Hadoop ecosystem  Developed Spark Streaming programs to process near real time data from Kafka and process data with both stateless and state full transformations  Worked with HIVE data warehouse infrastructurecreating tables data distribution by implementing partitioning and bucketing writing and optimizing the HQL queries  Built and implemented automated procedures to split large files into smaller batches of data to facilitate FTP transfer which reduced 60 of execution time  Worked on developing ETL processes Data Stage Open Studio to load data from multiple data sources to HDFS using FLUME and SQOOP and performed structural modifications using Map Reduce HIVE  D eveloping Spark scripts UDFS using both Spark DSL and Spark SQL query for data aggregation querying and writing data back into RDBMS through Sqoop  Written multiple MapReduce Jobs using Java API Pig and Hive for data extraction transformation and aggregationAvrom multiple file formats including Parquet Avro XML JSON CSV ORCFILE and other compressed file formats Codecs like gZip Snappy Lzo  Strong understanding of Partitioning bucketing concepts in Hive and designed both Managed and External tables in Hive to optimize performance  Developed PIG UDFs for manipulating the data according to Business Requirements and also worked on developing custom PIG Loaders  Developing ETL pipelines in and out of data warehouse using combination of Python and Snowflakes SnowSQL Writing SQL queries against Snowflake  Experience in report writing using SQL Server Reporting Services SSRS and creating various types of reports like drill down Parameterized Cascading Conditional Table Matrix Chart and Sub Reports  Used DataStax Spark connector which is used to store the data into Cassandra database or get the data from Cassandra database  Wrote oozie scripts and setting up workflow using Apache Oozie workflow engine for managing and scheduling Hadoop jobs  Worked on implementation of a log producer in Scala that watches for application logs transform incremental log and sends them to a Kafka and Zookeeper based log collection platform  Used Hive to analyze data ingested into HBase by using HiveHBase integration and compute various metrics for reporting on the dashboard  Transformed tPySpark using AWS Glue dynamic frames with PySpark cataloged the transformed the data using Crawlers and scheduled the job and crawler using workflow feature  Worked on installing cluster commissioning  decommissioning of data node name node recovery capacity planning and slots configuration  Developed data pipeline programs with Spark Scala APIs data aggregations with Hive and formatting data JSON for visualization and generatiPySpark     Environment AWS Cassandra PySpark Apache Spark HBase Apache Kafka HIVE SQOOP FLUME Apache oozie Zookeeper ETL UDF Map Reduce Snowflake Apache Pig Python Java SSRS  Onfidential  Developed and implemented Hadoop code while observing coding standards  Optimized and tuned Hadoop environments and modified hardware to meet prescribed performance thresholds  Developed new functions and applications to conduct analyses  Created graphs and charts detailing data analysis results  Tested validated and reformulated models to foster accurate prediction of outcomes           Python Developer        092012   to   102013     Fiserv    –    City     STATE             AWS S3 EC2 LAMBDA EBS IAM Datadog CloudTrail CLI Ansible MySQL Python Git Jenkins DynamoDB Cloud Watch Docker Kubernetes  Leveraged open communication collective decisionmaking and thorough reviews to create performant and scalable systems  Worked with serverside and frontend technologies and leveraged common design patterns to code dynamic and userfriendly systems  Implemented new API routes architected new ORM structures and refactored code to boost application performance  Harnessed version control tools to coordinate project development and individual code submissions  Introduced cloudbased technologies into Python development to expand onpremise deployment options  Wrote clear and clean code for use in projects  Resolved customer issues by establishing workarounds and solutions to debug and create defect fixes          Education and Training       Post Graduate      Data Engineering      Expected in   022022     Purdue University      West Lafayette     IN     GPA                Post Graduate      Data Science And Business Analytics      Expected in   092021     University of Texas At Austin      Austin     TX     GPA                Bachelor of Arts     Business Administration And Management     Expected in   122009     Califonia State University       Fullerton CA          GPA|none
Data Engineer|https://www.livecareer.com/resume-search/r/senior-data-center-lab-engineer-99a816296ff7460daf6f5c4230dd5baf|65679956705363143962195955010725210777|Jessica  Claire                             resumesampleexamplecom                      555 4321000                       Montgomery Street     San Francisco     CA      94105                                                                                                                                                                                                             Summary      Resultsdriven IT management professional with 20 years of experience in diverse industries including Infrastructure and data center management Expertise includes team leadership technical architecture training  recruiting mentoring  development disaster recovery planning asset management inventory control VAR experience contract to hire experience and information protection analysis Knowledge of Enterprise Project Lifecycle methodology with a emphasis in Infrastructure engineering with strong background in project management product support including breakfix to the board level More than 15 years in IT project management skilled in installation configuration migration and implementation of rack systems cable management cable testing server power and cooling infrastructure including retrofitting commissioning and decommissioning  data centers from the ground up Dynamic resourceful and extremely driven individual with a deep passion for creating and delivering programs and solutions that empower a team company and customer to meet and exceed desired expectations               Highlights         Enterprise platforms  Experienced in infrastructure design  Forecasting specialist  Knowledge of Product Lifecycle Management PLM  Supplier interface  Performance criteria tracking  Endtoend product lifecycles  Collaborative  Inventory tracking  Vendor management         Project tracking  Hardware and software upgrade planning  Product requirements documentation  Selfdirected  Budgeting and resource management  MS Visio  Decisive  Cost reduction  Colo experience and management  Staffing augmentation hiring and training                     Education       Training Technologies    Rancho Cucamonga     CA      Expected in   1997     –      –               A CNA certification          GPA            Coursework in Computer Networking and Information Technology         Certifications       A  certified 9E8DTT2557  Network  certification  Microsoft Certified Professional 1267994 Windows NT 40  Microsoft Certified Professional 1269364 Windows 2000   7073 NT Server 40  7067 Windows 2000 Professional  70270 Windows SQL 70  Administration Microsoft Networking Essentials 7058   Hewlett Packard authorized technician  SD0436  Compaq authorized technician  Dell authorized technician  25933  Network Analysis with Sniffer  Interconnecting Cisco Network Devices  Light Brigade fiber certification           Accomplishments       Responsible for managing the infrastructure project commissioning of a 428000 Sq Ft data center from a empty building to completion including assembling the infrastructure team required to install the equipment racks cabling power successfully ahead of schedule  Responsible for managing the decommissioning project of a DR data center successfully transferring the entire contents to another DR data center including the inventory and assets  Successfully Increased core system availability to 100 by developing standards in house breakfix ability redundant hot swap equipment allowing immediate replacement within minutes instead of hours and implementing best practices  Successfully transitioned a mainframe data center to a standard open system data center including the high volume printers successfully without error  under budget and ahead of schedule  Reduced the incidence of IT issues by 50 globally by designing a training improvement program for the infrastructure engineers increasing their skill sets and knowledge with industry certifications related to their daily tasks  Reduced costs and delays by internally completing breakfix on the hardware instead of contracting out the breakfix function The quality of the repairs also increased because of pride of ownership and the expectation that it be repaired correctly the first time                          Experience       Apex Systems      Senior Data Center Lab Engineer   Middleton     WI                   072016      Current       Insight Global contract position      Install and perform repairs to hardware and peripheral equipment following design and installation specifications including copperfiber cabling for connectivity This includes Dell HP servers and blades Cisco switches and firewalls HP switches  EMC arrays F5 and related KVM devices etc     Provided feet and hands support for commissioningdecommissioning breakfix to the board level cabling installation and testing and rack installation for the Barrington Chicago Milwaukee and Wauwatosa data centers as required     Conduct computer diagnostics firmware upgrades to investigate and resolve problems and provide technical assistance and support to product developers and programmers       Design maintain and audit inventory according to present and forth coming projects      Provide space power and cooling direction  and installation according to project hardware and software requirements      Provide quarterly data center hardware audits using Visio to maintain FDA standards and requirements                Accenture      Senior Data Center Engineer   Fort Harrison     MT                   102015      072016      Apex contract position   Provided daily commissioning and decommissioning of various types of equipment into racks based on HP Service Manager customer tickets including required copperfiber cables including cable management  Provided vendor escorts to install andor provide breakfix of customer equipment  Provided breakfix for servers switches firewalls and other related equipment to the board level and beyond  Provided hands and feet services for offsite engineers to troubleshoot install repair upgrade or anything required to return their equipment to operational status  Maintained the cleanliness of the data center including the floors and both the interior and exterior of each rack being installed in the data center  Set up and configure servers and blade servers in the lab racks prior to going live on the data center floor according to owner requirements  Participate in bridge calls requiring assistance for failed equipment andor connections until corrected as the onsite engineer  Maintain and monitor the power and cooling systems and related alarms      ​          Cincinnati Bell      IBM Global Remote Data Center Manager   West Chester     OH                   022015      062015      Compunnel contract position   Manage IBM Colo for Baxter pharmaceutical customer daily request for connectivity and hardware installation remotely  Project management to both decommission old customer equipment and to commission customers design in the COLO for new racks equipment and connectivity  Managed customer split between Baxter pharmaceutical and Baxalta pharmaceutical and ensure that the connectivity and equipment is moved and reinstalled in the COLO ensuring to separate companies  Worked directly with customer network administration to complete customer request for network connectivity and hardware trouble shooting including issuing the proper TCPIP and VMWare scopes  Provided mentoring and trouble shooting experience with onsite remote hands engineers to complete customer new orders for cable connectivity and hardware installation and trouble shooting       ​          Engility Corporation      Infrastructure Manager   Fort Meade     MD                   052009      062014     Directed and managed the infrastructure and engineers to bring the data online from a empty building to a fully operational 428000 Sq Ft production data center   Managed daytoday activities of 12 infrastructure technicians and DR data center which included handling daily ITSM tickets for  power server switch and router installations decommissioning and connectivity issues  Conducted performance reviews of engineers and scheduling of PTO ECC and on call 24X7 coverage  Directed engineers course of action resolving Internet connectivity general software and hardware issues  Directed handson management of racking stacking decommissions inventory asset management cable tracing cable clean up cable testing and new circuit installations including Roadm and dark fiber  Redesigned recruiting process requiring stringent technical knowledge  and experience and training for seven data centers including the training for engineers colo space and remote hands  This involved the following Windows operating systems from XP thru Windows 7 Server 2003 Cisco Nexus 7000 6500 3750s and 2800 series Net scout Netbotz 500 Compaq RF code HP and Dell servers Liebert CRACs and PDUs Terminal server using Cisco 2600 and Cisco Airports for wireless  Participated in the weekly change control and risk meetings collaborating with all levels of management from director to CTO  Hired trained and mentored 75 new infrastructure engineers  Managed the 75 person local data center infrastructure team allocating resources to ongoing projects and enforcing deadlines  Collaborated with the global team to resolve IT support cases in the data centers           Sentinel Technologies Inc      Self employed   Bloomington     IL                   032008      052009     Assisted residential and small business owners with daily hardware and software support  This included breakfix reimaging network connectivity wireless networks cabling and network installation and maintenance  This involved the following Windows from 98 thru Vista Microsoft Office 97 thru 2007 Linksys and DLink routers and switches phone support           Granite Telecommunications Llc      Premise Technician   Chicago     IL                   092007      032008     Installed UVerse into customers homes and businesses on a daily basis which involved making cross connects at the VRAD and then completing the connection using a balun at the customers NID  Cat5coax was then installed throughout the home or business which was terminated tested and certified and connected to a television andor computer  This involved the following Windows from 98 thru Vista Microsoft Office 97 thru 2007 Linksys and DLink routers and switches including trouble tickets           Amerisourcebergen Corporation  Corporate      System Integration Manager   Dothan     AL                   102006      042007      CompuCom contract position   Managed contract account for GE Healthcare including budget profit margin hiring recruiting and mentoring  This included the projects for each of my teams in cooperation with GE managers which consisted of 45 technicians ranging from tier one to designer  Responsible for the daily operation of GE end users and responded to help desk tickets to meet SOP and SLAs which ranged from windowsUNIX server issues and everything in between  This involved Windows XP and Server 2000 and 2003 UNIX 9 10 and Linux on HP Compaq Dell and Sun servers               ​     ​          ZurichFarmers Insurance      Facility Data Center Manager   City     STATE                   062006      092006      Teksystems contract position   Installed server racks and servers into the data center and maintained and monitored their connectivity  Also maintained the Liebert 750KVA UPS and Liebert CRAC units using Liebert sitescan 30  This included the Liebert PDUs and halon fire suppression system on a 247 oncall basis  This involved Windows 2000 Server UNIX and HP AUX           Wisconsin Department Of Corrections      SIS Project Manager   City     STATE                   042006      052006      Teksystems contract position   Managed the project to transfer all ownership and technical support of the Department of Corrections computer systems to the Department of Engineering which included transferring eight thousand and five hundred Microsoft Outlook accounts and six hundred and fifty print servers  This involved Outlook 2003 and process management           JP MorganChase      Data Center Engineer   City     STATE                   2006      042006      Teksystems contract position   Installed and deinstalled servers on a daily basis and installed either the Windows server OS or the UNIX OS depending upon the requirement using a script  This also involved breakfix on Dell Compaq and HP servers to the board level and maintenance and monitoring of the Liebert power and cooling systems  Collaborated with the global team to decommission the data center and transfer the assets           Allergan Pharmaceutical      NOC Manager   City     STATE                   2005      042005      Compucom contract position   Managed the daily operation of 55 tier one and tier two technicians that responded to help desk tickets for end user assistance ranging from file and folder issues to server connectivity issues  This also involved managing the SLAs SOPs and SarbanesOxley audits to ensure FDA regulation compliance  Handled the recruiting hiring and mentoring of the staff which included vendor management           Publicis Groupe Leo Burnett USA Inc      Data Center Manager   City     STATE                   012002      2005     Directed and managed the transition from a main frame data center to a traditional open systems data center including printing services  Managed three global data centers and participated in the building and project management of a fourth data center spanning Chicago Michigan New York and Europe  Directed the management of 9 analysts 2 networktelecom technicians and 3 electricians which included training and mentoring  I also managed and was responsible for calculating the cooling and power needs of the data centers using Liebert UPS and CRACs  This involved the daily breakfix of all hardware within the data centers and the maintenance and management of the AS390 mainframe on a daily basis including transitioning from the mainframe to open systems solely  This involved Dell Compaq and HP Sun HP AUX servers and Panduit racks using Windows NT 40 and 2000 Novell 411  Managed help desk ticket and phone support queue          Skills       15 years of experience in recruiting hiring training and mentoring infrastructure engineers  10 years of experience managing the daily functioning of 247 data centers  18 years of experience performing breakfix to the board level on servers desktops laptops and most printers  10 years of experience upgrading commissioning and decommissioning global data centers|none
Data Engineer|https://www.livecareer.com/resume-search/r/lead-data-engineer-7dc7cc010ca540828e6322bd6605e6e6|94356944266639456107307305550356935516|Jessica    Claire                                 609 Johnson Ave       49204     Tulsa     OK   100 Montgomery St 10th Floor   Home   555 4321000        Cell           resumesampleexamplecom                  Summary      · Seasoned data engineer professional adept at understanding mandates developing plans leading and implementing enterprisewide solutions Complex problemsolver with an innovative approach A proven track record with experience in all facets of data engineering from ETL to data consumption  Extensive experience in Hadoop and cloud computing platforms with focus on automated CICD Strong programming skills in design and implementation using JavaJ2EE Scala SQL and other scripting languages Excellent leadership management qualities with excellent communication and interpersonal skills        Skills          · Design and Create scalable platforms and products in data realm including ETL in hadoop ecosystem data services and SQLNoSql databases  · Create and review high level design documentation architecture diagrams  · Design and create automated CICD for various data platform both onprem and cloud ecosystems    · Lead and participate in all aspects of SDLC collaborating with product owners engineering devops and delivery teams to align and deliver products  · Test software products to ensure that the software products developed by the engineering team meet the companys quality and standards  · Guide and mentor engineering team on technical matters including design architecture coding practices                      Experience      022020   to   Current     Lead Data Engineer      Transamerica Life Insurance Company    –    Charlotte     NC            · Managing 3 scrum teams of ETL services and devOps across data platforms  · Oversaw and develop the Largescale real data processing pipelines to handle transaction and real time data using kafka and spark to various databases as part of Data Management Platform team  · Leading migration from hbase to aerospike and solr to elasticsearch which including 30TB historical data migration using spark  · Collaborate with devOps network infra teams to create data plaform architecture and establish project plans and timeline  · Design and create seamless CICD pipelines and provide solutions to all application both onprem and cloud applications And also manage build engineering team  · Managing entitlement of the applications and tools extensively working with security risk and architecture teams to define and implement RBACs across data platform  · Working closely with security infrastructure and vendors to remediate software and infrastructure vulnerabilities including in house and third party applications part of data platform   Recipient of Values Champions Award for 2021 at Early Warning         112012   to   022020     Senior Data Engineer      Change Healthcare    –    Kennesaw     GA            · Developed Batch and streaming spark application in scala to load data kafka hbase and solr on cloudera based Hadoop platform in DMP  · Explored with the Spark improving the performance and optimization of the existing algorithms in Hadoop using Spark Context Spark SQL Data Frame PairRDDs Spark YARN  · Developed ETL pipelines using Streamsets to move data from kenisiskafka to various datastores  · Extensive experience in designing and implementation of continuous integration continuous delivery continuous deployment through Chef ansible bamboo gitlab and harness  · Setup full CICD pipelines so that each commit a developer makes will go through standard process of software lifecycle and gets tested well enough before it can make it to the production  · Created Streamsets pipelines to consume data from Amazon Kinesis and Redhsift for data processing         042011   to   092012     Software Engineer      General Motors    –    West Chester     OH            · Involved in analyzing system specifications designing and development for multiple J2EE wholesale applications  · Performed a shakeout test to the code migrated to UAT for the new customer setups defects and for the enhancements  · Performed acceptance testing and conducted functional testing for the customer using WebMethods and UNIX environment  · Extensively worked on PM Online application project from scratch  · Conducted full lifecycle software development from planning to deployment and maintenance  · Reviewed and modified unit and integration tests to improve software quality and reliability  · Performed backend testing using SQL queries to validate the data in the backend database Used SQL to validate backend database changes deletes and update         122007   to   032011     Software Developer      Walt Disney Co    –    Cincinnati     OH            · Delivered code to meet functional or technical specifications  · Designed frontend and backend solutions for testdriven development  · Participated in code review meetings providing input on bugs inefficiencies and potential solutions to emergent issues  · Modified existing software systems to enhance performance and add new features  · Performed regression and performance tests for updated systems         Education and Training      Expected in        Bachelor of Science     Electrical Engineering     University of South Alabama      Mobile     AL     GPA|none
Data Engineer|https://www.livecareer.com/resume-search/r/technical-support-engineer-data-protection-advisory-division-682fb3cc81704e3d87a843b304cfc62a|142168863301654727446038493985454191825|Jessica    Claire               Montgomery Street       San Francisco     CA  94105    609 Johnson Ave       49204     Tulsa     OK      Home   555 4321000        Cell           resumesampleexamplecom                  Summary     Data Protection Consultant with 10 years of experience with a diverse background in Hyperconverged  storage technologiesBuilding  Implementing  providing thoughtful solutions to external customers clients are best equipped to deal with Disaster situations        Experience      02XXX6   to        Technical Consultant      Perficient    –    Saint Louis     MO           Designed  delivered  deployed  migrated complex solutions and providing architectural recommendations on Data Protection technologies for vendors like DELL EMC  Rubrik  Cohesity and their integration with cloud providers  AWS  different applications like SQLOracle ExchangeDeveloped Run books for various proceduresProvided  participated with vendors to investigate root cause analysisProvided strategic direction and ensure the delivery of technical based projectsDevelop Service proposals for each scope of work for various vendors​        05XXX3   to   02XXX6     Delivery Specialist      Amobee    –    Manila     AR           Performed necessary storage infrastructure maintenance and necessary data migration as required Document articles on product behavior and set guidelines for the sameManage troubleshoot Integrate Implement as well as support DELL Provided proactive recommendations to external client for improving their use of DELL EMC Data Protection solutions         07XXX1   to   05XXX3     SYSTEMS ENGINEER      Servicenow    –    Hamburg     NY             Managed multiple DELL EMC Networker Environments for various clients  Performed upgrading  trouble shooting various Data Protection issues  Proactively manage space requirements for backup environments across the company  Understand and support the application level backups and restores of a robust exchange environment  Created Backup reports to discuss storage utilization every week           ​             102008   to   082009     TECHNICAL SUPPORT EXECUTIVE      Softcell Technologies Limited    –    City     STATE           As a member of Security team performed installation of Symantec Endpoint Protection AntivirusParticipated in maintenance  activities for the Lifecyle of productHelped customer to provide best possible solutions to prevent malicious attacks on workstations​        Education      Expected in   XXX1     Master of Science     Telecommunication Management     Stevens Institute of Technology      Hoboken     New Jersey     GPA   GPA 3389        Telecommunication Management GPA 3389          Expected in   2007     Bachelor of Engineering     Electronics and Telecommunication     Ramrao Institute of Technology      Mumbai     Maharashtra     GPA   GPA 34        Electronics and Telecommunication GPA 34          Expected in   2004     Diploma     Industrial Electronics     Bharati Vidyapeeth Institute of Technology      Mumbai     Maharastra     GPA   GPA 38        Industrial Electronics GPA 38|none
Data Engineer|https://www.livecareer.com/resume-search/r/senior-data-engineer-5e86ce6ea1a64e939ce3a7158956de13|130969556747859829302611690656487220649|Jessica    Claire                                   609 Johnson Ave       49204     Tulsa     OK   100 Montgomery St 10th Floor    H   555 4321000    C       resumesampleexamplecom    Date of Birth         India                      single                    Summary      Practical Database Engineer possessing indepth knowledge of data manipulation techniques and computer programming paired with expertise in integrating and implementing new software packages and new products into system Offering 12year background managing various aspects of development design and delivery of database solutions Techsavvy and independent professional bringing outstanding communication and organizational abilities Hardworking and reliable Data Engineer with strong ability in building Data pipelines Highly organized proactive and punctual with teamoriented mentality        Skills           Requirements Gathering  Analysis and Modeling  Data Warehousing  SQL Reporting  Business Intelligence      Data Management  Microsoft SQL  Database Analysis  SQL Tuning  Critical Thinking                       Experience       Senior Data Engineer       122017      Current     Splunk    –    Dallas     GA            Adept in troubleshooting and identifying current issues and providing effective solutions  Managed performance monitoring and tuning while identifying and repairing issues within database realm  Worked as part of project teams to coordinate database development and determine project scopes and limitations  Trained nontechnical users and answered technical support questions  Collected outlined and refined requirements led design processes and oversaw project progress  Created conceptual logical and physical data models for use in different business areas  Wrote and coded logical and physical database descriptions specifying identifiers of database to management systems  Applied Conceptual Logical and Physical  DimensionalRelational model designs to ETL tasks  Managed endtoend operations of ETL data pipelines maintaining uptime of 95  Assisted in User Acceptance Testing for accountingmarketing users verifying ETL jobs complied with assigned parameters achieving desired results  Worked successfully with diverse group of coworkers to accomplish goals and address issues related to our products and services  Worked closely with team members to deliver project requirements develop solutions and meet deadlines           Senior Database Consultant       022013      122017     AmazonCom Inc    –    Lewisville     TX            Created Informatica mappingsETL’s using  Informatica Power Center  to load the data from Oracle MySQL databases to SQL Server 2016 databases hosted on AWS cloud  Performed the data manipulations using various  Informatica  Transformations like Expression Lookup Update Strategy Router and SQL transformation  Designed  Informatica  workflows with many sessions with Event with task Event raise task and Email task Scheduled the created workflowsjobs using  Informatica Scheduler   Created multiple  TSQL  objects mainly Stored procedures and Functions for new and existing software application requirements  Created multiple Linked Servers for ease of the users to execute commands on remote servers  Developed new code and finetuned existing Stored procedures to improve performance while utilizing the SQL Server Profiler and Database engine tuning wizard  Created SSIS packages to migrate data from legacy systems such as Oracle MySQL HP Vertica SQL Server flat files to centralized IT destination Created SSIS packages utilizing different SSIS transformations like  Script component Merge Join Look Up  and implemented error handling and logging  Performed unit testing and QA testing at various levels of the ETL’s and actively involved in team code reviews  Developed Report Models using report builder and distributed reports in multiple formats using SQL Server Reporting Services SSRS in Business intelligence development studio BIDS and SQL Server Data ToolsSSDT Created  Parameterized Cascaded Drilldown Crosstab and Drillthrough Reports  using SSRS 2008 R22012  Created Ad hoc Queries in TSQL Stored Procedures and Views to store the data of third parties and use them in SSRS reports to generate reports on the fly Worked with multivalued parameters for parameterized reports in SSRS  Developed VBA scripts for periodic Financial Daily Weekly reports generated directly from Excel utilizing Power Pivot options in Excel  Managed report delivery based on  Time driven and Data driven subscriptions  and  report security  for providing SSRS report  server level folder level and item level  permissions to various users across the organization based on role based access controlRBAC  Worked on resolving any performance issues with SSIS packages and SSRS reports and fine tune them for better performance  Worked on cleaning up users on SQL server and audit the access level Revoke Inappropriate access setting up AD groups and grant access based on the created groups  Worked on database  performance  and  maintenance  duties  such as  tuning   backup   restoration   Provide OnCall support for Production job failures Resolve and close the time critical Incidents in an appropriate way Perform root cause analysis create Problem report and work on any subsequent code changes to stop them from reoccurring           Database Consultant       082011      022013     AmazonCom Inc    –    Lithia Springs     GA            Involved in gathering business requirements definition and design of the data sourcing and data flows data quality analysis working in conjunction with the data warehouse architect on the development of logical data models  Using  TSQL  created complex  Stored Procedures Functions Cursors Tables and Views  and used other SQL joins and statements for applications in SQL Server 20052008  Developed standalone  SSIS  packages to extract data from different sources like  SQL Server Flat Files Excel Oracle and Sybase  transform and load the data onto required databases  Using  SSIS  transformations filtered bad data from different sources using  Derived Column Lookup Fuzzy lookup and Conditional split   Involved in creation of Technical Specs Design Documents Implementation Documents and Unit testingTest case test plan documents and maintained Issue logs  Using Script Component in  SSIS  wrote  C  NET  code to generate dynamic file names and create a text files Debugged and verified the values getting stored in  variables  in runtime using  C  code  Created dynamic  SSIS  packages through Variables and Script task components C  and VBNET and scheduled the packages using SQL Server Agent to process and load the data  Scheduled the package based on the Enterprise Calendar through SQL Server Agent Created several onetime and recurring jobs for package scheduling  Created XML file for package configurations and implemented parentchild package configuration in  SSIS  packages Implemented error and event handling precedence Constraints Break Points data grid and Logging in  SSIS  packages  Using  SSRS  developed multiple types of reports including Sub Reports Parameterized and Drill Down Reports using global variables expressions and functions based on the requirements provided  Deployed  SSRS  rdl reports on to the report server and created time driven subscriptions on the deployed reports  Created cubes with multiple fact measures groups and multiple dimension hierarchies based on the reporting needs using  SSAS   Modified existing dimensions and created new dimensions as per new business requirements  Created GUI interfaces using CNET and NET Framework to simplify the database access to end business users Enhanced existing GUI interfaces based on new requirements and improved efficiency  Resolved and closed production incident tickets generated because of failure of Daily Jobs          Education and Training       Master of Science       Electrical Engineering       Expected in   012011                California State University  Sacramento      Sacramento     CA     GPA        Status   |none
Data Engineer|https://www.livecareer.com/resume-search/r/system-services-representative-data-center-engineer-08ef2cab178d43c78255173d2136d97d|303008830723647812981083487132193910900|Jessica    Claire               Montgomery Street       San Francisco     CA  94105    609 Johnson Ave       49204     Tulsa     OK      Home   555 4321000        Cell           resumesampleexamplecom                  Experience      012015   to   Present     System Services Representative Data Center Engineer      Bridger Steel    –    Evansville     WY             Hired and trained by IBM to perform multiple tasks including hardware breakfix warranty repair in a multivendor environment  I am responsible for setting up coordinating and monitoring the operation of server equipment at two Delta Airline datacenters located at the airport  I run diagnostic tests to detect machine malfunctions  Independently handle high impact critical ticketsincidents  I use my connectivity skills to connect to the servers management port with SSH or Telnet  Other duties include but not limited to the following Rack stack cable configure and provision servers  Perform installation of wiring patch panel cables network switches hubs and KVMs  Deploy Cisco Layer 23 networking equipment  Installupgradereplacedeinstall servers devices and network components  Resolve issues  Execute planned changes  Use ServiceNow to follow change management requests until completion  Be accountable for ensuring a high level of client satisfaction with service delivery  Perform required site inspections  Perform audits  Problem analysis and remediation          012012   to   012014     IT Manager      City Of Atlanta    –    City     STATE             Hired by City of Atlanta to ensure reliability and availability of City of Atlanta data centers  Provided ongoing identification diagnosis and resolution of issues for users and City departments  Collaborated with internal teams and vendors at all technical levels to troubleshoot and resolve issues  Managed Windows Update Services for enterprise wide patches and security updates  Provided Exchange 2003 and 2010 administration  Upgraded maintained and installed servers and switch equipment  Provided server searches for open records act requests and litigation discovery searches  Involved in domain migration  Installed and maintained the security system for new and existing Windows servers  Proactively monitored production systems with a sense of urgency when issues arose  Worked with enterprise network loadbalancers Juniper Palo Alto and Cisco devices  Experience working with multiple server hardware platforms including IBM Dell Sun EMC and HP  Performed data center security monitoring  Successful citywide migration of Windows XP to Windows 7  Successfully implemented security software for City of Atlanta open records requests          012003   to   012012     Remote System x Server Technical Support Specialist      IBM    –    City     STATE             Hired by IBM to ensure reliability and availability of servers for IBM customers  This role participates in remote technical support of IBM hardware and software products andor systems and include the following  Provided remote troubleshooting and analysis assistance for installation or reinstallation usage and configuration questions  Provided answers for general usage and operation questions  Provided problem determination  problem source Identification  Reviewed diagnostic information to assist in isolation of a problem cause which could include assistance interpreting traces and dumps  Identify known defects and fixes to resolve problems  Identify suspected defects and engage development teams to assist in resolution  Helped with questions regarding product documentation related to the supported products  Interpreted online manuals regarding IBM code and application interfaces  Collaborated with other support centers and business units to provide seamless problem resolution  Demonstrated proficiency in the hardware and software platform supported by maintaining applicable technical certifications  Provided technical support service delivery within established guidelines demonstrating soft skills and technical skills that contribute to client satisfaction  Demonstrated excellent oral and written communication skills  Acquired industry certification and skills training  Exceeded customer satisfaction and case resolution metrics  Supported product lines including eSeries xSeries Intellistation Blade Center AIX iDataPlex fiber switches QLOGIC Emulex Cisco Brocade Quantum tape backup libraries  Provided additional support for FastT DASD fiber channel cabling ServeRAID Manager and management processors          Education      Expected in   2011     Associates of Applied Science Degree     Cyber Security     Chattahoochee Technical College      Marietta     GA     GPA       Cyber Security        Expected in        Security Certified Professional Network Certified Professional Server Certified Professional A Certified Professional Cisco Certified Technician                           GPA               Expected in        Blade eSeries xSeries AIX NAS SAN Certified          IBM University                GPA               Summary     Committed to ongoing professional development with CompTIA A Network Server and Security certifications  Also extensive academic training in network administration tracking intrusion detection firewall configuration OS administration cloud computing High level of technical proficiency with network utilities Master level of providing upperlevel support to management Master level of providing remote troubleshooting support to ensure continual operations of critical customer network systems Master experience in fastpaced high volume call environment with 12 years experience supporting IBM xSeries Blade Center Lenovo EMC AS400 DASD fiber NAS SAN RAID network appliances and tape library products Exceptional root cause analysis skills        Highlights         MS Server 2008 MS Server 2012 MS Windows 7 MS Windows 10 VMware Redhat Enterprise UNIX Networking  TCPIP SSL TLS SSH Telnet FTP HTTPS DHCP DNS WPA2 Ping Tracert TACACS Kerberos RADIUS RAS NAS IDSIPS Firewalls ToolsApplications  Solarwinds WireShark Snort Tera Term PuTTY MS Windows Security Templates MS Windows Security Update Service Microsoft Exchange 20032010 MS Windows Active Directory LDAP Terminal Services MS Windows Access Control MegaRAID Microsoft Office Lotus Notes Visual Basic 2010                       Skills     A Certified Active Directory AIX tape backup cables cable cabling change management Cisco Cisco Certified excellent oral hardware client customer satisfaction DASD delivery Dell DHCP diagnosis documentation DNS Firewalls FTP HP hubs IBM IBM hardware IDS LDAP litigation Lotus Notes Access Exchange Microsoft Exchange 2003 Microsoft Office Windows 7 Windows MS Windows 7 MS Windows Windows XP migration Enterprise NAS Network Networking Problem analysis problem resolution processors RAS Redhat SAN SSH servers SSL Sun switches switch TCPIP technical support Technician Telnet troubleshoot troubleshooting UNIX upgrade Visual Basic wiring written communication skills|none
Data Engineer|https://www.livecareer.com/resume-search/r/senior-data-engineer-03773a6bfb094914960c12c4167839e5|55652676729314852703085888775946776785|Jessica    Claire                                   609 Johnson Ave       49204     Tulsa     OK   100 Montgomery St 10th Floor    Home   555 4321000    Cell       resumesampleexamplecom              Summary       Strong IT experience in AWS cloud computing Bigdata  Data warehousing  Strong Business Domain Knowledge in Sales Segmentation  Territory Planning  Strong Coding  SQL experience in Python and Redshift  Having an experience in Agile and deliver the results based on stories and task assigned on the sprint  Implementation Knowledge in Serverless Architecture using AWS Cloud Computing  Having Good Hands on experience in GIT as well as CICD pipeline Integration  Having Good Hands on Experience in building Data Model based on requirements         Skills           Programming Languages Java Python Unix Unix Shell Scripting  Cloud Technologies Amazon Web Services AWS  Version Control AWS CodeCommit GIT GitHub Repositories      Continuous IntegrationContinuous DeliveryCICD AWS CodeDeploy AWS CodePipeline  Databases and SQL Redshift Oracle Netezza NoSQL DDB  Elasticsearch  Big Data Technologies Hadoop Hive Ozzie AirFlow Spark PySpark Scoop Flume                       Experience       Senior Data Engineer       012018   to   Current     Splunk    –    Bloomington     MN             Collaborated with product owners to gather requirement to help build a solution for Sales Segmentation  Identified key use cases and associated reference architectures for market segments and industry verticals  Worked as part of project teams to coordinate database and pipeline development and determine project scopes and limitations  Collaborated with solution architects to define database and analytics engagement strategies for operational territories and key accounts  Developed and managed enterprisewide big data environments  Specified user access levels for each database segment to protect database integrity and company information  Developed and implemented security initiatives to protect important company data  Established hardware requirements and devised storage capacity solutions and choose wisely on the AWS services by outweigh the requirement and business usecase           Big Data Engineer       122015   to   122017     Nike Inc    –    Gurnee     IL             Perform as a Big Data Developer and work in various phases like Data Ingestion Data Integration and Transformation  Create a Sqoop import command and pull the data both tables and all tables in DBs from MySQL DB to HDFS as part of Data Ingestion  Creates a MapReduce Programs as well as Spark programs to parse analyze and implement the solutions based on its customer need  Perform operations to filter the records from DB boundary query incremental update or insert in the Sqoop import commands  Perform operations to insert the data directly to Hive tables Change the delimiters and end line character and Change the formats like textFile AvroDataFile ORC file into HDFS systems using Sqoop Import commands  Perform Sqoop Eval function to evaluate the data in MYSQL  Perform Sqoop Export function to export the data from HDFS and loaded it into MYSQL and understand the delimiter of the file define the no of mapper to perform etc  Create a Flume config file to ingest the data from various source systems like Spool Directory NetCat Exec Sequence etc and loaded it into Avro HDFS etc  Define a proper channelsMemory File etc and loaded all the data comes from Source to Sinks  Used the interceptor to modify the data comes from Source like Filtering Regex Include the Timestamp Search and Replace etc  Create a MapReduce Program using Eclipse IDE and execute it through jar file  Create a Mapper Class and using Map method generate the key value pair as nodewithdate system utilization by writing in Context application  Create a Reducer Class and using reduce method generate the final output of system utilization per nodewithdate  Implements custom based writable class to get the two values in the mapOutputValue class  Implements custom based partitioner class to assign a appropriate data to the right reducerBasically try to achieve multilevel group by function with MR limitations  Implements Pattern Matching Logic for semistructured Data and routed the good and bad records separately  Create a custom based input format as well as record reader to parse the XML file  Handson in creating the Broadcast Variables  Handson in SparkSQL DataFrame creation DF via class object in Scala Convert DF to RDD TempTable Schema creation and So on           ETL Developer       092009   to   042015     Allegis Group    –    Jacksonville     FL             Created and implemented complex business intelligence solutions  Created conceptual logical and physical data models for use in different business areas  Developed and managed enterprisewide data analytics environments  Identified protected and leveraged existing data  Monitored multiple databases to keep track of all company inventory  Assisted maintenance team with completion of preventive maintenance and unscheduled service needs  Monitored installations to ensure compliance with local codes and industry best practices          Education and Training       Master of Science     Information Technology     Expected in        Amity University      Noida India          GPA                Bachelor of Engineering          Expected in   052008     College of Engineering Guindy Anna University      Chennai India          GPA|none
Data Engineer|https://www.livecareer.com/resume-search/r/aws-data-engineer-f1007ddd5382d9514a28eef265cea9d0|311813237829986595668673300748081977825|Jessica  Claire                             resumesampleexamplecom                      555 4321000                                         100 Montgomery St 10th Floor                                                                                                                                                                                                           Summary       Dynamic and motivated IT professional with around 15 years of experience as principal software developer having expertise in designing data intensive applications using Spark Ecosystem  Big Data Analytical  Cloud Data engineering  Data Warehouse  Data Mart Data Visualization  Reporting  and Data Quality solutions  Profound experience in performing Data Ingestion Data Processing Transformations enrichment and aggregations  Strong Knowledge on Architecture of Distributed systems and Parallel processing Indepth understanding of Spark execution framework  Experienced with the Spark improving the performance and optimization of the existing algorithms in Hadoop using Spark Context  SparkSQL  Dataframe API and worked explicitly on Scala   Handled ingestion of data from different data sources into HDFS using Sqoop and perform transformations using Hive Map Reduce and then loading data into HDFS  Experience of Partitions bucketing concepts in Scala and worked on fine tuning the sparkscala and sql queries to optimize performance   Experience with different file formats like Avro  parquet  Json and XML   Expertise in Creating Debugging Scheduling and Monitoring jobs using Airflow  Experienced with using most common Operators in Airflow  Python Operator Bash Operator  Handson experience in handling database issues and connections with SQL databases such as Netezza Oracle Redshift and PostgreSQL   Experience in designing and creating RDBMS Tables Views User Created Data Types Stored Procedures  Expert in designing ETL data flows using creating mappingsworkflows to extract data from Netezza  Oracle Servers  Expert in designing Parallel jobs using various stages like Join Merge Lookup remove duplicates Filter Dataset Lookup file set Complex flat file Modify Aggregator XML  Handson experience with Amazon EC2 Amazon S3 Amazon RDS VPC IAM Amazon Elastic Load Balancing Auto Scaling CloudWatch SNS SES SQS Lambda EMR and other services of the AWS family  Created and configured new batch job in Denodo scheduler with email notification capabilities and Implemented Cluster setting for multiple Denodo node and created load balance for improving performance activity  Instantiated created and maintained CICD continuous integration  deployment pipelines and apply automation to environments and applications  Worked on code versioning automation tools like GIT  Experienced with JSON based RESTful web services  Efficient Cloud Engineer with years of experience assembling cloud infrastructure Utilizes strong managerial skills by negotiating with vendors and coordinating tasks with other IT team members Implements best practices to create cloud functions applications and databases             Skills        ·  Big Data Technologies  Hadoop MapReduce HDFS Sqoop PIG Hive HBase Oozie Flume NiFi Kafka Zookeeper Yarn Apache Spark Mahout Sparklib  ·  Databases  Oracle MySQL SQL Server MongoDB Cassandra DynamoDB PostgreSQL Teradata Cosmos  ·  Programming  Python PySpark Scala Java C C Shell script Perl script SQL  ·  Cloud Technologies  AWS Microsoft Azure  ·  Frameworks  Django REST framework MVC Hortonworks  ·  Tools  PyCharm Eclipse Visual Studio SQLPlus SQL Developer TOAD SQL Navigator Query Analyzer SQL Server Management Studio SQL Assistance Eclipse Postman  ·  Versioning tools  SVN Git GitHub    ·  Operating Systems  Windows 78XP20082012 Ubuntu Linux MacOS  ·  Network Security  Kerberos  ·  Database Modelling  Dimension Modeling ER Modeling Star Schema Modeling Snowflake Modeling  ·  Monitoring Tool  Apache Airflow  ·  Visualization Reporting  Tableau ggplot2 matplotlib SSRS and Power BI  ·  Machine Learning Techniques  Linear  Logistic Regression Classification and Regression Trees Random Forest Associative rules NLP and Clustering                    Education and Training       Purdue University    West Lafayette     IN      Expected in   022022     –      –       Post Graduate         Data Engineering           GPA                    University of Texas At Austin    Austin     TX      Expected in   092021     –      –       Post Graduate         Data Science And Business Analytics           GPA                    Califonia State University     Fullerton CA           Expected in   122009     –      –       Bachelor of Arts        Business Administration And Management          GPA                     Experience       Deloitte      AWS Data Engineer   Rosslyn     CA                   012022      022022     Designed and setup Enterprise Data Lake to provide support for various uses cases including Analytics processing storing and Reporting of voluminous rapidly changing data  Responsible for maintaining quality reference data in source by performing operations such as cleaning transformation and ensuring Integrity in a relational environment by working closely with the stakeholders  solution architect  Designed and developed Security Framework to provide fine grained access to objects in AWS S3 using AWS Lambda  Performed end toend Architecture  implementation assessment of various AWS services like Amazon EMR Redshift S3  Used AWS EMR to transform and move large amounts of data into and out of other AWS data stores and databases such as Amazon Simple Storage Service Amazon S3 and Amazon RDS  Used Spark SQL for Scala Python interface that automatically converts RDD case classes to schema RDD  Import the data from different sources like S3  HDFS into Spark RDD and perform computations using sparkscalasparksql to generate the output response  Creating an automated alert notifications to identify and notify the idle EMR and EC2 clusters in our application regions to reduce the cost for EC2 and EMR resources  Developed reusable framework to be leveraged for future migrations that automates ETL from RDBMS systems to the Data Lake utilizing Spark Data Sources and Hive data objects  Developed Grafana Dashboards based on the Log stash data and Integrated different source and target systems into Elasticsearch for near real time log analysis of monitoring End to End transactions  Environment AWS EMR S3 RDS Redshift Lambda Apache Spark HIVE SQOOP Map Reduce Python  Assessed organization technology infrastructure and managed cloud migration process  Implemented cloud policies managed technology requests and maintained service availability           Splunk      Data Engineer   Memphis     TN                   012016      112019     Worked on Azure Data Factory to integrate data of both onprem MY SQL Cassandra and cloud Blob storage Azure SQL DB and applied transformations to load back to Azure Synapse  Managed Configured and scheduled resources across the cluster using Azure Kubernetes Service  Monitored Spark cluster using Log Analytics and Ambari Web UI  Transitioned log storage from Cassandra to Azure SQL Datawarehouse and improved the query performance  Involved in developing data ingestion pipelines on Azure HDInsight Spark cluster using Azure Data Factory and Spark SQL  Also Worked with Cosmos DB SQL API and Mongo API  Develop dashboards and visualizations to help business users analyze data as well as providing data insight to upper management with a focus on Microsoft products like SQL Server Reporting Services SSRS and Power BI  Performed the migration of large data sets to Databricks Spark create and administer cluster load data configure data pipelines loading data from ADLS Gen2 to Databricks using ADF pipelines  Created various pipelines to load the data from Azure data lake into Staging SQLDB and followed by to Azure SQL DB  Created Databrick notebooks to streamline and curate the data for various business use cases and also mounted blob storage on Databrick  Utilized Azure Logic Apps to build workflows to schedule and automate batch jobs by integrating apps ADF pipelines and other services like HTTP requests email triggers etc  Worked extensively on Azure data factory including data transformations Integration Runtimes Azure Key Vaults Triggers and migrating data factory pipelines to higher environments using ARM Templates  Ingested data in minibatches and performs RDD transformations on those minibatches of data by using Spark Streaming to perform streaming analytics in Data bricks  Environment Azure SQL DW Databrick Azure Synapse Cosmos DB ADF SSRS Power BI Azure Data lake ARM Azure HDInsight Blob storage Apache Spark  Adept in troubleshooting and identifying current issues and providing effective solutions  Managed performance monitoring and tuning while identifying and repairing issues within database realm  Identified key use cases and associated reference architectures for market segments and industry verticals  Designed surveys opinion polls and assessment tools to collect data  Tested validated and reformulated models to foster accurate prediction of outcomes  Created graphs and charts detailing data analysis results  Recommended data analysis tools to address business issues  Developed new functions and applications to conduct analyses  Cleaned and manipulated raw data  Collaborated with solution architects to define database and analytics engagement strategies for operational territories and key accounts           General Dynamics      Big Data Engineer  Hadoop Developer   Bossier City     MA                   102013      122015   AnsibleDenodoDenodoCloudWatchAvroPySparkPySparkPySparkMLlibDataframeNiFiNiFi  Interacted with business partners Business Analysts and product owner to understand requirements and build scalable distributed data solutions using Hadoop ecosystem  Developed Spark Streaming programs to process near real time data from Kafka and process data with both stateless and state full transformations  Worked with HIVE data warehouse infrastructurecreating tables data distribution by implementing partitioning and bucketing writing and optimizing the HQL queries  Built and implemented automated procedures to split large files into smaller batches of data to facilitate FTP transfer which reduced 60 of execution time  Worked on developing ETL processes Data Stage Open Studio to load data from multiple data sources to HDFS using FLUME and SQOOP and performed structural modifications using Map Reduce HIVE  D eveloping Spark scripts UDFS using both Spark DSL and Spark SQL query for data aggregation querying and writing data back into RDBMS through Sqoop  Written multiple MapReduce Jobs using Java API Pig and Hive for data extraction transformation and aggregationAvrom multiple file formats including Parquet Avro XML JSON CSV ORCFILE and other compressed file formats Codecs like gZip Snappy Lzo  Strong understanding of Partitioning bucketing concepts in Hive and designed both Managed and External tables in Hive to optimize performance  Developed PIG UDFs for manipulating the data according to Business Requirements and also worked on developing custom PIG Loaders  Developing ETL pipelines in and out of data warehouse using combination of Python and Snowflakes SnowSQL Writing SQL queries against Snowflake  Experience in report writing using SQL Server Reporting Services SSRS and creating various types of reports like drill down Parameterized Cascading Conditional Table Matrix Chart and Sub Reports  Used DataStax Spark connector which is used to store the data into Cassandra database or get the data from Cassandra database  Wrote oozie scripts and setting up workflow using Apache Oozie workflow engine for managing and scheduling Hadoop jobs  Worked on implementation of a log producer in Scala that watches for application logs transform incremental log and sends them to a Kafka and Zookeeper based log collection platform  Used Hive to analyze data ingested into HBase by using HiveHBase integration and compute various metrics for reporting on the dashboard  Transformed tPySpark using AWS Glue dynamic frames with PySpark cataloged the transformed the data using Crawlers and scheduled the job and crawler using workflow feature  Worked on installing cluster commissioning  decommissioning of data node name node recovery capacity planning and slots configuration  Developed data pipeline programs with Spark Scala APIs data aggregations with Hive and formatting data JSON for visualization and generatiPySpark     Environment AWS Cassandra PySpark Apache Spark HBase Apache Kafka HIVE SQOOP FLUME Apache oozie Zookeeper ETL UDF Map Reduce Snowflake Apache Pig Python Java SSRS  Onfidential  Developed and implemented Hadoop code while observing coding standards  Optimized and tuned Hadoop environments and modified hardware to meet prescribed performance thresholds  Developed new functions and applications to conduct analyses  Created graphs and charts detailing data analysis results  Tested validated and reformulated models to foster accurate prediction of outcomes           Fiserv      Python Developer    City     STATE                   092012      102013     AWS S3 EC2 LAMBDA EBS IAM Datadog CloudTrail CLI Ansible MySQL Python Git Jenkins DynamoDB Cloud Watch Docker Kubernetes  Leveraged open communication collective decisionmaking and thorough reviews to create performant and scalable systems  Worked with serverside and frontend technologies and leveraged common design patterns to code dynamic and userfriendly systems  Implemented new API routes architected new ORM structures and refactored code to boost application performance  Harnessed version control tools to coordinate project development and individual code submissions  Introduced cloudbased technologies into Python development to expand onpremise deployment options  Wrote clear and clean code for use in projects  Resolved customer issues by establishing workarounds and solutions to debug and create defect fixes|none
Data Engineer|https://www.livecareer.com/resume-search/r/sr-data-analyst-support-engineer-0690548375b14b17a0ecaf5aa825cc34|71493749037436587054693787398602463147|JC     Jessica    Claire                                        100 Montgomery St 10th Floor           555 4321000                 resumesampleexamplecom                         Summary       7 years of experience as a BI developer with a proven track record in Business Intelligence BI Data Warehouse DWH and Data Analytics related consulting projects  Proven ability to identify business needs and develop valuable solutions to drive accuracy and process efficiency  Experienced in developing implementing documenting monitoring and maintaining the data warehouse extracts transformations and ETL process in various industries like Financial Health Care and Retail Industry with  Sales Marketing Inventory Management Supply Chain and Finance  domains    Delivered BI reporting solutions in Power BI Reporting Services SSRS  Expertise in  Data Warehousing Architectures  including  ETL  design  Staging   Transformations   Deltachange Data  capture  StarSchemas  Cubes and  History  loading  Skilled in writing  TSQL Queries  Dynamicqueries subqueries and joins for generating  Stored Procedures Triggers Userdefined Functions  Views and Cursors  Experience with all phases of software development life cycle SDLC and Agile methodologies  Have delivered as a team member team lead and as an independent consultant on medium to large scale projects         Skills           DataBusinessSystems  Tools MS SQL Server IntegrationSSIS Analysis ServicesSSAS Metl  Databases SQL Server 20122016Netezza 72 Oracle 11g Azure  Development Skills TSQL DAX MDX C      BI Reporting Tools Power BI Reporting Services Services SSRS  Data Quality and Standards  Agile Methodology  Programming Languages   TSQL C VB Scripting                       Education        Expected in   052013   Bachelor of Science       Information Technology    GMR Institute of Technology     Rajam India           GPA               Experience        052020   to   Current   Sr Data AnalystSupport Engineer    Honeywell         Gladstone     MO            Client  Citi Bank Irving Tx   Working as Level2 Support Engineer for Data Pipelines the Retail Customer Applications and Azure Data Staging  Analyzed large amounts of data to identify trends and find patterns signals and hidden stories within data  Developing and supporting DevOps Repos and code pipelines for all ETLs Tasks and Jobs  Developed  Standard  ETL  integrations  to extract CommunityLoanLocation data from Mainframes system and implemented Business Rules to confirm the data  Experience in creating and managing SSAS tabular models creating dimension and fact tables  Responsible for data administration tasks  maintenance plans   performance tuning   backup and security  for MS SQL Server systems  Primarily involved in data migration using SQL SQL Azure Azure storage and azure data factory SSIS Powershell  Integrated Custom Visuals based on business requirements using Power BI desktop  Developed complex SQL queries using stored procedures common table expressions CTEs temporary table to support Power BI and SSRS reports  Developed complex calculated measures using Data Analysis Expression language DAX  Embedded Power BI reports on the Salesforce portal page and also managed access of reports and data for individual users using Roles  Provided continued maintenance and development of bug fixes for the existing and new Power BI Reports            082018   to   052020   Sr BI Data Developer    Butler Technical Group         Opa Locka     FL            Led the development of Data Mart for supply chainmarketing departments along with analysis of existing data warehouse for performance improvements  Worked on all phases of data warehouse development life cycle from gathering requirements implementation testing training and support  Interviewed Business Users of the Data Warehouse and the Business Analysts to understand and troubleshoot the existing bottlenecks and problem areas  Developed applications and designed processes for transformation and data management from companywide databases  Developed automated data dictionary for Enterprise Data Warehouse using SSRS and SQL  Completed a thorough analysis of the issues with the cube processing and query processing to identify bottleneck for the existing facts and dimensions  Designed and developed ETL packages to facilitate incremental load process  Created aggregates partitions attribute relationships and user defined hierarchies with the goal to reduce the cube processing time and query processing time  Created stored procedures and performed index analysis for slow performing SSRS reports to bring down the report rendering time  Developed Enterprise wide cascading reports in SSRS that were used throughout the agency to monitor the performance of the cube logging of the nightly ETL loads and also to monitor most active users of the cube  Created robust and highperforming ETL mappings using  SSIS  and  Metl   Migrated existing selfservice reports and adhoc reports to Power BI  Developed custom calculated measures using DAX in Power BI to satisfy business needs  Assisted users in accessing databases troubleshooting malfunctions and removing systembased barriers to task completion            112016   to   072018   Sr ETL Developer    Kairos Technologies Inc         City     STATE            Client  Cvs Caremark Irving Tx      Worked on ambitious project to develop an Enterprise Wide Drug plan Record system data warehouse connecting Insurance companies and Drug Manufacturers for CVS Caremark  Worked with Business Intelligence Manager to plan BI strategies create BI road map and budget plans to deliver on organizations Business Intelligence needs  Assessed the impact of current business processes on users and stakeholders  Developed multiple dashboards analytical reports KPIs and Interactive reports based on business requirements using SSRS to support executive business needs  Transferred data from various data sourcesbusiness systems including MS Excel MS Access Flat filesCOSMOS etc to SQL Server using SSIS  Implemented Query Optimization and performance tuning for slow performing SQL queries  Involved in writing complex TSQL queries and stored procedures to perform data transformations and to support SSRS Reports  Involved in creating User Security and Roles in reporting services at both parent level and report level  Supported maintenance of Data Quality Services DQS knowledge base and development of Master Data Services database            072013   to   042016   Business Data Analyst    Tata Consultancy Services         City     STATE            Client  Sun Trust Bank US   Designed Implemented and aided EndtoEnd data migration project using Microsoft SSIS  Assisted in creation of internal applications for marketing and customer relations departments including financial reporting tools and reports  Designed SSIS Packages to extract data from various data sources such as Excel spreadsheet and flat files and load data into destination databases for further Data Analysis and Reporting  Performed rigorous business case analyses and proposed various process improvements  Used Excel and Access applications for visualizing the data functionality  Led an initiative to convert all excel files which were used in inhouse timeexpense reporting wherein I automated the process to find discrepancies in timesheets by creating tables views using stored procedures    Client   Marks and SpencerUK   Improved business direction by prioritizing customers and implementing changes based on collected feedback  Analyzed open orders backlog and sales data to provide sales team with insights  Created tables and define their relations by using foreign key and primary key relationship  Involved in creating database objects using stored procedures Triggers Functions Views and TSQL Joins using TSQL  Performed normalization of database to reduce redundancy and achieve maximum system performance  Wrote custom TSQL stored procedures and triggers to improve performance preserve referential integrity and provide additional application functionality  Worked as ETL Developer for an EndtoEnd implementation of Operation Data Warehousing Project  Responsible for data integration and transformation using SSIS  Formulated and documented the physical ETL process design based on business requirements and system specifications with strong ETL design skills  Created source to target mappings transformations lookups aggregations expressions  Involved in scheduling reports creating snapshot reports and subscription for the reports Using SSRS|none
Data Engineer|https://www.livecareer.com/resume-search/r/senior-data-engineer-ffd843d6febb4217800488911db2a3f8|137893745859917600174161396390961745079|Jessica    Claire               Montgomery Street       San Francisco     CA  94105    609 Johnson Ave       49204     Tulsa     OK      Home   555 4321000        Cell           resumesampleexamplecom                  Professional Summary      Business Intelligence Consultant with a 10year career in data warehousing business intelligence reporting and data management architecture Progressive developer and technical team lead with a strength in design  development as well as driving performance reducing inefficiencies and cutting costs Possess comprehensive knowledge and hands on experience in both ETL and Reporting tools Knowledge of Credit Card account life cycle management in Finance domain Functional knowledge of Collections and Recovery operations Expertise in planning executing and spearheading various SDLC and Agile Scrum projects in compliance to quality standards Known for effective communication with excellent relationship building  interpersonal skills strong analytical problem solving  organizational abilities Proven track record of taking ownership and diving deeper into issues to identify the root cause and troubleshoot towards resolution        Skills           ETL Tools  Ab Initio  Scripting Languages  Unix shell scripting Python SparkScala  Cloud Services Microsoft Azure Cloud Services Data Lake  DataBricks and Data Pipelines Azure Data Factory  BI Reporting Skills  Tableau Desktop Tableau Server Power BI Reporting  SAP Business Objects SAP BOUniverse Designer Tool SAP BO XI WEBI ReportingSAP BO XI Deski Reporting  Database  Oracle  Teradata Hive      Scheduler tools  Autosys ControlM  Relational Database Management  Business Intelligence Reporting  Project Management  Data Analysis and Visualization                       Work History      062017   to   Current     Senior Data Engineer      Thoughtworks    –    Memphis     TN            A multitenure loyalty program across all Williams Sonoma brands – the first time that customers can earn points by purchasing across the multiple brands WSI Pottery Barn West Elm etc I work in the customer data warehouse CDW which is Teradata and work with their 3rd party marketing systems vendor There are various data points and integrations with the data warehouse which holds all customer information points transactions loyalty IDs etc   Worked with Requirements Analysts and PDMs to identify understand and document business needs for data flow Analyze requirementsUser stories at business meetings and strategize impact of requirements on different platformsapplications Worked with Project Management in creation of project estimates for each Agile story  Engaged in projects that uses Scala and Azure DatabricksDatafactoryDatalake to extract process and load Adobe Clickstream data received for Williams Sonoma ECOM website Deployed custom codes in Scala to read JSON extract CSV files from Adobe add column headers handle badmalformed records handle invalid records before finally writing cleansed data into ParquetDelta file format partitioned by date and hour  Build and review design deliverables Perform dependency analysis between new objects created in Ab Initio graphs Conduct IT and UAT testing of each of these graphs Record errors reported during Unit and Integrated testing  Prepare production Implementation Plan to deploy codes successfully to production environment  Coordinate daily standups short meetings where teammates talk through whats being worked on yesterday what was done today and if blocked Involved in variety of other scrum meetings such as planning meetings where team pulls in stories requirements grooming meeting to look at backloglist of stories and flush out timeline and work expected demo show work that was completed in sprint etc  Reporting  Visualization in Tableau and Power BI  Design and deploy rich Graphic visualizations with Drill Down and Drop down menu option Prepare Dashboards using calculations parameters Apply various reporting objects like Filters prompts Calculated fields Groups Parameters Work on the development of Dashboard reports for the Key Performance Indicators for the top management          032010   to   062017     Senior DeveloperTechnical Team Lead      Tech Mahindra Synchrony Financial Services    –    City     STATE            Synchrony Financial is a consumer financial services company offering consumer financing products including credit promotional financing and loyalty programs and installment lending through Synchrony Bank its wholly owned subsidiary Synchrony is the largest provider of private label credit cards in the US The company provides private label credit cards for such brands as Amazon JC Penney CheapOAir OneTravel Sams Walmart Lowe’s Guitar Center Gap BP We as Data warehouse solution providers store this credit card holder information from the instance a credit card is applied till the account is closedcharged off   Understanding the full scope of requirements from business Estimating time and effort involved from gathering project requirements till project implementation  Answering technical queries driving product initiatives and metric collection and analysis  CoOrdinating between project stake holders – Business Client and offshore teams during all phases of project  Preparing design documentation design reviews development performing code reviews to ensure coding standards are followed testing and deployment of application enhancements  Experience in Ab Initio toolsets including the following  o Parallel and serial flow batch graphs conditional components other components like reformat normalize and join lookup and graphs processing ASCII and EBCDIC layouts  o Knowledge on Abinitio architecture including the GDE Cooperating system EME and other related items  o Fine tuning of Abinitio graphs based on performance enhancement by proper usage of memory in the components  o Well versed with various Ab Initio components such as Join Rollup Partition Departition Dedup sorted Scan Normalize DeNormalize  o Expertise knowledge improving Performance and Troubleshooting of the AbInitio graphs and monitoring ABInitio run time statistics  o Experience with advanced Abinitio metaprogramming air commands and other admin related tasks including the creation of save and performing migration from one server to the other  Establish support such as acquiring conditioned test data support from third partyteam etc for Integration Testing to simulate production environment and to ensure correctness and quality of buildparameter set up  Getting sign off from IT managers for deploying parameterset up onto production environment  Documenting implementation plan and Hour by Hour plan listing down the tasks in sequence of their execution on the date of implementation  Coordinate release activities across multiple teams          Education      Expected in   4 2008     Bachelors     Information Technology     College of Engineering Bhubaneswar      India          GPA               Accomplishments      • Tableau Desktop Specialist Certified No expiration  These are Open Badges that I have been awarded and that attest to my skills  httpswwwyouracclaimcombadges556948fdd8114f8097d245ab6c530d9clinkedinprofile   o Tableau Desktop Specialist title use their foundational knowledge of Tableau Desktop and data analytics to solve problemsDesktop Specialists can connect to prepare explore and analyze data and share their insights        Skills       ETL Tools  Ab Initio  Scripting Languages  Unix shell scripting Python SparkScala  Cloud Services Microsoft Azure Cloud Services Data Lake  DataBricks and Data Pipelines Azure Data Factory  BI Reporting Skills  Tableau Desktop Tableau Server Power BI Reporting  SAP Business Objects SAP BOUniverse Designer Tool SAP BO XI WEBI ReportingSAP BO XI Deski Reporting  Database  Oracle  Teradata Hive    Scheduler tools  Autosys ControlM  Relational Database Management  Business Intelligence Reporting  Project Management  Data Analysis and Visualization         Work History      062017   to   Current     Senior Data Engineer       Kforce Inc Williams Sonoma Inc   –   San Francisco     CA     A multitenure loyalty program across all Williams Sonoma brands – the first time that customers can earn points by purchasing across the multiple brands WSI Pottery Barn West Elm etc I work in the customer data warehouse CDW which is Teradata and work with their 3rd party marketing systems vendor There are various data points and integrations with the data warehouse which holds all customer information points transactions loyalty IDs etc   Worked with Requirements Analysts and PDMs to identify understand and document business needs for data flow Analyze requirementsUser stories at business meetings and strategize impact of requirements on different platformsapplications Worked with Project Management in creation of project estimates for each Agile story  Engaged in projects that uses Scala and Azure DatabricksDatafactoryDatalake to extract process and load Adobe Clickstream data received for Williams Sonoma ECOM website Deployed custom codes in Scala to read JSON extract CSV files from Adobe add column headers handle badmalformed records handle invalid records before finally writing cleansed data into ParquetDelta file format partitioned by date and hour  Build and review design deliverables Perform dependency analysis between new objects created in Ab Initio graphs Conduct IT and UAT testing of each of these graphs Record errors reported during Unit and Integrated testing  Prepare production Implementation Plan to deploy codes successfully to production environment  Coordinate daily standups short meetings where teammates talk through whats being worked on yesterday what was done today and if blocked Involved in variety of other scrum meetings such as planning meetings where team pulls in stories requirements grooming meeting to look at backloglist of stories and flush out timeline and work expected demo show work that was completed in sprint etc  Reporting  Visualization in Tableau and Power BI  Design and deploy rich Graphic visualizations with Drill Down and Drop down menu option Prepare Dashboards using calculations parameters Apply various reporting objects like Filters prompts Calculated fields Groups Parameters Work on the development of Dashboard reports for the Key Performance Indicators for the top management          032010   to   062017     Senior DeveloperTechnical Team Lead       Tech Mahindra Synchrony Financial Services   –   Chicago     IL     Synchrony Financial is a consumer financial services company offering consumer financing products including credit promotional financing and loyalty programs and installment lending through Synchrony Bank its wholly owned subsidiary Synchrony is the largest provider of private label credit cards in the US The company provides private label credit cards for such brands as Amazon JC Penney CheapOAir OneTravel Sams Walmart Lowe’s Guitar Center Gap BP We as Data warehouse solution providers store this credit card holder information from the instance a credit card is applied till the account is closedcharged off   Understanding the full scope of requirements from business Estimating time and effort involved from gathering project requirements till project implementation  Answering technical queries driving product initiatives and metric collection and analysis  CoOrdinating between project stake holders – Business Client and offshore teams during all phases of project  Preparing design documentation design reviews development performing code reviews to ensure coding standards are followed testing and deployment of application enhancements  Experience in Ab Initio toolsets including the following  o Parallel and serial flow batch graphs conditional components other components like reformat normalize and join lookup and graphs processing ASCII and EBCDIC layouts  o Knowledge on Abinitio architecture including the GDE Cooperating system EME and other related items  o Fine tuning of Abinitio graphs based on performance enhancement by proper usage of memory in the components  o Well versed with various Ab Initio components such as Join Rollup Partition Departition Dedup sorted Scan Normalize DeNormalize  o Expertise knowledge improving Performance and Troubleshooting of the AbInitio graphs and monitoring ABInitio run time statistics  o Experience with advanced Abinitio metaprogramming air commands and other admin related tasks including the creation of save and performing migration from one server to the other  Establish support such as acquiring conditioned test data support from third partyteam etc for Integration Testing to simulate production environment and to ensure correctness and quality of buildparameter set up  Getting sign off from IT managers for deploying parameterset up onto production environment  Documenting implementation plan and Hour by Hour plan listing down the tasks in sequence of their execution on the date of implementation  Coordinate release activities across multiple teams|none
Data Engineer|https://www.livecareer.com/resume-search/r/data-support-services-engineer-fd6014dbd6d04903b67269cf3fc6cd59|12880653418622435105799992611550629230|Jessica    Claire                   Montgomery Street     San Francisco     CA  94105    609 Johnson Ave       49204     Tulsa     OK       H   555 4321000    C       resumesampleexamplecom    Date of Birth         India                      single                    Summary     Desktop and Server Support Application Server Technician Offer my Windows Server 20122008 R22003 Windows XP78 Mac OS X Linux Application Server Microsoft Office 2010 and Office Mac 2011 Active Directory and Network LANWAN switches and routers experience Desktop and server hardware and software technical support experience Strong analytical troubleshooting communication and customer service skills  Skilled Windows System Administrator offering 10 years of experience building and maintaining multiplatform technology services with a solid understanding of current Windows Mac and UNIX application systems       Highlights           Systems	Windows XP78 Desktop	Max OS X 108 109 1010	iO78 mobile and tablet  Windows 20032008 Server	Android mobile		Red Hat Enterprise Linux  Unix web applications	LANWAN  Mobile Phone	iPhoneiPad Apple	Blackberry		Android  Applications	Microsoft Office 20072010	Office Mac 2010		Final Cut 7 and 10  Microsoft Office 365	Pages OS X		Numbers OS X  Adobe Creative Suite cloud	Adobe Acrobat XXI	Adobe Lighthouse 45  Parallels	WebEx  Utilities	Symantec Antivirus	Voltage Email Encryption	Barracuda Backup Cloud  PGP DesktopServer	Symantec Ghost  Server Applications	Active Directory	PowerShell Scripting	WINS	DFS  DHCP	FilePrint Services	LDAP	Group Policy GP  Exchange 2010	NTFS security		HyperV	DNS                         Accomplishments       Requirements Analysis    Completed business requirements analysis including the evaluation of systems specifications for the Soundview Throgs Neck Community Health Center     Strategy and Planning    Developed and communicated Electronic Health Record security policies and standards to all users  Established policies and procedures for medical record documentation     IT Training    Successfully trained all employees to use Electronic Health Record and Billing systems     Network Support    Acted as first point of contact for all major technical issues including power outages system failures and disaster recovery  Oversaw infrastructure of three offices and acted as support for helpdesk technicians of Yeshiva University          Experience       Data Support Services Engineer       072013      092013     Montefiore Medical Center formally SVTNCMHC Health Care Services    –    City     STATE            Managed the daytoday IT operations for the Montefiore Medical Center  Assisted in the migration of technology services from Yeshiva Universitys servers to Montefiores servers including computers user logins data files printer settings software applications and email archives  Provided QA testing in the migration of the centers Electronic Health Record Mindlinc and Billing IMA system  Trained all staff in the use of Montefiores technical services including clerical registration billing electronic health record and emailprintingdata file usage           Technical System Support Engineer       072003      072013     Yeshiva University Health Care Services Soundview Throgs Neck Community Health Center SVTNCMHC    –    City     STATE            Desktops Mobile Phones Printers and Application Servers Provided all levels of enduser desktop server mobile phonetablet and printer technical support for 2 healthcare center locations in the Bronx  Backend technical support for all server and network services  Responsible for managing 15 application servers including 4 domain controllers  Deployed and maintained a Windows 2008R2 and 2003 Active Directory environment  Managed all aspects of server and application security using Active Directory LDAP and Linux  Planned and implemented the physical deployment and migration of Windows 7 desktops from Windows XP  Consulted daily with the executive clinical and administrative staff concerning the overall quality and possible improvement of technology systems for the medical center  Trained all staff in the use of SVTNYeshiva Universitys technical services including clerical registration billing electronic health record and emailprintingdata file usage  Provided QA support and testing of our internal and external billing system IMA  Work closely with outside vendors to design and maintain the EHR Billing and Backup applications  Implemented and maintained the centers data backup system using Barracuda Cloud Backup  Identified designed and implemented the requirements for the centers disaster recovery system  Responsible for managing and maintaining the centers audiovideo conference room system          Education       Graduate Certificate       Digital Media and Project Management       Expected in                   The New School      New York     NY     GPA        Status                  BBA       Computer Information Systems       Expected in                   Baruch College City University of New York      New York     NY     GPA        Status                  Skills      Active Directory administrative Adobe Adobe Acrobat Antivirus Apple audio Backup Billing billing system clerical Encryption Desktops DHCP disaster recovery DNS Email Ghost LAN LDAP Linux Mac managing Max Exchange Microsoft Office Office Windows 7 Windows Windows XP migration Enterprise network OS printer Printers quality QA Red Hat Servers Scripting Symantec technical support Phones Phone Unix Utilities video WAN web applications|none
Data Engineer|https://www.livecareer.com/resume-search/r/aws-data-engineer-fcef99cc1f1c4bdeb25cbb8d5b3ac32c|339690346324715490168338998099130748299|Jessica    Claire                                   609 Johnson Ave       49204     Tulsa     OK   100 Montgomery St 10th Floor    H   555 4321000    C       resumesampleexamplecom    Date of Birth         India                      single                    Summary       Dynamic and motivated IT professional with around 7 years of experience as a Big Data Engineer with expertise in designing data intensive applications using Hadoop Ecosystem  Big Data Analytical  Cloud Data engineering  Data Warehouse  Data Mart Data Visualization  Reporting  and Data Quality solutions   In  depth knowledge of Hadoop architecture and its components like YARN  HDFS Name Node Data Node Job Tracker Application Master Resource Manager  Task Tracker and Map Reduce programming paradigm  Extensive experience in Hadoop led development of enterprise level solutions utilizing Hadoop components such as Apache Spark MapReduce HDFS Sqoop PIG Hive HBase Oozie Flume NiFi Kafka Zookeeper and YARN  Profound experience in performing Data Ingestion Data Processing Transformations enrichment and aggregations  Strong Knowledge on Architecture of Distributed systems and Parallel processing Indepth understanding of MapReduce programming paradigm and Spark execution framework  Experienced with the Spark improving the performance and optimization of the existing algorithms in Hadoop using Spark Context  SparkSQL  Dataframe API  Spark Streaming MLlib  Pair RDD s and worked explicitly on PySpark and Scala   Handled ingestion of data from different data sources into HDFS using Sqoop Flume and perform transformations using Hive Map Reduce and then loading data into HDFS  Managed Sqoop jobs with incremental load to populate HIVE external tables Experience in importing streaming data into HDFS using Flume sources and Flume sinks and transforming the data using Flume interceptors  Experience in Oozie and workflow scheduler to manage Hadoop jobs by Direct Acyclic Graph  DAG  of actions with control flows  Implemented the security requirements for Hadoop and integrating with Kerberos authentication infrastructure KDC server setup creating realm domain managing  Experience of Partitions bucketing concepts in Hive and designed both Managed and External tables in Hive to optimize performance   Experience with different file formats like Avro  parquet  ORC  Json and XML   Expertise in Creating Debugging Scheduling and Monitoring jobs using Airflow and Oozie  Experienced with using most common Operators in Airflow  Python Operator Bash Operator Google Cloud Storage Download Operator Google Cloud Storage Object Sensor  Handson experience in handling database issues and connections with SQL and NoSQL databases such as MongoDB  HBase  Cassandra  SQL server  and PostgreSQL   Created Java apps to handle data in MongoDB and HBase Used Phoenix to create SQL layer on HBase  Experience in designing and creating RDBMS Tables Views User Created Data Types Indexes Stored Procedures Cursors Triggers and Transactions  Expert in designing ETL data flows using creating mappingsworkflows to extract data from SQL Server and Data Migration and Transformation from OracleAccessExcel Sheets using SQL Server SSIS   Expert in designing Parallel jobs using various stages like Join Merge Lookup remove duplicates Filter Dataset Lookup file set Complex flat file Modify Aggregator XML  Handson experience with Amazon EC2 Amazon S3 Amazon RDS VPC IAM Amazon Elastic Load Balancing Auto Scaling CloudWatch SNS SES SQS Lambda EMR and other services of the AWS family  Created and configured new batch job in Denodo scheduler with email notification capabilities and Implemented Cluster setting for multiple Denodo node and created load balance for improving performance activity  Instantiated created and maintained CICD continuous integration  deployment pipelines and apply automation to environments and applications  Worked on various automation tools like GIT Terraform Ansible Experienced in fact dimensional modeling  Star schema Snowflake schema  transactional modeling and SCD Slowly changing dimension  Experienced with JSON based RESTful web services and XMLQML based SOAP web services and also worked on various applications using python integrated IDEs like Sublime Text and PyCharm   Efficient Cloud Engineer with years of experience assembling cloud infrastructure Utilizes strong managerial skills by negotiating with vendors and coordinating tasks with other IT team members Implements best practices to create cloud functions applications and databases         Skills          ·  Big Data Technologies  Hadoop MapReduce HDFS Sqoop PIG Hive HBase Oozie Flume NiFi Kafka Zookeeper Yarn Apache Spark Mahout Sparklib  ·  Databases  Oracle MySQL SQL Server MongoDB Cassandra DynamoDB PostgreSQL Teradata Cosmos  ·  Programming  Python PySpark Scala Java C C Shell script Perl script SQL  ·  Cloud Technologies  AWS Microsoft Azure  ·  Frameworks  Django REST framework MVC Hortonworks  ·  Tools  PyCharm Eclipse Visual Studio SQLPlus SQL Developer TOAD SQL Navigator Query Analyzer SQL Server Management Studio SQL Assistance Eclipse Postman  ·  Versioning tools  SVN Git GitHub    ·  Operating Systems  Windows 78XP20082012 Ubuntu Linux MacOS  ·  Network Security  Kerberos  ·  Database Modelling  Dimension Modeling ER Modeling Star Schema Modeling Snowflake Modeling  ·  Monitoring Tool  Apache Airflow  ·  Visualization Reporting  Tableau ggplot2 matplotlib SSRS and Power BI  ·  Machine Learning Techniques  Linear  Logistic Regression Classification and Regression Trees Random Forest Associative rules NLP and Clustering                      Experience       AWS Data Engineer       012022      022022     Accenture Contractor Jobs    –    Rochester     NY            Designed and setup Enterprise Data Lake to provide support for various uses cases including Analytics processing storing and Reporting of voluminous rapidly changing data  Responsible for maintaining quality reference data in source by performing operations such as cleaning transformation and ensuring Integrity in a relational environment by working closely with the stakeholders  solution architect  Designed and developed Security Framework to provide fine grained access to objects in AWS S3 using AWS Lambda DynamoDB  Set up and worked on Kerberos authentication principals to establish secure network communication on cluster and testing of HDFS Hive Pig and MapReduce to access cluster for new users  Performed end toend Architecture  implementation assessment of various AWS services like Amazon EMR Redshift S3  Implemented the machine learning algorithms using python to predict the quantity a user might want to order for a specific item so we can automatically suggest using kinesis firehose and S3 data lake  Used AWS EMR to transform and move large amounts of data into and out of other AWS data stores and databases such as Amazon Simple Storage Service Amazon S3 and Amazon DynamoDB  Used Spark SQL for Scala  amp Python interface that automatically converts RDD case classes to schema RDD  Import the data from different sources like HDFSHBase into Spark RDD and perform computations using PySpark to generate the output response  Creating Lambda functions with Boto3 to deregister unused AMIs in all application regions to reduce the cost for EC2 resources  Importing  exporting database using SQL Server Integrations Services SSIS and Data Transformation Services DTS Packages  Coded Teradata BTEQ scripts to load transform data fix defects like SCD 2 date chaining cleaning up duplicates  Developed reusable framework to be leveraged for future migrations that automates ETL from RDBMS systems to the Data Lake utilizing Spark Data Sources and Hive data objects  Conducted Data blending Data preparation using Alteryx and SQL for Tableau consumption and publishing data sources to Tableau server  Developed Kibana Dashboards based on the Log stash data and Integrated different source and target systems into Elasticsearch for near real time log analysis of monitoring End to End transactions  Implemented AWS Step Functions to automate and orchestrate the Amazon SageMaker related tasks such as publishing data to S3 training ML model and deploying it for prediction  Integrated Apache Airflow with AWS to monitor multistage ML workflows with the tasks running on Amazon SageMaker  Environment AWS EMR S3 RDS Redshift Lambda Boto3 DynamoDB Amazon SageMaker Apache Spark HBase Apache Kafka HIVE SQOOP Map Reduce Snowflake Apache Pig Python SSRS Tableau  Assessed organization technology infrastructure and managed cloud migration process  Configured computing networking and security systems within cloud environment  Implemented cloud policies managed technology requests and maintained service availability           Data Engineer       012016      112019     Verizon    –    Beaverton     OR            Worked on Azure Data Factory to integrate data of both onprem MY SQL Cassandra and cloud Blob storage Azure SQL DB and applied transformations to load back to Azure Synapse  Managed Configured and scheduled resources across the cluster using Azure Kubernetes Service  Monitored Spark cluster using Log Analytics and Ambari Web UI  Transitioned log storage from Cassandra to Azure SQL Datawarehouse and improved the query performance  Involved in developing data ingestion pipelines on Azure HDInsight Spark cluster using Azure Data Factory and Spark SQL  Also Worked with Cosmos DB SQL API and Mongo API  Develop dashboards and visualizations to help business users analyze data as well as providing data insight to upper management with a focus on Microsoft products like SQL Server Reporting Services SSRS and Power BI  Performed the migration of large data sets to Databricks Spark create and administer cluster load data configure data pipelines loading data from ADLS Gen2 to Databricks using ADF pipelines  Created various pipelines to load the data from Azure data lake into Staging SQLDB and followed by to Azure SQL DB  Created Databrick notebooks to streamline and curate the data for various business use cases and also mounted blob storage on Databrick  Utilized Azure Logic Apps to build workflows to schedule and automate batch jobs by integrating apps ADF pipelines and other services like HTTP requests email triggers etc  Worked extensively on Azure data factory including data transformations Integration Runtimes Azure Key Vaults Triggers and migrating data factory pipelines to higher environments using ARM Templates  Ingested data in minibatches and performs RDD transformations on those minibatches of data by using Spark Streaming to perform streaming analytics in Data bricks  Environment Azure SQL DW Databrick Azure Synapse Cosmos DB ADF SSRS Power BI Azure Data lake ARM Azure HDInsight Blob storage Apache Spark  Adept in troubleshooting and identifying current issues and providing effective solutions  Managed performance monitoring and tuning while identifying and repairing issues within database realm  Identified key use cases and associated reference architectures for market segments and industry verticals  Designed surveys opinion polls and assessment tools to collect data  Tested validated and reformulated models to foster accurate prediction of outcomes  Created graphs and charts detailing data analysis results  Recommended data analysis tools to address business issues  Developed new functions and applications to conduct analyses  Cleaned and manipulated raw data  Collaborated with solution architects to define database and analytics engagement strategies for operational territories and key accounts           Big Data Engineer  Hadoop Developer       102013      122015     Two95 International Inc    –    Boca Raton     FL          AnsibleDenodoDenodoCloudWatchAvroPySparkPySparkPySparkMLlibDataframeNiFiNiFi  Interacted with business partners Business Analysts and product owner to understand requirements and build scalable distributed data solutions using Hadoop ecosystem  Developed Spark Streaming programs to process near real time data from Kafka and process data with both stateless and state full transformations  Worked with HIVE data warehouse infrastructurecreating tables data distribution by implementing partitioning and bucketing writing and optimizing the HQL queries  Built and implemented automated procedures to split large files into smaller batches of data to facilitate FTP transfer which reduced 60 of execution time  Worked on developing ETL processes Data Stage Open Studio to load data from multiple data sources to HDFS using FLUME and SQOOP and performed structural modifications using Map Reduce HIVE  D eveloping Spark scripts UDFS using both Spark DSL and Spark SQL query for data aggregation querying and writing data back into RDBMS through Sqoop  Written multiple MapReduce Jobs using Java API Pig and Hive for data extraction transformation and aggregationAvrom multiple file formats including Parquet Avro XML JSON CSV ORCFILE and other compressed file formats Codecs like gZip Snappy Lzo  Strong understanding of Partitioning bucketing concepts in Hive and designed both Managed and External tables in Hive to optimize performance  Developed PIG UDFs for manipulating the data according to Business Requirements and also worked on developing custom PIG Loaders  Developing ETL pipelines in and out of data warehouse using combination of Python and Snowflakes SnowSQL Writing SQL queries against Snowflake  Experience in report writing using SQL Server Reporting Services SSRS and creating various types of reports like drill down Parameterized Cascading Conditional Table Matrix Chart and Sub Reports  Used DataStax Spark connector which is used to store the data into Cassandra database or get the data from Cassandra database  Wrote oozie scripts and setting up workflow using Apache Oozie workflow engine for managing and scheduling Hadoop jobs  Worked on implementation of a log producer in Scala that watches for application logs transform incremental log and sends them to a Kafka and Zookeeper based log collection platform  Used Hive to analyze data ingested into HBase by using HiveHBase integration and compute various metrics for reporting on the dashboard  Transformed tPySpark using AWS Glue dynamic frames with PySpark cataloged the transformed the data using Crawlers and scheduled the job and crawler using workflow feature  Worked on installing cluster commissioning  decommissioning of data node name node recovery capacity planning and slots configuration  Developed data pipeline programs with Spark Scala APIs data aggregations with Hive and formatting data JSON for visualization and generatiPySpark     Environment AWS Cassandra PySpark Apache Spark HBase Apache Kafka HIVE SQOOP FLUME Apache oozie Zookeeper ETL UDF Map Reduce Snowflake Apache Pig Python Java SSRS  Onfidential  Developed and implemented Hadoop code while observing coding standards  Optimized and tuned Hadoop environments and modified hardware to meet prescribed performance thresholds  Developed new functions and applications to conduct analyses  Created graphs and charts detailing data analysis results  Tested validated and reformulated models to foster accurate prediction of outcomes           Python Developer        092012      102013     Fiserv    –    City     STATE            AWS S3 EC2 LAMBDA EBS IAM Datadog CloudTrail CLI Ansible MySQL Python Git Jenkins DynamoDB Cloud Watch Docker Kubernetes  Leveraged open communication collective decisionmaking and thorough reviews to create performant and scalable systems  Worked with serverside and frontend technologies and leveraged common design patterns to code dynamic and userfriendly systems  Implemented new API routes architected new ORM structures and refactored code to boost application performance  Harnessed version control tools to coordinate project development and individual code submissions  Introduced cloudbased technologies into Python development to expand onpremise deployment options  Wrote clear and clean code for use in projects  Resolved customer issues by establishing workarounds and solutions to debug and create defect fixes          Education and Training       Post Graduate        Data Engineering        Expected in   022022                Purdue University      West Lafayette     IN     GPA        Status                  Post Graduate        Data Science And Business Analytics        Expected in   092021                University of Texas At Austin      Austin     TX     GPA        Status                  Bachelor of Arts       Business Administration And Management       Expected in   122009                Califonia State University       Fullerton CA          GPA        Status   |none
Data Engineer|https://www.livecareer.com/resume-search/r/data-science-data-engineer-intern-bd32a7569cbb4dd2a9f164b4801eef35|266612002933194965787459684177947415296|Jessica  Claire                             resumesampleexamplecom                      555 4321000                       Montgomery Street     San Francisco     CA      94105                                                                                                                                                                                                             Summary     Highly motivated Sales Associate with extensive customer service and sales experience Outgoing sales professional with track record of driving increased sales improving buying experience and elevating company profile with target market           Skills         Machine LearningData Mining  NLP  Linear Regression neural networksdeep learning Naive Bayes SVM Logistic Regression  decision trees Kmean KNN N Grams edit distance gradient descent  Statistical Programming  Packages  R Python NumPy Matplotlib scikitlearn pandas ggplot2 Shiny dplyr caret e1071keras  Business Intelligence  Visualization  Tableau Qlik View Qlik Sense Excel OBIEE  Hadoop Ecosystem Components  Spark Hive Sqoop Flume Kafka Impala  Databases  Oracle MySql PostgreSql  Oracle ERP  Fusion Middleware  Oracle EBusiness Suite 11i  R12 Oracle SOA Oracle Service Bus  Other Languages  Tools  SQL PLSQL core java Scala RStudio Jupyter SqlDeveloper Toad Atom  Certifications  Tableau SQL  PLSQL                       Education and Training       University of Utah David Eccles School of Business    Salt Lake City     Utah      Expected in   August 2017     –      –       Master of Science        Information Systems          GPA           Information Systems Data Science and Analytics specialization   Recipient of 15000 Graduate Fellowship from David Eccles School of Business Academic Capstone Project  Big Data  Building statistical regression and classification models cleaning exploring data and developing interactive web interface using R Shiny which helps the company to classify clients loan type and predicting the amount of loan they will take in future Kaggle  House Prices Predictions  Applied different machine learning simple and advanced models on housing predictors for predicting the sales prices of houses used imputation methods for filling missing and null values in the data set Independent Study  Research  Apache Spark using Scala and Python Rajeev Gandhi Memorial College of Engineering and Technology          India                        Expected in   May 2012     –      –       Bachelor of Science        Computer Science and Engineering          GPA           Computer Science and Engineering Designed Hand Draw Shape Recognition interface which helps the user to invoke desired application just by drawing the shape linked to the application          Experience       Envestnet      Data Science  Data Engineer Intern   Secaucus     NJ                   012017      Present     Working on Big Data Ingestion using Sqoop for transferring data from multiple MySql database servers to transient storage in amazon EMR Hcatalog and using Hive to transfer data to persistent storage in amazon S3 bucket  Developing Sqoop and Hive scripts for data ingestion  Using R and spark in amazon EMR for filtering exploring analyzing providing insights on data and developing reports           First American Corporation      Oracle Technical Consultant  Data Analyst   City          India              022013      072016     Created SQL scripts for daily extracts adhoc requests  reporting and for analyzing large data sets  Designed ER diagrams conceptual models logical and physical models created database objects  Tables Indexes Sequences and Views  Developed Oracle Business Intelligence reports created and modified Oracle database objects  Tables Views and Indexes which increased the performance of Oracle Business Intelligence reports by 60 in production environment  Prepared SQL  Loader scripts for loading data from other systems into oracle ERP system worked with onsite business team in performing data fixes  Created PLSQL interfaces for doing business validation transferring data between ERP modules and loading data to base tables           CMC Limited      Data Analyst Intern   City          India              112012      012013     gt Developed SQL scripts worked on oracle 11i database and oracle reports          Skills     Academic ad Apache Big Data Business Intelligence Draw clients Data Mining Databases database EBusiness edit ERP filling drawing java Machine Learning Excel Middleware MySql NLP networks neural Oracle Oracle database PLSQL PostgreSql Programming Python reporting Research sales servers scripts SQL SQLLoader Tableau Tables Toad type validation View|none
Data Engineer|https://www.livecareer.com/resume-search/r/data-center-engineer-b2eec8f867b4482e996b65dec2238532|224493945599255295224336362821325623329|Jessica  Claire                             resumesampleexamplecom                      555 4321000                       Montgomery Street     San Francisco     CA      94105                                                                                                                                                                                                             Profile      Dedicated Data Center Engineer with excellent technical analytical and communication skills demonstrated by 5 years of experience  Innovative Fiber Optic Engineer specialize in Design and DeploymentExperience with purchasing products and vendor relationships  Multitask oriented Resourceful and Businesssavvy            Skills         Project Management  Fiber optic Design Implementation  Infrastructure Cabling Solutions  Analog Circuit Design and Deployment      PBX Telecommunications  Microsoft Office Suite Word Excel Power PointVisio  Reqlogic 8                        Education and Training       University of Phoenix               Expected in   2014     –      –       Bachelor of Science        Management          GPA                    Katharine Gibbs School    New York     NY      Expected in   2007     –      –       Associate of Applied Science        Computer Networking           GPA            Deans List Academic Achievement Award  38 GPA  Graduated Cum Laude           Accomplishments      First Technician on DCO team to achieve FOA Certified Fiber Optic Technician  and to progress to Certified Fiber Optic Design Certification   Promoted to Engineer and 2nd Shift Lead Supervisor    Successfully Trained 7 other DCO Staff Members in Fiber Optic testing and terminations   Developed Fiber Optic Strategy Deployment to help reduce installation times  This is achieved by limiting the amount of cables to be extended by increasing fiber infrastructure out to our customers and shortening the distances to within 100 FT or less Thus saving time and materials         Professional Experience       Sentinel Technologies Inc      Data Center Engineer    Lansing     MI                   072012      Current     Designed and develop Fiber Optic Infrastructure for 990000 Sq Ft Facility  Test and trouble shoot Layer 1 and 2 Local Area Network issues    Supervise 2nd shift technicians provide leadership and training for new technicians    Maintain Inventory and purchasing of all project materials    Negotiate competitive with vendors on pricing through cost evaluation of daily materials consumed   Provide estimates and cost analysis of cabling projects   Coordinate with cross functional departments and outsourced vendors to meet deadlines    Maintain Office infrastructure deployment of Internet Data and Voice Applications PBX and VOIP              Contegix      Data Center Technician    Arlington     VA                   032007      072012       Maintain Inventory and Purchase Materials for daily work and projects  Field and document network related trouble notifications while Monitoring troubleshooting and resolving Tier 1 and 2 Local Area Network problems  Install and assist with the design of Cat6 6a Copper Coax and Fiber connections for new integrated networks serving major corporations  Mounting and Installation of IBM Dell Sun Microsystem Servers Cisco Juniper Firewalls Routers Switches and DWDM Optical equipment           United States Air Force      Installation Patrolman   City     STATE                   2002      2006      Developed installation traffic management programs   Provided police services to over 10000 personnel in community   Airman of the Year Nominee   Provided security for multibillion dollar aircraft a deep spacetracking station and non nuclear munitions storage areas   Directly contributed to 48th Security Forces Squadron selection as “Outstanding Large Security Force Unit” for 2003|none
Data Engineer|https://www.livecareer.com/resume-search/r/data-engineer-iii-e867612a74144501b4d70b51d5b2f7e9|5533667039977703598659155174781970519|Jessica    Claire                                   609 Johnson Ave       49204     Tulsa     OK   100 Montgomery St 10th Floor    H   555 4321000    C       resumesampleexamplecom    Date of Birth         India                      single                    Summary      Seasoned Senior Data Engineer possessing indepth knowledge of RDBSM environments ETL techniques architecture data modeling and integration between systems Offering 10 years of background managing various aspects of development design and delivery of database solutions Analytical passionate and aspiring leader bringing proven communication and organizational abilities Seeking a fulltime remote position        Skills            Expertise in Microsoft SQL Server Management Studio 20052019     Microsoft Certified Professional Designation  Microsoft Database Fundamentals Designation  Temporary Tables DLL statements Loops Schema creations Common Table Expressions View Dynamic SQL scripts Merge statements Indices Performance Tuning Triggers Functions Store Procedures Joins Parametrization Cross Apply Outer Apply Automation Job Creation Scheduling Environment Variable Deployment Variables Store Procedures Pivots Performance Tuning     Expertise in BIDSVisual Studio     Extraction from various sources eg flat files DBs XML etc Dynamic SQL Automation Deployment Parameterization Looping ProgramProcess Executions Custom coding using Script Tasking Flat FileXML File Creation UTF8 conversion MergeSCD implementation     Adept Excel User     Pivots use of Macros Formulas Charts Tabular data from SSAS cubes     Data Architecture and Modeling     Use of Star and Snowflake Schema utilizing tools like Visio to create Flow Charts using data modeling tools like SQLDB to create denormalized structures creating business specific entities to create balance between efficiency and use case       Oracle     Familiarity and use of PLSQL corroborated financial reports using Oracle Transaction Business Intelligence OTBI and the UCM as well     Familiarity of Presentation Layer Tools     Salesforce Tableau Qlikview SSRS OTBI     Subject Matter Expert     Deep IT derived knowledge in business operations including Finance Accounting Marketing Underwriting Compliance and some Specialty Risk Programs     Other Pertinent Skills     Agile HybridKANANWaterfalls methodology Familiarity with AzureDevOps GitHub TFS Skilled Design Documentation     Personal Skills     Diligent Adaptive Organized Methodical Analytical HonestBlunt                       Experience       Data Engineer III       072016      Current     Crown Castle Usa Inc    –    Salt Lake City     UT            Development    Utilized various IDEs including Visual Studio SQL Server Management Studio Astera Centerprise to build ETL solutions  Created dynamic SQL to droprecreate objects  Utilized Activity Monitortype tools such as FogLight and Solarwinds DPA tool for bottlenecks  Created technical and operational audits within process to better catch issues  Performance tuned process cutting down an 8 hour process to 5 minutes  Created and ingested delimited files  Created pivot structures within SQL taking data and transposing it in the other direction eg horizontal data to vertical  Utilized VB and C languages to create custom Script Task components to use in ETL solutions    Integration    Integrated claims personal and commercial lines products  Extensively developed piloted and implemented integration solution between OLTP data and Salesforce created API pipeline delivering quote details to business thereby allowing them to make key decisions with agents  Created data consumption and delivery solutions for claims including though not limited to sending flat files to vendors containing company data receiving decompressing unpacking ingesting data creating a wrapper shell on a program that was called by SSIS solution dynamically recreating dll with parameterized inputs    Analytics    Researched financial disparities between Oracle and TSQL restructured format  Sequenced data dictionary from Oracle to extrapolate and originate data sources to better deliver solutions  Created pivoted OLAPTabulated SSAS structures to help display intersection of trends and data    Reporting    Created canned subscription and ad hoc reports for business stakeholders sectors including finance claims actuary legal statistical statutory marketing and underwriting  Substantiated differences between expected and actual results in control reports allowing business to see disparities    Architecture    Architected a SCD Type 1  2 and 3 denormalized and normalized structures  Created conceptual logical and physical data models by utilizing tools such as Visio SysDiagram and SQLDBM    Leadership    Led and organized scrumstatus meetings Provided guidance and focused delivery tasks to colleagues whilst assessing for gaps  Provided instructional and informational background on projects to new comers detailing them thoroughly on the historical and current SDLC processes lessons learned etc  Piloted groups to create best practices and code vettingreview within organization    Organizational    Incorporated various methodology including though not limited to Waterfall Agile KANBAN Hybrid  Created several detailed design documents some serving as a standard and template for other developers  Coordinated project management updates to determine project scopes and limitations  Managed performance monitoring and tuning while identifying and repairing issues within database realm  Part of SWAT delivery service a team designed to tackle high velocity and profile requests in company Managed solution implementation for several highprofile projects from start to finish           Application Developer       122014      072016     Honeywell    –    Deer Park     TX            Development    Created ETL solutions using Visual Studio and SQL Studio Management Studio  Parsed and massaged data into Guidewire specific formats following tight edits  Promoted and automated ETL processes  Performance tuned existing queries to cut down on time reducing overall process from 2 hours to 8 minutes    Integration    Integrated commercial and personal lines Farm and Ranch insurance products into Guidewire Claims Center  Worked closely with business stakeholders to understand data whilst also pushing for systemoriginated corrections where fixes could not be done via ETL    Leadership    Mentored colleagues and fellow testers in TSQL scripting    Organizational    Utilized Agile Methodology and TFS to check inout code from repository  Created design documents detailing process and flow  Worked closely with business stakeholders to understand requirements and provide deliverables per their specifications    Educational    Actively sought out areas to increase insurance domain of knowledge  Enrolled and successfully completed AINS 24 offered by The Institutes  Informed and trained with Guidewire and SAP HANA software  Became Farm and Ranch SME for data           ETL Developer       032013      102014     American Homes 4 Rent    –    Cincinnati     OH            Development    Created complex integration solution to ingest and parse rowdelimited flat files using the FiServ Data model  Ingested outputted files from FNMA and FHLMC  Further refined this data using ETL based on businessend user requirements  Participated in code review sessions with colleague to assess bottlenecks strategize resource consumption kill deadlocks and tailor code to become more IO efficient  Created an SDLC lifecycle for process flow including environments for development testing and production  Installed and Upgraded SQL Server Studio    Integration    Delivered outputs using webservice calls fetching unique systemoriginated keys from OLTP system to use within TSQL    Leadership    Trained and mentored users on how to utilize TSQL and create simple SSIS packages  Crosstrained colleagues on ETL solution    Organizational    Created several design documents detailing pipeline of ETL solution caveatslimitations and future development requirements          Education and Training       Associate of Arts              Expected in   122011                Collin College      Frisco TX          GPA        Status           Summa Cum Laude Honors graduate  Phi Theta Kappa International Honor Society member  Sigma Kappa Delta National English Honor Society member  Student Leadership Academy graduate|none
Data Engineer|https://www.livecareer.com/resume-search/r/senior-data-engineer-c2991ccc65f9419cbf914b7149f33d26|274097087237322696861922203277862748921|Jessica  Claire                             resumesampleexamplecom                      555 4321000                                         100 Montgomery St 10th Floor                                                                                                                                                                                                           Professional Summary       Having 9 years of Industry experience in ETL Tools such as DataStage  Informatica and SSI Packages  Having experience in Data Bricks Hive SQL Azure CICD pipeline Delta Lake Data Lake Hadoop File system Snowflake  Having experience in Building ETL pipe lines using Apache Spark Python  Excellent Experience in Designing Developing Documenting Testing of ETL jobs and mappings in Server and Parallel jobs using DataStageInformatica to populate tables in Data Warehouse DataMart ODS and Large Data sets  Experience in working on streaming data using IBM MQ and Kafka  Experience in working using AgileSCRUM and Waterfall Development Methodology  Experience in logging tickets in Service now Version control tools PVCS Azure DevOps CICD pipeline  Experience in Azure work environment  Work experience in IBM Master Data ManagementMDM Architecture  Working Experience on Azure Cloud  Experience in working with multiple Data Bases like Oracle SQL Server DB2 Netezza NOSQL Mongo DB Salesforce Snowflake DB  Experience in working on data migration from oracle 9i to 10g and DB2 to Netezza  Expertise in using DataStageInformatica to integrate with different Sources and Targets like Azure SQL database Oracle Mainframe systems Netezza Salesforce SOAP and REST services XML SQL Server and MongoDB  Experience in UNIX AIX and Linux server resource monitoring and load balancing  Ensured that user requirements are effectively and accurately communicated to the other members of the development team and Facilitate communications between business users developers and testing teams  Conducting internal and external reviews as well as formal walkthrough among various teams and documenting the proceedings  Excellent problemsolving and troubleshooting capabilities Quick learner highly motivated result oriented and an enthusiastic team player             Education       Sri Krishnadevaraya University    Kurnool AndhraPradesh           Expected in   052011     –      –       Bachelor of Engineering        Computer Science  Information Technology          GPA                   Skills         ETL Tools  DataStage Informatica Power Centre and SSIS Packages  Big Data Technologies  HiveSpark  HDFSKafka Sqoop  Database  Oracle SQL ServerDB2 Netezza  Mongo Snowflake  Programming Languages  UNIX Python PLSQL  Working experience in Agile Waterfall model and tracking in JIRRA and Microsoft Devops  Configuration Tools  PVCS  Microsoft TFS Azure CICD pipeline  Cloud Experience Azure      Job Scheduling Tools CA7 Control M  Operating System  Win XP 7 10 and UNIX  Adaptability  Data management  Organization and Time management  Teamwork                     Certifications      IBM Data Stage  Oracle  Informatica  Netezza          Work History       Factset Research Systems Inc      Senior Data Engineer   San Francisco     CA                   022021      Current     Bank Operational Data Distribution Hub is highly availability distribution center for operational data The servers have been set up to provide failover capabilities in the event of any issues which could cause the hardware to shut down The design of this system focuses on four main vendors We load data to  HDFS storage as well and built HIVE on top of this to analyze   Developed implemented supported and maintained data analytics protocols standards and documentation  Analyzed complex data and identified anomalies trends and risks to provide useful insights to improve internal controls  Contributed to internal activities for overall process improvements efficiencies and innovation  Communicated new or updated data requirements to global team  Explained data results clearly and discussed how it can be utilized to support project objectives  Planned and implemented security measures to safeguard vital business data  Created and implemented database designs and data models  Monitored incoming data analytics requests executed analytics and efficiently distributed results to support strategies  Built databases and table structures following OLAPOLTP architecture methodology for web applications           Cox Communications Inc      Lead Data Engineer   Dayton     OH                   012018      012021    Master Data ManagementMDM EQH is primary vehicle for customer selfservice for Life and Annuity products Displays current policy values statements confirmation notices and prospectuses Supports profile maintenance including address phone and email address changes financial profile and investment strategies Selfservice tools include performance financial transactions ACH payments and loans   Responsibilities    Leads programproject application engineering teams consisting of cross functional global and virtual groups directly supervises staff assigns responsibility to members monitors progress of daily activities  Monitor and manage programproject application engineering baseline to ensure activities are occurring as planned  scope budget and schedule and managing variances  Managed performance monitoring and tuning while identifying and repairing issues within database realm  Proactively identify risks issues and problems on programsprojects  leading engineering and projectprogram team to develop risk management and issue management plans  I have saved 1 person monitoring work by performing optimization   Ability to clearly articulate problems and proposed options and solutions and apply judgment in implementing application engineering methodologies processes and practices to ensure security resilience maintainability and quality of MDM solutions  Analyses and defines detailed MDM processes tasks data flows and dependencies  Develop custom mapping functions  Participates in system and integration testing  Produces database code SQL stored procedures and any other database specific code solutions meeting technical specifications and business requirements according to established designs  Proactively resolved issues within team  Validated warehouse data structure and accuracy  Cooperated fully with product owners and enterprise architects to understand requirements  Collaborated with multifunctional roles to communicate and align development efforts  Mapped data between source systems and warehouses  Performed systems and data analysis using variety of computer languages and procedures  Documented data warehouse architecture to guarantee capacity met current and forecasted needs  Developed and modified programs to meet customer requirements  Quickly learned new skills and applied them to daily tasks improving efficiency and productivity  Provided global thought leadership in analytics solutions to benefit customers           Epam Systems Inc      Senior ETL Developer   Washington     DC                   082017      122017    Netezza Rewrite This project is about migrating around 70 Data Marts runs on Oracle to Netezza in 10 phases This includes redesigning DataStage jobs integrates with oracle to change it to Netezza and Informatica to DataStage migration   Role  Responsibilities     Requirement Analysis Creating mappings Unit Testing Defect Fixing Documentation and Status Reporting  Identifying Entities cardinality and developing Logical and Physical Data Model  Mentored newly hired employees offering insight into job duties and company policies for easier transition to job position  Prioritized and organized tasks to efficiently accomplish service goals  Analyzing existing process scripts and preparing design document with performance optimized approach  Performed impact analysis on every source and target tables  Responsible for estimation of Design Development and Unit testing  Analyzing dependent objects and data involved and updating efficient unit testing approach  Responsible for scheduling changes which includes changing node to new 115 server change in run time parameters change in predecessor or successor requirements and removing jobs  Have published Play book or Implementation plan for every release  Responsible for driving implementation and doing post implementation data checks  Resolved complex DataStage performance issues and other environment issues  Designed and Developed reusable components which can parse dsx and provide input and output SQLs used in DataStage code  Reviewed Netezza Deliverables and DataStage deliverables in every phase of project  Resolved Netezza SQL issues to Business users  Coordinated with downstream systems and worked on impacted system sign off review and production preparation           Epam Systems Inc      Senior ETL Developer   PA     State                   012016      072017    Financial Move Forward inforce Data Equitable Enterprise Data Warehouse EDW manages collection of components in both Mainframe Information DatabaseIDB and Distributed environments Open system Data WarehouseOSDW that include batch processes operational data stores business intelligence BI data marts and general data services to all IT lines of business   FMFInforce Data project consists of two phases  First phase involves migration of DB2 data to Netezza DB with help of integrated ETL tool Data Stage 87  Second phase contains Data Modelling and DataMart design of migrated tables in Netezza  First phase basically involves initial data load IDL of 400 Db2 tables to Netezza DB  Took care of installing Netezza client on UNIX box where Data stage client exists and ensured connectivity is good for designing data stage jobs Role  Responsibilities  Understanding requirements and coming up with high level design  Created Lowlevel design of mapping document  Created mappings and transformations as per business requirements  Writing reusable mapplets and Oracle PLSQL stored procedures  Unit test jobs according to test plans  Monitored debugged and scheduled mappings according to requirements  Improving performance of mapping execution thus reducing CPU and execution cost and time  Providing System Testing and User Testing Support IQA of Mappings  Capable of assisting team of developers both onshore and offshore to provide strategic plan for execution of this project  Ability to work with key team members to ensure solution meets business requirements  Provided Proof of Concept POC for technical approach regarding design of data stage jobs  Understanding requirements and coming up with technical design strategies with project team and business users  Contributed to detailed estimation of development work  Involved in Estimation of DBA Effort for this project  Designed Field level mapping template design based on business rules transformations and validations  Performed problem assessment resolution and documentation for new and existing database objects  Prepared Knowledge Transition documents which were appreciated by business IT people  Communicated with data architects programmers and engineers to keep projects on track|none
Data Engineer|https://www.livecareer.com/resume-search/r/aws-data-engineer-63b337f6d6bf36b19ae995691c672ca0|270987204323396713165325793790364446993|Jessica  Claire                             resumesampleexamplecom                      555 4321000                                         100 Montgomery St 10th Floor                                                                                                                                                                                                           Summary       Dynamic and motivated IT professional with around 7 years of experience as a Big Data Engineer with expertise in designing data intensive applications using Hadoop Ecosystem  Big Data Analytical  Cloud Data engineering  Data Warehouse  Data Mart Data Visualization  Reporting  and Data Quality solutions   In  depth knowledge of Hadoop architecture and its components like YARN  HDFS Name Node Data Node Job Tracker Application Master Resource Manager  Task Tracker and Map Reduce programming paradigm  Extensive experience in Hadoop led development of enterprise level solutions utilizing Hadoop components such as Apache Spark MapReduce HDFS Sqoop PIG Hive HBase Oozie Flume NiFi Kafka Zookeeper and YARN  Profound experience in performing Data Ingestion Data Processing Transformations enrichment and aggregations  Strong Knowledge on Architecture of Distributed systems and Parallel processing Indepth understanding of MapReduce programming paradigm and Spark execution framework  Experienced with the Spark improving the performance and optimization of the existing algorithms in Hadoop using Spark Context  SparkSQL  Dataframe API  Spark Streaming MLlib  Pair RDD s and worked explicitly on PySpark and Scala   Handled ingestion of data from different data sources into HDFS using Sqoop Flume and perform transformations using Hive Map Reduce and then loading data into HDFS  Managed Sqoop jobs with incremental load to populate HIVE external tables Experience in importing streaming data into HDFS using Flume sources and Flume sinks and transforming the data using Flume interceptors  Experience in Oozie and workflow scheduler to manage Hadoop jobs by Direct Acyclic Graph  DAG  of actions with control flows  Implemented the security requirements for Hadoop and integrating with Kerberos authentication infrastructure KDC server setup creating realm domain managing  Experience of Partitions bucketing concepts in Hive and designed both Managed and External tables in Hive to optimize performance   Experience with different file formats like Avro  parquet  ORC  Json and XML   Expertise in Creating Debugging Scheduling and Monitoring jobs using Airflow and Oozie  Experienced with using most common Operators in Airflow  Python Operator Bash Operator Google Cloud Storage Download Operator Google Cloud Storage Object Sensor  Handson experience in handling database issues and connections with SQL and NoSQL databases such as MongoDB  HBase  Cassandra  SQL server  and PostgreSQL   Created Java apps to handle data in MongoDB and HBase Used Phoenix to create SQL layer on HBase  Experience in designing and creating RDBMS Tables Views User Created Data Types Indexes Stored Procedures Cursors Triggers and Transactions  Expert in designing ETL data flows using creating mappingsworkflows to extract data from SQL Server and Data Migration and Transformation from OracleAccessExcel Sheets using SQL Server SSIS   Expert in designing Parallel jobs using various stages like Join Merge Lookup remove duplicates Filter Dataset Lookup file set Complex flat file Modify Aggregator XML  Handson experience with Amazon EC2 Amazon S3 Amazon RDS VPC IAM Amazon Elastic Load Balancing Auto Scaling CloudWatch SNS SES SQS Lambda EMR and other services of the AWS family  Created and configured new batch job in Denodo scheduler with email notification capabilities and Implemented Cluster setting for multiple Denodo node and created load balance for improving performance activity  Instantiated created and maintained CICD continuous integration  deployment pipelines and apply automation to environments and applications  Worked on various automation tools like GIT Terraform Ansible Experienced in fact dimensional modeling  Star schema Snowflake schema  transactional modeling and SCD Slowly changing dimension  Experienced with JSON based RESTful web services and XMLQML based SOAP web services and also worked on various applications using python integrated IDEs like Sublime Text and PyCharm   Efficient Cloud Engineer with years of experience assembling cloud infrastructure Utilizes strong managerial skills by negotiating with vendors and coordinating tasks with other IT team members Implements best practices to create cloud functions applications and databases             Skills         ·  Big Data Technologies  Hadoop MapReduce HDFS Sqoop PIG Hive HBase Oozie Flume NiFi Kafka Zookeeper Yarn Apache Spark Mahout Sparklib  ·  Databases  Oracle MySQL SQL Server MongoDB Cassandra DynamoDB PostgreSQL Teradata Cosmos  ·  Programming  Python PySpark Scala Java C C Shell script Perl script SQL  ·  Cloud Technologies  AWS Microsoft Azure  ·  Frameworks  Django REST framework MVC Hortonworks  ·  Tools  PyCharm Eclipse Visual Studio SQLPlus SQL Developer TOAD SQL Navigator Query Analyzer SQL Server Management Studio SQL Assistance Eclipse Postman  ·  Versioning tools  SVN Git GitHub      ·  Operating Systems  Windows 78XP20082012 Ubuntu Linux MacOS  ·  Network Security  Kerberos  ·  Database Modelling  Dimension Modeling ER Modeling Star Schema Modeling Snowflake Modeling  ·  Monitoring Tool  Apache Airflow  ·  Visualization Reporting  Tableau ggplot2 matplotlib SSRS and Power BI  ·  Machine Learning Techniques  Linear  Logistic Regression Classification and Regression Trees Random Forest Associative rules NLP and Clustering                     Education and Training       Purdue University    West Lafayette     IN      Expected in   022022     –      –       Post Graduate         Data Engineering           GPA                    University of Texas At Austin    Austin     TX      Expected in   092021     –      –       Post Graduate         Data Science And Business Analytics           GPA                    Califonia State University     Fullerton CA           Expected in   122009     –      –       Bachelor of Arts        Business Administration And Management          GPA                     Experience       Deloitte      AWS Data Engineer   Rosslyn     NV                   012022      022022     Designed and setup Enterprise Data Lake to provide support for various uses cases including Analytics processing storing and Reporting of voluminous rapidly changing data  Designed and developed Security Framework to provide fine grained access to objects in AWS S3 using AWS Lambda DynamoDB  Set up and worked on Kerberos authentication principals to establish secure network communication on cluster and testing of HDFS Hive Pig and MapReduce to access cluster for new users  Used AWS EMR to transform and move large amounts of data into and out of other AWS data stores and databases such as Amazon Simple Storage Service Amazon S3 and Amazon DynamoDB  Import the data from different sources like HDFSHBase into Spark RDD and perform computations using PySpark to generate the output response  Creating Lambda functions with Boto3 to deregister unused AMIs in all application regions to reduce the cost for EC2 resources  Importing  exporting database using SQL Server Integrations Services SSIS and Data Transformation Services DTS Packages  Coded Teradata BTEQ scripts to load transform data fix defects like SCD 2 date chaining cleaning up duplicates  Conducted Data blending Data preparation using Alteryx and SQL for Tableau consumption and publishing data sources to Tableau server  Implemented AWS Step Functions to automate and orchestrate the Amazon SageMaker related tasks such as publishing data to S3 training ML model and deploying it for prediction  Integrated Apache Airflow with AWS to monitor multistage ML workflows with the tasks running on Amazon SageMaker  Environment AWS EMR S3 RDS Redshift Lambda Boto3 DynamoDB Amazon SageMaker Apache Spark HBase Apache Kafka HIVE SQOOP Map Reduce Snowflake Apache Pig Python SSRS Tableau  Assessed organization technology infrastructure and managed cloud migration process           Bank Of America Corporation      Data Engineer   Arcadia     CA                   012016      112019     Worked on Azure Data Factory to integrate data of both onprem MY SQL Cassandra and cloud Blob storage Azure SQL DB and applied transformations to load back to Azure Synapse  Managed Configured and scheduled resources across the cluster using Azure Kubernetes Service  Involved in developing data ingestion pipelines on Azure HDInsight Spark cluster using Azure Data Factory and Spark SQL  Develop dashboards and visualizations to help business users analyze data as well as providing data insight to upper management with a focus on Microsoft products like SQL Server Reporting Services SSRS and Power BI  Performed the migration of large data sets to Databricks Spark create and administer cluster load data configure data pipelines loading data from ADLS Gen2 to Databricks using ADF pipelines  Created various pipelines to load the data from Azure data lake into Staging SQLDB and followed by to Azure SQL DB  Worked extensively on Azure data factory including data transformations Integration Runtimes Azure Key Vaults Triggers and migrating data factory pipelines to higher environments using ARM Templates  Ingested data in minibatches and performs RDD transformations on those minibatches of data by using Spark Streaming to perform streaming analytics in Data bricks  Environment Azure SQL DW Databrick Azure Synapse Cosmos DB ADF SSRS Power BI Azure Data lake ARM Azure HDInsight Blob storage Apache Spark           Cumming Llc      Big Data Engineer  Hadoop Developer   Aliso Viejo     CA                   102013      122015   AnsibleDenodoDenodoCloudWatchAvroPySparkPySparkPySparkMLlibDataframeNiFiNiFi  Interacted with business partners Business Analysts and product owner to understand requirements and build scalable distributed data solutions using Hadoop ecosystem  Developed Spark Streaming programs to process near real time data from Kafka and process data with both stateless and state full transformations  Worked with HIVE data warehouse infrastructurecreating tables data distribution by implementing partitioning and bucketing writing and optimizing the HQL queries  Built and implemented automated procedures to split large files into smaller batches of data to facilitate FTP transfer which reduced 60 of execution time  Worked on developing ETL processes Data Stage Open Studio to load data from multiple data sources to HDFS using FLUME and SQOOP and performed structural modifications using Map Reduce HIVE  D eveloping Spark scripts UDFS using both Spark DSL and Spark SQL query for data aggregation querying and writing data back into RDBMS through Sqoop  Written multiple MapReduce Jobs using Java API Pig and Hive for data extraction transformation and aggregationAvrom multiple file formats including Parquet Avro XML JSON CSV ORCFILE and other compressed file formats Codecs like gZip Snappy Lzo  Strong understanding of Partitioning bucketing concepts in Hive and designed both Managed and External tables in Hive to optimize performance  Developed PIG UDFs for manipulating the data according to Business Requirements and also worked on developing custom PIG Loaders  Developing ETL pipelines in and out of data warehouse using combination of Python and Snowflakes SnowSQL Writing SQL queries against Snowflake  Experience in report writing using SQL Server Reporting Services SSRS and creating various types of reports like drill down Parameterized Cascading Conditional Table Matrix Chart and Sub Reports  Used DataStax Spark connector which is used to store the data into Cassandra database or get the data from Cassandra database  Wrote oozie scripts and setting up workflow using Apache Oozie workflow engine for managing and scheduling Hadoop jobs  Worked on implementation of a log producer in Scala that watches for application logs transform incremental log and sends them to a Kafka and Zookeeper based log collection platform  Used Hive to analyze data ingested into HBase by using HiveHBase integration and compute various metrics for reporting on the dashboard  Transformed tPySpark using AWS Glue dynamic frames with PySpark cataloged the transformed the data using Crawlers and scheduled the job and crawler using workflow feature  Worked on installing cluster commissioning  decommissioning of data node name node recovery capacity planning and slots configuration  Developed data pipeline programs with Spark Scala APIs data aggregations with Hive and formatting data JSON for visualization and generatiPySpark     Environment AWS Cassandra PySpark Apache Spark HBase Apache Kafka HIVE SQOOP FLUME Apache oozie Zookeeper ETL UDF Map Reduce Snowflake Apache Pig Python Java SSRS  Onfidential  Developed and implemented Hadoop code while observing coding standards  Optimized and tuned Hadoop environments and modified hardware to meet prescribed performance thresholds  Developed new functions and applications to conduct analyses  Created graphs and charts detailing data analysis results  Tested validated and reformulated models to foster accurate prediction of outcomes           Fiserv      Python Developer    City     STATE                   092012      102013     AWS S3 EC2 LAMBDA EBS IAM Datadog CloudTrail CLI Ansible MySQL Python Git Jenkins DynamoDB Cloud Watch Docker Kubernetes  Leveraged open communication collective decisionmaking and thorough reviews to create performant and scalable systems  Worked with serverside and frontend technologies and leveraged common design patterns to code dynamic and userfriendly systems  Implemented new API routes architected new ORM structures and refactored code to boost application performance  Harnessed version control tools to coordinate project development and individual code submissions  Introduced cloudbased technologies into Python development to expand onpremise deployment options  Wrote clear and clean code for use in projects  Resolved customer issues by establishing workarounds and solutions to debug and create defect fixes|none
Data Engineer|https://www.livecareer.com/resume-search/r/data-analyst-data-engineer-5d0c7b4ff12f4323b51fb55c6284662a|76199997604772823340207052419224154975|Jessica  Claire                             resumesampleexamplecom                      555 4321000                                         100 Montgomery St 10th Floor                                                                                                                                                                                                           Summary       Logical Data Analyst skilled in requirement analysis software development and database management Selfdirected and proactive professional with 35 years of vast experience collecting cleaning and interpreting data sets Natural problemsolver possessing strong crossfunctional understanding of information technology and business processes  Strong knowledge in AWS cloud services like  ECS   EC2  infrastructure  S3  for storage Elastic MapReduce EMR   Athena  as query manager and  CloudWatch   Very well experienced with various visualization tools like  Tableau  by extracting data from various data sources  MasteringLeading in development of applicationstools using  Python  for 3 years  Worked on performance tuning and optimization to improve the efficiency in script executions  Good working experience loading Data Files in  AWS  Environment and Performed SQL Testing on AWS redshift databases  Exceptional ability to research analyze and convey complex technical information to diverse endusers at all levels               Skills         Data Validation  UNIX System  SQL  Python3  BI ToolsTableau Looker Datapoint  Data BasesSqlServer Postgres MYSQl PythonOracle      Amazon Web Services AWS  Servicenow  Jenkins  Pagerduty  Splunk  GIT                     Education and Training       University of Mary HardinBaylor    Belton     TX      Expected in   122017     –      –               Management Information Systems          GPA                    Auroras Technological And Research Institute    UppalIndia           Expected in   082015     –      –       Bachelor of Science        Electrical Electronics And Communications Engineering          GPA                   Certifications       Licensed AWS Solution Architect  2019           Experience       Management Decisions Inc      Data AnalystData Engineer   Reston     VA                   092021      Current     Worked in Banking industry under Risk Management sector to maintain various applications tools data pipelines which have both upstream and downstream applications  Saved at least 7 hoursweek of team effort by automating manual business tasks using python pandas within first 3 months of joining the team  Strong experience in implementing various tables and schemas in Amazon Redshift DB Snowflake DB also worked on migrating various tables from Redshift to Snowflake DB  Organized several empathy sessions with business users and established brand new high impact Tableau dashboards along with improving existing dashboards as per new user requirement which received immaculate user response  Working knowledge of Amazon’s Elastic Cloud Compute EC2 infrastructure for computational tasks Simple Storage Service S3 as storage mechanism  Managed timely flow of business intelligence information to users  Collected tracked and evaluated current business and market trend data  Proven ability to manage all stages of project development Strong Problem solving skills and Analytical skills and abilities to make balanced and independent decisions           Capital One      Data Analyst   City     STATE                   042019      082021     Involved in analysis design and documenting business reports such as Executive summaries Scorecards and drilldown reports  Worked on performance tuning and Query Optimization for increasing the efficiency of scripts  Developed monitored the workflows and responsible for performance tuning of staging and 3NF workflows  Analyzing and profiling data returned for data integrity and business decisions  Responsible for migrating legacy reports to a new platform by rebuilding them to meet current business requirements  Audited internal data and processes to identify and manage initiatives improving business performance  Assisted integration of internal and external data tools and products maintaining stability and performance across systems  Provided technical support for existing reports dashboards or other tools  Maintained or updated business intelligence tools databases or dashboards  Disseminated information regarding tools reports or metadata enhancements  Communicated with customers competitors and suppliers to stay abreast of industry or business trends           Dollar Shave Club      Data AnalystProduction Support Analyst   City     STATE                   052018      032019     Used JIRA Agile methodology extensively to track day to day scrum activities  Writing SQL scripts for selecting the data from servers and modifying data as need with python pandas and stored back to different data base servers Organized and facilitated sprint planning daily standup meetings Scrum of Scrum Sprint review Sprint retrospectives and other Scrumrelated meetings  Writing SQL scripts for selecting the data from servers and modifying data as need with python pandas and stored back to different data base servers Organized and facilitated sprint planning daily standup meetings Scrum of Scrum Sprint review Sprint retrospectives and other Scrumrelated meetings  Manipulating cleansing and processing data using python code and SQL  Troubleshooted Various production failures related to data loads  Responsible for loading extracting and validation of client data Collected data from various databases to SQL server by extensively using Joins and Sub queries in SQL according to requirements of the dev team  Responsible for loading extracting and validation of client data Collected data from various databases to SQL server by extensively using Joins and Sub queries in SQL according to requirements of the dev team  Responsible for loading extracting and validation of client data Collected data from various databases to SQL server by extensively using Joins and Sub queries in SQL according to requirements of the dev team  Initiated daily status email to track the data loads in production environment|none
Data Engineer|https://www.livecareer.com/resume-search/r/sr-data-engineer-architect-898ff76e69d44c7c964261bd55776363|305667889169402374245195369321522535673|Jessica    Claire                                   609 Johnson Ave       49204     Tulsa     OK   100 Montgomery St 10th Floor    Home   555 4321000    Cell       resumesampleexamplecom              Summary      Seasoned Data Architect adept at understanding mandates developing plans and implementing enterprisewide solutions Complex problemsolver with an innovative approach Ready to bring 1Oplus years of progressive experience and take on a challenging new role with growth potential        Skills           Data Management  Organizational Skills  Critical Thinking  Team Management  Problem Resolution  Customer Service      Relationship Building  Team Building  Supervision  Leadership  Planning  Organizing  Friendly Positive Attitude                       Experience       Sr Data Engineer   Architect        082016   to   Current     Honeywell    –    Baltimore     MD             Used statistical software to analyze and process large data sets  Followed industry innovations and emerging trends through scientific articles conference papers or selfdirected research  Distilled data to devise solutions related to budgeting staffing and marketing decisions  Recommended data analysis tools to address business issues  Provided global thought leadership in analytics solutions to benefit customers  Captured and shared bestpractice knowledge amongst developers community  Cleaned and manipulated raw data  Created graphs and charts detailing data analysis results  Managed performance monitoring and tuning while identifying and repairing issues within database realm  Developed new functions and applications to conduct analyses  Assisted solution providers with definition and implementation of technical and business strategies  Tested validated and reformulated models to foster accurate prediction of outcomes  Contributed to maintaining AzureSQL SQL Sever and DB2 databases in conjunction with data development and software engineering teams  Adept in troubleshooting and identifying current issues and providing effective solutions  Promoted customer success in building and migrating applications software and services on Azure platform  Collaborated with solution architects to define database and analytics engagement strategies for operational territories and key accounts           Sr ETL Developer        012016   to   082016     Millennium Health    –    City     STATE             Assessed code during testing stage to determine potential glitches and bugs  Conferred with project managers and other stakeholders to fully understand software design specifications and plan optimal development approaches  Employed integrated development environments IDEs  Devised automation backup and recovery protocols to preserve and safeguard data  Analyzed user needs and software requirements to determine design feasibility  Collaborated with support team to assist client stakeholders with emergent technical issues and develop effective solutions  Applied security measures into systems development supporting final products resistance to intrusion and exploitation  Designed customized technical solutions to meet functional specifications outlined by Millennium Health database customers  Worked closely with systems analysts engineers and programmers to understand limitations develop capabilities and resolve software problems  Collaborated with Architects to define data extraction methodologies and data source tracking protocols  Utilized established design patterns to expedite novel software creation and support consistent performance results  Integrated objectoriented design and development techniques into projects to support usability goals  Analyzed code and corrected errors to optimize output  Identified opportunities for process improvements to decrease in support calls  Defined and documented SSIS ETL data mapping plans using Windows PowerShell scripting and custom solution from vendors ie Pragmatic Works  Resolved customer issues by establishing workarounds and solutions to debug and create defect fixes  Programmed applications and tools using objectoriented languages with goals of code abstraction stability and reuse  Assisted in User Acceptance Testing for Millennium customers verifying ETL jobs complied with assigned parameters achieving success during execution phases  Combined rootlevel authentication and authorization technologies with ongoing system design to harden finished solutions  Applied prescribed policies to programming syntax in compliance with internal language policies  Modified existing software to correct errors adapt to newly implemented hardware or upgrade interfaces  Leveraged Agile methodologies to move development lifecycle rapidly through initial prototyping to enterprisequality testing and final implementation  Developed software for embedded systems coding solutions for both new installations and insitu hardware  Performed troubleshooting of postrelease software faults to support live service and installed software patch design  Developed requirements for system modifications and new system installations  Recommended improvements to facilitate team and project workflow  Coordinated testing and validation procedures through software development lifecycle  Managed endtoend operations of ETL data pipelines maintaining uptime of 96  Improved and corrected existing software and system applications  Applied Conceptual Logical and Physical  DimensionalRelational model designs to ETL tasks           Sr Database App   BI Developer       052013   to   102015     TransCanada Corporation    –    City     STATE             Analyzed and developed technical and functional specifications for databases  Developed and updated all documentation related to database technologies for department  Built integrations from multiple data sources including Salesforce and Pardot  Identified databases not reaching peak performance and determined ways to solve concerns  Applied various skills to evaluate design implement and optimize databases and database applications  Managed financial management systems customer and production databases and inventory production equipment and editing systems  Provided support to clients in understanding and manipulating data to obtain value through SQL and ETL technical processes and visual analytics tools  Managed all levels of internal analytics practice including ETL database administration report development and integration  Produced complex database project with zero issues due to effective troubleshooting  Developed designed and optimized data structures for analysis  Partnered with project management teams on development of scope and timelines  Assisted clients in understanding and manipulating data to gain value through SQL and ETL technical processes and visual analytics tools  Developed data models and database designs to plan projects  Developed and implemented security initiatives to protect important company data  Constructed database and warehouse streamlined disparate data sources and unverified queries into main source  Wrote scripts and processes for data integration and bug fixes  Planned designed and streamlined data structures for analysis  Supervised all levels of internal analytics practice including ETL database administration report creation and integration  Built database and warehouse including consolidating disparate data sources and unverified queries into central source  Created integrations from various data sources including Salesforce and ERD Systems           Database Application Developer        022011   to   042013     Barclays Plc    –    City     STATE             Modified existing software to correct errors adapt to newly implemented hardware or upgrade interfaces  Utilized established design patterns to expedite novel software creation and support consistent performance results  Employed integrated development environments IDEs  Developed logic flowcharts and diagrams to use in program coding and workflow planning  Developed software for embedded systems coding solutions for both new installations and insitu hardware  Identified opportunities for process improvements to decrease in support calls  Analyzed code and corrected errors to optimize output  Liaised with clients to clarify business challenges and objectives to optimize performance of existing systems  Trained and coached new hires and junior developers and shared insight into ways to meet tight deadlines and improve overall efficiency  Coordinated testing and validation procedures through software development lifecycle  Combined rootlevel authentication and authorization technologies with ongoing system design to harden finished solutions  Identified debugged and fixed system bottlenecks and problems  Resolved customer issues by establishing workarounds and solutions to debug and create defect fixes  Devised automation backup and recovery protocols to preserve and safeguard data  Applied innovative approaches to application design through creative inception and planning  Contributed to requirements gathering and design development meetings  Improved and corrected existing software and system applications  Leveraged Agile methodologies to move development lifecycle rapidly through initial prototyping to enterprisequality testing and final implementation  Assessed code during testing stage to determine potential glitches and bugs  Worked closely with systems analysts engineers and programmers to understand limitations develop capabilities and resolve software problems  Conferred with project managers and other stakeholders to fully understand software design specifications and plan optimal development approaches  Applied prescribed policies to programming syntax in compliance with internal language policies  Recommended strategies to maximize performance and lifespan of equipment involved in software installations  Developed requirements for system modifications and new system installations  Performed testing on user defined functions and triggers  Utilized best practices to identify and remedy bugs in applications within specific timeframe  Recommended improvements to facilitate team and project workflow  Optimized application process flow to improve performance  Programmed applications and tools using objectoriented languages with goals of code abstraction stability and reuse  Updated software upon release of vendor patches to mitigate vulnerabilities  Monitored equipment function to verify conformance with specifications  Analyzed user needs and software requirements to determine design feasibility  Applied application product support to contractors located internationally  Worked closely with brand and marketing teams across organizations to promote specific applications  Increased efficiency through task automation  Applied security measures into systems development supporting final products resistance to intrusion and exploitation  Assessed project scope to identify necessary requirements  Established clear system performance standards and wrote specifications  Collaborated with support team to assist client stakeholders with emergent technical issues and develop effective solutions  Integrated objectoriented design and development techniques into projects to support usability goals  Reviewed project requirements to identify customer expectations and resources needed to meet goals  Performed troubleshooting of postrelease software faults to support live service and installed software patch design          Education and Training       Bachelor of Science     Electrical Electronics Engineering     Expected in   072006     University Of Leicester      Leicestershire England           GPA               Accomplishments       Led team to achieve overhaul and enhancement of our Operational Data Store as well as upgrade to our Cognos Application earning recognition from upper management and financial reward  Negotiated with vendors saving company over US1M annually  Improved delivery of Data for data driven decisions by modernizing our applicationsystems realizing overall increase in customer satisfaction and cost efficiency         Activities and Honors       Member Alumni Association         Certifications       Certified Microsoft ProfessionalSQL Server 2008R2  2010  Certified Microsoft Azure Data Engineer  2020  Certified Microsoft Azure Architect  2020|none
Data Engineer|https://www.livecareer.com/resume-search/r/aws-data-engineer-5cc9299938587076e54cae645ae21ec1|83985006356839563643115453489150250520|Jessica    Claire                                 609 Johnson Ave       49204     Tulsa     OK   100 Montgomery St 10th Floor   Home   555 4321000        Cell           resumesampleexamplecom                  Summary       Dynamic and motivated IT professional with around 7 years of experience as a Big Data Engineer with expertise in designing data intensive applications using Hadoop Ecosystem  Big Data Analytical  Cloud Data engineering  Data Warehouse  Data Mart Data Visualization  Reporting  and Data Quality solutions   In  depth knowledge of Hadoop architecture and its components like YARN  HDFS Name Node Data Node Job Tracker Application Master Resource Manager  Task Tracker and Map Reduce programming paradigm  Extensive experience in Hadoop led development of enterprise level solutions utilizing Hadoop components such as Apache Spark MapReduce HDFS Sqoop PIG Hive HBase Oozie Flume NiFi Kafka Zookeeper and YARN  Profound experience in performing Data Ingestion Data Processing Transformations enrichment and aggregations  Strong Knowledge on Architecture of Distributed systems and Parallel processing Indepth understanding of MapReduce programming paradigm and Spark execution framework  Experienced with the Spark improving the performance and optimization of the existing algorithms in Hadoop using Spark Context  SparkSQL  Dataframe API  Spark Streaming MLlib  Pair RDD s and worked explicitly on PySpark and Scala   Handled ingestion of data from different data sources into HDFS using Sqoop Flume and perform transformations using Hive Map Reduce and then loading data into HDFS  Managed Sqoop jobs with incremental load to populate HIVE external tables Experience in importing streaming data into HDFS using Flume sources and Flume sinks and transforming the data using Flume interceptors  Experience in Oozie and workflow scheduler to manage Hadoop jobs by Direct Acyclic Graph  DAG  of actions with control flows  Implemented the security requirements for Hadoop and integrating with Kerberos authentication infrastructure KDC server setup creating realm domain managing  Experience of Partitions bucketing concepts in Hive and designed both Managed and External tables in Hive to optimize performance   Experience with different file formats like Avro  parquet  ORC  Json and XML   Expertise in Creating Debugging Scheduling and Monitoring jobs using Airflow and Oozie  Experienced with using most common Operators in Airflow  Python Operator Bash Operator Google Cloud Storage Download Operator Google Cloud Storage Object Sensor  Handson experience in handling database issues and connections with SQL and NoSQL databases such as MongoDB  HBase  Cassandra  SQL server  and PostgreSQL   Created Java apps to handle data in MongoDB and HBase Used Phoenix to create SQL layer on HBase  Experience in designing and creating RDBMS Tables Views User Created Data Types Indexes Stored Procedures Cursors Triggers and Transactions  Expert in designing ETL data flows using creating mappingsworkflows to extract data from SQL Server and Data Migration and Transformation from OracleAccessExcel Sheets using SQL Server SSIS   Expert in designing Parallel jobs using various stages like Join Merge Lookup remove duplicates Filter Dataset Lookup file set Complex flat file Modify Aggregator XML  Handson experience with Amazon EC2 Amazon S3 Amazon RDS VPC IAM Amazon Elastic Load Balancing Auto Scaling CloudWatch SNS SES SQS Lambda EMR and other services of the AWS family  Created and configured new batch job in Denodo scheduler with email notification capabilities and Implemented Cluster setting for multiple Denodo node and created load balance for improving performance activity  Instantiated created and maintained CICD continuous integration  deployment pipelines and apply automation to environments and applications  Worked on various automation tools like GIT Terraform Ansible Experienced in fact dimensional modeling  Star schema Snowflake schema  transactional modeling and SCD Slowly changing dimension  Experienced with JSON based RESTful web services and XMLQML based SOAP web services and also worked on various applications using python integrated IDEs like Sublime Text and PyCharm   Efficient Cloud Engineer with years of experience assembling cloud infrastructure Utilizes strong managerial skills by negotiating with vendors and coordinating tasks with other IT team members Implements best practices to create cloud functions applications and databases         Skills          ·  Big Data Technologies  Hadoop MapReduce HDFS Sqoop PIG Hive HBase Oozie Flume NiFi Kafka Zookeeper Yarn Apache Spark Mahout Sparklib  ·  Databases  Oracle MySQL SQL Server MongoDB Cassandra DynamoDB PostgreSQL Teradata Cosmos  ·  Programming  Python PySpark Scala Java C C Shell script Perl script SQL  ·  Cloud Technologies  AWS Microsoft Azure  ·  Frameworks  Django REST framework MVC Hortonworks  ·  Tools  PyCharm Eclipse Visual Studio SQLPlus SQL Developer TOAD SQL Navigator Query Analyzer SQL Server Management Studio SQL Assistance Eclipse Postman  ·  Versioning tools  SVN Git GitHub    ·  Operating Systems  Windows 78XP20082012 Ubuntu Linux MacOS  ·  Network Security  Kerberos  ·  Database Modelling  Dimension Modeling ER Modeling Star Schema Modeling Snowflake Modeling  ·  Monitoring Tool  Apache Airflow  ·  Visualization Reporting  Tableau ggplot2 matplotlib SSRS and Power BI  ·  Machine Learning Techniques  Linear  Logistic Regression Classification and Regression Trees Random Forest Associative rules NLP and Clustering                      Experience      012022   to   022022     AWS Data Engineer      Deloitte    –    Rosslyn     MA             Designed and setup Enterprise Data Lake to provide support for various uses cases including Analytics processing storing and Reporting of voluminous rapidly changing data  Responsible for maintaining quality reference data in source by performing operations such as cleaning transformation and ensuring Integrity in a relational environment by working closely with the stakeholders  solution architect  Designed and developed Security Framework to provide fine grained access to objects in AWS S3 using AWS Lambda DynamoDB  Set up and worked on Kerberos authentication principals to establish secure network communication on cluster and testing of HDFS Hive Pig and MapReduce to access cluster for new users  Performed end toend Architecture  implementation assessment of various AWS services like Amazon EMR Redshift S3  Implemented the machine learning algorithms using python to predict the quantity a user might want to order for a specific item so we can automatically suggest using kinesis firehose and S3 data lake  Used AWS EMR to transform and move large amounts of data into and out of other AWS data stores and databases such as Amazon Simple Storage Service Amazon S3 and Amazon DynamoDB  Used Spark SQL for Scala  amp Python interface that automatically converts RDD case classes to schema RDD  Import the data from different sources like HDFSHBase into Spark RDD and perform computations using PySpark to generate the output response  Creating Lambda functions with Boto3 to deregister unused AMIs in all application regions to reduce the cost for EC2 resources  Importing  exporting database using SQL Server Integrations Services SSIS and Data Transformation Services DTS Packages  Coded Teradata BTEQ scripts to load transform data fix defects like SCD 2 date chaining cleaning up duplicates  Developed reusable framework to be leveraged for future migrations that automates ETL from RDBMS systems to the Data Lake utilizing Spark Data Sources and Hive data objects  Conducted Data blending Data preparation using Alteryx and SQL for Tableau consumption and publishing data sources to Tableau server  Developed Kibana Dashboards based on the Log stash data and Integrated different source and target systems into Elasticsearch for near real time log analysis of monitoring End to End transactions  Implemented AWS Step Functions to automate and orchestrate the Amazon SageMaker related tasks such as publishing data to S3 training ML model and deploying it for prediction  Integrated Apache Airflow with AWS to monitor multistage ML workflows with the tasks running on Amazon SageMaker  Environment AWS EMR S3 RDS Redshift Lambda Boto3 DynamoDB Amazon SageMaker Apache Spark HBase Apache Kafka HIVE SQOOP Map Reduce Snowflake Apache Pig Python SSRS Tableau  Assessed organization technology infrastructure and managed cloud migration process  Configured computing networking and security systems within cloud environment  Implemented cloud policies managed technology requests and maintained service availability          012016   to   112019     Data Engineer      Verizon Communications    –    Irving     TX             Worked on Azure Data Factory to integrate data of both onprem MY SQL Cassandra and cloud Blob storage Azure SQL DB and applied transformations to load back to Azure Synapse  Managed Configured and scheduled resources across the cluster using Azure Kubernetes Service  Monitored Spark cluster using Log Analytics and Ambari Web UI  Transitioned log storage from Cassandra to Azure SQL Datawarehouse and improved the query performance  Involved in developing data ingestion pipelines on Azure HDInsight Spark cluster using Azure Data Factory and Spark SQL  Also Worked with Cosmos DB SQL API and Mongo API  Develop dashboards and visualizations to help business users analyze data as well as providing data insight to upper management with a focus on Microsoft products like SQL Server Reporting Services SSRS and Power BI  Performed the migration of large data sets to Databricks Spark create and administer cluster load data configure data pipelines loading data from ADLS Gen2 to Databricks using ADF pipelines  Created various pipelines to load the data from Azure data lake into Staging SQLDB and followed by to Azure SQL DB  Created Databrick notebooks to streamline and curate the data for various business use cases and also mounted blob storage on Databrick  Utilized Azure Logic Apps to build workflows to schedule and automate batch jobs by integrating apps ADF pipelines and other services like HTTP requests email triggers etc  Worked extensively on Azure data factory including data transformations Integration Runtimes Azure Key Vaults Triggers and migrating data factory pipelines to higher environments using ARM Templates  Ingested data in minibatches and performs RDD transformations on those minibatches of data by using Spark Streaming to perform streaming analytics in Data bricks  Environment Azure SQL DW Databrick Azure Synapse Cosmos DB ADF SSRS Power BI Azure Data lake ARM Azure HDInsight Blob storage Apache Spark  Adept in troubleshooting and identifying current issues and providing effective solutions  Managed performance monitoring and tuning while identifying and repairing issues within database realm  Identified key use cases and associated reference architectures for market segments and industry verticals  Designed surveys opinion polls and assessment tools to collect data  Tested validated and reformulated models to foster accurate prediction of outcomes  Created graphs and charts detailing data analysis results  Recommended data analysis tools to address business issues  Developed new functions and applications to conduct analyses  Cleaned and manipulated raw data  Collaborated with solution architects to define database and analytics engagement strategies for operational territories and key accounts          102013   to   122015     Big Data Engineer  Hadoop Developer      Cumming Llc    –    Boston     MA           AnsibleDenodoDenodoCloudWatchAvroPySparkPySparkPySparkMLlibDataframeNiFiNiFi  Interacted with business partners Business Analysts and product owner to understand requirements and build scalable distributed data solutions using Hadoop ecosystem  Developed Spark Streaming programs to process near real time data from Kafka and process data with both stateless and state full transformations  Worked with HIVE data warehouse infrastructurecreating tables data distribution by implementing partitioning and bucketing writing and optimizing the HQL queries  Built and implemented automated procedures to split large files into smaller batches of data to facilitate FTP transfer which reduced 60 of execution time  Worked on developing ETL processes Data Stage Open Studio to load data from multiple data sources to HDFS using FLUME and SQOOP and performed structural modifications using Map Reduce HIVE  D eveloping Spark scripts UDFS using both Spark DSL and Spark SQL query for data aggregation querying and writing data back into RDBMS through Sqoop  Written multiple MapReduce Jobs using Java API Pig and Hive for data extraction transformation and aggregationAvrom multiple file formats including Parquet Avro XML JSON CSV ORCFILE and other compressed file formats Codecs like gZip Snappy Lzo  Strong understanding of Partitioning bucketing concepts in Hive and designed both Managed and External tables in Hive to optimize performance  Developed PIG UDFs for manipulating the data according to Business Requirements and also worked on developing custom PIG Loaders  Developing ETL pipelines in and out of data warehouse using combination of Python and Snowflakes SnowSQL Writing SQL queries against Snowflake  Experience in report writing using SQL Server Reporting Services SSRS and creating various types of reports like drill down Parameterized Cascading Conditional Table Matrix Chart and Sub Reports  Used DataStax Spark connector which is used to store the data into Cassandra database or get the data from Cassandra database  Wrote oozie scripts and setting up workflow using Apache Oozie workflow engine for managing and scheduling Hadoop jobs  Worked on implementation of a log producer in Scala that watches for application logs transform incremental log and sends them to a Kafka and Zookeeper based log collection platform  Used Hive to analyze data ingested into HBase by using HiveHBase integration and compute various metrics for reporting on the dashboard  Transformed tPySpark using AWS Glue dynamic frames with PySpark cataloged the transformed the data using Crawlers and scheduled the job and crawler using workflow feature  Worked on installing cluster commissioning  decommissioning of data node name node recovery capacity planning and slots configuration  Developed data pipeline programs with Spark Scala APIs data aggregations with Hive and formatting data JSON for visualization and generatiPySpark     Environment AWS Cassandra PySpark Apache Spark HBase Apache Kafka HIVE SQOOP FLUME Apache oozie Zookeeper ETL UDF Map Reduce Snowflake Apache Pig Python Java SSRS  Onfidential  Developed and implemented Hadoop code while observing coding standards  Optimized and tuned Hadoop environments and modified hardware to meet prescribed performance thresholds  Developed new functions and applications to conduct analyses  Created graphs and charts detailing data analysis results  Tested validated and reformulated models to foster accurate prediction of outcomes          092012   to   102013     Python Developer       Fiserv    –    City     STATE             AWS S3 EC2 LAMBDA EBS IAM Datadog CloudTrail CLI Ansible MySQL Python Git Jenkins DynamoDB Cloud Watch Docker Kubernetes  Leveraged open communication collective decisionmaking and thorough reviews to create performant and scalable systems  Worked with serverside and frontend technologies and leveraged common design patterns to code dynamic and userfriendly systems  Implemented new API routes architected new ORM structures and refactored code to boost application performance  Harnessed version control tools to coordinate project development and individual code submissions  Introduced cloudbased technologies into Python development to expand onpremise deployment options  Wrote clear and clean code for use in projects  Resolved customer issues by establishing workarounds and solutions to debug and create defect fixes          Education and Training      Expected in   022022     Post Graduate      Data Engineering      Purdue University      West Lafayette     IN     GPA               Expected in   092021     Post Graduate      Data Science And Business Analytics      University of Texas At Austin      Austin     TX     GPA               Expected in   122009     Bachelor of Arts     Business Administration And Management     Califonia State University       Fullerton CA          GPA|none
Data Engineer|https://www.livecareer.com/resume-search/r/manager-student-and-resident-data-3e141e5ce83341f0b9b1ba584e2a5912|278624286922027916746373616168944850452|Jessica  Claire                             resumesampleexamplecom                      555 4321000                       Montgomery Street     San Francisco     CA      94105                                                                                                                                                                                                             Summary      Management professional seeking a director position  which allows me to utilize my strong administrative and technical experience managerial and interpersonal skills and quality assurance initiatives to maximize efficiency data procurement and customer satisfaction Resultsoriented handson professional with a highly successful record of accomplishments in quality process improvement survey management communications and career development             Key Skills         Continuous Quality Improvement Measures DMAIC  Survey Management  Data Analysis  Database Management      Customer Service  Outcomes Projections  Performance Tracking and Evaluation  Team Building                     Education       Indiana University               Expected in        –      –       Bachelor of Arts        Theater and Drama          GPA            Minor in English  Member Phi Beta Sigma           Accomplishments      Personally facilitated the creation of a new Graduate Medical Education GME Census online data application This included serving as a liaison between the American Medical Association AMA and the Association of American Medical Colleges AAMC creating and testing online technical design and functionality establishing new procedural standards for quality assurance and implementing new marketing constructs  Created all publishing promotional and help manuals for the Census with both an electronic delivery and hardcopy format  Since established in 2002 Census response rates have consistently grown by 20 to their present mark of 98    Spearheaded and supervised the collection monitoring and quality control of GME data from over 8900 US residency programs and 160000 residency training segments This includes personally maintaining multiple Access databases and coordinating and documenting all process flows between multiple departments and organizations Coordinated and participated  in all annual design and development changes of GME Track with the AMA GME Department and any AAMC staff Improved and streamlined processes which coincided with staff reductions of 70 due to reorganizations and departmental reconstructions  Despite losing personnel improved productivity and results by over 60    Directly took over and managed all student data procurement and quality without  increasing staff or resources despite these tasks being formerly held by a separate unit  Led multiple process reviews and implemented new standards which reduced the amount of manual processing by 70    Asked to be on multiple crossdepartmental and creative teams formed to address a variety of issues including departmental skills matrix development contract process improvement organizational strategic planning and various departmental improvement initiatives   Created a departmental electronic forum to capture common questions and encourage process review This forum led to several policy and process adjustments by the data and business divisions        Experience       American Medical Association      Manager Student and Resident Data   City     STATE                   112000      Current     Hired and developed staff on the use of the AMA Graduate Medical Education GME Database AMA physician Masterfile GME Track Online Census and departmental procedures  Provided professional and highly regarded GME Census customer service for all content and technical questions from both external and internal customers  Became the leader for all GMErelated data questions within the Division used consistently by divisional executives  Spearheaded and supervised the collection monitoring and quality control of all GME data  Managed all student data procurement and quality  Served as PC Coordinator providing PC technical and application support participating with rollouts of critical updates and testing new software and services as they applied to the department  Encouraged the AMA to become members of the American Society for Quality ASQ Became the direct contact between the AMA and ASQ facilitating organizational and departmental process improvement and creating crossdivisional teams to address organizational deficiencies and issues  Conducted cost schedule contract performance variance and risk analysis  Offered feedback to executivelevel management on the effectiveness of strategies selling programs and initiatives  Coached and mentored staff members by offering constructive feedback and taking interest in their longterm career growth           American Medical Association      Survey Management Specialist   City     STATE                   091998      112000     Collected and monitored large quantities of GME data from over 8000 residency programs and 100000 residents                                Provided ongoing quality control of all data received through direct use upkeep and modification of Access programming   Created and helped to implement powerful survey applications that serve to track update and collect data as well as insure a high response rate and data accuracy   Participated directly in training all new employees and temporary staff on the GME Database AMA physician Masterfile and departmental procedures   Provided constant customer service through phone support for all survey questions as well as questions regarding GME                   Skills      10 year advanced experience with Customer service Database development and integration Team leadership and Professional Development Survey marketing and creation and MS Access  Concentration on Process Improvement Quality quality assurance quality control Six Sigma and strategic planning|none
Data Engineer|https://www.livecareer.com/resume-search/r/senior-supply-chain-data-analyst-decision-support-3e0fbfae5312436d8a49a103a1f0f10f|258445310291813121195717175915815811692|Jessica    Claire                   Montgomery Street     San Francisco     CA  94105    609 Johnson Ave       49204     Tulsa     OK       Home   555 4321000    Cell       resumesampleexamplecom              Summary     Excellent communication interpersonal intuitive and leadership skills  Experienced in Reporting and Data Analytics  Computer proficient with Windows Excel Access Office Cognos BI Lawson SAP etc  Ability to organize plan and execute various tasks simultaneously  Quick learner with the ability to achieve immediate and longterm goals       Skills           Guest services  Inventory control procedures  Merchandising expertise      Loss prevention  Cash register operations  Product promotions                       Experience       Senior Supply Chain Data AnalystDecision Support       102013   to   Current     Ipsos    –    Cincinnati     OH             Responsible for the development of monthly AdHoc reporting and dashboards focused on Cost Savings Analysis using MS Excel and Access  Work closely with internal customers to create data sets to gain foresight into their business needs  Developed MetricKPI dashboardreports using Excel and Oracle  Develop data models using Access and Excel to provide monthly reporting for business managers within the organization  Provide Financial Analysis to Directors on Large RFPs and Request for Enhancement Projects  Prepared presentations for Directors and Managers to explain monthlyquarterly performance to shareholders           Business Process AnalystEngineering       062011   to   092013     Choptank Transport    –    Allen     TX             Provided analytical support for weeklymonthly reporting using MS Excel and Cognos Report Developer  Assisted engineers process validation  Identified and evaluated improvements in methods procedures and workflow that increase productivity and decrease operating costs  Maintained configuration and assisted in the development of production reporting applications and related interfaces with warehouse management and distribution management systems  Prepared and maintained engineering documentation dealing with distribution center operations material handling or warehouse management issues  Researched and gathered information needed for strategies business case documentation dealing with distribution center operations material handling or warehouse management system issues  Assisted Business Process Engineer regarding new warehousedistribution methods and equipment to improve existing operations and to accommodate new business requirements  Reviewed production schedules and engineering specifications to ensure efficiencies in procedures and activities  Coordinated and maintained quality control objectives and activities to resolve production problems maximize product reliability and minimize cost           Help Desk SupportIntern       072017   to   112017     Waggener Edstrom    –    City     STATE             Microsoft domain model support  PC imaging and deployment  Windows Active Directory 2005 administration  MS Exchange Server 2005 administration  Documented problem resolutions  Supported multi user applications  Provided user training as necessary  TicketIncident tracking  Supported and trained end users  Provided support to end users on software and hardware problems via phones and email           Data AnalystIntern       042017   to   082017     Weyerhaeuser    –    City     STATE             Performed analytical support to the Weyerhaeuser Hardwoods and Industrial products business  This included  Maintained business unit KPIs and prepared supporting analysis and schedules graphs charts and related information  Developed pivot tables access and SQL queries and SOPs           Data Analyst       092017   to   122017     Robert Half Thales Avionics    –    City     STATE             Fulfilled equipment orders for onsite technicians  Maintained onsite inventory of parts by performing physical cycle counts while updating information in SAP system  Created new parts in SAP including part description quantity plant assignment and quality testing information  Assisted QA with the analysis of rejected parts submitted by technicians           Senior CustomerTechnical Support Representative       011   to   112017     Verizon Wireless    –    City     STATE             Handled general inbound call center customers and dealer inquiries concerns and reports in a challenging high callvolume environment  Analyzed billing inquiries process adjustments and enter service orders utilizing online computer systems  Analyzed pricing structures relative to airtime usage and advised customers of the best service plan for their account  Retained and effectively communicated current information regarding all marketplaces serviced by Verizon Wireless  Assisted customers with troubleshooting of all equipment data roaming and enhanced services offered by Verizon Wireless  Served as Tier II and III to representatives assisting customers with equipment data and service area issues           Sales Support Representative       011   to   112017     Airtouch Cellular    –    City     STATE             Processed and fulfilled equipment orders by working directly with Distribution Centers and logistics providers to ensure ontime delivery  Activated new lines of service and implemented all changes on existing accounts requested by agents  Educated agents on current price plans and promotions  Handled commercial and individual accounts with written and verbal price plan analysis  Evaluated and offered special pricing structure to qualified large business accounts  Worked closely with Major Account Executives on account level changes and fulfilling large equipment orders for our large business customers          Education and Training       BS     Information Technology Business Systems Analysis     Expected in   October 2010     University of Phoenix                GPA       Information Technology Business Systems Analysis 32        Skills     Active Directory Ad billing business case Business Process call center charts Cognos hardware delivery documentation email Engineer Financial Analysis graphs imaging inventory logistics Access MS Excel Excel MS Exchange Server Windows Oracle Developer pivot tables presentations pricing quality QA quality control reporting SAP SOP SQL user training phones troubleshooting validation workflow written       Activities and Honors|none
Data Engineer|https://www.livecareer.com/resume-search/r/data-entry-specialist-3e8b2e5124574d3081485139c3bd36f3|6361630242691360309919431676680490692|Jessica    Claire                   Montgomery Street     San Francisco     CA  94105    609 Johnson Ave       49204     Tulsa     OK       H   555 4321000    C       resumesampleexamplecom    Date of Birth         India                      single                    Summary     Highly motivated Sales Associate with extensive customer service and sales experience Outgoing sales professional with track record of driving increased sales improving buying experience and elevating company profile with target market       Skills           Performance driven  10years combined experience in customer service patient services entry processing and scheduling  Microsoft Office  Excel intermediate to advanced Word intermediate Outlook advanced  PowerPoint intermediate  Typing at a speed of 100 wmp 10 key                         Experience       Data Entry Specialist       032016      Present     Elara Caring    –    Harker Heights     TX            Compile sort and verify the accuracy of data before it is entered  Compare data with source documents or reenter data in verification format to detect errors  Store completed documents in appropriate locations  Locate and correct data entry errors or report them to supervisors  Ensures that all invoices are completely entered in a timely and accurate manner  On assigned days all mail is broken down sorted in an accurate efficient and timely manner  Ensures that on assigned days mail is scanned in an accurate efficient and timely manner           Administrative Assistant       112015      022016     Qualtek    –    Pittsburgh     PA            Answer telephones and give information to callers take messages or transfer calls to appropriate individuals  Operate office equipment such as fax machines copiers and phone systems and use computers for spreadsheet word processing database management and other applications  Greet visitors or callers and handle their inquiries or direct them to the appropriate persons according to their needs  Set up and maintain paper and electronic filing systems for records correspondence and other material  Open read route and distribute incoming mail or other materials and answer routine letters  Complete forms in accordance with company procedures  Make copies of correspondence or other printed material  Compose type and distribute meeting notes routine correspondence and reports  Maintain scheduling and event calendars  Schedule and confirm appointments for clients customers or supervisors  Order and dispense supplies  Provide services to customers such as order placement or account information  Coordinate conferences and meetings  Operate electronic mail systems and coordinate the flow of information internally or with other organizations           SchedulerCustomer Service Representative       082015      022016     Eastern Metal Supply    –    Winston     FL            Obtain customers names addresses and billing information product numbers and specifications of items to be purchased and enter this information on order forms  Prepare invoices shipping documents and contracts  Inform customers by mail or telephone of order information such as unit prices shipping dates and any anticipated delays  Receive and respond to customer complaints  Check inventory records to determine availability of requested merchandise  Compute total charges for merchandise or services and shipping charges  Schedule appointments for customers needing repairs on their existing appliances           Receptionist       042015      082015     Laz Parking    –    Westminster     CO            Greet persons entering establishment determine nature and purpose of visit and direct or escort them to specific destinations  Transmit information or documents to customers using computer mail or facsimile machine  Hear and resolve complaints from customers or the public  Provide information about establishment such as location of departments or offices employees within the organization or services provided  Receive payment and record receipts for services  Schedule appointments and maintain and update appointment calendars  Keep a current record of staff members whereabouts and availability  Provide support for sales team in managing operation work flow  Demonstrate proficiency in telephone email fax and front desk reception within a high volume environment  Schedule appointments for appliances being delivered           Customer Service RepresentativeCashier       052014      042015     STOPNGO    –    City     STATE            Receive payment by cash check credit cards vouchers or automatic debits  Issue receipts refunds credits or change due to customers  Assist customers by providing information and resolving their complaints  Establish or identify prices of goods services or admission and tabulate bills using calculators cash registers or optical price scanners  Greet customers entering establishments  Answer customers questions and provide information on procedures or policies  Sell tickets and other items to customers  Process merchandise returns and exchanges  Maintain clean and orderly checkout areas and complete other general cleaning duties such as mopping floors and emptying trash cans  Stock shelves and mark prices on shelves and items  Request information or assistance using paging systems  Count money in cash drawers at the beginning of shifts to ensure that amounts are correct and that there is adequate change  Calculate total payments received during a time period and reconcile this with total sales  Monitor checkout stations to ensure that they have adequate cash available and that they are staffed appropriately  Supervise others and provide onthejob training  Keep periodic balance sheets of amounts and numbers of transactions           PullerProcessor       042013      122013     CTI PAPER    –    City     STATE            Read orders to ascertain catalog numbers sizes colors and quantities of merchandise  Update daily logs for tracking file movements  Obtain customers names addresses and billing information product numbers and specifications of items to be purchased and enter this information on order forms  Check inventory records to determine availability of requested merchandise  Review orders for completeness according to reporting procedures and forward incomplete orders for further processing  Confer with production sales shipping warehouse or common carrier personnel in order to expedite or trace shipments  File copies of orders received or post orders on records  Verify customer and order information for correctness checking it against previously obtained information as necessary  Prepare invoices shipping documents and contracts  Inform customers by mail or telephone of order information such as unit prices shipping dates and any anticipated delays  Compute total charges for merchandise or services and shipping charges           Patient Services AssistantTravel Coordinator       032005      012010     WILLIAM S MIDDLETON VETERANS MEMORIAL HOSPITAL    –    City     STATE            Coordinate communication between patients family members medical staff administrative staff or regulatory agencies  Interview patients or their representatives to identify problems relating to care  Maintain knowledge of community services and resources available to patients  Investigate and direct patient inquiries or complaints to appropriate medical staff members and follow up to ensure satisfactory resolution  Explain policies procedures or services to patients using medical or administrative knowledge  Answer applicants questions about benefits and claim procedures  Interview benefits recipients at specified intervals to certify their eligibility for continuing benefits  Compile record and evaluate personal and financial data in order to verify completeness and accuracy and to determine eligibility status  Utilize knowledge and skills of medical terminology for emergency department check ins admitting dictation records and eligibility  Coordinate admission processes and prepare agreement packets          Education and Training       High School Diploma              Expected in   Jun 1999                MADISON EAST HIGH SCHOOL      MADISON     WI     GPA        Status                  Bachelor of Arts       Business Administration       Expected in   Jun                ASHFORD UNIVERSITY FORBES SCHOOL OF BUSINESS      SAN DIEGO     CA     GPA        Status         Business Administration        Skills     10 key administrative Schedule appointments balance sheets benefits billing calculators cash registers catalog conferences contracts Make copies credit clients customer service data entry database management dictation electronic mail email facsimile machine fax machines fax filing financial forms inventory Prepare invoices Issue receipts letters notes managing mark materials medical terminology meetings Excel mail money Microsoft Office Outlook PowerPoint Word office equipment direct patient personnel phone systems copiers policies processes Read reception repairs reporting sales scanners scheduling shipping spreadsheet take messages telephone telephones Typing type word processing       Activities and Honors|none
Data Engineer|https://www.livecareer.com/resume-search/r/secretary-customer-service-sales-data-base-entry-46df311c156e477c8d7f5406e116de02|147203991935502946470515237354155400269|Jessica    Claire                   Montgomery Street     San Francisco     CA  94105    609 Johnson Ave       49204     Tulsa     OK       Home   555 4321000    Cell       resumesampleexamplecom              Career Overview      Dedicated personable and motivated secretarycustomer service representative My focus is to maintain customer satisfaction and contribute to company success I have extensive work experience in a variety of customer service settings such as hospitals businesses and retail         Core Strengths           Strong organizational skills  Active listening skills  Sharp problem solver  Courteous demeanor  Energetic work attitude  Telephone inquiries specialist  Customer service expert  Invoice processing  Adaptive team player  Openingclosing procedures  Quick learner   Have worked with many business specific computer programs       Data collection  Data entry  Documentation  Email  Internet research  Speaking  Telephone skills  Multitasking                        Accomplishments       Customer Service    Researched calmed and rapidly resolved client conflicts to prevent loss of key accounts    Customer Interface    Greeted customers upon entrance and handled all cash and credit transactions  Assisted customers over the phone regarding store operations product promotions and orders     Database Maintenance    Assisted in the managing of the company database and verified edited and modified customers’ information         Work Experience       SecretaryCustomer ServiceSalesData Base Entry       092012   to   062015     Taco Bell    –    Gravette     AR             Responsible for daily operations and overall finances of a small but busy satellite company which includes but is not limited to billing budgeting customer invoicing through QuickBooks payroll quarterly payroll and company taxes Knowledge in word and excel spreadsheets Created customer accounts revising as necessary  Developed highly empathetic client relationships  Computed accurate sales prices for purchase transactions  Resolved product issues and shared benefits of new technology  Expressed appreciation and invited customers to return  Managed quality communication and customer support for each client  Interacted with customers to followup on shipping statuses and expedited orders  Promptly responded to general inquiries from members staff and clients via mail email and fax  Guaranteed positive customer experiences and resolved customer complaints  Executed outbound calls to existing customer            Manager       2011   to   042012     Smart Cow    –    City     STATE             Managed team of 34 employees  Served as mentor to junior team members  Took necessary steps to meet customer needs and effectively resolve food or service issues  Communicated clearly and positively with employees  Resolved customer complaints in a postive manner  Assisted in important decisions on new products and new employee hire   Quickly and efficiently processed payments and made accurate change  Closely followed standard procedures for safe food preparation assembly and presentation to ensure customer satisfaction  Performed general maintenance duties including mopping floors washing dishes wiping counter tops and emptying traps           SecretaryCNA in MomBaby Unit       082009   to   112011     Exempla Lutheran Medical Center    –    City     STATE              CNA     Took vital signs of mothers and newborns for a floor of up to 20 patients per shift  Took and recorded patients temperature pulse and blood pressure  Performed 24 hr infant testing including PKU hearing and jaundice  Worked as part of team to ensure proper care and safety of myself  and  patient and newborns  Assisted physicians with the circumcision of newborns  Accurately identified patients with patient chart by verbalizing and checking patient bracelet  Cleaned and sterilized instruments and disposed of contaminated supplies     Secretary     Accurately documented all elements of inpatient information discharge instructions and followup care  Managed smooth and effective communication among physicians patients families and staff  Handled incoming and outgoing correspondence including mail email and faxes  Screened telephone calls and inquiries and directed them as appropriate  Devised and maintained office systems to efficiently deal with paper flow  Organized personal and professional calendars and supplied reminders of upcoming meetings and events when necessary  Flexible and trained to fillin as secretary in sister units such as Labor and Delivery  and  NICU  Actively maintained strict confidentiality and safeguarded all patientrelated information with HIPPA knowledge    Well trained in hospital specific computer programs such as Epic and CPN            Educational Background       Obtained Cosmetology License      Cosmetology     Expected in   2012     Empire Beauty School      Arvada     CO     GPA                Obtained CNA License     Nursing     Expected in   2009     Front Range Community College      Denver     CO     GPA                           Expected in   2008     Community College of Denver      Denver     CO     GPA        Completed necessary courses that contributed to nursing career          Obtained high school diploma     Basic     Expected in   2004     Arvada High School      Denver     CO     GPA                Skills       Patientfocused care  Excellent interpersonal skills  Compassionate and trustworthy caregiver  Detailoriented  Effectively interacts with patients and families  Medical terminology  Charting and record keeping|none
Data Engineer|https://www.livecareer.com/resume-search/r/director-of-product-management-data-analytics-45e0a0c33e3e4e7ab0defd656835bdb2|112950596602995969298265417192508380139|Jessica    Claire               Montgomery Street       San Francisco     CA  94105    609 Johnson Ave       49204     Tulsa     OK      Home   555 4321000        Cell           resumesampleexamplecom                  Profile      Experienced Corporate and Software Professional specializing in Data  Analytics Search and Discovery turning data investments into business results I am subject matter expert in Search technologies and Analytics SolrElasticSearch Leading  influencing large teams Reputation for building professional trust by focusing on hearts heads and hands A Polyglot programmerengineer Excellent liaison between the technical and business world and facilitator of progress among various types of people groups and departments Ive been a software engineer consultant presales principal architect manager of IT systems and an academic researcher    ​        Core Qualifications           Excellent communication  Technical Executor  Facilitator of progress  Liaison between business and technical      Idea generator  Team integrator                       Education      Expected in   2016          Disruptive Strategy     Harvard Business School  HBX                GPA         Course on Disruptive Strategy in organizations          Expected in   2016          Credential of Readiness     Harvard Business School  HBX                GPA         Primer on the fundamentals of business through coursework in Business Analytics Economics for Managers and Financial Accounting          Expected in   2007     Master of Science     Computer Science     Georgia Institute of Technology      Atlanta     GA     GPA         National Science Foundation Fellowship Winner  Minors in Finance and Information Security          Expected in   2004     Bachelor of Science     Computer Science     Georgia Institute of Technology      Atlanta     GA     GPA         Graduated with Highest Honors          Professional Experience      112016   to   Current     Director of Product Management Data Analytics      Genesys    –    Salt Lake City     UT            Building software data products for GE  As a director responsible for finding repeatable problems and pain points for GE businesses and productizing the solution to it  Subject Matter Expert in SearchSolrElasticSearch and architecting Analytics Solutions  Hands on building systems and mentoring other team members  Currently leading a product team that is building a revolutionary Data Management and repeatable analytics product that will change how GE build analytic solutions  We are essentially productizing a solution that has been under RD for years  Primary responsibilities include   Designing  Developing products that include search and analytic technologies Solr Elastic Search and Analytics frameworks  Taking research solutions from the RD arm and productizing it for mass use  Helping to build an engineering team around the product  Interfacing with customers to understand their pain point  Translating customer needs to technical requirements for engineering  Leading the engineering team with priorities  Filling gaps technically personally when needed  Marketing  and being the voice of the product   ​​  ​         112015   to   112016     Manager Data Analytics of Industrial IoT      Us Government Other Agencies And Independent Organizations    –    Norfolk     VA            Manager of Data Analytics driving an outcomes based approach to delivering Analytics for Internal GE use cases  This includes architecting and building Search and Analytics solutions SolrElasticSearchSpark Essentially building the Analytics portion of Digital Thread within GE that spans all GE Businesses  Use cases span from Enterprise use cases to Industrial operational analytical use cases Primary outcomes so far   Founded the Repeatabile Analytics Initiative at GE to scale  Over 10 Million in efficiency gains through the deployment of analytics  Championing cross business interactions and knowledge sharing  Over a PetaByte of data  Standardized and championed an approach being studied by other internal groups  Running a team of 12 people          052015   to   112015     Manager Business Architect Search Analytics Industrial Internet IoT Predix Cloud      Verizon Communications    –    Brunswick     GA            Manager and Architect of the GE Data Lake and Predix Platform to serve Industrial Internet use cases and outcomes  Principal solutions architect of GEs Brilliant Factory Initiative guiding platform teams ingestion teams analytics teams and visualization teams to make GE Factories efficient Brilliant Factory outcomes include drive energy efficiency machine health quality manufacturing and process optimization  Very diverse data sources from machine sensor data ERP purchasing data unstructured work order weather data and more Responsibilities include   Find millions in efficiencies in outcomes for GE factories and Internal Sourcing  Play role of Solution Architect for all outcomes identified  Manage client relationships  Manage technical teams to drive implementation of outcomes  Play mentorship role for technical teams          032014   to   052015     Principal Architect Search  Big Data Analytics      Avalon Consulting LLC    –    City     STATE            Director of the Search Practice Solr  ElasticSearch Helping clients turn data investments into business results  Many large implementations and integrations with Hadoop  Wells Fargo Bell Helicopter Fossil and Securian Responsibilities include   Technical Execution of the biggest clients  POC Development  Production Support  Sales Enablement  Project Oversight as Architect  mentoring other team members  Thought Leadership through publications and speaking engagements  Internal Training  Big implementations          052011   to   112014     Senior Search Architect      Turner Broadcasting Systems    –    City     STATE            Architect and engineer for search implementations for all of Turner’s public websites and mobile sitesapps  Architect and Engineer for all TBS and TNT TV show Companion Sync Mobile App backend data publishers Solr and Autonomy IDOL    Responsibilities Include    Design development implementation ongoing support and managing an enhancement roadmap of Search implementations of a fast moving digital business  Internal search consulting resource for many clients CNN NBA TNT TBS Cartoon Network Adult Swim TruTV Golfcom PGAcom SportsIlustratedcom HLN News CNN Money TeamCococom and TheSmokingGuncom     Selected Accomplishments    Revamping the search implementations for wwwnbacom wwwgolfcom wwwcnncom wwwcartoonnetworkcom wwwadultswimcom and many more  Work is currently in progress  First of its kind Companion Sync Mobile App Backend Architect  Team Coco Sync App won an Emmy Award Big Bang Theory Sync App Leverage Sync App Falling Skies Sync App  Implemented first of its kind online video feeds for Fanhattan and other outside online video vendors  Search Implementation for Adult Swim Bump Builders Xbox Video App          072009   to   072012     Visual Analytics Research  Data Visualization  Discovery      Georgia Institute Of Technology    –    City     STATE            University research while pursuing plans to do a PhD Exploring Visual Analytics and Data Visualization of business connections in converging business ecosystems Built a visually interactive platform that allows users such as C levels venture capitalists analysts of any type to make sense of an entire industry or ecosystem of firms whom interactive with each other  This can be useful for competitive intelligence firm research and industry research       Responsibilities Included    Intelligently aggregated open and closed data sources  Mined the data  Architect the platform for the research  Visualized the connections found on an interactive platform for the user to play with    Presented our work at the IEEE VisWeek 2010 Conference and the Broadband Institute Annual Meeting in 2011 as a poster paper    Published in IEEE CGA 2012      Selected Accomplishments    Innovation RD of novel data visualization technology  2 Publications see publication section below  Website httpwwwccgatechedugvuiidotlink           2009   to   072009     Quantitative Investments Analyst      United Parcel Service    –    City     STATE            Analyst supporting the Chief Investments Officer and Portfolio Manager of UPSs Retirement and Pension Fund     Responsibilities Included    Supported investing management portfolio optimization of 17Billion of the UPS Retirement and Pension Fund   Performed quantitative model development due diligence interviewing of investment firms and investment managers  Analyzed return streams   Worked closely with the CIO and Portfolio Manager     Selected Accomplishments      Developed model for portfolio optimization that allowed input of constraints to enable viewing of optimal portfolios in various performance requirement scenarios  Conducted research that led to hiring of 3 investment firms for a 200M investment deal  Performed normality testing time series correlation and regression testing of return streams  Created internal VaR model for Retirement  Pension Plan including GARCH implementation          082008   to   Current     CEO and Founder      Concinnous Solutions    –    City     STATE            Architecting implementing and integrating Enterprise Search and PCI DSS data security implementations into production environments  Security implementations were to meet PCI DSS Compliance  Built and managed an offshore development team    Responsibilities Included    Managed PL  Sales Account Management Technical Architect Managed offshore team Execution and training and Production delivery with critical golive support  Some of the clients and environments include  Costco Wholesale Seattle Helzberg Diamonds Kansas City 1800Flowerscom New York and Presbyterian Health Services Albuquerque     Selected Accomplishments    Rearchitected American Medical Association’s Search Implementation  wwwamaassnorg   Produced a renowned solution and implementation that was referenced at the RSA conference and written about in news articles  Built and mentored an offshore team to produce results required for todays pace of business  Overall facilitated modernizing systems policies and procedures to meet operational and security compliance          032007   to   082008     Professional Services Consultant  Search  Discovery      HPAutonomy    –    City     STATE            Road warrior implementation consultant for Autonomy products       Responsibilities Included    Identified needs architect solutions implemented solutions for clients in need of Data Management in production environments  This position was constantly  Involved in technology integration and QA processes for production environments I also   Frequently prepared documentation and lead training exercises   Environments worked with include Washington Mutual JP Morgan Chase Time Warner Cable and CountryWideBank of America and many more …     Selected Accomplishments    Played major role in facilitating postacquisition integration of company technology for production environments  Performance optimization of production environments  Performed extensive implementations in a wide variety of production environments  Developed integrationimplementation procedures and authored best practices  Worked with technology partners and vendors at client sites to resolve client issues  Learned and broke apart new technology and environments very quickly in very fast paced and high valued consulting engagements          052006   to   072006     Information Technology Specialist      Federal Aviation Administration Intern    –    City     STATE             Selected Accomplishments      Improved efficiency by evaluating and implementing new technologies including VMWare  Installed servers and served as department’s internal webmaster  Facilitated preparations for Capability Maturity Model CMMi certification audit          022005   to   2007     Software Architect      United Parcel Service    –    City     STATE            Architect and developed first of its kind Treasury technologies envisioned by the Director of Treasury for UPS  Its still used around the world among UPS managers today       Responsibilities Included   Designed developed and supported an entire web infrastructure that served to automate UPS’s internal financial treasury process  This functional and analytical web infrastructure did not exist when I was hired and I built it from scratch  Worked closely with executives including the Directory of Treasury of UPS and translated business financial processes and needs to technical application objectives It quickly became a technology used worldwide among UPS  Helped build and technically lead a team of 4 individuals including interns  This solution solved a major manual process business problem and the solution is still in use today around the world among UPS employees    Selected Accomplishments    Gain organization wide efficiencies saving costs and reducing lead time of internal treasury processes facilitating smarter investment decisions  Conducted system training and served as system knowledge expert for financial management users worldwide  Created system recognized nationally as showcase as part of the internal Treasury process  Designed and developed the entire web infrastructure which required being multiple roles including business analyst technical project manager financial application developer database administrator and support engineer    System still in use around the world at UPS today          2005   to   042005     Artificial Intelligence Research Meta Learning      Georgia Institute Of Technology    –    City     STATE            Data Mining through case based reasoning decision trees and info gain attribute evaluation  This was premised research to test the feasibility of developing a new architecture of AI called Asynchronous Reasoning and Learning Used Java’s Weka library Matlab and proprietary software named Sentinel from the Enkia Corporation          Publications        “Visual Analytics for ConvergingBusinessEcosystem Intelligence”  IEEE CGA 2012 httpwwwccgatechedugvuiidotlink   “dotlink360 Visualizing Converging Business Ecosystems for Competitive Intelligence” VisWeek Conference 2010 Salt Lake City Utah October 2010  httpwwwccgatechedugvuiidotlink          Presentations       Explore Hadoop data with Search  Presented at the Chicago Solr Meetup Slides httpwwwslidesharenetLucidImaginationchicagosolrmeetupjune10thexploringhadoopwithsearch  High level Search  Discovery  Presented to business managers Presentation httpprezicomkun08pwxcg2jutmcampaignshareutmmediumcopy            Skills       Language Experience   OctaveMatlab Modeling for Machine Learning Python Java Angularjs nodejs dotNET C C Ruby LispScheme HTML5 PHP ASP VBscript Actionscript XML Perl   Frameworks and Tools   OctaveMatlab Play Framework Twitter Bootstrap Apache Mahout Scikit learn Google App Engine Hibernate SpringMVC JBoss EJBs Weka GATE and Lingpipe Webspinx Web Crawler and more     StorageSearch   Solr Elasticsearch Lucene Autonomy IDOL Cassandra MongoDB Hadoop ecosystem and traditional relational databases and more          Other Accomplishments       The Punchline Comedy Club – Atlanta GA    Standup Comedy Performance   Performed standup comedy twice at the punchline Learned the art of writing comedy and performancedelivery Helpful for professional presentations    Concourse Basketball League – Atlanta GA    Team Captain   Training and learning to lead a team to finally win this league out right  We’ve been a top 4 team to get a first round bye in the playoffs|none
Data Engineer|https://www.livecareer.com/resume-search/r/data-entry-specialist-36e2b426632b41d08cf146119467bc1c|97098914450695563702884660921271152925|Jessica    Claire                   Montgomery Street     San Francisco     CA  94105    609 Johnson Ave       49204     Tulsa     OK       H   555 4321000    C       resumesampleexamplecom    Date of Birth         India                      single                    Professional Summary      Meticulous and detailoriented Executive AssistantOffice Administrator adept at implementing innovative practices and procedures to improve efficiency Organized and implemented an efficient work flow system that resulted in 30 increase in productivity Established good working relationships with students faculty staff and members of the public Selected to assume additional duties as Recording Secretary for committee meetings averaging 20 attendees  Executive Assistant with management experience and exceptional people skills Versed in  communication  and  organization  Desires a challenging role as a teamplayer        Core Qualifications         Microsoft Office Suite Google Docs Datatel Excels in area pf details   Resultsoriented     Proficiency in supervision      Operations management   Clientfocused                       Experience       Data Entry Specialist       092015      102015     Elliot Davis    –    Nashville     TN            Prepared source data for computer entry by compiling and sorting information establishing entry priorities  Processed employee and account source documents by reviewing data for deficiencies resolving discrepancies by using standard procedures or returning incomplete documents to the team leader for resolution  Entered employee and account data by inputting alphabetic and numeric information on keyboard or optical scanner according to screen format  Maintained data entry requirements by following data program techniques and procedures           Executive Assistant       022015      072015     Xl Group    –    Miami     FL            Reviewed and provided comments on the adequacy of documents and took necessary steps to cure any deficiencies       Effectively controlled the release of proprietary and confidential information for general client lists  Represented Administrator through communication both verbal and electronic as well as in person  Extensive planning and preparation of meetings and events  Extensive creation and maintenance of records  Worked in liaison with College Deans offices organize faculty interviews  Organized coordinated and maintained Administrators calendar  Assisted prospective faculty with house hunting trips  Organized and coordinate prospective faculty moves  Arranged meetings with top level administrators  Coordinated travel arrangements for Administrator  Processed Sabbatical applications and various reports Processed faculty overloads and tuition reimbursements applications  Managed use and reconciled Administrators credit cards           Administrative AssistantOffice Administrator       2011      2015     Soriano Tax Services    –    City     STATE              Prepared correspondence accounting and financial documents for analysis  Provided onsite training      Provided tax preparation services represented clients before IRS resolved outstanding tax issues  Responded to inquiries maintain office database and files  Maintained and processed confidential information  Followed up on client inquires  Heavy telephone sales to secure clients           Administrative Secretary Vice President       082008      072011     California State University    –    City     STATE          Full time student at California State University Northridge majoring in Sociology         Office of Vice President       061997      032007     East Los Angeles College    –    City     STATE            Managed the daily operations of the Office of Academic Affairs  Prepared and distributed agendas of various committee meetings  Took transcribed and distributed minutes of various committee meetings  Maintained daily calendarschedule of administrator  Managed communication flow and work flow to administrators office  Established cross training system that improved efficiency of department by 50  Supervised trained clerical staff provided key input on performance evaluations Managed confidential personnel records  Served as official liaison between administrator and campus staff students and members of the public  Initiated coordinated and monitored hiring process for faculty and administrators  Composed correspondences reports presentations Proof read documents reports press releases for accuracy  Provided research support for reports and meetings  Communicated and implemented District policies  Monitored and tracked departments budget expenditures  Managed official travel system processed expense reports and reimbursements  Facilitated website updates on Office of Academic Affairs working in liaison with webmaster          Education       Bachelor of Arts       Sociology       Expected in   2011                California State		College of Behavioral Sciences      Northridge     CA     GPA        Status           Coursework in  Sociology      NonProfit  Humanitarian Work   Assisted in the coordination of fund raising campaigns for Doctors without Borders St Josephs Indian School and Oxfam International         Certifications     EDD Certification 73 words per minute with 98 accuracy Reeswood Secretarial College Certificate in Shorthand 120 wpm Graduated with honors in the program       Interests     Volunteered at Lighthouse for Women and Children a homeless shelter in Oxnard California       Languages     French Basic Spanish Basic       Skills     Academic budget clerical credit client clients data entry database expense reports French fund raising hiring keyboard team leader meetings Microsoft Office Suite Office 98 personnel policies presentations press releases Profit read research sales scanner Secretarial Shorthand sorting Spanish  tax preparation telephone travel arrangements website       Additional Information       Volunteered at Lighthouse for Women and Children a homeless shelter in Oxnard California|none
Data Engineer|https://www.livecareer.com/resume-search/r/data-entry-operator-3586d5320e6848b198a737749a7eba1b|138536846257210096623495337605137733129|Jessica    Claire                   Montgomery Street     San Francisco     CA  94105    609 Johnson Ave       49204     Tulsa     OK       H   555 4321000    C       resumesampleexamplecom    Date of Birth         India                      single                    Professional Summary       Committed and motivated Administrative Assistant with exceptional customer service and decision making skills Strong work ethic professional demeanor and great initiative  Energetic and reliable Office Manager skilled with working with a diverse group of people  Executive Assistant who is skilled at multitasking and maintaining a strong attention to detail Employs professionalism and superior communication skills to meet client and company needs          Areas of Expertise           Word Excel Access Word Perfect  Operations management  Communication   Interpersonal       Time management  Flexible  Works well under pressure  Employee training and development                       Work Experience       Data Entry Operator       032014      082014     Iron Mountain Incorporated    –    Fort Myers     FL            Performed general data entry using SAP Microsoft Excel and Word    Performed a wide variety of secretarial tasks in support of the business   Answered phones and create notifications in the system   Contacted with internal and external customers  Collaborated with other administrative team members human resources and the finance department on special projects and events  Developed and managed thirdtier resolution process to resolve issues originating from the customer retention team           Secretary       2010      2013     Walt Disney Co    –    Auburn Hills     MI            Arranged appointments sales calendars trainings for the sales of department  Maintained the operations sales database  Customized sales reports and sales literature  Verified and logged in deadlines for responding to daily inquiries  Improved communication efficiency as primary liaison between departments clients and vendors           Assistant Manager       2008      2010     Sumitomo Electric Group    –    Mount Prospect     IL            Recruited hired scheduled and motivated a staff of up to 8 people  Adapted in communicating effectively with customers vendors and staff  Reached the monthly goals  Managed the daytoday tactical and longterm strategic activities within the business  Reduced and controlled expenses by improving resource allocation          Education       Associate       Arts       Expected in                   Community College of Philadelphia      Philadelphia     PA     GPA        Status          Arts          Certified with diploma              Expected in   1 2013                Notary Public                GPA        Status                 Professional Affiliations              Languages     English Spanish       Skills      Interpersonal data entry database English Languages Access Microsoft Excel Excel Word sales SAP secretarial Spanish phones Word Perfect|none
Data Engineer|https://www.livecareer.com/resume-search/r/data-entry-customer-service-357f0974fe214cdfad27461bf1b36f96|321556423433782918032074297826301460362|JC     Jessica    Claire                      Montgomery Street       San Francisco     CA    94105             555 4321000                 resumesampleexamplecom                         Summary       Energetic and reliable Retail Sales Associate skilled in highend merchandise environments  Personable and responsible Cashier with 5 years in retail and customer service Solid team player with upbeat positive attitude  Resultsdriven with proven ability to establish rapport with clients  Dedicated Customer Service Representative motivated to maintain customer satisfaction and contribute to company success         Highlights          Problem resolution  Selfstarter  Deadlineoriented  Microsoft Office  Employee training and development  Customer service expert  Openingclosing procedures  Telecommunication skills      Strong organizational skills  Active listening skills  Large cashcheck deposits expert  Energetic work attitude  Top sales performer  Invoice processing  Courteous demeanor  Sharp problem solver                       Experience        072013   to   Current   Data Entry Customer Service    A Duie Pyle Inc         Stoughton     MA           •Performed general clerical duties as needed such as completing forms and reports  •Confered with Assembly Technician Lead and Manager to determine progress of work and to provide order status  •Assembled various components within established assembly time standards while adhering to procedures and set specifications  •Used Method Instructions to assemble equipment  •Inspect parts to ensure that quality standards are maintained  •Provide responsibility for the quality of work  •May cross train to perform other duties on the production lines  •Performs simple calculations  •Clean and maintain work area  •Will be required to wear personal protective equipment relevant to work area            Other duties as needed and assigned           072010   to   062013   Data Entry Clerk    Ferguson         Red Bank     NJ           •Received and scans large stacks of documents with excellent attention to quality  •Scan to file of hard copy job following standard operating procedures  •Inspect finished work for accuracy  •Conscientious and consistent effort to quickly and accurately complete each task andor job is the companys productivity standard  •File records as needed  •Destroy documents as stated within the policy           2010   to   062012   Front Desk ClerkNight Manager    Western Inn         City     STATE           • Process guest registrations including collecting payment   • Complete shift reports   • Respond to guest needs special requests and complaints alert the appropriate manager to potential issues as needed   • Assist customer with making room keys  • Assist customers in various assignments including finding nearby attractions restaurants and etc   • Prepare coffee for guest  • Transmit and receive messages via telephone and fax machine   • Sort and rack incoming messages and mail   • Assist guests with requests and problems related to their stay at the property   •Resolve guest complaints ensuring guest satisfaction  •Maintain complete knowledge of or where to access to following information a all hotel featuresservices hours of operation b all room types numbers layout decor appointments and location c all room rates special packages and promotions d daily house count and expected arrivalsdepartures e room availability status for any given day f scheduled daily group activities  •Pick up count and maintain bank Secure bank at all times  •Read the log book daily and record all pertinent information in the log book  •Process currency exchange and payments to guest accounts  •Process adjustments rebates paid outs and credits as required  •Verified that all checks are closed and closes and logs any open check in the POS Point of Sale system  •Run Room  Tax verifying that all room rates posted  •Verify Cashiers Report to drop log and paperwork  •Record room statistics  •Close POS after all work was balanced  •Run end of day program and close day  •Check that interfaces are up and running  •Run daily Flash Reports and distribute accordingly  •Run morning reports and backup reports and distribute accordingly  •Print express check out folios and distribute  •Sign out and brief relief  •Review Night Audit checklist and verify that all work has been completed  •Restock all printers  •Fill out and deposit payment and corresponding checks  •Review status of assignments and any followup action with oncoming Supervisor  •Document maintenance needs on work orders and submit to ManagerSupervisor             102008   to   2010   Retail Sales Consultant    Sprint         City     STATE           •Provided a total sales solution to the customer regarding their wirelessmobility needs that includes selling the value for Sprints devices accessories and service plans maximizing customer connections saving the customer money personalizing the customer experience protecting their investment  •Delivered an outstanding store experience that improves customer loyalty and strengthens the Sprint Brand  •Met key performance objectives that include sales and customer satisfaction goals  •Made certain accurate customer account setup so they are ready to use when leaving the store  •Identified the right solutions to customer billing technical and or account issues  •Completed all courses in your curriculum path with the required time frame  •Complied with all operational policies and procedures including the Sprint Code of Conduct  •Promote innovation and friendly competition to deliver unparalleled customer experience           112006   to   112008   ExpeditorCashier    Macys         City     STATE           •Assist customers in all aspects of service fulfillment by demonstrating proficient use of proprietary devices and applications proactively create enhanced shopping experiences through the heightened use of tools technology and collaboration  •Determined customer needs based on personal features and other customer preference related factors  •Demonstrated knowledge of store products and services to build sales and minimize returns  •Maintained a professional attitude with sincerity and enthusiasm reflecting Macy’s commitment to our customer – the most important person in our stores  •  POS procedures  •Assisted customers in all aspects of service fulfillment by demonstrating proficient use of proprietary devices and applications proactively create enhanced shopping experiences through the heightened use of tools technology and collaboration  •Recovered shoe sales floor and scan inventory back into stock  •Maintained integrity of shoe inventory by ensuring accuracy of scanning and placement  •Receive and process new merchandise          Education        Expected in   2008   Associates       Network Support System    Everest Institute     Houston     TX      GPA                 Expected in   2006   High School Diploma           United Christian School     Houston     TX      GPA               Accomplishments       Volunteer at Mustang Center teaching English to adults and teens 2010  until        Skills       10Key Account Management Active Learning Calendaring Client Relations Computer Proficiency Coordination Creative Problem Solving Critical Thinking Customer Needs Assessment Customer Service Data Collection Data Entry Documentation Email Executive Management Support Filing Grammar Internet Research Report Transcription Research Scheduling Service Orientation Speaking Spreadsheets Telephone Skills Time Management Travel Arrangements Travel Booking Travel Planning Type 3040 WPM Typing Writing Letters and Memos Lotus Notes Microsoft Excel Microsoft Office Suite Microsoft Outlook Microsoft PowerPoint Microsoft Word Minute Taking MultiTask Management Organizational Skills Prioritization Proofreading Reading ComprehensionCash handlingProfessional and friendly Careful and active listener Multitasking Production Mechanical Assembler Packager Labeling Inventory|none
Data Engineer|https://www.livecareer.com/resume-search/r/data-entry-operator-381caf3c16b649328748d7e6c673a7d8|283692866702135157759709078394118382144|Jessica    Claire                   Montgomery Street     San Francisco     CA  94105    609 Johnson Ave       49204     Tulsa     OK       H   555 4321000    C       resumesampleexamplecom    Date of Birth         India                      single                    Summary      Energetic worker with a broad range of customer service and team leader skills Data Entry specialist adept at developing and maintaining databases Highly skilled at creating effective organizational and filing systems Dynamic Data Analyst trained in an IT environment who goes above and beyond given job responsibilities to achieve superior results and maintain companywide integrity        Highlights           Certified in 10key  Time management  Meticulous attention to detail  Resultsoriented  Selfdirected  Excellent communication skills  Strong problem solver  Filing and data archiving  HIPAA compliance      Advanced MS Office Suite knowledge  Resourceful  Strong interpersonal skills  Pleasant demeanor  Understands grammar  Customer serviceoriented  Advanced clerical knowledge  Critical thinker                       Accomplishments       Data Entry    Preserved an accuracy of 98 during 5 years of employment    Training    Successfully trained staff in all office systems and databases policies and procedures while focusing on minimizing errors and generating superior results    Reporting    Maintained status reports to provide management with updated information for client projects    Administration    Performed administration tasks such as filing developing spreadsheets faxing reports photocopying collateral and scanning documents for externaldepartmental use    Multitasking    Demonstrated proficiencies in telephone email fax and frontdesk reception within highvolume environment   Implementation   Assisted in implementation of new tracking system that resulted in improved patient care    OSHA Compliance    Properly disposed of daily biohazard waste in compliance with federal and local regulations   Documentation   Drafted documents for internal meetings          Experience       Data Entry Operator       082009      Current     Iron Mountain Incorporated    –    Essex Junction     VT            8000 key strokes per hour  Trained staff to operate new environmental health technology  Verified that information in the computer system was uptodate and accurate  Processed confidential medical information  Identified and resolved system and account issues  Developed and created a more effective filing system to accelerate paperwork processing  Trained new employees and explained protocols clearly and efficiently  Provided base level IT support to company personnel  Troubleshot hardware issues and worked with service providers to facilitate repairs           Tutor       032012      062012     Arizona State University    –    Tempe     AZ            Tutored college level students in the fields of reading writing and computers  Routinely met with students regarding inclass issues and learning interruptions to discuss solutions  Performed student background reviews to develop tailored lessons based on student needs  Taught Creative writing to a diverse class of 20 students  Developed and implemented interesting and interactive learning mediums to increase student understanding of course materials           VolunteerMentor       082007      052008     Boys And Girls Club Of Northeast Florida    –    City     STATE            Coordinated after school tutoring hours to help students in need of extra attention  Received high remarks for the creativity of classroom lesson plans and instructional techniques from students parents and faculty  Created and enforced childbased handson curriculum to promote student interest and receptive learning  Designed lesson plans focused on age and levelappropriate material  Developed interesting course plans to meet academic intellectual and social needs of students  Consistently met schedules and deadlines for all illustration projects  Worked alongside the entire development team in an energetic and creative environment          Education       Associate of Arts       Business Administration       Expected in   2014                Florida State College at Jacksonville      Jacksonville     Florida     GPA        Status          360 GPA  Member of Phi Theta Kappa Honor Society  Recipient of 2014 Academic Achievement Award  Coursework in Marketing Public Relations and Business Management           Skills      10Key  Customer Service  Data Entry  Microsoft Office Suite|none
Data Engineer|https://www.livecareer.com/resume-search/r/data-management-services-coordinator-368330306fc74431af7e0137d3706178|189067289296683940487677712533012870883|Jessica    Claire                   Montgomery Street     San Francisco     CA  9XXX5    609 Johnson Ave       49204     Tulsa     OK       Home   555 4321000    Cell       resumesampleexamplecom              Summary     Administrator with over 15 years of professional experience Skilled in all aspects of office administration organization of filing systems use of electronic office equipment handling multiline phone systems reception data entry coordinating with staff scheduling appointments banking and accounts receivable and payable Communication skills demonstrated through verbal and writing abilities client relations marketing expertise customer service skills training new employees and the ability to produce indepth reports and correspondence       Highlights           Confidential Correspondence and Data  Microsoft Excel  Microsoft Word  Microsoft Outlook  Microsoft PowerPoint  Data Entry  Document Creation and Maintenance  Editing and Proofreading  Information Resource  Knowledge of Office Equipment CopierFax  10Key Calculator  Agenda and Event Coordination  Business Correspondence  Client Services  Call Screening  Mail Distribution  Stocking and Supplies  Typing  Data Entry  Billing Processes  Purchasing and Inventory  Payroll and Accounts Administration                         Experience       Data Management Services Coordinator       2009   to   Current     Penguin Random House    –    City     STATE             Performs highly accurate and detailed data entry for end of month invoicing  Performs data entry for business account orders in a timely manner  Responsible for several monthly reports submitted to management   Compiled statistical information for special reports     Organized billing and invoice data     Updated departmental standard operating procedures and database to accurately reflect the current practices       Identified and resolved system and account issues         Crosstrained and provided backup for other data management representatives when needed       Resolved spreadsheet issues and shared benefits of new technology         Interacted with customers to followup on shipping status and expedited orders           Promptly responded to general inquiries from members staff and clients via mail email and fax             Assisted customers in finding outofprint items             Kept abreast of rapidly evolving technology             Provided accurate and appropriate information in response to customer inquiries             Dispersed incoming mail to correct recipients throughout the office               Organized files developed spreadsheets faxed reports and scanned documents               Received and screened a high volume of internal and external communications including email and mail               Created and maintained spreadsheets using advanced Excel functions and calculations to develop reports and lists                  ReceptionistCashier Supervisor       2008   to   2009     Koons Of Westminster    –    City     STATE              Assessed customer needs and responded to questions       Organized register supplies      Worked with customer service to resolve issues        Provided professional and courteous service at all times       Worked overtime shifts during busy periods       Monitored a   team of  78  of professionals    Trained and mentored new cashiers      Hired 34 team members     Managed cashier shifts and breaks       Built and maintained productive relationships with employees       Greeted customers promptly and responded to questions       Documented performance issues       Counted and balanced cashier drawers       Worked in competitive team environment to exceed revenue quotas             OfficeProgram Assistant       2004   to   2008     General Dynamics Information    Technology    –    City     STATE             Maximized productivity by maintaining multiple calendars scheduling meetings tracking expenses and prioritizing phone calls for Program ManagersMaintained office equipment and ordered supplies  Prepared weekly spreadsheets monitoring more than 15 ongoing projectsOversaw status of projects by continually gathering information and followingup with Program Managers  Updated dynamic organizational charts and headcount spreadsheets  Answered multiline telephone system maintained appointment calendar filed personnel records and assisted Program Manager  Performed timely and highly accurate data entry to ensure fastest turnaround possible for end of month invoicing  Developed planned organized and administered policies and procedures for organization to ensure administrative and operational objectives were met  Implemented corrective action plan to solve problems  Established and maintained comprehensive and current record keeping system of activities and operational procedures in business office  Prepared reviewed and submitted reports concerning activities expenses budget government statutes and rulings and other items affecting business and program services  Consulted with staff and others in government business and private organizations to discuss issued coordinate activities and resolve problems  Prepared budget and directed and monitored expenditures of department funds  Directed and conducted studies and research and prepared reports and other publications relating to operational trends and program objectives and accomplishments           Loan Editor       2001   to   2004     BancFirst    –    City     STATE             Verified and examined information and accuracy of loan application and closing documents  Recorded applications for loan and credit loan information and disbursement of funds using computer  Accepted payment on accounts   Filed and maintained loan records    Presented loan and repayment schedule to customer   Calculated reviewed and corrected errors on interest principal payment and closing costs using computer and calculator    Contacted credit bureaus employers and other sources to check applicant credit and personal references    Assembled and compiled documents for closing such as title abstract insurance form loan form and tax receipt   Prepared and typed loan applications closing documents legal documents letters forms government notices and checks using computer    Interviewed loan applicant to obtain personal and financial data and to assist in filling out application    Complied with federal state and company policies procedures and regulations    Debited and credits accounts   Processed negotiable instruments such as checks and vouchers   Evaluated records for accuracy of balanced postings calculations and other records pertaining to business and operating transactions and reconciled and notes discrepancies   Recorded financial transactions and other account information to update and maintain accounting records          Education       Associate     Accounting     Expected in   2007     Ashworth University      Norcross     GA     GPA   GPA 355    Accounting GPA 355        Skills     10Key Calculator accounting administrative Billing budget Business Correspondence calculator charts closing credit Client Data Entry Editing Event Coordination Fax filling Financial forms funds government insurance Inventory invoicing legal documents letters notes meetings Microsoft Excel Mail office Microsoft Outlook Microsoft PowerPoint Microsoft Word Office Equipment Office Management organizational Payroll personnel Copier policies Processes Proofreading publications Purchasing record keeping research scheduling spreadsheets tax telephone phone Typing|none
Data Engineer|https://www.livecareer.com/resume-search/r/data-warehouse-developer-35a285e749a74031816e915414d2ae8b|14259385793885776770164514431890372233|Jessica    Claire                   Montgomery Street     San Francisco     CA  94105    609 Johnson Ave       49204     Tulsa     OK       H   555 4321000    C       resumesampleexamplecom    Date of Birth         India                      single                    Professional Summary       Proactive performancedriven professional with 105  years of experience in IT industry in Investment Banking domain   Proficient in the Integration of various data sources with multiple relational databases like Oracle11g Oracle10g9i Sybase into the staging area Data Warehouse which includes developing PLSQL Procedures Packages Triggers Bulk collections Cursors Views Objects and Performance Tuning of Data Warehouse environment  Data Warehousing ETL experience of using Informatica PowerCenter Client tools  Mapping Designer Repository manager Workflow ManagerMonitor and Server tool Repository Server manager   Proficient in UNIX shell scripting in automation of various processes Hands on experience in server setup to host files to automate the database refresh with help of Perlcgi scripts Developing web page applications using HTML5 CSS3 and Javascript for form validations Also using Ajax and PHP scripting to get back data from Oracle DB     Experience in using Automation Scheduling tools like Autosys and ControlM     Knowledge and hands on in Informatica ETL Tool for loading huge data files     Handson experience across all stages of Software Development Life Cycle SDLC including business requirement analysis data mapping build unit testing systems integration and user acceptance testing     Experience working in OnShoreOffshore Development Models     Strong time management skills in leading multiple projects and deadlines under minimal supervision     Recognized and highly appreciated for consistent success knowledge and flexibility          Areas of Expertise           Windows NTXP2007 UNIX MSDOS  ETL Tools Informatica Power Center 918171 Designer Workflow Manager Workflow Monitor Repository manager and Informatica Server  Databases Oracle 11g10g9i8i Sybase  Languages SQL PLSQL UNIX Shell scripts Perl HTML5 Java Scripting PHP  Scheduling Tools Autosys ControlM                         Work Experience       Data Warehouse Developer       032015      Current     22Nd Century Technologies    –    Bothell     WA            Customer Warehouse Environment CWE is a group in Fidelity focusing on providing analytical data to various business groups  This data helps the business community in increasing the Fidelity business in Retail and Institutional areas  The data constitutes of various customers accumulated from various sources  Major responsibilities include impact analysis support production support activities install planning and help answer business adhoc requests  Role and Responsibilities Providing resolution to the issues raised by users  Monitoring and providing batch support for the daily and monthly batches  Conduct regular meetings to check for weekly and monthly install  Provide month end batch support and provide oncall support  Enhancement of the existing application to provide more functionality  Identify long running process and tune the same  Unix scripts is used to ftp the files from vendor sites update the data files before loading the data using ETLInformatica to process data from various vendors  Used SQLDeveloperToad for creating all types of PLSQL objects like tables Indexes packages triggers sequences and stored procedures  Optimized the existing long running processes to run faster with usage of Bulk Loader Hints and limits on bulk loader Used Explain Plans to analyze long running queries and degree of Parallel to make queries run faster  Create new web applications from HTML5 and CSS  Javascript for form validation Host the web applications on windows server 2012 R2 machine Used PHP as the server side language to psftp the files from users machine  Call oracle client functions ODBC to connect to db and get back the results on HTML forms           ETLData Warehouse Developer       072012      032015     22Nd Century Technologies    –    Burkeville     VA            The Strategic Investment Product team works on providing investment plans for individuals investment plan and guidance tool for retailers retirement plans 401k for organizations  The tasks involved as part of this are loading and processing the stocks and mutual fund details from different sources categorize and customize such that retail and individual investors get the accurate details which would help in investments  Role and Responsibilities Understand and analyze requirements follow up with business analysts and subject matter expert team for any clarification if required  DesignReview the Test Cases for Integration testing System testing and User Acceptance testing Unix scripts is used to ftp the files from vendor sites update the data files before loading the data using ETLInformatica to process data from various vendors  From staging area data is processed and modified as per the requirement and then loaded to integration area through stored procedures and ETL Informatica mappings  Use Toad for developing all types of PLSQL objects like tables Indexes packages triggers sequences and stored procedures  Developed and modified Oracle packages stored procedures functions Scripts synonyms tables and indexes to implement business requirements and rules  Applied optimizer hints to tune the queries for faster performance  Worked on Performance tuning by using Explain plans and various hints  Worked on Table Partitioning and deploying various methods of indexing like local Indexes and Global Indexes on partitioned tables  Organize and analyze the behavior of each Investment Instrument like Stocks Bonds etc for a certain period and provide the complete detailed analysis to investors which would help them in planning their portfolio and the investments  Evaluate the performance of different funds which would be ideal for long term investing which is the primary requirement of a retirement plan 401k aimed at institutions  Project Title PARA reporting for an Investment Bank           Data Warehouse Developer       2009      062012     22Nd Century Technologies    –    Columbia     MO            Location Bangalore Tokyo and NY Description The department division deals in reporting profit and loss to back to the central system  It also involves doing the daily adjustments and sending the feed to different streams which will do further processing at their end  The data involved capital markets data like Securities Bonds Funds Repos etc  Role and Responsibilities Handling all user support requests from across the regions APAC UK  USA  Automating frequent process with shell scripting and Autosys scheduler  Handling major UATs independently  representing client from offshore office  Responsible for all Production Release across regions  Generate reports required by Japanese and US Federal Gov  Developed and modified Packages Functions Synonyms tables and indexes to implement business requirements and rules  Bulk loading of data done using utilities like BCP and Sybase Central  Code tuning or Query Optimization done using Explain Plans Hints  Analyzing and monitoring system performances using DBCC Trace on commands query plan outputs system  Handling various enhancements to the system this entailed writing new codes and changing some existing codes  Wrote new complex stored procedures in Sybase and optimized the existing code written in Sybase  Debugging the scripts and jobs in Production environment written in Shell and PERL  Handling and creating various Autosys jobs in Production environment  Providing daily status reports to the clients  Provided production support and 247 support for resolving the critical production issues  Involved in the solving the tickets that are raised by the end users  Responsible for creating PLSQL Programs and UNIX Scripts for Data Validation and Data Conversion  Project Title Basel 2 Risk Platform UK based bank           Data Warehouse Developer       012006      112008     Royal Bank Of Scotland    –    City     STATE            Location Bangalore Description FMIT is a dedicated IT division within RBS and we provide a fully managed service for Finance IT Business As Usual BAU team  Designed the tables indexes triggers stored procedures functions and packages to implement the requirement  Unix scripts is used to ftp the files from vendor sites update the data files before loading the data using ETLInformatica to process data from various vendors  Informatica Mappings are used in loading the target databases which is usually on different schema and the data is transformed in the process before loading to target  Analysis of Source data Oracle Source Objects and identifying the methods for loading data to target  Created and used External Tables for migrating flat file data into target  Responsible for the creation of Packages Functions and Procedures  Performed Testing of the Packages Procedures and Functions  Wrote scripts for creating tables Indexes Grants and Synonyms in different schemas and made modifications for the existing tables as per business logic  Preparation of test scripts for System and Integration Testing and Traceability Matrix for the assurance of complete coverage of system requirements  Develop bug fixes and enhancements  Production support of some of the applications of the bank which includes resolving issues of the overnight batch processes and daily users queries          Education       Bachelors       Telecommunication       Expected in   2005                VTU                GPA        Status         Telecommunication        Professional Affiliations              Skills     Bonds capital markets CSS client clients Data Conversion Data Validation Databases Debugging ETL Finance forms ftp Funds Grants HTML HTML5 PHP indexing Informatica investments Japanese Javascript Java Scripting logic meetings office Windows NT works MSDOS ODBC Operating Systems Optimization Oracle db Developer PLSQL PLSQL PERL processes profit and loss reporting requirement Retail Scheduling Securities Shell Scripts Shell scripts shell scripting SQL Strategic Sybase Tables user support Toad UNIX Unix scripts utilities validation web applications windows server Workflow written|none
Data Engineer|https://www.livecareer.com/resume-search/r/data-warehouse-data-modeler-business-analyst-332f51ac4f5f47fb9bc32931a9abc7b0|50268375443711598882491696221600115197|JC     Jessica    Claire                      Montgomery Street       San Francisco     CA    94105             555 4321000                 resumesampleexamplecom                         Career Overview      ClientsEmployers Thompson Reuters Health Care Truven Health Analytics Blue CrossBlue Shield Michigan Microsoft Wayne County Michigan         Skill Highlights           Oracle 1110g98i SQL Server MS Access DB2 zOS  Data Warehouse Data Modeling  Erwin 9873 System Architect 8 Kimball and Inmon Methodologies Conceptual Logical Physical Dimensional Data Modeling Star and ExtendedStar Schema MDM Data Mapping  SQLPlus Explain Plan Data Mining SQLLoader OLAP OLTP Job Scheduling Design Data Profiling Data Mapping Data Scrubbing Data Cleansing  BI Business Intelligence     Dimensional Data Modeling Analytics Data Governance MDM Programming Languages  SQL TransactSQL SQLPlus Stored Procedures VBNET CNET  MainFrame COBOL  Environments  Windows SunUltra HPUX Red Hat  Project Management  MS Project MS Office Serena CAPanvalet  Data Warehouse Data ModelerBusiness Analyst Contract Position                       Technical Skills      VBNET CNET NET Application Development Architect  Automation Budget Business Analyst BI Business Intelligence  COBOL Coldfusion CA hardware concept concept development contracts  Data migration Data Mining Data Modeling Data Warehousing  Database development DC Dialog email Erwin Erwin 9 ESRI ESRI ArcSDE ETL GIS Drawing HPUX DB2 PROFS Imaging IMS DB Information Systems J2EE Languages LINUX Macromedia MainFrame Access Access Database Microsoft Access  C Microsoft Excel Microsoft Exchange Microsoft Office Microsoft Project Windows Windows platform Windows NT Microsoft Word  Modeling OLAP OS Oracle Developer OracleSQL Panvalet pricing p Programming Project Management Quality Red Hat Reporting SharePoint Portal Server  Siebel SQLPlus SQL Server SQL SQL Loader Sun System Architect 8 Systems Architecture System Integration Tables TransactSQL  TSO UNIX Shell Scripting UNIX Scripts VBA Microsoft Visual Basic VB         Work Experience        042011   to   082014   Data Warehouse Data ModelerBusiness Analyst    Ait Laboratories         Birmingham     AL            Translates business requirements and models into feasible and acceptable data warehouse designs designs and builds appropriate data repositories and data movements dimensional databases to ensure that business needs are met  Creates database models which serve as blueprints for project engagements of all complexities   Designs and oversees the implementation of data transformation and change processing procedures to ensure that data from multiple sources is aggregated normalized and updated and then published to multiple target environments Interacts with clients while designing internal and external data interfaces to ensure that database development needs are according to client specifications coordinates with clients external data providers and business team to ensure that business model is accurately represented and understood by all relevant parties   Establishes data standards and policies including security and healthcare PHI compliance data modeling systems architecture design and migration system architectures to ensure access to and integrity of data assets   Analyzes changes in on line transactional processing as it affects the data warehouse business processes and external information sources and recommends modifications to improve quality of applications and meet additional requirements   Lead and coordinate activities of data modelers analysts and ETL developers   Develop strategies and parameters to ensure cost effectiveness and system efficiency   Evaluate reusability of current data for additional analysis while maintaining integrity and confidentiality of information conducts data cleaning to rid the system of old unused or duplicate data for better management or quicker access   Develop data warehousing hardware and software platforms and integrates systems to ensure that integration is effective and meets client specifications            102005   to   042011   Business Intelligence    Fidelity National Information Services         Charlotte     NC            Work with Business Units to develop approve and implement new Healthcare Data Warehouse Subject Area Data Models Subject Areas consisting of Claim Membership Provider Lab Pharmacy Medicare Advantage Blue Health Intelligence and Care Management Develop Data Mart Data Models Manage reviews updates versioning and publishing of Data Models Monitor track and report progress   Resolve issues mitigate risks and devise contingency plans Architect and Implement centralized data model repository dramatically increasing data modeling productivity Technology Architecture  Federal Programs Business Unit  Medicare Advantage Systems Coordinate system integration and testing Work with Project Management Application Testing and Application Development to establish project plans resources hours dates issues  risks Assign tasks to developers  Monitor track and report progress Resolve issues troubleshoot testing results mitigate risks and devise contingency plans  Manage development testing implementation and follow up Work with business unit claim and pharmacy vendors to develop and approve problem incident and change request documents into business requirement and solution approach documents Data Modeling  Provider Registration and Credentialing Create data migration plan mapping current state to future state data elements Data Warehouse ArchitectureData Warehouse Modeling            082002   to   082005   Microsoft Software Developer Tools Sales Specialist    Microsoft         City     STATE            Developed strategies to gain adoption of the NET platform in large enterprise accounts   Created and delivered ROI TCO developer tools product feature and licensing presentations to customers   Performed Siebel Sales Data mining and research to qualify leads and prospects  Built 1 million  sales pipeline for each fiscal year   Coordinated Telesales Rep efforts with Microsoft Project Engaged partners to close business develop marketing campaigns and conduct proofofconcept development   Negotiated pricing and terms Created and delivered resellerpartner incentives    Managed technical team to deliver NET Proofofconcepts Architected proofofconcept NET applications with Microsoft staff developers and customers  using Net and C             021996   to   112002   Business Analyst    Wayne County Michigan         City     STATE            Responsible for Microsoft Visual Basic Application Development for County Prosecutors Office and County Sheriff to track warrant requests from all county municipalities including the City of Detroit   Responsible for Microsoft Access Application Development at Human Relations department to track vendor certifications and contracts   Managed Microsoft Visual Basic Application Development for Accounts Payables application to automatically send check requests to the County Treasurer for printing   Managed 20 technicians to collect and assess Y2K impact on over 1000 desktops and printers and 20 servers   Developed Y2K Implementation Plan GIS Architected Designed and Implemented the Countys Geographical Information Systems OracleSQL Server data warehouse  Installed Oracle SQL Server and ESRI ArcSDE  Spatial Data Engine Modeled In Erwin Real Property and Taxbased Data Layers  Converted logical data models to physical created DDL generated tables Developed and executed data migration plans data load processes using SDELoader Access SQL Loader and SQLPlus          Education and Training        Expected in   1998   Bachelors Degree       Computer Science    Wayne State University     Detroit     Michigan      GPA|none
Data Engineer|https://www.livecareer.com/resume-search/r/sql-devloper-dba-data-analyst-3355f0f1c12b4eb9a813a0ab85705db5|186341187280622283409609294755555521868|Jessica    Claire                   Montgomery Street     San Francisco     CA  94105    609 Johnson Ave       49204     Tulsa     OK       Home   555 4321000    Cell       resumesampleexamplecom              Profile       Has a Master’s of Science Degree in Management Information Systems with Business Intelligence Concentration  Has  5  years of experience working as a SQL server Developer SQL DBA and Data Analyst with excellent analytical and problemsolving skills to work with minimal supervision  Strong knowledge and experience of RDBMS like MS SQL Server 2008 R22012 MS Access MySQL and TSQL queries stored procedures   Strong knowledge and experience in Business Intelligence –SSIS SSRS SSAS Power BI  Power Pivot Power Query Power View Power Map and Pivot Table  Experience in Windows server 20082012 Active Directory AdministrationUsers and Computers DNS DHCP  Experience with data analysis and visualization tools like Excel and Tableau          Core Qualifications           Business Intelligence Data Analytics  Database Development Administration  Windows Server Administration  Windows Azure      Data warehouseData Mining  Microsoft Office  Web Design  Amazon Web Services                       Technical Skills       SQL Server MS Access MS Excel MYSQL   SSIS SSAS SSRS Power BI  TSQL VBA MS Access Excel Macros  Tableau      RapidMiner XLMiner Data Mining   HTML CSS WordPress Dreamweaver Photoshop JavaScript         Professional Experience       SQL DevloperDBAData Analyst       092012   to   032015     Market Footwear Fred Lurie Associate Inc    –    City     STATE            Responsibilities   Created ETL packages involving various data sources SQL Server Flat Files Excel source files  etc  using MS SSIS  Developed data quality solution using SQL Server data services DQS as part of ETL  Analyzed data using using SSAS Excel Tableau and Power BI tools for decision making process  Built Self Service Business Intelligence  dashboards using Power BI tools in Excel  Wrote TSQL queries  for data Analysis and Reporting  Developed reports using MS SQL Server Reporting Services SSRS and Excel  Helped decision makers to understand data on reports and dashboards and gain insights  Installed administered and maintained MS SQL Server 20082012 including upgrades security configuration and service packs   Designed implemented and maintained SQL Server databases   Designed and implemented tables views functions stored procedures and triggers in SQL Server  Planned and implemented SQL Server Security and database permissions   Performed  Database Performance Analysis and Tuning using Database Engine Tuning Advisor SQL Server Profiler and SQL Server Extended Events  Setup HighAvailability as part Disaster Recovery Strategy for the SQL server 2012 databases Failover Clustering Database Mirroring Log Shipping and Replication             SQL Server developerDBA       072009   to   082012     Cifra Systems    –    City     STATE             Responsibilities    As a midlevel DBA Installed configured administered and secured SQL servers 20082008 R2   Created and optimize database objects eg Tables Views indexes cursors stored procedures functions and Triggers   Scheduled and automated maintenance plans using SQL Server Job Agent   Scheduled and automated fulldifferentialtransactional backups and implemented recovery strategies   Configured and monitored database Mirroring Replication and Log Shipping as HADR strategy  Planned and implemented SQL Server Security and database permissions   Extensively used Joins and subqueries for complex queries involving multiple tables  Created indexes clustered and nonclustered  to speed up query performance  Designed Excel dashboard  for tabular and chart reports with drill down  functionality           Web DesignerSQL DBADeveloperMedia Specialist       022005   to   042009     Miami Christians Fellowship    –    City     STATE             Designed desktop database application in MS Access using VBA  Developed financial report using MS Access and Excel  Created website for the organization utilizing HTML WORDPRESS CSS PHP MSSSQL and MYSQL  Performed regular website maintenance and update while also designing graphics for banners flyers and posters  Recorded and edited videos to be distributed in DVD  CD format and upload them to organization’s website  Trained staff members how to utilize computers use software to maintain website and other media support services            Web Developer and Database Support       072003   to   2005     Hotsilhouette Inc    –    City     STATE            Responsibilities   Developed and maintained  companys websites using Dreamweaver HTML CSS ASPNET JavaScript  Designed and managed backend SQL Server databases for web applications  Wrote complex TSQL queries to manipulate  data  Designed and edited graphics and photos for websites using Photoshop     Installed Configured and managed SQL Server and Access databases  Analyzed sales data from different sources and created dashboards using MS Excel  Provided technical computer support to end users          Education       Master of Science     Management Information Systems     Expected in   2015     Nova Southeastern University      Fort Lauderdale     FL     GPA       Concentration Business Intelligence         Associate of Science     Computer Programming and Analysis     Expected in   2003     Miami Dade College      Miami     FL     GPA                Bachelor of Science     Agriculture Plant Science     Expected in   1988     Haremaya University Of Agriculture      Haremaya     Harer     GPA|none
Data Engineer|https://www.livecareer.com/resume-search/r/master-data-administrator-31c35b60e1ac44dca945d5f7ec7c63f5|30676790225757216281363371732283671861|Jessica    Claire               Montgomery Street       San Francisco     CA  94105    609 Johnson Ave       49204     Tulsa     OK      Home   555 4321000        Cell           resumesampleexamplecom                  Career Focus     I am an outofthe box thinker who is actively looking for the opportunity to utilize my analytical and logical skills and to update my knowledgeskills with the latest trends  I am looking to be part of a team that works dynamically towards the growth and stability of the organization and would nurture the growth of career opportunities for long term stability I am currently a Master Data Administrator for a pharmaceutical company and am a JD Edwards Subject Matter Expert SME for the Product Data Management PDM module for the California site  I manage the maintenance of branch items bill of materials routers and work centers in the JDE system     I have worked in a cGMP manufacturing environment for over 12 years with experience in Data Analysis Document Control and Review Process Mapping Deviation Investigations Root Cause Analysis Quality Assurance and Project Management  I have extensive administrative experience ranging from a small sixman office to large corporate settings  My strong technical and organization skills allow me the fJessicability and ability to run various tasks efficiently  I am a highly motivated goal oriented team focused individual who is also detailoriented organized and an extraordinary fast learner who is eager to find new challenges       Summary of Skills           Guest services  Inventory control procedures  Merchandising expertise      Loss prevention  Cash register operations  Product promotions                       Accomplishments              Professional Experience      092008   to   Current     Master Data Administrator      Seneca Foods    –    Janesville     WI             JD Edwards Subject Matter Expert SME for the Product Data Management PDM module for the California site  conduct system troubleshooting user assistance and training investigate resolve and escalate system data issues and respond to inquiries related to master data and provide support on data quality and integrity improvements   Create and maintain item branch plant item information ensuring the integrity of the data for 130 SKUs using JD Edwards MRO raw materials WIP and finished good items  commercial and noncommercial   Create and maintain the bill of material BOM router and work center records ensuring alignment with master batch records continuous assessment through the change control management system of master batch records new and revised to determine JDE impact   Support new product launches and ensure JDE readiness to meet established timelines developed a onestopshop document to eliminate redundant and manual processes   Perform master data audits to ensure proper material attributes are assigned to maintain an adequate flow of raw materials work in process and purchased parts through the site   Revise product standards for yearly budget cycle partner with Manufacturing Packaging and Finance to identify areas in need of change and implement BOMs routers work centers yields scrap   Creation of business process flow diagrams for all products current and new in the pipeline RD and commercial   Active participant in various Kaizen events and OpEX initiatives to identify opportunities to reduce cost and increase throughput   Collaborated with crossfunction team to develop and implement a global process to ensure products marketed global adhere to the international regulatory requirements   Developed a more robust labeling communication process between Central Labeling Group and the Corona site to help facilitate the labeling phasein and phaseout dates implement strategies to minimize inventory obsolescence   Developed PDM site on the company Portal to house various system process maps and user training aids  localized information hub   Create and modify cGMP documentation Standard Operating Procedures SOP training aids and work instructions for PDM processes including item setups BOM and Router maintenance   Perform root cause analysis for deviations write detailed investigations conduct product impact assessments CAPA developmentimplementation and effectiveness checks          092002   to   092008     Administrative Assistant II      Centene Corporation    –    Mobile     AL             Coordinate meetingscalendars for department and multiple MRP II teams including room reservation setup and preparation of meeting materials   Prepare the metrics for monthly scorecard Supplier DeliveryLead Time Materials Management Deviations Fill Rate   Conduct the Weekly Inventory Review meeting  review products under 8 WOS and determine status   Coordination of noncontrolled retention sample destructions determine expiration date coordination with Lab process for destruction   Coordinate training ensuring 100 compliant as the department Training Coordinator ISOtrain entry run various reports to track training requirements and history   Type and track Standard Operating Procedure SOP revisionschange controls for the department and Warehouse utilizing TrackWise maintained 100 for 3year SOP Review Compliance   Maintenance of Department Operating Procedures DOP including implementing distributing course creation track training scheduling training for multiple MRP II teams   Creation research and issuance of ExpireRetest Report for Commercial and RD products   Provide administrative support for the department such as sorting of mail typing Company memosletters and meeting minutes seminar registration preparing of travel arrangements and expense reports ordering supplies and phone messaging          072002   to   092002     Secretary      Wayne Resa    –    Detroit     MI             Coordinate meetingscalendars for department  Coordinate training for department as a Training Coordinator achieved 100 training compliance in 3 months  Ensure department personnel met their training deadlines by scheduling training sessions andor reserving seats  Provide general administrative support for the department such as sorting of mail typing Company memosletters and meeting minutes preparing of travel requestsarrangements and expense reports ordering supplies and phone messaging          2000   to   022002     Administrative Assistant      North Country Academy    –    Castaic     CA             Maintained the input and updating of Engineering data on a regular basis to provide accurate and effective reports   Performed general clerical and administrative functions to support the department such as payroll mail Company memosletters travel requests vacation schedules and phone messaging   Ensured the recording of files and materials for future access and maintenance   Generate reports and data from various sources required to maintain Company functions check data entry and monitor information as determined by Engineering Management   Provide support for marketing and sales drawing requests transferring AutoCAD drawing to PDF files   Ensured the ordering and receipt of materials and supplies for the Department          Education      Expected in   1998     BA     Behavioral Sciences     California State Polytechnic University      Pomona     CA     GPA               Professional Affiliations              Skills     Administrative administrative support Auditing AutoCAD budget Business Process clerical Data Analysis data entry Data Management Delivery documentation ERP Finance drawing hub Inventory Inventory Control JD Edwards JDE letters marketing materials Materials Management meetings messaging access mail Microsoft Office Suite MRP MRP II Packaging payroll PDF PDM personnel processes Project Management quality Quality Assurance recording research Router routers sales scheduling SOP user training phone travel arrangements troubleshooting Type typing Visio|none
Data Engineer|https://www.livecareer.com/resume-search/r/lead-bi-developer-principal-data-analyst-32054a80aded41e18624a6e2cbe7c111|305688115928869989677251199110310744808|Jessica    Claire                                 609 Johnson Ave       49204     Tulsa     OK   100 Montgomery St 10th Floor   Home   555 4321000        Cell           resumesampleexamplecom                  Summary      Proactive BI DeveloperData Analyst with Master’s in Computer Science and 7 years of extensive IT experience in Design Development and Delivering of Business Intelligence solutions in Financial Utilities and Retail industries Extensive experience working with Tableau Desktop Tableau Server in various versions of Tableau in creating highly interactive Data Visualization Reports and Dashboards using complex functionalities Database Design PL Designing Development Integration Implementation and maintenance of Business Intelligence and the related Database Platforms Worked with ETL and ELT process to Extract Transform and Load  Extract Transform and Load data into stage area and data warehouse Deploy the reports and Scheduled Reports for the use of end users and customers on the server Good interaction with clients understanding Business Applications Business Data Flow and Data Relations Good understanding of technical trends architectures and highly motivated to know more about latest technology new software and products Team player with good communication and interpersonal skills Responsible for interacting with business partners to identify information needs and business requirements for reports Ability to handle multiple tasks concurrently and meet the deadlines Talented Analyst with background analyzing competitors synthesizing business intelligence and evaluating trends to enhance business results Forwardthinking and enterprising when meeting expected demands with realtime data and strategic recommendations Natural leader with resourceful and systematic approach        Skills           Tableau Desktop Server Public Online  Reader v 2020x 2019x2018x MS Excel SSRS  Snowflake DB Cassandra MEMsql Oracle 11g10g  9i MS SQL Server 2005  2000 MS Access Postgres Amazon S3      SQL Python  TSQL HTML CSS Java  Microsoft Dynamics Salesforce MS Word MS Excel Outlook FrontPage PowerPoint                       Experience      012019   to   Current     Lead BI Developer Principal Data Analyst      Danaher    –    Coralville     IA             Responsible for the data and Reporting ecosystem for all the Sales and Amazon Connect reports  Gather the report requirements from various stakeholders cross functional departments business users  Build publish customized interactive reports and dashboards report scheduling using Tableau desktopserver  Designed and built critical hierarchy rollup tables for RANKING the associatesterritories based on the performance quality economics customer relations SLA inventory and call metrics  Perform Data Quality checks analysis on the source tables and developed metric tables as per the business definitions  Designed and owned Python framework that automates the addition of new metrics into the reports without manual efforts  Worked with a diverse team on decommissioning projects from Cassandra to Snowflake DB  MEMSQL warehouses  Developed persistent metric layers for the Tableau by coding the metrics in a way to process only the incremental records in the base table to improve the SQL performance and execution time drastically  Worked on internal frameworks to export data to Amazon S3 and create Symphony pipelines to flow data from Amazon S3 buckets to Snowflake Extract Load and Transform  Create metadata and lineage about the table developed classify the sensitivity of data NPI API PCI etc as per the Data risk policies and document all the code process for easy transition to the business teamsData Risk Management and Data Governance  Prepare and update documentations Data Analysis Data Mapping File Business Requirement Description Data Validation etc to ensure all the procedures and knowledge are traceable in future cycles  Analyze complex business problems and issues using data from internal and external sources to provide insight to decisionmakers  Environment Tableau Desktop 2019220183 Tableau server Snowflake DB Cassandra MemSQL Oracle 10g AWS Postgres Excel files Salesforce MS Access          082017   to   012019     BI Consultant  Sr Data Analyst      Iqvia Holdings Inc    –    Fort Wayne     IN             Worked on gathering and converting data over to Tableau using SQLSASExcel data over to Tableau reports and Dashboards  Created metrics attributes filters reports and dashboards created advanced chart types visualizations and complex calculations to manipulate the data Creating New Schedules and checking the tasks daily on the server  Involved in creating adhoc analysis and reporting requests in a timely manner for Business Risk related to fraud Approvals Declines daily monthly and yearly  Created organized customized analysis and visualized projects and dashboards to present to executive leadership  Created Complicated Calculation Based LOD Level of detail feature  Designing and developing data warehouse and Amazon Redshift BI based solutions  Evaluated database performance issues and executed database optimization  Designing and developing prototyping the various dashboards using TableauDesktop  Extensively involved in building the dashboards such as creating Extracts refreshing extracts Layout designing worksheet Actions functions connectors Live and Extract Dashboard color coding formatting and report operations sorting filtering Quick Filters Cascading filters context Filters ranking TopN Analysis hierarchies  Worked with clients to better understand their reporting and dashboarding needs and present solutions using a structured Waterfall and Agile project methodology approach          012016   to   072017     Sr Data Analyst      Mantri Inc    –    City     STATE             Interpret data from primary and secondary sources using statistical techniques and provide ongoing reports  Compile and validate data reinforce and maintain compliance with corporate standards  Develop and initiate more efficient data collection procedures  Build publish customized interactive reports and dashboards report scheduling using Tableau desktopserver  Mastered the ability to design and deploy rich Graphic visualizations with Drill Down and Drop down menu option and Parameterized using Tableau          032013   to   072014     Data Analyst      Rise Technologies    –    City     STATE             Used SAS Data Integration Studio to develop various job processes for extracting cleansing transforming integrating and loading data into Data marts and Data warehouse database  CreationModification of Data Sets on the Remote Server using SASBASE and Macros  Prepared graphs using the modified data for business analysis  Coordinating the production of monthly quarterly and annual performance reports for senior management  Extensively used SAS Macro facility to provide reusable programs that can be conveniently used to update reports and to run weekly and monthly reportsShell scriptings  Prepared documentation for end users  Trained Power users and Business users on building their skills to assist in the development and testing of new reports          Education and Training      Expected in   122015     Master’s     Computer Science                     GPA       GPA 36        Expected in   052013     Bachelor of Technology     Electronics and Communication Engineering                     GPA       GPA 33        Certifications       Certified BASE SAS DEVELOPER ADOBE EXPERIENCE MANAGER DEVELOPER|none
Data Engineer|https://www.livecareer.com/resume-search/r/data-imaging-quality-coordinator-304c14d8e353455fa2fab6359acd65f3|150381217013943721721188659402167996802|Jessica  Claire                             resumesampleexamplecom                      555 4321000                       Montgomery Street     San Francisco     CA      94105                                                                                                                                                                                                             Professional Summary       Dependable Flexible Detailed Organized Ensures Confidentially Excellent MultiTasking Skills Great Leadership Quick Learner QuickThinker and Works Independently             Core Qualifications         Chart Audit Tracking Microsoft Word Cardiac IMS PowerPoint Crystal Reports Powerscan Data ManagerSuperuser Provation Eclipses Radnet EpicSuperuser Secure Vision Invision Patient Care Softdent Medquest Streamline HealthSuperuser Microsoft Excel                       Education       Colorado Technical University Online    Colorado Springs     Co      Expected in        –      –       Bachelor of Science        Science of Information Services and Technology Business          GPA             Colorado Technical University Online	Colorado Springs Co Bachelor of Science Science of Information Services and Technology GPA GPA 336 Cumulative GPA 336 Coursework completed Academic and Career Success Algebra for Business American Government and Public Affairs Anatomy and Physiology Essentials Career Planning and Management Composition and Critical Thinking Computer and Information Technology Environmental Science and Sustainability Fundamentals of Reimbursement in Healthcare Introduction into College Math Introduction into Healthcare Systems Management Fundamentals Medical Terminology Software Applications in Healthcare           Colorado Technical University Online               Expected in        –      –       Associate of Science                  GPA           Colorado Technical University Online	Colorado Spring CO Associate of Science Healthcare Healthcare Administration Services April 1 2014 to present Healthcare Healthcare Administration Services        Certifications                Experience       Cedars Sinai      Data Imaging  Quality Coordinator   El Segundo     CA                   072006      Current     Aug 2006Present Lead teams by serving as captain Ensures that all turnaround time and record availability goals are met and that the JACHO delinquency never exceeds 50 of AMD Responsible for the Quality and Assurance on all Ers Urgent Care Inpatient Outpatient Surgery Charts and all Miscellous documentation through our Electronic Medical Record systems Assign deficiencies for chart completion using the Electronic Medical Record systemswhen needed Merge patients who have had a duplicate medical record number created using EPIC and Streamline Health when needed Responsible for sending all paper charts to fireproof via EPIC for destruction after the Q and A process is complete Performs monthy audits on employees in my area Assist in creating different document types needed for scanning into Streamline Health Media Manager EPIC and Stream IT client Assists with system and interface testing for all software systems within Health Information Management Communicate issueschangescorrections to our end users and outside vendors to get all issues resolved in a timely manner Maintained a high level of customer satisfaction by providing timely response to issuesconcerns Make recommendations to system and software enhancements Responsible for daily maintenance for the scanners in Health Information Management Department Also responsible for scheduling preventive maintained on the scanners Responsible for running monthly reports for the Management team for productivity statistics Responsible for creating workarounds in the event that a system should go down so that staff can continue to perform their daily duties Participate in staff meetings Attend training sessions to increase knowledge and skills Instruct others in program methods procedures or functions Train or supervise student interns or new staff members           Quinn Group Inc      Health Information Tech II Floater   Hesperia     CA                   042003      072006     May 2003Aug 2006 Responsible for coverage to all areas in the Health Information Management to include Correspondence Assembly and Analysis  Outpatient Clinics Scanning incomplete records and any other duties assigned by the management team Assist in the software installation of Streamline Health           Ascension Health      Health Information Training Specialist   Standish     MI                   072001      042003     Aug 2001May 2003 Responsible for coordinating the training and orientation of all new staff as well as cross train existing staff Periodically collect data on procedural compliance and provide the information to the management team for evaluation Create help me books for each position in our department Provide each new employee with comprehensive on the job training as well as comprehensive training on all computer systems Assist the management team with updating all policy and procedures with thin the department Troubleshoot problems in all areas of responsibility and implement solutions as needed Maintain the highest level of customer service and serve as a role model for all employees complete any other duties assigned by management           Loma Linda University Medical Center      Health Information Tech II   BeaumontHighland Springs     CA                   042001      072001     May 2001Aug 2001 Responsible for the comprehensive medical record services to the outpatient care clinics Responsible for pulling charts daily to fulfill clinic appointments receive create and file all charts using a computerized system Update and create any new charts daily Assist personnel in locating charts pull charts and deliver charts to correspondence for request for records Purge all old charts In addition send them to fireproof file any and all loose attaching in the correct chart also look up medical record numbers for documents missing a medical record number Provide coverage to all other clinics as needed and any other duties assigned to me by management           Nationwide Childrens Hospital      Receptionist II   City     STATE                   092000      042001     Responsible for greeting all external an internal customers directing customers to the correct location Answering phones for requests for records and direct all other calls to the proper area Assist with all release of information to include answering questions from visitors such as attorneys parents insurance companies regarding the correct procedure to obtain medical records Also responsible for signing in and out charts using a computerized system to fulfill request for records ultizlying patient care to determine what type of records that are available Interact with hospital personnel regarding medical records requests Provide backup coverage for correspondence and any other duties assigned to me by management           Nationwide Childrens Hospital      Medical Records Specialist   City     STATE                   011999      092000     Feb 1999Oct 2000 Responsible for the comprehensive medical record service to the outpatient and inpatient care centers Responsible for assembling and analyzing inpatient and outpatient charts for completeness using a computerized system to meet deadlines Enter immunization data online assist any personnel with quality assurance audits and reviews Also enter charges and ICD codes for outpatient clinics also complete any other duties given to me by management           Nationwide Childrens Hospital      Correspondence Clerk   City     STATE                   051994      011999     Jun 1994Feb 1999 Responsible for the comprehensive processing of requests for medical record information to include customer service for all internal and external clients Opening and processing incoming mail verifying authorizations forms faxing and pulling charts obtaining microfiche and old film to complete request for records Preparing letters of response for legal attorneys and insurance companies Copying and faxing records to requesters in emergency situations Identify problems in the daily workflow and take the initiative to resolve the issue          Community Involvement              Skills       Outpatient Scanning Training Audits Documentation Epic Imaging Increase Maintenance Satisfaction Scheduling Statistics Testing Correspondence Receptionist Customer Service Retail Sales Clerk Clients Copying Faxing Incoming Mail Microfiche Workflow Assembly Medical Records Solutions Icd Healthcare Associate Answering Answering Phones Greeting Audit Cardiac Crystal Reports Excel Ims Microsoft Excel Microsoft Word Powerpoint Word File Outpatient Care Environmental Science Geology Public Affairs|none
Data Engineer|https://www.livecareer.com/resume-search/r/director-data-strategy-32247e20852f400f8618bc28c023c18d|12450237558870164188469853008696385489|Jessica    Claire                   Montgomery Street     San Francisco     CA  94105    609 Johnson Ave       49204     Tulsa     OK       Home   555 4321000    Cell       resumesampleexamplecom              Summary      Accomplished Product Manager with a proven track record of indepth Product Marketing leading both Agile and Waterfall development teams     Great Software    Passionate about developing userfriendly products that solve clients needs and generate yearoveryear revenue growth    Product Marketing    Focus on end users and key stakeholders to ensure accurate requirements are identified from the beginning     Team Leadership   Successfully led large and small software development teams with an emphasis on the big picture to ensure ontime and onbudget results          Highlights            Product Development and PLM   Market Research and Analysis   SaaS Cloudbased Solutions Suite  Marketing Strategy      Crossfunctional team leadership  Demand Generation  Strategic Alliances  Sales Enablement                       Accomplishments       Responsible for Aberdeen Data Product suite achieving 90  repeat business  Managed revenue recognition on a 13M book of business   Revenue growth of 28 in XXX9 to 58 in 2010 for Ci Pipeline product line   Certified in Pragmatic Marketing Foundations Focus and Build courses  Excellent of Achievement Award  Qwest Communications  Finalists for DMA Future Product Innovation Award XXX9 for Ci Pipeline  XXX9 Employee of the Year HarteHanks         Experience       Director Data Strategy       022014   to   042016     Yodlee    –    Larkspur     CA             Directed 13M suite of data and analytic products  Collaborated with internal stakeholders on 2M OPS budget and developed processes to assess and grade external vendors  Maintained data and technology landscape of over 2 billion data points  Led crossfunctional teams to unify multiple product offerings aligning to global gotomarket strategy and product vision   260 productivity increase with primary research team for products updates    Supervised teams to improve quality email validation processes and KPIs           Director Client Success       032012   to   022014     C2fo Limited    –    San Francisco     CA             Built and led a team to address client experience and retention problem  Accountable for client support of a growing 13M  book of business  Managed both prepost sales client services and fulfillment  Created new processes and KPIs to track client experience and quality  Achieved a 53 Net Promoter Score NPS score for overall client satisfaction  Granted signing authority set product pricing and contract proposal creation           Content Manager       04XXX8   to   032012     Exos    –    Ann Arbor     MI             Organized product designs achieving doubledigit revenue growth  Collaborated with Sales and Marketing as the product expert to clients  Expanded Ci Technology Database CiTDB product from 250K locations to over 47M ontime and onbudget  Created overall CiTDB data taxonomy structure and product deliverables  Led agile team for quarterly product updates to add clientdriven functionality over several product releases           Senior Account Manager       04XXX5   to   04XXX8     Microdesk    –    Seattle     WA             18M in subscription renewals from four Fortune 500 clients over three years  Leveraged QBRs and MROI studies to ensure ongoing client subscriptions  Expert trainer delivering both onsite and online training sessions for endusers  Recognized single point of contact for client escalations and concerns           Marketing Product Manager       04XXX3   to   10XXX4     Argo Data    –    Richardson     TX             Deployed VoIP enabled product platforms for prepaid enhanced services  Updated internal systems and process for effective reporting to management  Redesigned client invoicing system as well as upgrades to network security  Created several software tools designed specifically to allow better troubleshoot network service issues           Network Operations Manager       10XXX2   to   04XXX3     Albany Charter School Network    –    Fogelsville     PA              Ensured the networks   stability and resolved serviceimpacting issues   Oncall 24x7 and internal and external point of escalation for troubletickets  Achieved 99997 annual network availability and uptime           Director of Service       02XXX1   to   10XXX2     Callipso formerly CNM Networks    –    City     STATE             Managed Customer Support Teams and Wholesale Customer channel  24x7 customer experience and service including invoicing and collections  Improved legacy systems to solve B2B Whole Customer needs  Assisted with several projects for thirdparty partnerships for international call centers tollfree services and international trafficVoIP solutions          Education       Bachelor of Science     Business Management     Expected in        University of Utah      Salt Lake City     Utah     GPA       Business Management        Skills        Disciplines   Product Management Product Marketing PLM MDM Customer Experience Data Visualization Sales Enablement Vendor Management Persona Marketing Quality and CRM    Software    Microsoft Dynamics ERP   Salesforcecom Pardot Tableau MS SQL MS Office Adobe MS Visio MS Sharepoint and HTML              Additional Information       Qualified Docent at USS Midway Museum San Diego CA|none
Data Engineer|https://www.livecareer.com/resume-search/r/data-systems-manager-31466092ce5e455a949a1715be23b7ef|213433970150847599349669535542233950201|Jessica    Claire                   Montgomery Street     San Francisco     CA  94105    609 Johnson Ave       49204     Tulsa     OK       H   555 4321000    C       resumesampleexamplecom    Date of Birth         India                      single                    Objective      To find a position where the skills I have learned over the years can be beneficial to both the company I am working and for myself        Skills         MS Office Suite Genesis 200 MAS 200 Profit 21 Docstar SOS Lauris Online SAMIS Concordia                       Accomplishments     Implemented the transition of an all paper medical records system to an electronic medical records system for 2000 active clients       Experience       Data  Systems Manager       022013      Current     Alakaina Family Of Companies    –    Kirtland AfbAlbuquerque     NM            Provides daily assistance to staff for training guidance reporting capabilities and trouble shooting for the agencies electronic medical record EMR system  Trouble shooting of staff issues and concerns that may arise and hamper their ability to complete paperwork as well as train staff on usage of the EMR system  Act as liaison between organization and Lauris Online Implementation Specialist to customize the EMR system to meet the agencys needs  Make andor arrange for necessary changes to forms and documents to be made per director requests  Determine best practices for obtaining data needed for reporting purposes for directors funders and upper management  Implementation and crossover of medical billing from old paper system to new system including configuration of billing module training of staff working with clearing house to determine payor needs and minimizing rejections from payors  Data uploading to Concorida data system for monthly services  Analyze data for trends to determine missing criteria database concerns or staff completion issues           Executive Assistant       092008      022013     Yodlee    –    Secaucus     NJ            Provided daily administrative assistance to the VP of Clinical Services Assistant VP of Clinical Services Director of Clinical Training and 10 Clinical Program Directors  Position was later changed to Executive Assistant to both the Director of Clinical Services and the Director of Childrens Programs  Routine Duties  Maintain daily calendar for upper management including scheduling meetings conferences and trainings  Provide daily technical support and trouble shooting for staff using the new data system  Reconcile monthly financial reports for program funders  Ensure all clinical staff and vendors are paid in a timely fashion and within the contractual obligations of funders  Maintain staff rosters for HMOs including Medicaid UMBH and Magellan  Provide backup for all departments in the clinical services division  Transcribe psychiatric evaluations performed by staff psychiatrists  Collaborate with planning team members to organize and execute company special events  Facilitated the implementation of the organizations new webbased electronic medical record system including providing training to office personnel writing standard procedures and uncovering and remedying compatibility and user interface issues  Organized trainings for internal clinical staff and external members of the community with renowned speakers           Program Assistant       022008      092008     Community Care Inc    –    Elkhorn     WI            Provided administrative support to 20 licensed clinical staff during the implementation of the new evidencebased Early Childhood Wellness ECW Program funded by the Childrens Services Council of Palm Beach County  Ordered logged and maintained program materials and supplies for initial startup of the ECW program in 10 subsidized daycare centers throughout the county  Organized monthly 2day trainings for all staff  Worked with developers to create Access database for the capturing of client data and outcomes           Customer Service Representative       022004      102007     Guard Insurance Group    –    San Francisco     CA            Distributor of Exxon Mobil Lubricant Provided support to 2000 customers in businesstobusiness distribution of fuel and lubricant products for both commercial and automotive industries  Established and maintained customer relationships resulting in increased customer service and satisfaction  Provided administrative support for outside sales team of six representatives  Increased sales by up to 10 by promoting Product of the Month and new merchandise  Created reports and Excel spreadsheets for use internally as well as by customers  Provided technical support for customers  Collaborated with other departments including Dispatch Credit Warehouse and Delivery to get products to customers accurately and efficiently  Managed orders from the data entry stage to completion of billing process with less than 1 error rate           Loan Processor       082002      112003     District Of Columbia Housing Finance Agency    –    Washington     MN            Teamed with loan originators clients and multiple financial institutions to fulfill first mortgage and refinance loans  Inputted client applications into computer system  Communicated with clients to obtain information and documentation required for loan processing  Worked oneonone with banks to determine the correct programs for the client  Secured loan funding in a timely fashion           Receptionist       081997      012001     Erickson Living    –    Silver Spring     MD            Assisted sales team of 65 licensed agents and brokers in three different offices while working with outside companies and sellers to set up appointments for potential buyers  Operated and routed all incoming calls on multiline switchboard  Managed agents showing calendars  Designed and produced marketing materials for potential clients  Computer input of sales leads property listings and appointments  Maintained customer files including residential and commercial listings contracts and appointment logs          Education and Training       BS       Communications       Expected in                   College of Staten Island      Staten     New York     GPA        Status         Communications        Skills     administrative administrative support agency automotive backup billing conferences contracts Council Credit client clients customer service data entry database Delivery documentation special events fashion financial financial reports forms loan processing Director marketing materials materials medical billing meetings Access database Excel spreadsheets MS Office Suite office 2000 outside sales personnel Profit reporting sales scheduling switchboard technical support Trouble shooting user interface|none
Data Engineer|https://www.livecareer.com/resume-search/r/data-integrity-technician-316cfe0704cc4fd2ac39922050cf602b|142827837106598415747988017219956801397|Jessica  Claire                             resumesampleexamplecom                      555 4321000                            San Francisco     CA      94105                                                                                                                                                                                                             Professional Summary     Enthusiastic RHIT eager to contribute to team success through hard work attention to detail and excellent customer service and organizational skills Motivated to learn grow and excel in ProMedica Health System with over 28 years of experience in various roles ensuring ProMedica’s mission and values           Skills         Microsoft Office  Clerical  Payroll  Training  Scheduling  Research  Data TrackingReporting  Administrative  Administrative support  Attention to detail  Clerical  Critical thinking  Customer Service  Data Management  Databases  Documentation  Fast  Teambuilding  Leadership      Meetings  Mail  Microsoft Office  Office  Multitasking  Payroll  Process improvement  Processes  Protocols  Quality  Reporting  Research  Risk Management  Safety  Scheduling  Spreadsheets  Teamwork  Phone  Transportation  Travel arrangements                     Education       University Of Toledo    Toledo     OH      Expected in   052020     –      –       Bachelor of Science        Health Information Administration          GPA                    Owens Community College               Expected in   052014     –      –       Associate of Applied Science        Health Information Technology Toledo Ohio          GPA                     Work History       YaleNew Haven Health      Data Integrity Technician   Bridgeport     CT                   022016      Current     Health Information Management is an integrated function providing services for ProMedica Provider Acute and Ambulatory Care  HIM is responsible for maintaining secure complete and accessible patient health information  Data Management and integrity function are performed in ensure the integrity of the electronic health record in multiple databases  Master Patient indexMPI maintenance  Verifying interface transactions involving medical record documentation and standardization of health information management processes system wide  Resolve MPI overlay and interface errors impacting patient care  Monitor chart correction work queues and assures timely completion  Coordinates and performs corrections           ProMedica Toledo And Flower Hospitals      Administrative AssistantUnit ClerkNursing AssistantPatient Registration   City     STATE                   041992      012016     Provided Administrative support for the Vice President of Patient Safety  Quality  Provided Administrative support for the Medical Directors and Chairmen of Emergency Medicine  Managed and monitored multiple physicians work calendars and meeting schedules  Receive sort distribute mail with significant amount of confidentiality  Updated spreadsheets and databases to track analyze and report on performance  Performed research to collect and record research and process improvement data  Attend weekly ED Leadership meetings participated in peer interviewing  Welcomed office visitors warmly and alerted staff to arrivals of scheduled appointments  Coordinated travel arrangements including booking airfare hotel and ground transportation  Organized staff meetings take accurate minutes of meeting distribute minutes  Distribute routine correspondence memos reports as directed  Contact for Public Relation to assist in scheduling ED Leadership to address media inquiries  Facilitates resolution of customer inquiries and concerns  Facilitates resolution of Risk Management  Safety events in RL6  Patient Registration in fast paced Emergency Department Level I Trauma Center                 Unit ClerkNursing Assistant duties                                      Monitor EMS phone for incoming patient reports and assign appropriate room assignment and notify health care team  Page out Trauma Stoke alerts as directed  Knowledge of disaster protocols and procedures identify banding and logging all incoming patients during a drill or disaster as well as carry out all other necessary assignments effectively and efficiently from command center  Train new Unit Clerk staff  Arrange volunteer’s schedules and shadowing experience          Work History       ProMedica Health Information Management     Data Integrity Technician   Toledo     OH    022016      Current     Health Information Management is an integrated function providing services for ProMedica Provider Acute and Ambulatory Care  HIM is responsible for maintaining secure complete and accessible patient health information  Data Management and integrity function are performed in ensure the integrity of the electronic health record in multiple databases  Master Patient indexMPI maintenance  Verifying interface transactions involving medical record documentation and standardization of health information management processes system wide  Resolve MPI overlay and interface errors impacting patient care  Monitor chart correction work queues and assures timely completion  Coordinates and performs corrections           ProMedica Toledo and Flower Hospitals     Administrative AssistantUnit ClerkNursing AssistantPatient Registration   Toledo     OH    041992      012016     Provided Administrative support for the Vice President of Patient Safety  Quality  Provided Administrative support for the Medical Directors and Chairmen of Emergency Medicine  Managed and monitored multiple physicians work calendars and meeting schedules  Receive sort distribute mail with significant amount of confidentiality  Updated spreadsheets and databases to track analyze and report on performance  Performed research to collect and record research and process improvement data  Attend weekly ED Leadership meetings participated in peer interviewing  Welcomed office visitors warmly and alerted staff to arrivals of scheduled appointments  Coordinated travel arrangements including booking airfare hotel and ground transportation  Organized staff meetings take accurate minutes of meeting distribute minutes  Distribute routine correspondence memos reports as directed  Contact for Public Relation to assist in scheduling ED Leadership to address media inquiries  Facilitates resolution of customer inquiries and concerns  Facilitates resolution of Risk Management  Safety events in RL6  Patient Registration in fast paced Emergency Department Level I Trauma Center                Unit ClerkNursing Assistant duties                       Monitor EMS phone for incoming patient reports and assign appropriate room assignment and notify health care team  Page out Trauma Stoke alerts as directed  Knowledge of disaster protocols and procedures identify banding and logging all incoming patients during a drill or disaster as well as carry out all other necessary assignments effectively and efficiently from command center  Train new Unit Clerk staff  Arrange volunteer’s schedules and shadowing experience          Accomplishments       Registered Health Information Technician RHIT  Notary Public  American Heart Association BLS  Volunteered for ProMedica Health System at various events which included concerts sporting events Steam plant tours first aid Jeep Fest Botanical Gardens Toledo Public Schools reading mentor         Affiliations       American Health Information Management AssociationAHIMA  Ohio Health Information Management Association OHIMA  Northwest Ohio Health Information Management Association NWOIMA         Skills      Microsoft Office  Clerical  Payroll  Training  Scheduling  Research  Data TrackingReporting  Administrative Administrative support Attention to detail Clerical Critical thinking Customer Service Data Management databases documentation fast Teambuilding Leadership meetings mail Microsoft Office office Multitasking Payroll process improvement processes protocols Quality Reporting Research Risk Management Safety Scheduling spreadsheets Teamwork phone transportation travel arrangements|none
Data Engineer|https://www.livecareer.com/resume-search/r/customer-service-rep-data-entry-specialist-310bd6492d984a508733b5a0867f8181|266817285702702318762050947543698628321|Jessica  Claire                             resumesampleexamplecom                      555 4321000                       Montgomery Street     San Francisco     CA      94105                                                                                                                                                                                                             Summary      Detailoriented human resources professional who excels under tight deadlines while anticipating and averting potential problems by proactively streamlining processes              Skills       Positive employee Advanced Knowledge in all Microsoft officeApplications CRM HICS and Softheon                     Education and Training       University of Arkansas at Monticello    Monticello     Arkansas      Expected in   697     –      –       Bachelor of Science        Psychology          GPA           Psychology          Experience       Community Action Partnership Of San Luis Obispo County      Customer Service RepData Entry Specialist   Delano     CA                   102018      Present     Provide assistance to members andor providers regarding website registration and navigation Document all activities for quality and metrics reporting through the Customer Relationship Management CRM application Research and identify any processing inaccuracies in claim payments and route to the appropriate site operations team for claim adjustment Identify any trends related to incoming or outgoing calls that may provide policy or process improvements to support excellent customer service quality improvement and call reduction Document all activities for quality and metrics reporting through the Customer Relationship Management CRM application Updated activities in CRM including HICS from CMS according to the turnaround times prepare compile and sort documents for data entry check source documents for accuracy store completed documents in designated locations enter data from source documents into prescribed computer database files and forms Troubleshot issues members may have with enrollment eligibility and reinstatement with their healthcare insurances  Update information with members healthcare insurance and contact other medical company for prior authorizations as needed  Input Merchant Capture Setup for various Banks Deposit Gateway Provide effective account maintenances upon client request Correspond with internal and external clientscustomers via telephone and email Complete reportsspreadsheets as assigned in a timely manner Meet numerous projects deadlines Work effectively as a team member           Viejas Enterprises      Program Eligibility Specialist   Alpine     CA                   062018      042018     Reviews referrals for services and interviews applicants andor family members to explain eligibility requirements form completion requirement and community resources  Requests information to determineestablished procedures  May serve as a liaison to other divisions and agencies to develop policies and procedures for communitybased programs           FISMetavante Corporation      Merchant Capture Administrator   City     STATE                   062018      062018     Input Merchant Capture Setup for various Banks Deposit Gateway Provide effective account maintenances upon client request Correspond with internal and external clientscustomers via telephone and email Complete reportsspreadsheets as assigned in a timely manner Meet numerous projects deadlines Work effectively as a team member           Spherion Staffing APS Healthcare      Human Resource Administration Assistant   City     STATE                   102018      042018     Providing Administrative Assistant to the Human Resources department at APS  Administer references checks employment and degree verification and testing for all prospective candidates process background preemployment checks  Maintain an Applicant tracking log system of all candidates  Assisted in employment operations by processing all open positions Updated and revised job descriptions Assisted in creating and running reports to obtain data in the HR Dept  Handled front office operations in the HR Dept  Prepared monthly termination report for corporate use Assisted in recruitment activities by posting job openings at appropriate external organizations such as technical schools professional organizations internet sites etc  Developed numerous spreadsheets and reports which obtain HR data  Detailoriented and have strong computer skills in Word and Excel  Assignment Ended           Randstad Staffing Inc Milwaukee Journal Sentinel      Employment Coordinator   City     STATE                   062018      022018     Primary responsibilities is greeting job candidates administers testing processes personnel paperwork enters payroll information in computerized system performs preemploymentpostoffer reference checks assists employees and external customers with questions and handles a variety of other human resource functions and provide excellent customer service skills  Assisted in employment operations by processing all open position requests posting full and parttime job postings on company bulletin boards as required and distributing postings using Journal Communications format generates open position log  Responsible for newhire processing to includes preparation of status advice preemployment paperwork assists HR Information Coordinator with entering employee data into the payroll system prepares folders with information for new employee orientation and put together interview packets and maintain personnel forms  handled front office operations for Human Resources assists employees with questions and provides quick resolutions maintain personnel files including creating new hire folders updating and removing files and filing employee information into their files  Administered reference checks employment and degree verification and testing for all prospective candidates runs driver and background preemployment checks schedules preemployment drug screens maintains a log all preemployment random and postaccident screen results          Skills     filing front office develop policies spreadsheets|none
Data Engineer|https://www.livecareer.com/resume-search/r/graduate-assistant-data-scientist-30e747ef925940eb909e346892bc157e|233404906853350828820150465750701247563|Jessica    Claire                   Montgomery Street     San Francisco     CA  94105    609 Johnson Ave       49204     Tulsa     OK       H   555 4321000    C       resumesampleexamplecom    Date of Birth         India                      single                    Experience       Graduate Assistant Data Scientist       011      011     Pace University    –                     Information System IS Analyze data using SPSS for faculty development  Part of the research team on conference proceedings like AMCIS ICIS and ECIS on geographic information system GIS spatial analysis and location analysis  Assist undergraduate students understanding SQL MYSQL etc  Data Visualization using tableau pivot tables D3js etc           Business Analyst  eCARGO       011      011     Information System    –                     The project involves responsibility for the product planning and execution throughout the Product Lifecycle including gathering and prioritizing product and customer requirements defining the product vision and working closely with operations sales client delivery technology and other stakeholders to implement new products ensure revenue and customer satisfaction goals are met  The Product Managers job also includes ensuring that the product supports the companys overall strategy and goals  Responsibilities Reviewed  gathered business requirements with the business and created business analysis process  Created detailed Functional Requirement Specification FRS and NonFunctional Requirements for Individual Market Portal Project based on the approved scope document  Facilitated JAD sessions and workshops required to understand workflows business needs and storyboards  Conducted Scrum meetings on regular basis  Kept the Product Owner  Project Manager informed about project status and issues that may impact client relations  Attended client meetings and assist with determination of project requirements  Organized meetings team celebrations between team members and clients  Recorded minutes at meetings  kept detailed project notes and records  Worked with cross functional team like UX design development QA marketing and different Line of Businesses  Generated Use Case diagrams Activity diagrams Business Object to depict process flows and PowerPoint presentations  Performed User Acceptance Testing UAT for various web based and database related applications  Work on defining the sprint scope and oversee the BA schedule and deliverables  Work with IT to design and develop data collection and management tools to manage the information  Certifications and Training PH1252x Data Science Visualization Certificate ID          June XXX8 ExiLearn Business Analyst          Aug XXX8 Communicated with the client to elicit analyze and validate the requirements  Created System Requirements Specification SRS Business Requirements Specification and Document  Created Wireframes using Mockup Plus and InVision  Created Use case activity and sequence diagrams using drawio Prepared Gantt Chart Requirement Traceability Metrix using Microsoft Excel           Academic Projects       011      011     1Store One Stop Shop    –                     Objected at creating an application to integrate all utilities like electricity internet travel and mobile recharge Scraped data from all utility websites and REST APIs provided by them The framework used is Ionic 20 with Angular 2 Worked with users and stakeholders to analyze and validate requirements Managed project through status meetings weekly reports identifying risks and tracking issues  Refreshable Braille Display for Mathematical Equations          Feb15May16  Developed a hardware tool that could help visually impaired to read and understand mathematical equation using braille pins and  tactile displays  Identified the solutions that could help visually impaired to read and understand mathematical equation Responsible for specifications implementations and analytics Prepared business models flowcharts and diagrams          Education       Masters       Computer Science       Expected in                   Pace University Seidenberg School of CSIS                GPA        Status         Computer Science GPA 384         Algorithms and computing theory Mobile Web Content and Development Web Development and Content Management system Human Factors and Usability Metrics              Expected in                                   GPA        Status                  Bachelors       Computer Engineering       Expected in                   University of Mumbai                GPA        Status         Computer Engineering GPA 321         Analysis of algorithm Software Engineering Computer graphics Artificial Intelligence Distributed databases Data Warehouse and mining Cryptography and system security              Expected in                                   GPA        Status                 Summary     To leverage my knowledge and expertise to growth of organization and self Master of Science in Computer Science with graduate assistantship and GPA of 384 Strong communication skills Expert in Algorithms and Computing Theory Master in Artificial Intelligence Demonstrated efficiency in team projects as well as handled projects independently Highly organized with the ability to manage multiple projects and meet deadlines        Highlights           Mac Windows Linux Ubuntu  Programming Languages SQL Python MySQL Relational databases HTML5 CSS3 JavaScript XML XHTML jQuery JSON D3 ThreeJS  WebGL SVG images HTML Canvas Ionic 20 AngularJS React  Applications Jira InVision Axure Blueprint Mockup Plus Agile Scrum Microsoft Excel Pivot Tables VSLOOKUP macros  VBA Tableau Visual Studio Android Studio Photoshop Gimp Quincy Eclipse NetBeans GitHub                         Skills     Photoshop Agile API Artificial Intelligence BA Blueprint Business Analyst business analysis Canvas hardware draw Cryptography CSS3 client clients client relations customer satisfaction data collection Data Visualization Data Warehouse Databases database delivery Eclipse XML Functional Gimp GIS Computer graphics UX HTML HTML5 JavaScript jQuery JSON Linux notes Mac macros marketing Market meetings Microsoft Excel PowerPoint presentations Windows MYSQL Operating Systems Pivot Tables product planning Product Manager Programming Python QA read Relational databases Requirement research sales Scrum Software Engineering Specification SPSS SQL strategy Tableau utilities vision VBA Visual Studio Web Development and Content websites Web Content and Development workshops XHTML       Additional Information       Extracurricular Activities Event Organizer for colleges cultural and technical festival Participant in the CodeZilla Competition held by my Undergraduate School in XXX4 Honors and Awards Pace University Scholarship worth 6000|none
Data Engineer|https://www.livecareer.com/resume-search/r/payroll-data-entry-clerk-2f381848a4c64eb0ac4843c23759d8f1|47664845955243791599205766919614592298|Jessica    Claire               Montgomery Street       San Francisco     CA  94105    609 Johnson Ave       49204     Tulsa     OK      Home   555 4321000        Cell           resumesampleexamplecom                  Summary     To obtain a position where my business education and administrative and marketing skills can make a significant contribution to my employer and where I can make a difference in the lives of the customers I assist       Highlights          MS Office   Customer Service   Marketing tool development     Office Administration                        Experience      062014   to   122014     Payroll Data Entry Clerk      Volunteers Of America  Greater New Orleans    –    Denham Springs     LA             Maintains payroll information by collecting calculating and entering data Processing medical delivery tickets ongoing Maintains payroll operations by following policies and procedures reporting needed changes  Maintains employee confidence and protects payroll operations by keeping information confidential  Contributes to team effort by accomplishing related results as needed  Analyzing Information  Data Entry Skills Attention to Detail Confidentiality Thoroughness General Math Skills Financial Software Reporting Skills Verbal Communication Organization          042014   to   052014     Financial Invoice Bookkeeper      Emplicity    –    Irvine     CA             Develops system to account for financial transactions by establishing a chart of accounts defining bookkeeping policies and procedures  Maintains subsidiary accounts by verifying allocating and posting transactions  Balances subsidiary accounts by reconciling entries  Maintains general ledger by transferring subsidiary account summaries  Balances general ledger by preparing a trial balance reconciling entries  Maintains historical records by filing documents  Prepares financial reports by collecting analyzing and summarizing account information and trends  Complies with federal state and local legal requirements by studying requirements enforcing adherence to requirements filing reports advising management on needed actions  Contributes to team effort by accomplishing related results as needed          2014   to   022014     Bookkeeper      Aircraft Owners And Pilots Association    –    Frederick     MD             Temp Assignment Invoice Preparer Gather data from vendor invoices to ensure that billing information is accurate as well as collects information from the receiving and stocking department to verify that the materials on the invoice were received into the company  Review all invoices for appropriate documentation and approval prior to payment Ensure pricing accuracy and resolve billing inaccuracies  Records information in bookkeeping records from invoice data  This usually involved data entry into QuickBooks  Sort and distribute incoming mail          2014   to   022014     Telemarketer      Merit Medical Systems Inc    –    CA     State             Deliver prepared sales talks reading from scripts that describe products or services in order to persuade potential customers to purchase a product or service or to make a donation  Explain products or services and prices and answer questions from customers  Obtain customer information such as name address and payment method and enter orders into computers  Record names addresses purchases and reactions of prospects contacted  Obtain names and telephone numbers of potential customers from sources such as telephone directories magazine reply cards and lists purchased from other organizations Adjust sales scripts to better target the needs and interests of specific individuals  Answer telephone calls from potential customers who have been solicited through advertisements  Telephone or write letters to respond to correspondence from customers or to follow up initial sales contacts  Maintain records of contacts accounts and orders          2014   to   012014     Member Services Representative      Marriott Vacations Worldwide    –    Miami     FL             Operate telephone switchboard to answer screen or forward calls providing information taking messages or scheduling appointments  Greet persons entering establishment determine nature and purpose of visit and direct or escort them to specific destinations  Provide information about establishment such as location of departments or offices employees within the organization or services provided  File and maintain records  Collect sort distribute or prepare mail messages or courier deliveries          112013   to   012014     Logistics Clerk      Hopkins Manufacturing Corp    –    Arlington Heights     IL             Establish operational procedures to verify incoming and outgoing shipments  Ensure shipments are received into inventory or ship timely  Work with Supply Chain to maintain adequate inventory levels as required  Oversee the daily logistics functions and interface with internalexternal supply chain functions  Maintain procedures and ensure full compliance of the regulations governing the movement of goods  Participate with logistics sourcing teams in the development of customers shipping importexport requirements and provide pricing quotations for the transportation of goods in response to proposals for future international business opportunities  Monitor and track the global movement of goods based on customer contractual requirements to verify order fulfillment  Complete and maintain all record keeping of domestic and international transportation documentation for exportimport activity          052013   to   2014     Marketing Agent      City Of Albany Or    –    Albany     OR             Temp Assignment ATT UVerse SalesMarketing Successfully learn the appropriate intrapersonal skills to apply with customers Adequately use the persuasive script and strategies for customers Offer ATT products and services with the intent to upgrade the customer to UVerse Specialize in consumer retail and business to business sales Learn direct marketing door to door sales Telemarketing involved as well          2013   to   052013     Customer Service Representative      Ascena Retail Group    –    Baton Rouge     LA             Deliver outstanding service to customers and fulfill the customers needs in a claims center using various means of communication Follow standard screensscripts to perform tasks Resolve questions and problems addresses by claimant Confirm or enter sale of product or insurance transactions Be knowledgeable of company products and services          052012   to   052013     TutorEmbedded Tutor      Miami Dade College Hialeah Campus    –    City     STATE             Assisted all students with writing grammar and editing on their assignments Assisted students individually with their English assignments Attended diverse classrooms to listen to professors lectures Aided students with their writing techniques and assignments Assisted reading students to review their virtual reading course          062011   to   012013     Human Resources Director      American Home Health    –    City     STATE             Provided job candidates by screening interviewing and testing applicants notifying existing staff of internal opportunities maintaining personnel records obtaining temporary staff from agencies  Maintained records and distributed checks as per payroll period Administered medical insurance provided application information helped with form completion verified submission and notifying employees of approvals  Maintained human resources records by recording new hires transfers terminations changes in job classifications merit increases tracking vacation sick and personal time  Oriented new employees by providing orientation information packets reviewing company policies gathering withholding and other payroll information explaining and obtaining signatures for benefit programs  Documented human resources actions by completing forms reports logs and records  Updated job knowledge by participating in educational opportunities reading professional publications  Accomplished human resources department and organization mission by completing related results as needed          012012   to   042012     Intern      Florida International Training Institute    –    City     STATE             Developed marketing tools and identified and implemented new marketing venues including usage of social media  In addition I influenced enrollment strategies for students  Related Coursework  Marketing In this class I learned that in an everexpanding world understanding how marketing decisions must be adapted to be global rather than just domestic is essential for successful careers in business  Helped promote the school enrollment utilizing flyers advertisements and newspapers to increase student matriculation  Assisted my supervisor with the vision of the institutes website to attract students attention by adding enthusiastic current student photos to the main portal  Thought about ways that sets the institute apart from the rest of the institutes tuition fees identified a unique academic curriculum implementation and emphasized that there is a possibility that students who attend the institute would most likely become a certified medical assistant          042008   to   072011     Administrative Aid Student Assistant      Miami Dade College    –    City     STATE             Provided a wide variety of administrative support for three staff members  Provided advisement and services to students  Managed office processes and administration  Prepared reports and course schedules for the entire department          Education      Expected in   May 2010     Associate of Arts     Accounting     Miami Dade College      Hialeah     FL     GPA       Accounting        Expected in   July 2012     Bachelors of Science     Management Supervision     Miami Dade College      Hialeah     FL     GPA   GPA 30    Management Supervision GPA 30        Languages     Bilingual Fluent English Spanish       Skills      academic administrative support advertisements Attention to Detail trial balance billing bookkeeping Customer Service Data Entry data   Processing delivery direct marketing documentation editing Fluent English English filing Financial forms general ledger human resources insurance international business inventory legal letters logistics marketing materials Math mail MS Office office newspapers Office Administration payroll personnel persuasive policies pricing processes proposals publications QuickBooks reading receiving reconciling record keeping recording reporting retail Sales scheduling scripts script shipping Spanish supervisor Supply Chain switchboard Telemarketing Telephone transportation unique upgrade Verbal Communication vision website|none
Data Engineer|https://www.livecareer.com/resume-search/r/data-entry-2eb0374c14c44351843e4e5ba4b32aa5|267879675808448796943774710600414002247|JC     Jessica    Claire                      Montgomery Street       San Francisco     CA    94105             555 4321000                 resumesampleexamplecom                         Professional Summary     To secure a position with a well established organization with a stable environment that will lead to a lasting career Courteous demeanor Adaptive team player Data Entry Data collection Microsoft knowledge Large cashcheck deposits expert Customer Service expert Telecommunication skills       Work Experience        022015   to   102015   Data Entry    Ul         Agoura Hills     CA            Organized billing and invoice data and prepared accounts receivable and expected revenue reports for controllers  Duties may include verifying data and preparing materials for printing  Verified that information in the computer system was uptodate and accurate  Developed more efficient filing systems and customer database protocols  Maintained detailed administrative and procedural processes to improve accuracy and efficiency etc            052014   to   012015   Receptionist    Faegre Baker Daniels         Indianapolis     IN            Maintain calendar and scheduling for staff and board members  Screen calls take messages respond to inquiries and request for information as directed  Maintain General Manger files and information flow including inboxoutbox email mail  Research filing document preparation as directed             112013   to   042014   Customer Service Representative    Hubbell Inc         Greenville     SC            Excelled in exceeding daily credit card application goals  Assisted customers with store and product complaints  Organized weekly sales reports for the sales department to track product success  Performed daily maintenance of the loan applicant database  Educated customers on the variety of loan products and available credit options  Collections answering multiline phone lending loans with proper information etc            112012   to   112013   Customer Service Representative    Hubbell Inc         Lincoln     NH            Assist clients with proper transportation meeting all the needs of medicaid recipients  Made reasonable procedure exceptions to accommodate unusual customer requests  Provided accurate and appropriate information in response to customer inquiries  Addressed customer service inquiries in a timely and accurate fashion          Education and Training        Expected in   052010   High School Diploma           Opelousas High School     Opelousas     LA      GPA               Skills     10Key accounts receivable administrative billing Maintain calendar Creative Problem Solving credit Critical Thinking clients Client Relations Customer Service Data Collection Data Entry database Documentation Email Executive Management fashion Filing General Manager Letters materials Microsoft Excel mail Microsoft Office Suite Microsoft Outlook Microsoft PowerPoint Microsoft Word MultiTasking Needs Assessment Internet Research Organizational Skills processes Proofreading protocols public speaker Speaking Reading Research sales sales reports Scheduling Spreadsheets take messages phone Telephone Skills Transcription transportation Type 40 WPM Typing Vendor Management|none
Data Engineer|https://www.livecareer.com/resume-search/r/data-entry-specialist-safety-coordinator-2eadfbd82728463cabd01a13e050f1ec|235281194702109789618551198259270346472|Jessica    Claire               Montgomery Street       San Francisco     CA  94105    609 Johnson Ave       49204     Tulsa     OK      Home   555 4321000        Cell           resumesampleexamplecom                  Summary      Driver Manager Data Entry Specialist Forklift Operator CORE Competencies and Reading Comprehension Sales Marketing Strategy Development Public Speaking Science Mathematics Monitoring Management of Material Resources Management of Personnel Resources Time Management Judgment and Decision Making Industrial Health and Safety Active Learning Management of Financial Resources and Operations Analysis Operations and Control Equipment Selection Equipment Maintenance Installation Operation Efficiency Monitoring Quality Control Analysis and Repairing Active Listening Social Perceptiveness Coordination Persuasion Negotiation Training and Instructing Critical Thinking Learning Strategies        Highlights          TOOLS  TECHNOLOGY   Operate PC and navigate Internet efficiently Familiar with Word Excel and Windows With 20 years using computers I easily manage whatever task is place in front of me and if not familiar I can adapt quickly and seek out appropriate instruction    Can operate motor vehicles of different sizes and design to deliver and or transport equipmentpersonnel or goods to desired location both safely and in a timely manner    Possess clean driving record and advanced knowledge in maintaining and operating company vehicles                      Accomplishments        Developed introduced and organized health and safety filing and training system for 37 employee team saving substantial amounts of time and funds to be used to further production goals and maintain safety record that far surpassed that of other departments     Led many men to gain their General Education Diplomas many of which continued on into various levels of continued education    Became the first in company history to pass Certified Laundry Linen Manager certification course with 96           Experience      072013   to   092014     Data Entry Specialist  Safety Coordinator      Calportland    –    Austin     TX             Maintained and created detailed filing system for fast paces industrial laundry  Developed organized and maintained safety training classes and OSHA compliance for 37 employee crew  Operated computer system for data entry in production shipping and receiving safety files water treatment center and human resource department employee files  Demonstrate or explain products methods or services to persuade customers to purchase products or use services  Provide product samples coupons informational brochures or other incentives to persuade people to buy products  Keep areas neat while working and return items to correct locations following demonstrations  Record and report demonstrationrelated information such as the number of questions asked by the audience or the number of coupons distributed  Sell products being promoted and keep records of sales  Practice demonstrations to ensure that they will run smoothly  Prepare or alter presentation contents to target specific audiences          012007   to   102008     Laborer  Driver      River City Roofing    –    City     STATE             Ordered picked up and delivered materials to job sites  Installed various roofing applications and repaired other areas as needed  Inspect problem roofs to determine the best repair procedures  Set up scaffolding to provide safe access to roofs  Align roofing materials with edges of roofs  Clean and maintain equipment  Cement or nail flashing strips of metal or shingle over joints to make them watertight  Install repair or replace singleply roofing systems using waterproof sheet materials such as modified plastics elastomeric or other asphaltic compositions  Cut felt shingles or strips of flashing to fit angles formed by walls vents or intersecting roof surfaces  Cut roofing paper to size using knives and nail or staple roofing paper to roofs in overlapping strips to form bases for other materials  Cover exposed nailheads with roofing cement or caulking to prevent water leakage or rust          042012   to   062014     Instructor Clerk      Golden Hills Adult School    –    City     STATE             Tutored for GED preparation and college entry students  Also taught selfhelp programs and instructional workshops  Organized and maintained data entry for multiple classrooms and different classes including grading testing and personal filing  Adapt teaching methods and instructional materials to meet students varying needs and interests  Conduct classes workshops and demonstrations and provide individual instruction to teach topics and skills such as cooking dancing writing physical fitness photography personal finance and flying  Monitor students performance to make suggestions for improvement and to ensure that they satisfy course standards training requirements and objectives  Observe students to determine qualifications limitations abilities interests and other individual characteristics  Instruct students individually and in groups using various teaching methods such as lectures discussions and demonstrations  Establish clear objectives for all lessons units and projects and communicate those objectives to students  Instruct and monitor students in the use and care of equipment and materials to prevent injury and damage  Prepare students for further development by encouraging them to explore learning opportunities and to persevere with challenging tasks  Prepare materials and classrooms for class activities  Enforce policies and rules governing students  Plan and conduct activities for a balanced program of instruction demonstration and work time that provides students with opportunities to observe question and investigate  Prepare instructional program objectives outlines and lesson plans  Maintain accurate and complete student records as required by administrative policy  Participate in publicity planning and student recruitment  Plan and supervise class projects field trips visits by guest speakers contests or other experiential activities and guide students in learning from those activities  Attend professional meetings conferences and workshops to maintain and improve professional competence  Meet with other instructors to discuss individual students and their progress  Confer with other teachers and professionals to plan and schedule lessons promoting learning and development  Attend staff meetings and serve on committees as required  Prepare and administer written oral and performance tests and issue grades in accordance with performance          012007   to   042009     Precast Concrete Laborer      Fintech Precast Inc    –    City     STATE             Worked in a fast paced precast concrete plant with various tools large concrete saws and operated multiple forklifts moving materials and transporting equipment  Operated various tools such as grinders rotohammer and concrete saws to maintain the quality of product          Education      Expected in    2014     Certification  Certified Laundry and Linen Manager	2014 Association of Linen Management	Avenal CA Certificate  Workforce Readiness Cert 1037829	2014 Golden Hills Adult School	Avenal Ca Certificate  Industrial Health and Safety	2014 TPC Training Systems	Avenal CA Certificate  Production and Safety Clerk Proficiency	2014 Prison Industry Authority	Avenal CA Certificate  Child Development and Nurturing Parenting	2013 ARISE Quality Group Homes Inc	Avenal CA Certificate  Conflict Resolution	2013 ARISE Quality Group Homes Inc	Avenal CA Certificate  Criminal Behavior and Human Nature 	2013 Harvard University Richard Q Wilson Professor of Government	Harvard University Certificate  Technology Fundamentals	2013 Golden Hills Adult School	Avenal CA Certificate  Business Principles  Basics Workshop	2013 Golden Hills Adult School	Avenal CA Certificate  Seven Habits of Highly Effective People	2013 Covey Leadership Center	Avenal Ca Certificate  INSIGHT	2014 Partnership for Reentry PREP	Los Angeles CA Certificate  21 Indispensable Qualities of a Leader	2013 Golden Hills Adult School	Avenal Ca Certificate  Life and Job Skills	2013 PLATO Learning Systems	Avenal CA Certificate  Quality Fundamentals	2013 Golden Hills Adult School	Avenal Ca		CONTINUING PROFESSIONAL DEVELOPMENT Certified Laundry and Linen Manager 2014 HONORS  AWARDS Voluntary Educational Tutor Recognition 2013 Certificate of Appreciation Turning Point Programs 2014 Certificate of Participation Reentering the Job Market Dr Brownlee 2014 Certificate of Completion Leisure Education Group      Management     Association for Linen Management      Richmond     Kentucky     GPA        Certification Number 1861 Final Score of 96 Credentials good through 12312016         Expected in        Associate of Science     Psychology Pharmacology     Lassen Community College      Susanville     CA     GPA               Expected in   2014          Industrial Health and Safety     TCP Training       Susanville     CA     GPA               Expected in             Business Management      Golden Hills Adult School      Avenal     CA     GPA        Completed various certification courses including Workforce Readiness Business Basics  Parenting Technology Fundamentals Situational Judgment Conflict Resolution Life Science and J C Maxwells 21 Qualities of a Leader workshop          Expected in        Select One     Paralegal  Certified Legal Assistant Certification     Blackstone Career Institute      Avenal     CA     GPA        100 scores on 12 of 14 exams to date         Expected in                        Susanville     CA     GPA               Interests      Worked as a volunteer literacy tutor for GED and college students through Golden Hills Adult School Volunteered for elderly in the community with shopping landscaping and health care assistance Writing letters to troubled youth to encourage pursuit of education and to educate and empower them to gain success in future References are available        Professional Affiliations      Association for Linen Management Clamper Lassen Loomis ECV Chapter 1914 Clampers Sept 20 2014 Industrial Health and Safety TCS Training Golden Hills Adult School Workforce Readiness Certified Lassen Community College Certified Nurturing Parenting Programs        Skills                  Additional Information       VOLUNTEER WORK    Volunteer literacy tutor for GED and college students through Golden Hills Adult School Volunteered for elderly in the community with shopping landscaping and health care assistance References are available|none
Data Engineer|https://www.livecareer.com/resume-search/r/psm-service-provider-data-center-operator-2d42089200b842ed9cde9bea9ea51a89|297571546504346138360712427500168158534|Jessica  Claire                             resumesampleexamplecom                      555 4321000                       Montgomery Street     San Francisco     CA      94105                                                                                                                                                                                                             Professional Summary     To secure an Information Technology position through analytical and technical skills while acquiring new skills within the changing technology           Core Qualifications         Guest services  Inventory control procedures  Merchandising expertise      Loss prevention  Cash register operations  Product promotions                     Education       Queensborough Community College    Bayside     NY      Expected in        –      –       AAS        Data ProcessingComputer Information Systems          GPA           Data ProcessingComputer Information Systems         New York University    New York     NY      Expected in        –      –       Certificate in Local Area Network Administration                  GPA                     Experience       American Eagle      PSM Service ProviderData Center Operator   Annapolis     MD                   042014      032015     Ensure all evidence repositories activities are done in a timely manner and contact vendor team about any issues  Provide timely communication to Team Leader and Management on any unaccounted for media using the IBM eTOC software  Communicate and oversee vendor team on a regular basis to ensure issues and concerns are addressed and closed quickly  Provide accurate and timely responses to all audit data requests by following the company Standard Operating Procedure  Oversee and interact with tape operational staff ie  vendors IBMIron Mountain to ensure work instructions are accurate well understood and being followed by tape operations team  Identify and implement innovative ways to increase security of PSM hardware and media by following the company standard procedure  Commit to supporting efforts to ensure account documentation is accurate current and stored in the appropriate repository PSM Document Library Account Profile Hub and Evidence Repository  Meet or exceed our targets in Service Delivery quality and customer satisfaction           Fannie Mae      Data Center Operator   City     STATE                   112009      032014     Maintains operations by monitoring error and stoppage messages observing peripheral equipment entering commands to correct errors and stoppages reloading paper making adjustments in process notifying supervisor for additional resources  Provide documentation or reports of operations during a shift a workday or some other specified period  Communicate with developers and analysts of business unit staff about the jobs or production runs daily  Monitor supplies and equipment necessary to ensure continuous operations  Contact vendors to research new products and pricing coordinate delivery and installation of software hardware and network components  Maintain the proper inventory level of computer supplies this includes updating inventory control sheets ordering supplies and getting emergency supplies from the storage room           Childrens National Medical Center	Silver Spring      Lead Computer Operator                           012007      102009     Perform daily weekly and emergency backup procedures and ensure their accuracy using IBM Tivoli software  Perform file application and system recovery when needed  Responsible for maintaining and upgrading the backup and recovery application and its associated database  Develop and maintain all backup and recovery tools  Send tapes media offsite on a timely manner and according to schedule policies using the outside vendor Iron Mountain database system  Maintain integrity of all data in the system by monitoring daily system activities using CA Unicenter NSM software  Monitor different types of operating systems that are running at the Network Operating Center such as Window and Unix servers  Ensures maintenance of equipment and workspace  Perform required cleaningvacuuming of equipment and preventive maintenance procedures  In general ensure that the environment and equipment are clean and secure  Run hourly checklists of all the servers at NOC for any unusual activities using BMC health monitoring system  Prepare equipment for operations by accessing software in computer loading paper into printers and plotters preparing for output  Maintain a variety of documentation including operations procedures tape libraries and error logs           American Society Of Civil Engineers      Legato Backup and Systems Operator   City     STATE                   101998      122006     Process daily weekly monthly and yearly jobs and reports  Maintain integrity of all data in the system by monitoring daily system activities  Inform appropriate persons regarding software and any hardware problems  Assist microgroup in installation of hardware and software for Windows and Unix Server  Process print and reprint reports upon request  I perform all the electronic processing  Monitor Sun Solaris Servers  Operate DEC Alpha and Solaris Unix computers  Restore files for users and programming staff as needed  In charge of the distribution of computer laptops through the company inventory database  Run and rerun specific programs needed to complete the monthly serving for Civil Engineer magazines and journals  Update Solaris operating system patches Group1 database Legato backup software Networker with the new version  Send backup tapes offsite according to schedule policies          Professional Affiliations              Skills     backup Civil Engineer CA hardware customer satisfaction database DEC Alpha Delivery documentation Hub IBM inventory inventory control Local Area Network laptops Team Leader Legato Windows Window Network operating systems operating system plotters policies pricing printers research new products programming quality Servers Sun Solaris Solaris supervisor Tivoli Unix Unix servers upgrading|none
Data Engineer|https://www.livecareer.com/resume-search/r/data-analyst-2d0c01d4f49448da8b2b9cb8af8481f4|230388201717447766043406647718212528575|JC     Jessica    Claire                             San Francisco     CA                 555 4321000                 resumesampleexamplecom                         Accomplishments       Diversity Committee at University of Illinois at UrbanaChampaign  PROJECT LEAD Data Visualization Final Course Project CONSULTANT Business Intelligence Group School of Information Sciences INFORMATION TECHNOLOGY LEAD Association for Computing Machinery INSTRUCTOR Jeevan Jyot NGO Mumbai India Projects Yelp Data Analysis University of Illinois at UrbanaChampaign          Jan  2018  Apr2018 Built a simple text classifier using Pythons Pandas NLTK and Scikitlearn libraries  Created a sentiment analysis model that predicts whether a user liked a local business or not based on their review on Yelp  Performed analysis on businesses as well as users data and outlined the analysis using interactive visualizations in python  Evaluating Thought Leadership in Insurance University of Illinois at UrbanaChampaign   Oct  2017  Dec  2017 Helped the client in Accessing Thought Leadership Reports of their Competitors in the Insurance industry  Performed regressive analysis of the reports generated visualizations to depict complex data and processes  Data Visualization Final Course Project UIUC          Sep  2017  Dec 2017 Designed dashboards to display visualizations with interactive components of IPywidgets  Performed data aggregation and audio integration using Python  Distributed Document Clustering Using a Hybrid Approach University of Mumbai Sept  2016  Apr  2017 Developed a Hybrid algorithm comprising of KMeans Particle Swarm Optimization PSO Latent Semantic IndexingLSI Algorithms for distributed clustering of documents  Used Hadoop MapReduce Framework for clustering 20000 documents 20NewsGroups and 21578 documents Reuters21578 on single and multiple nodesmachines  Android Joystick Shri Bhagubhai Mafatlal Polytechnic          Sept  2013  Apr  2014 Developed an Android Application that turned smart phones into Computer Remote Controllers to allow users to wirelessly operate a remote desktop via Bluetooth connectivity  Provided different features for customizing the controller for user flexibility and comfort         Professional Summary      Experienced Data Analyst committed to maintaining cutting edge technical skills and uptodate industry knowledge        Skills           Python and R  proficient  Tableau Power BI  SQL MySQL Hadoop  Microsoft Excel proficient  Excellent communication skills      Photoshop SharePoint Adobe Creative  Suite  HTML5 CSS3 JavaScript  Java Android  Excellent problemsolving abilities                       Work History        012018   to   Present   Data Analyst             Long Island City                 Implementing data preprocessing using python to clean a dataset containing over million entries and generating valuable insights from the clean dataset through visualizations  Using Natural Language Processing toolkit NLTLK package to perform topic segmentation and analyzing the trends in equipment features over years at John Deere  Using Google Analytics to analyze data of the mobile applications and make data driven decisions to improve customer support and experience            012018   to   Present   Technology Consultant    Jones Lange Lasalle Inc                          Providing strategic consulting for a leading company in the electrical data networking industry to implement a governance framework on their intranet portal  Developing a business model for the client to improvise their intranet design optimizing item placement usability and searchability            112017   to   012018   Data Analyst Intern    Hewlett Packard Enterprise                          Worked with AACSB process manager for data extraction and cleaning using R and analyzed the data using descriptive visualizations in Tableau  Compiled information on faculty activities collected data for surveys performed data quality control activities using Microsoft Excel  Transformed the data using data wrangling in a format specified by the management            122015   to   012016   Application Developer and Content Management Intern    Do It Best Corp                   India       Interacted with senior professionals to develop and design business processes to enhance the functionality of the Android application  Implemented the business processes on the backend using JSON  Used Tableau for data collected from multiple sites to generate insights for the senior professionals to carry out decision making          Certifications     Data Visualization Applied Business Research Data Statistics  Information Big Data Analytics Cloud computing Data Mining  Business Intelligence Data Structure  Algorithms Advanced Database Management Systems Software Project Management Programming for Analytics and Data Processing Competitive Intelligence  Knowledge Management        Education        Expected in   Dec 2018   MS       Information Management    University of Illinois     Urbana Champaign     IL      GPA       Information Management GPA 350          Expected in   May 2017   BE       Information Technology    University of Mumbai     Mumbai           GPA       Information Technology GPA 395          Expected in   May 2014   Diploma       Information Technology    Shri Bhagubhai Mafatlal Polytechnic                GPA       Information Technology GPA 375        Publications     Published a technical paper on the project Android Joystick IJARCCE Journal Vol 5Issue11 Nov 2016       Skills     Adobe Illustrator Photoshop Big Data BI Business Intelligence business processes Business Research Competitive Intelligence consulting CSS3 Client customer support Data Processing Data Mining Data Modelling Data Visualization Database Management decision making features Google Analytics HTML5 Java JavaScript JSON Knowledge Management lEADERSHIP Microsoft Excel Microsoft Office SharePoint MySQL Natural Language Processing networking Programming Project Management Python quality control SQL Statistics strategic surveys Tableau|none
Data Engineer|https://www.livecareer.com/resume-search/r/data-analyst-1edf3bdef6744bc69520a01d3285bbf8|317372527761722178757702714562875550369|Jessica  Claire                             resumesampleexamplecom                      555 4321000                       Montgomery Street     San Francisco     CA      94105                                                                                                                                                                                                             Summary     Highly talented and accomplished professional with extensive skills and experience in complex work environments Coordination planning and support of daily operational and administrative functions Detailoriented and well organized when completing projects able to multitask effectively Experienced working in fast paced environments demanding strong organizational technical and interpersonal skills           Skills       Microsoft Word Excel Publisher PowerPoint Outlook Lawson Time Matters and Internet                     Education and Training       ATLANTAS JOHN MARSHALL LAW SCHOOL               Expected in   May     –      –       Juris Doctor                  GPA                    CHEYNEY UNIVERSITY OF PENNSYLVANIA               Expected in   May 2001     –      –       BS        Business Administration          GPA           magna cum laude Business Administration          Experience       Lewis Pr      Data Analyst   New York     NY                   072012      Present     Collect and compile data for statefederal requirements which includes audit documentation regarding professional learning activities  Assist the Title II Department with the allocation management and tracking of Title II  Part A program funds  Maintains and develops electronic files records for easy access of reports  Prepare spend down reports for various departments that use Title II funds  Enter requisitions for activities allowable under Title IIA  Provides ongoing technical support to publicprivate school and other district personnel including conducting meetings regarding compliance  Compiles and summarizes program data for all required Federal and State reports  Assist with the preparation of documents for meetings involving stake holders  Assist in preparation of presentations and meetings  Assist with procurement process of compliance with documentation  Conduct surveys with personnel and stakeholders to assess the needs of the district and compile data for reports  Works closely with various departments to track expenditures and gather information necessary as requested by Title II Department           Lewis Pr      Data Analyst   Chicago     IL                   062012      112012     Compiled and evaluated student data for the purpose of assessing program effectiveness student growth and provider quality including completion of federal and state reports  Assisted with the development of district policies and procedures for effectively implementing monitoring and evaluating the Title I Supplemental Educational Service program in accordance with federal law  Evaluated and processed vendor invoices against student attendance reports and performance data to ensure reliability and validity  Assisted with preparation processing and review of contractual agreements for all vendors as well as enter contract information in Lawson system  Developed and created marketing programs to effectively communicate with parents district personnel and the community regarding the SES program services  Facilitated training and workshops for schooldistrict personnel parents vendors and community members regarding Title I program guidelines  Monitored school sites where tutorials take place to ensure that providers are in compliance with guidelines set forth           Primrose School      Administrative Assistant   Oldsmar     FL                   092009      112012     Provided administrative support for the Supplemental Educational Services Program including acting as a liaison between the tutorial providers school personnel and parents adhering to and interpreting state and federal program guidelines and relaying that information to the public and meeting deadlines for reports  Prepared spreadsheets and data reports summarizing enrollment data by schoolprovider  Monitored school sites where tutorials take place to ensure that providers are in compliance with guidelines set forth  Prepared correspondence create email distribution lists maintain calendars organize mass mailings and file management  Maintained and track database of over 2400 students  Verified freereduced lunch status of students requesting to participate in the program  Assisted with completion of all state reportssurveys regarding SES  Provided executivelevel administrative support to the Program Director of Title I Office with a demonstrated ability to improvise improve procedures and meet demanding deadlines  Collaborated and met with other departments to complete special projects including summer school  Conducted surveys regarding summer school and compile data for reports           State Of Ohio      Legal Assistant   Wayne County     OH                   042002      122008     Provided administrative support to Managing Partner and Associates in general practice law firm with a demonstrated ability to improvise improve procedures and meet demanding deadlines  Acted as a liaison between clients and attorneys arranged meetings maintained calendars drafted correspondence maintained and organized files sent documents by facsimile photocopied proofread prepared memos sent documents by overnight mail scanned documents and downloaded documents  Managed client files opening and closing files maintaining client databases and attorney billing  Prepared and interpreted legal documents such as but not limited to Contracts of Sale Promissory Notes and Powers of Attorney  Assisted accounting department in maintaining bank accounts including managing subaccounts for clients writing checks and communicating with the bank regarding deposits and wire transfers  Supervised and trained parttime and summer employees including delegating responsibilities overseeing and reviewing tasks completed and collecting time sheets  Provided support to the office manager in handling payroll and accounts payablereceivable responsibilities  Assisted with firm marketing including preparation of packets for presentations building and fostering working relationships with affiliated companies to increase clientele          Interests     Notary Public Commissioned in the State of Georgia       Skills     accounting accounts payable administrative support Attorney billing closing Computer experience Contracts clientele client clients databases database documentation email facsimile file management forth funds IIA Lawson law legal documents Notes Director Managing marketing meetings access Excel mail Office Outlook PowerPoint Publisher Microsoft Word Works office manager payroll personnel policies presentations procurement quality spreadsheets surveys technical support workshops       Additional Information       LICENSES Notary Public Commissioned in the State of Georgia|none
Data Engineer|https://www.livecareer.com/resume-search/r/military-account-coordinator-administrative-assistant-data-entry-2102360b276a470492d7218e3b5ba3f4|47261525280753010442436831741143595004|Jessica  Claire                             resumesampleexamplecom                      555 4321000                       Montgomery Street     San Francisco     CA      94105                                                                                                                                                                                                             Summary      Administrative Assistant with extensive accounts payable background who excels at completing multiple tasks simultaneously and following through to achieve project goals             Highlights         Windowsbased programs and OS  Internet navigations  Mozilla Firefox  Zimbra  Google Applications      Microsoft Office Suite  Spreadsheet development  AuthNet payment system  Microsoft Dynamics software Navision                     Education       North American College  Clifton Campus    Phoenix     Ariz      Expected in        –      –               Travel and Tourism          GPA                    Phoenix College    Phoenix     AZ      Expected in        –      –       GED        General          GPA                     Experience       Arbor Realty Trust      Military Account Coordinator Administrative Assistant Data Entry   Cleveland     OH                   062007      Current     Set up and monitor government and commercial accounts  Answer multi phone lines and emails to provide product knowledge place orders and quotes    Directly supports CEO in managing operation work flow  Designed electronic file systems and maintained electronic and paper files   Evaluated and determined export compliance and submits license for export trade approval of product   Maintains and implements all GSA contract requirements    Created databases and spreadsheets to improve contract management and reporting accuracy  Implemented government collection procedures for payment increasing ontime payments by 95 and collecting more than 13000000 in back debt ­   Process payments reconcile and balance financial activities in accounting systems   Contributes to team effort by helping to achieve departmental goals  Provide discretionary customer support regarding account information and balances   Performs collections via customer account statements receipts ­and open communication   Deliver EFT info check and cash to accounting team for daily electronic lock box deposits ­   Provide primary support to management and teammates ­on government laws and acquisition processes   ­Submits invoices for payment via electronic Internet payment platforms    Made copies sent faxes and handled incoming and outgoing correspondence   Ensures and complies with all safety standards as an area Safety Coordinator            DocuMart      Administrative Assistant Sales Agent Customer Relations   City     STATE                   092006      062007     Assisted customers with copies faxes printing and bindery ­processes   Maintained detailed administrative and procedural processes to improve accuracy and efficiency  Verified and logged in deadlines for responding to daily inquiries  prioritized and coordinated work flow  Developed more efficient filing systems   Counted cash drawer­ and reconcile cash deposits to include verifying and recording end of day deposits  Increased sales volume 5 months in a row by 25 to achieve bonus award  Handled quality issues ­and resolved customer complaints  Track and follow up on orders in process  ­    Communicated effectively between departments clients and vendors   Provided quality ­bindery ­services ­to include collate cut laminate coil and perform document review  Maintain a safe and clean working environment by complying with procedures rules and regulations            Colorado Avenue Veterinary Hospital      Receptionist Administrative Assistant   City     STATE                   072006      092006     Managed the receptionist area including greeting visitors and responding to telephone and inperson requests for information  Scheduled and confirmed appointments for entire veterinary hospital  File ­fax and ­scan ­reports to other veterinary hospitals and clinics   Maintain a safe work environment and practice A septic cleaning procedures ­   Listen and provide empathy to owners and compassionately attend to patients animals            Quality Concepts Manufacturing Inc      Document Administration Surface Mount Line Lead   City     STATE                   022001      072006     ­Efficiently and effectively scheduled work ­loads to maximize established goals   Provided supervision and support for 8 to 10 employees ­and increased quality and production output ­by 30  Interpreted prints drawings and sketches  Assisted engineering with documentation and production issues ­   Set up and performed hand and automatic assembly operations on components subassemblies and assemblies­   Performed on safety committee team  Assessed work for errors or compliance issues and made corrections and modifications when necessary  Performed as production floor manager for 6 months ­   Performed as exemplary team player             Colorado Assembly Specialist      Document Administration Quality Assurance Coordinator   City     STATE                   102000      012001     Reviewed all engineer drawings and bills of materials for current revisions of proper assembly builds   Evaluated and implemented changes to documents per engineering change orders­   Performed assembly and soldering assignments  Reviewed and reported data collection through charts and graphs  Data entry to record assemblies and document defects          Credentials      Silver Certificate awarded through Pikes Peak Work Force   First Aid  CPR Certification valid through 2016|none
Data Engineer|https://www.livecareer.com/resume-search/r/data-scientist-2a3791654fd140e2ad9f230d470f1043|57144578075288773773635457122564211508|Jessica    Claire                   Montgomery Street     San Francisco     CA  94105    609 Johnson Ave       49204     Tulsa     OK       H   555 4321000    C       resumesampleexamplecom    Date of Birth         India                      single                    Summary       7 years of IT Industry experience in in designing and developing data mininganalytics solutions data centric integration developing and maintaining Business analytics   Adept in data query data migration data analysis predictive modeling machine learning data mining and data visualization implementations with extensive use of SQL Python R Java and Unix Shell scripting with platform of Toad Oracle developer Jupyter Notebook Pycharm RStudio Tableau Hadoop with Spark  Experience in predictive analytic procedures used in supervised learning Classification Regression Decision trees Random Forest SVM Neural Networks unsupervised learning ClusteringkMeans and PCA and reinforcement learning  Solid theory background for machine learning data mining text mining graph mining statistics modeling NLP and deep learning  Expert in Natural Language Processing like POS Tagging Parsing Named Entity Recognition Relationship extraction Information       Retrieval Sentimental Classification Machine Translation etc  Solid knowledge of deep learning algorithms like CNN RNN LSTM GRU etc for text mining and image processing  Professional in writing complex SQL queries on Oracle MS SQL server Teradata and MySQL using a lot of subqueries joins aggregate functions analytical functions and temporary tables etcWorked on Big Data Analytics Hadoop ecosystems Hadoop Sqoop Hive Pig Mapreduce and Spark for big data migration cleaning transformation processing query and analysis  Familiar with software lifecycle includes requirement collectingdocumentation development and testing for Unit Smoke  integration system nonfunctional testing regarding performance scalability usability enduration load and volume testing and regression testing multivariate testing AB testing and system maintenance  Work with business domain experts and application developers to identify data relevant analysis  mining and develop new predictive  analytical modeling methods andor tools in Financial like loan and foreign exchange Product Customer Sales domains etc  Experience in data aggregation and reduction techniques of large data sets with high performance and parallel computing for high performance analytical projects  Involved in diagnosing and resolving predictive  analytical model performance issues monitoring analytical system performance  ·       and implementing efficiency improvements  Conversant with MS SQL Oracle PLSQL and RDBMS Contributed in data definitions for new database filetable development andor changes to existing ones as needed for analysis and mining purpose  Experienced Oracle PLSQL Developer for designing developing debugging  maintaining and administrating database in Oracle RDBMS Solid experience in PLSQL and SQL programming and performance tuning   Familiarity with Oracle data warehousing features such as star  snowflake data modeling schemas materialized views bitmap indexes Index Organized Tables external tables etc and OLTP system using Btree index Hash Join etc  Experienced in frontend developing using Java Javascript C and backend developing using C  Professional in integrating and maintaining code using version control tools PVCS SVN CVS  Solid experience and knowledge in ETL and Data warehousing conceptsData Processing experience in designing implementing transformation processes using ETL tool   Involved in all aspects of ETL requirement gathering with standard interfaces to be used by operational sources data cleaning data loading strategies ETL mappings designing documentation and ETL jobs performance testing                    Using Unix bashcorn shell scripting to do backend process operation system resources  checking job scheduling batch data loading performance tuning and reporting     Conversant with Project Management deliverables and SDLC phases – Waterfall and Agile   A selfstarter team player excellent communicator prolific researcher  Expert technical documentation skills Strong interpersonal and communication skills both written and oral ability to communicate with people in a wide variety of areas and at various levels from technical specialists to senior management          Skills                        Roles  Data Scientist Data Analyst Business System Analyst Oracle PLSQL developer   Data Visualization  D3js Tableau R visualization packages Microsoft Excel    Data Analytics ToolsProgramming                 Python numpy scipy pandas scikitlearn gensim keras Rcaret weka ggplot  MATLAB Microsoft SQL Server Oracle PLSQL     Machine Learning Algorithms  classification regression clustering feature engineering    Big Data Tools  Hadoop MapReduce SQOOP Pig Hive NOSQL Cassandra Spark    Others Deep Learning NLP Topic Modeling Sklearn Graph Mining Text Mining C C  Java Javascript ASP Shell Scripting  					 				 			 		        Experience       Data Scientist       082011      092016     Lockheed Martin Corporation    –    Yuma     AZ                              Actively develop predictive models and strategies for effective fraud detection for credit and  customer banking activities using Kmeans clustering using Python    Assisted senior data scientist to do text mining on customer reviewcomment data using topic modeling  and sentimental classification using deep learning algorithms like CNN RNN LSTM GRU to  remediate according financial products using Python    Assisted senior quantitative analyst in assessing risk management of financial derivative products like foreign exchange products bonds funds etc using machine learning techniques for providing appropriate investment recommendations using Collaborative filtering recommender system using Python    Mentored sophisticated organizations on large scale customer data and analytics using advanced  machine learning and statistical models relying for issuing loan using Random Forest using R    Performed kMeans clustering in order to understand customer backgrounds and segment the  customers based on the customer transaction behavior information for customized product  offering customized and priority service to improve existing profitable relationships and to avoid customer churn etc using R    Worked on Interactive Dashboards for building story and presenting to business using Tableau     Implementing Hadoop to provision big data analytics platforms for customer data Used  MapReduce Sqoop Hive and Spark to migrate and analyze large callqualitydata datasets from  multiple Data sources like integrated funds transfer system like FedWire CHIPS SWIFT for  securities treasury or derivatives and webbased cash management systems eGifts GiftsWEB GiftsWEB EDD for fraud detection and risk management for accounts based on positive pay and Automated Cash Handling balance reporting etc    Installed and configured Hadoop cluster in Test and Production environments Moving data from Oracle 9i database to HDFS and viceversa using SQOOP Collecting and aggregating large amounts of log data using Apache Flume and staging data in HDFS for further analysis Developed multiple MapReduce jobs in java for data cleaning and preprocessing Writing Pig scripts to transform raw data from several data sources into forming baseline data  Solved performance issues in Hive and Pig scripts with understanding of Joins Group and aggregation and how does it translate to MapReduce jobs Developed Oozie workflow for scheduling and coordinating the ETL process Using Spark for further data analysismining     Experience in using Sequence files RCFile AVRO and HAR file formats  Work with Data Analytics team to develop time series and optimization    Involved in development and maintenance of Oracle database using PLSQL and backend  development using CC for intranet management system for Employee Management System  EMS and Agent Payout System APS              Business System Analyst       042009      082011     Accenture    –    Overland Park     KS            Project Summary   This project is in Application service group for Mercury system in Canon USA Inc  which mainly in charge of the new item request item disclosure between companies item data import from other Canon Americas companies to Canon USA Canon Americas Master inquiry Model tree maintenance model configurations and cameravideo merchandise Maintenance for Canon Americas systems includes S21 for Canon USA merchandise master S98 for Panama CCI21 for Canada S85 for Mexico Chili Brazil and Argentina Ideal for Latin Americas countries       HardwareSoftware       Windows VistaNTXP7 Linux Oracle 11g10g9i8i SQLPLUS  Oracle SQL developer Toad  Microsoft SQL Server management studio 2008Microsoft Visual Studio 60ODBCJDBC  Microsoft IIS 511 Putty Cygwin Winmerge VPN ITG project management system PQedit IIS AutosysPCXware 510 MS Word Excel Access Project Visio      Responsibilities     Operational support for Canon Americas Mercury system includes data adjustmentresearch batch data loading system migration Technical and functional specification documentation reports business process alignment workflow stuck and reconciliation etc      BreakFix any issues or bugs collected from client and development regarding setup performance functionality and workflow stuck etc   System Enhancement regarding functionality and performance etc  Reproduce and review existing oracle 9i schema objects includes tables temporary tables views materialized views indexes triggers procedures functions packages based on customer requirement and system upgrade using Toad and Oracle SQL developer tools        Review and analyze ASP code for UMC Mercury application web development for data research and system feature fix and enhancement using Visual Interdev 60        Query realtime data regarding Canon Americas new item request item status inquiry item data disclosure and import model configuration and maintenance warranty maintenance and model configuration inquiry  etc  using complex SQL queries on Oracle 9i Canon mercury database      Using Unix bashcorn shell scripting to do backend process operation system resources checking job scheduling batch data loading performance tuning and reporting  Maintain scheduled day and night batch jobs for mercury system using AutosysPCXware and Unix box and check the MQ series using PQ edit      Implement client session action module service instance level endtoend application tracing using SQL trace with TKPROF and Explain plan to check execution plans for highload and Top SQL statement  Using Cygwin FTP Putty with Unix Bash shell to make a tunnel for Oracle database connection       Using Tortoise SVN for code checkout update and release–comparison etc       Tracking and documenting tickets for development and reproduction Using ITG ticket tracking system                        Assisted QA and build team to be involved in unit smoke integration system UAT nonfunctional testing regarding performance scalability usability  enduration load and volume testing and  regression testing and maintenance using SOUP UI and Seapine QA Wizard Pro for product release          Data loading using Impexp data pump and external tables from Americas Mercury system to S21CUSA merchandise master to RossCUSA retails system and Global Mercury system                Oracle PLSQL Developer       2008      042009     Cognizant Technology Solutions    –    Novi     MI            Project Summary   NYU Langone Medical Center a worldclass patientcentered integrated  academic medical center is one of the nation’s premier centers for excellence in healthcare biomedical research and medical education The project is to develop new oracle database objects on online Health Information Managment system on FindWdev instanceserver for 29 NYU medical school departments using in clinical education research and foundational areas etc to be used as Oracle staging area to store the loaded data from NYU Medical Dash DWH from different source systems to provide further data to be loaded into DWH for historical record Decision support and Datamart for reports  and Cube for UI display      HardwareSoftware     Unix Oracle 11g Oracle developer 11g Oracle EBS 11 ERP R12 IBM DataStage 80 Designer Director Manager Parallel Extender Oracle Enterprise Manager MS SQL server management studio 2008 Toad for Oracle 90 TSQL  PLSQL XML Erwin Microsoft Visio Autosys IBM Data stage 8 Oracle reports 11g   Responsibilities                      Independently develop Oracle database objects includes tables views materialized views indexes triggers functions procedures packages etc     Cooperated with BA SME to collect and document database design requirements and do data modeling with DB architect using Erwin and Microsoft Visio     Assisted DBA for job scheduling data loading and performance tuning using OEM SQL tuningaccess advisor hints  explain plan  SQL trace and V performance views under Unix     Write complicated queries using a lot of aggregate functions joins analytical functions subqueries  etc to provide realtime data from Oracle DB  for client and UI development supporting  Checking execution plan using explain plan together with SQL trace with TKPROF using trcsess under unix to realized endtoend application tracing      Add optimization hints into high–load and top SQL statements to change the optimization goal access method join method join order and parallelization etc    Designed and developed ETL processes using DataStage designer to load data from Oracle to staging database and from staging to the target Data Warehouse    Worked with Datastage Manager for importing metadata from repository new job Categories and creating new data elements  Used DataStage stages namely Hash file Sequential file Transformer Aggregate Sort Datasets Join Lookup Change Capture Funnel Peek Row Generator stages in accomplishing the ETL Coding  Job scheduling using Autosys  Coorporated with QA team for debugging unit system functional UI regression testing for new ISO release production    Working on Linux system for batch data loading job scheduling and system resource checking etc    Assisted backend developer for reviewing and debugging C program for Health information management systems                  Involved in web development of online Health information management systems using JAVA  Reviewed and reproduced online JAVA reports of Health information management system checked DB references in it for intelligent Decision Support System            Education       Master of Science       Computer Science       Expected in   2016                University of California      Los Angeles     CA     GPA        Status          GPA378   Courses                Statistics Programming Databases and Knowledge Bases Graphs and Network Flows  Language and Thought Current Topics in Computer TheoryMachine Learning Algorithm Computer Science ClassicsBasic Data Science Data Mining and Big Data Analytics System Security            Master of Science       Electrical Engineering       Expected in   2010                University of Bridgeport      Bridgeport     CT     GPA        Status          GPA362   Courses Computer Networks Database Management Systems Data and Computer Communications Data Structures          Bachelor of Science       Telecommunications Engineering       Expected in   2007                Jilin University      Changchun     Jilin     GPA        Status         GPA 350|none
Data Engineer|https://www.livecareer.com/resume-search/r/salesforce-data-engineering-manager-2952c98aac2e4e23b74d04686af5b7fe|232212542609558337631349637936500570010|JC     Jessica    Claire                      Montgomery Street       San Francisco     CA    94105             555 4321000                 resumesampleexamplecom                         Summary     Salesforce Data migration and SQL BI Developer offering 7 years of leading crossfunctional teams and completing projects ontime Seamlessly manages workload to meet deadlines       Skills           Salesforce Data migration expert  Salesforce Data Loader expert  Salesforce Administrator  Strong Microsoft SQL server MYSQL SAP skills  SSIS and SSRS expert  Fluent in TSQL C C Microsoft Tools  Data warehousing and analytics  JIRA and TFS  Strong decision maker  Excellent communicator  Team player  Selfstarter  Active Directory knowledge  Requirements analysis and design phases                         Experience        082013   to   Current   Salesforce Data Engineering Manager    Talent Rover LLC         City     STATE            Managing all data migrations into Talent Rover  Migrate data from multiple sources into Salesforce  Create complex queries to extract data from SQL server andor MYSQL based on the clients requirement  Created data migration templates to migrate from multiple sources into Salesforce  Manage multiple teams across the globe to complete the implementation life cycle on time  Work with project managers and delivery leads to plan for the sprints and successful implementation of the project  Meet with clients pre sales to provide the quote for data migration after analyzing there data and functionality  Create SSIS package templates for the data migration from similar sources  Complete the data mapping with client and Project manager  Have weekly meeting with multiple clients to update on the progress in the project  Complete the first data migration into Salesforce and guide clients to perform the data validation and track issues  Complete the data validation and get the signoff from client  Plan for the delta or GoLive load and support the client after golive  Manage multiple clients implementation in parallel  Use data loader and Workbench to get the data into Salesforce            072013   to   082013   MS SQL Server  SSISSSRS Architect    Estuate Inc         City     STATE            Create a single data warehouse to hold the data from individual data warehouses  Added a new dimension table and modified the data model of the data warehouse depending on the requirement  Implement ETL solution to extract data from multiple sources into one DW  Designed the highlevel design document of the complete process flow  Created a SSISETL package to run across different data warehouses just by changing the connection string of the data source  Designed a SQL agent job that triggers the SSIS package on a schedule  Created reports to compare data between different Data warehouses  Created stored procedures and complex queries to extract the required data from the final data warehouse  Created a web page to implement a simple authentication page for the uses to access the reports  The users can enter the required parameter for each report and execute the report  All the reports were using dynamic parameters which used to be the input for the stored procedures to fetch the appropriate data  Reports had an option to select single or multiple Data warehouses from the drop down menu  Implemented different types of charts for the graphical representation of the data  Deployed the SSISETL with a oneclick deployment to the test and production servers  Deployed reports on to the report server with a simple deployment utility            042011   to   032013   MS SQL Server  SSIS SSRS Developer Technical team lead  Data Architect    Workers Compensation Insurance Rating Bureau WCIRB         City     STATE            Designed database after analysis of the business requirement  Designed the highlevel design document of the complete process flow  Worked closely in developing the detail design document and presenting to the client and implementing their feedback on a weekly basis  Designed development plan and the assigned individual task to team  Worked with an offshore development team communicating on a daily basis with the team  Designed the complete flow of the file processing  Designed power shell to monitor the file location for the file existence and copymove to specific location after looking at a character inside the file  Inserted into the tables from the power shell by calling stored procedures  Designed the file processing using the queue first in first out concept  Implemented the Queue logic by starting SQL Agent jobs which pointed to deployed SSIS packages on the integration server  Designed SSIS packages to implement the file processing logic depending on the source of the file  Deployed SSIS packages with a simple oneclick deployment to the integration server  Maintained different branches in TFS as development for release 2 and testing for release 1 were together  Resolved the conflicts while merging code in TFS  Deployed different database instances for development QA UAT and production from TFS  Designed reports using SSRS for the client as per their specifications  Deployed SSRS on to the report server with an easy way of deployment  Created subscriptions on the deployed reports using report manger  Called those subscriptions using a stored procedure which fired the report subscription and saved the reports on the file server  Used Databasesqlcmdvars for deploying the database instances giving the flexibility to change the variables used in the deployment  Implemented the SQL agent jobs creation while deploying the database instance itself by adding them on to the post deployment scripts  Created the SQL server users and file server users with required permissions by including them in the scripts  Implemented the power shell as a windows service which is used to monitor the file existence  Implemented matrix tabular and charts while creating the reports using SSRS  Used expressions extensively for hiding textboxes display labels and hiding charts matrix and tabular depending on certain conditions  Used parameters images to retrieve appropriate data from the common data source added globally  Saved images in a binary form in the configuration tables for easy retrieval from SSRS  Implemented Derived column file system task conditional split lookup transformation OLE DB Command Data conversion Data flow Execute SQL task Bulk task Script task for each loop Ftp task and other tasks in SSIS  Optimized the loads by adding Indexes wherever needed dropped and recreated indexes while doing the full loads  Maintained the SQL Server Agent jobs to run depending on the requirement  Used IBM OLE DB connection manager to connect to IBM DB2 database and get some input data to the look up loads  Used Update and Merge statements while working on the Incremental loads            102010   to   042011   SSIS Technical Lead    Focus On The Family         City     STATE            Worked with an offshore development team communicating on a daily basis with the team  Defined planned and lead the Development tasks  Tracked and reported status risks and issues to the business  Designed and developed SSIS Packages to import and export data from MS Excel and Flat files  Implemented SSIS packages for data exportimport and created maintenance procedures and deployed them to the server  Extensively used SSIS ImportExport Wizard for performing the ETL operations  Built Control flows and data flow for incremental data loads  Involved in automation of Jobs that perform Incremental load on a timely basis using lookups and data is delivered in the form of flat files to certain storage points  Used Configuration files for changing variables easily  Worked with SSIS package event handlers property expressions  Designed the production rollout strategy and migration of assets from environment to environment  Implemented data integrity procedures and logics  Assessed requirement and defined the strategy technical architecture implemented plans and delivery of a data warehouse  Made the SSIS code changes depending on the business requirement deployed the changes SSIS packages and propagated them into different environments  Worked on encryption of the file set using PGP and GPG  Designed SSIS packages to send the encrypted file to different vendors using winSCP  Designed SSIS Packages to shrink backup encrypt databases  Designed SSIS packages to copy data from historical Server IBM to SQL server 2008 using liked servers and open queries  Designed SSIS packages to populate data into ListSelect database for the reporting team  Implemented Audit tasks tables in the databases to maintain logs for the SQL Server Agent jobs  Implemented Full loads once a week and Incremental loads daily in schedules  Created new Views Synonyms Stored Procedures Functions and Triggers to accomplish the changes in the requirement  Successfully fixed the errors in the SSIS packages and was able to rerun the jobs from the checkpoint files  Worked on different kinds of Transformations like Import Column Export Column Lookups Derived Column Merge Join Fuzzy Lookup ForLoop ForEachLoop Conditional Split Union all Script component in SSIS as per the clients Requirement  Implemented the changes depending on the new releases into data warehouse adding new columns changes in the data types of the columns new tables etc  Optimized the loads by adding Indexes wherever needed dropped and recreated indexes while doing the full loads  Used Update and Merge statements while working on the Incremental loads  Maintained the SQL Server Agent jobs to run depending on the requirement          Education and Training        Expected in   DEC 2009   Masters of Science       Computer science Computer Science and Electrical Engineering    State University Of New York     New Paltz     NY      GPA       Computer science 337 Computer Science and Electrical Engineering Created a parallel parking simulator using a scribbler robot and Python language via Bluetooth Princeton College of Engineering and Technology JNTU Hyderabad Andhra Pradesh INDIA          Expected in   MAY 2008   Bachelors           Atomic Energy Central School     Hyderabad           GPA       on Electrical and communication  Scored 6767  Participated in Crime Scene investigation workshop help during Shaastra 06 IIT Madras Built a street light timing simulator with a group of 4 as my final year project from Wine Yard Technologies Kakaitya Academy BIE Hyderabad Andhra Pradesh INDIA Intermediate in Mathematics physics and chemistry MPC Scored First division 764          Expected in      Class X           Central Board of Secondary Education CBSE                GPA       Scored 656         Skills     Active Directory GoLive automation backup C C charts chemistry concept encryption client clients Data conversion Data migration data validation data warehouse Data warehouses databases Database Data warehousing delivery ETL fetch Ftp IBM DB2 logic Managing Mathematics access MS Excel windows migration MYSQL communicator OLE DB page physics presenting progress Python QA reporting Requirement Requirements analysis sales SAP Selfstarter servers shell scripts Script Microsoft SQL server SQL SQL Server strategy tables Team player TSQL web page Workbench|none
Data Engineer|https://www.livecareer.com/resume-search/r/data-dictionary-analyst-1beed068903f41a19100e8de6c5bb495|164611178195860836193375889079593369238|Jessica    Claire               Montgomery Street       San Francisco     CA  94105    609 Johnson Ave       49204     Tulsa     OK      Home   555 4321000        Cell           resumesampleexamplecom                  Professional Summary     Experienced Information Technology professional Key strengths include but not limited to systems support in health data management business analysis quality assurance and functional testing ability to manage multiple projects simultaneously adapt to process procedures and implementation to client specification excellent communication critical thinking investigative  problem resolution strategies exceeding customer expectations       Education and Training      Expected in        Master of Information Technology MBA          American Intercontinental University      Dunwoody     GA     GPA               Expected in        Bachelor of Science BS          Long Island University  CW Post      Brookville     NY     GPA               Accomplishments       Building Coordinator  Office of Quality  Safety  Emory Healthcare Reports Management Committee  Administrative Offices  Emory Healthcare Advisory Board  Administrative Offices  Emory Healthcare Epsilon Pi Tau   Delta Delta Chapter  American Intercontinental University Spotlight Award Winner  Specialty Brands  MCIVerizon Business         Skill Highlights           Experience in all phases of the System Development Life Cycle for enterprise application implementations  Experience with application level support for multifunctional end user expertise in clinical data management  Experience in project management methodology effective independently or in a team environment  Knowledge of information security concepts cryptography incident response policyaudit and threat analysis  Knowledge of security Firewalls IDSIPS PKI TCPIP Operating Systems LANWAN and the OSI Model  Knowledge of HIPPASOXPCI compliance standards and Management of Information Systems Access CoordinatorEnterprise applications Safety  ComplianceRisk mitigation and Disaster Response  System Administrator United Health Care Optum Cloud Availity CIGNA Humana and BCBS Payer Websites  ICD9CPT4 coding systems Access Blue Care Medic Claim Logic EDI Comtec EPIC Health Quest  IDXGE Centricity Business I Suite Power Chart and Microsoft Office Suite software applications  Lawson Lotus Notes Micro Strategy data warehouseFPSC webbased reporting database applications  Cryptography Concepts Computer Forensics Computer NetworkingTCPIP Information Security Principles  JAVA Programming ORACLEdb10g OPNET IT Guru Windows OS UNIXLinux OS                         Professional Experience      012004   to   Present     Data Dictionary Analyst      Global Indemnity Limited    –    Scottsdale     AZ             Perform system administration business analysis and maintenance of healthfinancial Database Dictionaries for internalexternal clinicalbusiness units Query webbased research toolssystem modules for data integrity and operations compliance maintain finance charge master manage security setupaccess control to billing interfaces for end users SME for Electronic Data Interchangesystem configurations for revenue cycle optimization  Accomplishments Executed billing application configurations for ICD10 implementation for CPT code compliance Instrumental in transitioning encounter based charge capture to electronic formats for provider services Maintained access managementsecurity to secure payer web portals for enterprise of 10000 end users Subject matter expert for GE Centricity Business implementation increased database integrity by 95 Designed testing scripts executed testing in Enterprise Dictionaries for system buildoperational validation Developed technical documentation of department process improvement initiatives for application support Audited EDI system code logic English translation improved data transparencyecommerce AR by 25          011999   to   012004     Operations Analyst III      DERRICK FROST MCIVerizon    –    City     STATE             Senior member of the marketing operations team administered audits controls reporting and coordinated account setup Maintained EDIecommerce PINCard order process utilizing EPICLawson and WebO interface applications for logistics with West coast Hub maintained weekly quality assurance reporting providing a snapshot of metrics in operational efficiency Accomplishments Project managed web based product catalogue portal Tracked all custom and branded applications in one repository Achieved 98 service level compliance in salesmarketing of product imaging merchandising plans and account setup Executed audits of inventory practices that led to a twoday reduction in sales to fulfillment rates          Skills     billing business analysis Computer Networking CPT4 CPT Cryptography data management data warehouse database applications Database ecommerce Electronic Data Interchange EDI English finance financial Firewalls Hub ICD10 IDS imaging Information Security Information Systems inventory JAVA Programming LAN Lawson Linux OS Logic logistics Lotus Notes marketing merchandising Access Microsoft Office Suite Windows OS 98 Micro Strategy Enterprise Operating Systems optimization OSI PCI process improvement marketing of product coding project management quality assurance Quest reporting research Safety sales scripts System Administrator system administration TCPIP TECHNICAL TRAINING technical documentation translation UNIX validation Websites WAN|none
Data Engineer|https://www.livecareer.com/resume-search/r/data-analyst-1d5c0e96b48d4a65b163501a6a6adfb1|17155897641748297909372247622701130843|Jessica    Claire               Montgomery Street       San Francisco     CA  94105    609 Johnson Ave       49204     Tulsa     OK      Home   555 4321000        Cell           resumesampleexamplecom                  Professional Summary     5  years of experience on Database development and administration knowledge of relational database on SQL Server particularly on SSMS SSRS SSIS TransactSQL and SQL Server Agent Extensive exposure to creation of Database Objects Stored Procedures Triggers Views User Defined Functions and Cursors       Core Qualifications           SQL  Server Tools          SQL Server Management Studio SSMS  Data Warehouse Tools          MS SQL Server 200520082012 Integration Services  Business Intelligence Tools        SQL Server 200520082012 Business Intelligence Development Studio  Programming Languages	     TSQL  Reporting Tools          SQL Server 200520082012 Reporting Services  Development Environment        Visual Studio 200520082012  Operating Systems	         Windows XP20032008 Server Win 3x9598 Vista Win 7  Advanced Excel          Vlookup Subtotal Pivot table and Chart                         Experience      112014   to   Current     Data Analyst      Liberty Healthcare Corporation    –         OK             Experience in Constraints rules and default setting Primary Foreign Unique and Default Key  Developed Joins and SubQueries to simplify complex queries involving multiple tables  Experienced in using temporary tables table variables common table expression CTE to enhance optimized SQL queries form improved performance of queries  Experience in crating and updating Clustered and NonClustered Indexes to keep up the SQL Server Performance  Well versed in Normalization DeNormalization techniques both in OLTP and OLAP system  Experienced in using Try catch block introduced in SQL Server 2005 and error handling  Great deal of experience on authoring managing and deploying ad hoc enterprise advance and interactive reports using SQL Server Reporting Servers  Expert in Data Extraction Transforming and Loading ETL using various tools such as SSIS DTS Bulk Insert data cleansing and profiling  Well experienced using different transformations tools like Aggregate Cache Transformation Conditional split Copy columns Sort column Data conversion Derived column Merge Merge join Union all Import and Export columns and OLE DB command  Data Extraction form OLE DB server encrypt and compressed with the TF PGP and TF compression task to the remote server location and FTP Server on the CSV format  Implementation of point in time backup and recovery of databases executing package scheduling and managing jobs on SQL Server Agent and maintain good documentation  Managed and maintained users security and permissions and migration database objects form one server to another server database to another database  Exposure to Business Analysis and requirements gathering in Business and Health Care Domains mainly on HIPAA  Knowledge of complete Software Development Life Cycle and work experience in Agile and environment  Strong research analytical coordination interaction skills team player and able to quickly grasp new technologies and products          092012   to   102014     Data Analyst SQL Server DeveloperSSISSSRS      EBS    –                      EBSEthiopian Broad Casting Service aims to promote Ethiopian and African countries values Cultures and traditions on a global scale  The muchneeded information provided by EBS would  Help bridge the cultural divide and narrow the communication gap for Ethiopians residing in  North America and around and world  Involved in gathering business requirements  Installation and configuration of SQL Server  Created database tables wrote stored procedures for developers and users  Created SQL scripts and defined functions check constraints indexes and views  Created triggers to enforce data and referential integrity  Create new SSIS package 2008R2 to extract date from legacy to SQL Server objects  Extensively used SSMS and SSIS ImportExport system for performing ETL operations  Performed data conversion from fat file and excel in to a normalized database structure  Configured Server for sending automatic mails  Developed monitored and deployed SSIS packages 2008R2  Installation and configuration of reporting server  Generated Snapshot Drill Down and parameterized reports using SSRS Prepared Adhoc reports through report builders and published through Report Manager Design and created different types of reports like Sub Reports DrillThrough Cascading Drill Down adhoc Reports in visual Studio and deploy and manage on Microsoft SQL Server Reporting Services Configuration Manager  Ethiopian Magical Farm PLC Jessica Ababa Ethiopia          022010   to   072012     SQL ETL DeveloperSSISSSRS          –                      Responsibility Designed and developed the databases  Created store procedures views and tables and generated TSQL script for application  Business Intelligence Development Studio BIDS to create edit and deploy SSRS and SSIS  Designed deployed and maintained of various SSRS Reports in SQL Server 2008R2  Created ETL packages using SSIS to extract data from relational database and then transform and load in to the database  Developed deployed and monitored SSIS packages including upgrades DTS to SSIS  Developed executed documented and maintained appropriate BI procedures  Collaborated with network operators application developers and DBAs to enhance end user experience  Scheduling Jobs and Alerting using SQL Server Agent          Education      Expected in        BSc Degree     Information Science     Admas University                GPA       Information Science        Professional Affiliations              Skills     Ad Agile aims automate backup Business Analysis BI Business Intelligence business management Hardware data collection Data conversion Data migration data modeling DTS data warehouse databases database delivery documentation edit ETL fat FTP logic managing Access MS Excel excel Excel          V Microsoft SQL Win 7 Win 3x 9598 Windows XP migration enterprise network OLAP OLE Operating Systems DB Pivot table PLC Programming quality relational database reporting requirement requirements gathering research Scheduling Servers scripts script Software Development sorting MS SQL Server Microsoft SQL Server SQL SQL  Server SQL Server tables team player TSQL TSQL translating Unique upgrades Vista Visual Studio|none
Data Engineer|https://www.livecareer.com/resume-search/r/data-scientist-consultant-26d8093a10f14c83bb8218b443e4f969|190995324271360738531549311082018797149|Jessica    Claire                      San Francisco     CA  94105    609 Johnson Ave       49204     Tulsa     OK      Home   555 4321000        Cell           resumesampleexamplecom                  Professional Summary     Data scientist with 1 years of experience in deClairevering datadriven insights in large data management enterprise fastpaced hedge fund and media entertainment conglomerate passionate and skilled at solving business problems with machine learning models and data analytics       Skills           Regression GLM Ridge Lasso KNN  Classification Logistic Regression Decision Trees Random Forest XGB SVM NaiveBayes  Clustering KMeans Hierarchical DBSCAN  Statistics  AB Testing Hypothesis Testing Bayesian Inference ProbabiClairety  Programming  Python SQL R Hive Spark Git Scala Java      Ad  Automate  Clustering  Credit  CRM  ETL  Java  Marketing  ModeClaireng  Predict  Programming  Promotion  Python  QuaClairety  Sales  SQL  Statistics  VaClairedation                       Work History      092019   to   Current     Data Scientist Consultant      Deloitte    –    San Juan     PR             Implemented and deployed marketing propensity model using XGBoost for customer acquisition on upcoming movies identified top 70 firsttime purchasers with highest product interest scores  Constructed adhoc SQL queries and performed AB test for quantifying retention and churn campaign promotion upClairefts collaborated with CRM teams to identify key metrics and evaluate testing results  Designed and developed ETL process using SQL and R to automate data vaClairedation process for identifying and tracking data quaClairety issues  Created user defined function using Kmeans in Snowflake warehouse to segment customer by user behavior and demographic information  Developed and pubClaireshed several interactive and scalable Rshiny visuaClairezation dashboards to increase visibiClairety on various KPIs          062019   to   082019     Data Scientist Intern      Ascend Learning    –    Nashua     NH             Identified and analyzed problems of cascade effect and data misrepresentation when using credit card transaction to predict companies’ sales provided solutions that reduced outofsample MAE error by 75  Partnered with investment team from different sectors to increase size of modeClaireng data using clustering sampClaireng and rule based method effectively improved data reClaireabiClairety and reduced geobias from various alternative data sources          052018   to   092018     Data Scientist Intern          –    Orlando     FL             Designed developed and deployed automated streamClairened procedure in Python for parsing test performance data and building visuaClairezation platform using Pyplot and Tableau for multiple drive performance comparison improving tasks efficiency by 30  UtiClairezed Hive platform to develop an automated pipeClairene for data query cleaning and transformation          Education      Expected in   052019     Master of Science     Statistical Science     Duke University      Durham     NC     GPA       GPA 37        Expected in   082016     Bachelor of Arts          University Of CaClairefornia Berkeley      Berkeley     CA     GPA       GPA 392        Work History      092019   to   Current     Data Scientist Consultant       Warner Bros Entertainment Inc Insight Global and Horkus Solutions   –   Burbank     CA      Implemented and deployed marketing propensity model using XGBoost for customer acquisition on upcoming movies identified top 70 firsttime purchasers with highest product interest scores  Constructed adhoc SQL queries and performed AB test for quantifying retention and churn campaign promotion upClairefts collaborated with CRM teams to identify key metrics and evaluate testing results  Designed and developed ETL process using SQL and R to automate data vaClairedation process for identifying and tracking data quaClairety issues  Created user defined function using Kmeans in Snowflake warehouse to segment customer by user behavior and demographic information  Developed and pubClaireshed several interactive and scalable Rshiny visuaClairezation dashboards to increase visibiClairety on various KPIs          062019   to   082019     Data Scientist Intern       Point72 Asset Management LP   –   New York     NY      Identified and analyzed problems of cascade effect and data misrepresentation when using credit card transaction to predict companies’ sales provided solutions that reduced outofsample MAE error by 75  Partnered with investment team from different sectors to increase size of modeClaireng data using clustering sampClaireng and rule based method effectively improved data reClaireabiClairety and reduced geobias from various alternative data sources          052018   to   092018     Data Scientist Intern          –   Sunnyvale     CA      Designed developed and deployed automated streamClairened procedure in Python for parsing test performance data and building visuaClairezation platform using Pyplot and Tableau for multiple drive performance comparison improving tasks efficiency by 30  UtiClairezed Hive platform to develop an automated pipeClairene for data query cleaning and transformation          Skills      Regression GLM Ridge Lasso KNN  Classification Logistic Regression Decision Trees Random Forest XGB SVM NaiveBayes  Clustering KMeans Hierarchical DBSCAN  Statistics  AB Testing Hypothesis Testing Bayesian Inference ProbabiClairety  Programming  Python SQL R Hive Spark Git Scala Java  Ad automate Clustering credit CRM ETL Java marketing modeClaireng predict Programming promotion Python quaClairety sales SQL Statistics vaClairedation|none
Data Engineer|https://www.livecareer.com/resume-search/r/data-center-operations-assembler-25c66e22758c464c9c790e6de8203e29|202867358446938731459558786091626273121|JC     Jessica    Claire                      Montgomery Street       San Francisco     CA    94105             555 4321000                 resumesampleexamplecom                         Summary      Analytical  Networking Technician  adept at resolving complex network issues Critical thinker who addresses technical issues quickly and who consistently exceeds performance standards         Highlights           Excellent quantitative and analytical skills  Ability to work independently with limited required direction and guidance    Computer proficient    Bilingual  English and Spanish       Process improvements  Training and development  Strategic planning  Equipment Maintenance                       Experience        032015   to   Current   Data Center Operations Assembler    Vital Smiles         Greenwood     SC            Top performer in installation maintenance and troubleshooting of new servers  Run install  and troubleshoot ethernet and fiber optic per defined process  Assembledisassemble and populatedepopulate equipment racks   Installation of new switches routers and networking gear   Demonstrate excellent mechanical knowledge of machines and tools including use repair and maintenance                           062012   to   032015   Orthodontic Assistant    First Midwest Bank         Genoa     IL             Prepared patients for dental examinations     Properly sterilized dental equipment and examination rooms in accordance with infection control policies     Effectively operated xray machines and developed xrays    Coordinated appointment schedules for both the dentist and oral surgeon     Routinely completed inventory supply orders and restocked supplies       Made preliminary impressions for study casts and occlusal registrations for mounting study casts                    ​            082009   to   072012   Teller    Bank Of America         City     STATE            Provided excellent customer service to clients by receiving and processing personal and business transactions such as general deposits withdrawals loan payments and monetary instrument sales   Maintained confidentiality of bank records and client information      Processed sales referrals and promoted bank services and products    Built customer loyalty     Received regional branch recognition award for outstanding customer service              052006   to   082009   AuditorQuality Assurance Analyst    TCIM         City     STATE               Audited the Customer service Representatives and performance monitoring elements to assess effectiveness  Worked with the QA Manager to develop implement monitor and manage the company’s compliance with internal control requirements    Provides mentoring training and development to customer service representatives as needed          Education        Expected in   2012   Associate of Science           Tulsa Community College     Tulsa     OK      GPA                 Expected in   2006   High School Diploma           Central High School     Tulsa     OK      GPA|none
